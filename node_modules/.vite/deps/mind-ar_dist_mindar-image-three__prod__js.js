import {
  Group,
  Matrix4,
  PerspectiveCamera,
  Quaternion,
  Scene,
  Vector3,
  WebGLRenderer,
  sRGBEncoding
} from "./chunk-6TW3OHB4.js";
import {
  __commonJS
} from "./chunk-IVLCYF2H.js";

// node_modules/node-fetch/browser.js
var require_browser = __commonJS({
  "node_modules/node-fetch/browser.js"(exports, module) {
    "use strict";
    var getGlobal = function() {
      if (typeof self !== "undefined") {
        return self;
      }
      if (typeof window !== "undefined") {
        return window;
      }
      if (typeof global !== "undefined") {
        return global;
      }
      throw new Error("unable to locate global object");
    };
    var globalObject = getGlobal();
    module.exports = exports = globalObject.fetch;
    if (globalObject.fetch) {
      exports.default = globalObject.fetch.bind(globalObject);
    }
    exports.Headers = globalObject.Headers;
    exports.Request = globalObject.Request;
    exports.Response = globalObject.Response;
  }
});

// browser-external:util
var require_util = __commonJS({
  "browser-external:util"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_6, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "util" has been externalized for browser compatibility. Cannot access "util.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:buffer
var require_buffer = __commonJS({
  "browser-external:buffer"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_6, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "buffer" has been externalized for browser compatibility. Cannot access "buffer.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// node_modules/safe-buffer/index.js
var require_safe_buffer = __commonJS({
  "node_modules/safe-buffer/index.js"(exports, module) {
    var buffer = require_buffer();
    var Buffer2 = buffer.Buffer;
    function copyProps(src, dst) {
      for (var key in src) {
        dst[key] = src[key];
      }
    }
    if (Buffer2.from && Buffer2.alloc && Buffer2.allocUnsafe && Buffer2.allocUnsafeSlow) {
      module.exports = buffer;
    } else {
      copyProps(buffer, exports);
      exports.Buffer = SafeBuffer;
    }
    function SafeBuffer(arg, encodingOrOffset, length) {
      return Buffer2(arg, encodingOrOffset, length);
    }
    SafeBuffer.prototype = Object.create(Buffer2.prototype);
    copyProps(Buffer2, SafeBuffer);
    SafeBuffer.from = function(arg, encodingOrOffset, length) {
      if (typeof arg === "number") {
        throw new TypeError("Argument must not be a number");
      }
      return Buffer2(arg, encodingOrOffset, length);
    };
    SafeBuffer.alloc = function(size, fill, encoding) {
      if (typeof size !== "number") {
        throw new TypeError("Argument must be a number");
      }
      var buf = Buffer2(size);
      if (fill !== void 0) {
        if (typeof encoding === "string") {
          buf.fill(fill, encoding);
        } else {
          buf.fill(fill);
        }
      } else {
        buf.fill(0);
      }
      return buf;
    };
    SafeBuffer.allocUnsafe = function(size) {
      if (typeof size !== "number") {
        throw new TypeError("Argument must be a number");
      }
      return Buffer2(size);
    };
    SafeBuffer.allocUnsafeSlow = function(size) {
      if (typeof size !== "number") {
        throw new TypeError("Argument must be a number");
      }
      return buffer.SlowBuffer(size);
    };
  }
});

// node_modules/string_decoder/lib/string_decoder.js
var require_string_decoder = __commonJS({
  "node_modules/string_decoder/lib/string_decoder.js"(exports) {
    "use strict";
    var Buffer2 = require_safe_buffer().Buffer;
    var isEncoding = Buffer2.isEncoding || function(encoding) {
      encoding = "" + encoding;
      switch (encoding && encoding.toLowerCase()) {
        case "hex":
        case "utf8":
        case "utf-8":
        case "ascii":
        case "binary":
        case "base64":
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
        case "raw":
          return true;
        default:
          return false;
      }
    };
    function _normalizeEncoding(enc) {
      if (!enc)
        return "utf8";
      var retried;
      while (true) {
        switch (enc) {
          case "utf8":
          case "utf-8":
            return "utf8";
          case "ucs2":
          case "ucs-2":
          case "utf16le":
          case "utf-16le":
            return "utf16le";
          case "latin1":
          case "binary":
            return "latin1";
          case "base64":
          case "ascii":
          case "hex":
            return enc;
          default:
            if (retried)
              return;
            enc = ("" + enc).toLowerCase();
            retried = true;
        }
      }
    }
    function normalizeEncoding(enc) {
      var nenc = _normalizeEncoding(enc);
      if (typeof nenc !== "string" && (Buffer2.isEncoding === isEncoding || !isEncoding(enc)))
        throw new Error("Unknown encoding: " + enc);
      return nenc || enc;
    }
    exports.StringDecoder = StringDecoder;
    function StringDecoder(encoding) {
      this.encoding = normalizeEncoding(encoding);
      var nb3;
      switch (this.encoding) {
        case "utf16le":
          this.text = utf16Text;
          this.end = utf16End;
          nb3 = 4;
          break;
        case "utf8":
          this.fillLast = utf8FillLast;
          nb3 = 4;
          break;
        case "base64":
          this.text = base64Text;
          this.end = base64End;
          nb3 = 3;
          break;
        default:
          this.write = simpleWrite;
          this.end = simpleEnd;
          return;
      }
      this.lastNeed = 0;
      this.lastTotal = 0;
      this.lastChar = Buffer2.allocUnsafe(nb3);
    }
    StringDecoder.prototype.write = function(buf) {
      if (buf.length === 0)
        return "";
      var r;
      var i6;
      if (this.lastNeed) {
        r = this.fillLast(buf);
        if (r === void 0)
          return "";
        i6 = this.lastNeed;
        this.lastNeed = 0;
      } else {
        i6 = 0;
      }
      if (i6 < buf.length)
        return r ? r + this.text(buf, i6) : this.text(buf, i6);
      return r || "";
    };
    StringDecoder.prototype.end = utf8End;
    StringDecoder.prototype.text = utf8Text;
    StringDecoder.prototype.fillLast = function(buf) {
      if (this.lastNeed <= buf.length) {
        buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
        return this.lastChar.toString(this.encoding, 0, this.lastTotal);
      }
      buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
      this.lastNeed -= buf.length;
    };
    function utf8CheckByte(byte) {
      if (byte <= 127)
        return 0;
      else if (byte >> 5 === 6)
        return 2;
      else if (byte >> 4 === 14)
        return 3;
      else if (byte >> 3 === 30)
        return 4;
      return byte >> 6 === 2 ? -1 : -2;
    }
    function utf8CheckIncomplete(self2, buf, i6) {
      var j = buf.length - 1;
      if (j < i6)
        return 0;
      var nb3 = utf8CheckByte(buf[j]);
      if (nb3 >= 0) {
        if (nb3 > 0)
          self2.lastNeed = nb3 - 1;
        return nb3;
      }
      if (--j < i6 || nb3 === -2)
        return 0;
      nb3 = utf8CheckByte(buf[j]);
      if (nb3 >= 0) {
        if (nb3 > 0)
          self2.lastNeed = nb3 - 2;
        return nb3;
      }
      if (--j < i6 || nb3 === -2)
        return 0;
      nb3 = utf8CheckByte(buf[j]);
      if (nb3 >= 0) {
        if (nb3 > 0) {
          if (nb3 === 2)
            nb3 = 0;
          else
            self2.lastNeed = nb3 - 3;
        }
        return nb3;
      }
      return 0;
    }
    function utf8CheckExtraBytes(self2, buf, p6) {
      if ((buf[0] & 192) !== 128) {
        self2.lastNeed = 0;
        return "�";
      }
      if (self2.lastNeed > 1 && buf.length > 1) {
        if ((buf[1] & 192) !== 128) {
          self2.lastNeed = 1;
          return "�";
        }
        if (self2.lastNeed > 2 && buf.length > 2) {
          if ((buf[2] & 192) !== 128) {
            self2.lastNeed = 2;
            return "�";
          }
        }
      }
    }
    function utf8FillLast(buf) {
      var p6 = this.lastTotal - this.lastNeed;
      var r = utf8CheckExtraBytes(this, buf, p6);
      if (r !== void 0)
        return r;
      if (this.lastNeed <= buf.length) {
        buf.copy(this.lastChar, p6, 0, this.lastNeed);
        return this.lastChar.toString(this.encoding, 0, this.lastTotal);
      }
      buf.copy(this.lastChar, p6, 0, buf.length);
      this.lastNeed -= buf.length;
    }
    function utf8Text(buf, i6) {
      var total = utf8CheckIncomplete(this, buf, i6);
      if (!this.lastNeed)
        return buf.toString("utf8", i6);
      this.lastTotal = total;
      var end = buf.length - (total - this.lastNeed);
      buf.copy(this.lastChar, 0, end);
      return buf.toString("utf8", i6, end);
    }
    function utf8End(buf) {
      var r = buf && buf.length ? this.write(buf) : "";
      if (this.lastNeed)
        return r + "�";
      return r;
    }
    function utf16Text(buf, i6) {
      if ((buf.length - i6) % 2 === 0) {
        var r = buf.toString("utf16le", i6);
        if (r) {
          var c = r.charCodeAt(r.length - 1);
          if (c >= 55296 && c <= 56319) {
            this.lastNeed = 2;
            this.lastTotal = 4;
            this.lastChar[0] = buf[buf.length - 2];
            this.lastChar[1] = buf[buf.length - 1];
            return r.slice(0, -1);
          }
        }
        return r;
      }
      this.lastNeed = 1;
      this.lastTotal = 2;
      this.lastChar[0] = buf[buf.length - 1];
      return buf.toString("utf16le", i6, buf.length - 1);
    }
    function utf16End(buf) {
      var r = buf && buf.length ? this.write(buf) : "";
      if (this.lastNeed) {
        var end = this.lastTotal - this.lastNeed;
        return r + this.lastChar.toString("utf16le", 0, end);
      }
      return r;
    }
    function base64Text(buf, i6) {
      var n = (buf.length - i6) % 3;
      if (n === 0)
        return buf.toString("base64", i6);
      this.lastNeed = 3 - n;
      this.lastTotal = 3;
      if (n === 1) {
        this.lastChar[0] = buf[buf.length - 1];
      } else {
        this.lastChar[0] = buf[buf.length - 2];
        this.lastChar[1] = buf[buf.length - 1];
      }
      return buf.toString("base64", i6, buf.length - n);
    }
    function base64End(buf) {
      var r = buf && buf.length ? this.write(buf) : "";
      if (this.lastNeed)
        return r + this.lastChar.toString("base64", 0, 3 - this.lastNeed);
      return r;
    }
    function simpleWrite(buf) {
      return buf.toString(this.encoding);
    }
    function simpleEnd(buf) {
      return buf && buf.length ? this.write(buf) : "";
    }
  }
});

// browser-external:fs
var require_fs = __commonJS({
  "browser-external:fs"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_6, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "fs" has been externalized for browser compatibility. Cannot access "fs.${key}" in client code. See http://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// node_modules/mind-ar/dist/ui-85e81035.js
var x = typeof globalThis < "u" ? globalThis : typeof window < "u" ? window : typeof global < "u" ? global : typeof self < "u" ? self : {};
function M(n) {
  return n && n.__esModule && Object.prototype.hasOwnProperty.call(n, "default") ? n.default : n;
}
function w(n) {
  if (n.__esModule)
    return n;
  var t = n.default;
  if (typeof t == "function") {
    var i6 = function e() {
      if (this instanceof e) {
        var o = [null];
        o.push.apply(o, arguments);
        var s = Function.bind.apply(t, o);
        return new s();
      }
      return t.apply(this, arguments);
    };
    i6.prototype = t.prototype;
  } else
    i6 = {};
  return Object.defineProperty(i6, "__esModule", { value: true }), Object.keys(n).forEach(function(e) {
    var o = Object.getOwnPropertyDescriptor(n, e);
    Object.defineProperty(i6, e, o.get ? o : {
      enumerable: true,
      get: function() {
        return n[e];
      }
    });
  }), i6;
}
var h = (n, t) => {
  const i6 = 2 * Math.PI * t * n;
  return i6 / (i6 + 1);
};
var p = (n, t, i6) => n * t + (1 - n) * i6;
var P = class {
  constructor({ minCutOff: t, beta: i6 }) {
    this.minCutOff = t, this.beta = i6, this.dCutOff = 1e-3, this.xPrev = null, this.dxPrev = null, this.tPrev = null, this.initialized = false;
  }
  reset() {
    this.initialized = false;
  }
  filter(t, i6) {
    if (!this.initialized)
      return this.initialized = true, this.xPrev = i6, this.dxPrev = i6.map(() => 0), this.tPrev = t, i6;
    const { xPrev: e, tPrev: o, dxPrev: s } = this, r = t - o, u = h(r, this.dCutOff), c = [], d = [], l = [];
    for (let a = 0; a < i6.length; a++) {
      c[a] = (i6[a] - e[a]) / r, d[a] = p(u, c[a], s[a]);
      const m = this.minCutOff + this.beta * Math.abs(d[a]), f = h(r, m);
      l[a] = p(f, i6[a], e[a]);
    }
    return this.xPrev = l, this.dxPrev = d, this.tPrev = t, l;
  }
};
var g = `<div class="mindar-ui-overlay mindar-ui-loading">
  <div class="loader"/>
</div>
`;
var v = `<div class="mindar-ui-overlay mindar-ui-compatibility">
  <div class="content">
    <h1>Failed to launch :(</h1>
    <p>
      Looks like your device/browser is not compatible.
    </p>

    <br/>
    <br/>
    <p>
      Please try the following recommended browsers:
    </p>
    <p>
      For Android device - Chrome
    </p>
    <p>
      For iOS device - Safari
    </p>
  </div>
</div>
`;
var y = `<div class="mindar-ui-overlay mindar-ui-scanning">
  <div class="scanning">
    <div class="inner">
      <div class="scanline"/>
    </div>
  </div>
</div>
`;
var b = ".mindar-ui-overlay{display:flex;align-items:center;justify-content:center;position:absolute;left:0;right:0;top:0;bottom:0;background:transparent;z-index:2}.mindar-ui-overlay.hidden{display:none}.mindar-ui-loading .loader{border:16px solid #222;border-top:16px solid white;opacity:.8;border-radius:50%;width:120px;height:120px;animation:spin 2s linear infinite}@keyframes spin{0%{transform:rotate(0)}to{transform:rotate(360deg)}}.mindar-ui-compatibility .content{background:black;color:#fff;opacity:.8;text-align:center;margin:20px;padding:20px;min-height:50vh}@media (min-aspect-ratio: 1/1){.mindar-ui-scanning .scanning{width:50vh;height:50vh}}@media (max-aspect-ratio: 1/1){.mindar-ui-scanning .scanning{width:80vw;height:80vw}}.mindar-ui-scanning .scanning .inner{position:relative;width:100%;height:100%;opacity:.8;background:linear-gradient(to right,white 10px,transparent 10px) 0 0,linear-gradient(to right,white 10px,transparent 10px) 0 100%,linear-gradient(to left,white 10px,transparent 10px) 100% 0,linear-gradient(to left,white 10px,transparent 10px) 100% 100%,linear-gradient(to bottom,white 10px,transparent 10px) 0 0,linear-gradient(to bottom,white 10px,transparent 10px) 100% 0,linear-gradient(to top,white 10px,transparent 10px) 0 100%,linear-gradient(to top,white 10px,transparent 10px) 100% 100%;background-repeat:no-repeat;background-size:40px 40px}.mindar-ui-scanning .scanning .inner .scanline{position:absolute;width:100%;height:10px;background:white;animation:move 2s linear infinite}@keyframes move{0%,to{top:0%}50%{top:calc(100% - 10px)}}";
var k = class {
  constructor({ uiLoading: t, uiScanning: i6, uiError: e }) {
    const o = document.createElement("style");
    o.innerText = b, document.head.appendChild(o), t === "yes" ? this.loadingModal = this._loadHTML(g) : t !== "no" && (this.loadingModal = document.querySelector(t)), e === "yes" ? this.compatibilityModal = this._loadHTML(v) : e !== "no" && (this.compatibilityModal = document.querySelector(e)), i6 === "yes" ? this.scanningMask = this._loadHTML(y) : i6 !== "no" && (this.scanningMask = document.querySelector(i6)), this.hideLoading(), this.hideCompatibility(), this.hideScanning();
  }
  showLoading() {
    this.loadingModal && this.loadingModal.classList.remove("hidden");
  }
  hideLoading() {
    this.loadingModal && this.loadingModal.classList.add("hidden");
  }
  showCompatibility() {
    this.compatibilityModal && this.compatibilityModal.classList.remove("hidden");
  }
  hideCompatibility() {
    this.compatibilityModal && this.compatibilityModal.classList.add("hidden");
  }
  showScanning() {
    this.scanningMask && this.scanningMask.classList.remove("hidden");
  }
  hideScanning() {
    this.scanningMask && this.scanningMask.classList.add("hidden");
  }
  _loadHTML(t) {
    const i6 = document.createElement("template");
    i6.innerHTML = t.trim();
    const e = i6.content.firstChild;
    return document.getElementsByTagName("body")[0].appendChild(e), e;
  }
};

// node_modules/mind-ar/dist/controller-495b585f.js
function GI(n, t) {
  for (var e = 0; e < t.length; e++) {
    const s = t[e];
    if (typeof s != "string" && !Array.isArray(s)) {
      for (const o in s)
        if (o !== "default" && !(o in n)) {
          const r = Object.getOwnPropertyDescriptor(s, o);
          r && Object.defineProperty(n, o, r.get ? r : {
            enumerable: true,
            get: () => s[o]
          });
        }
    }
  }
  return Object.freeze(Object.defineProperty(n, Symbol.toStringTag, { value: "Module" }));
}
var EI = 1e-7;
var LI = 1e-4;
var Mg = class {
  constructor(t, e) {
    this.backend = t, this.dataMover = e, this.data = /* @__PURE__ */ new WeakMap(), this.dataIdsCount = 0;
  }
  get(t) {
    return this.data.has(t) || this.dataMover.moveData(this.backend, t), this.data.get(t);
  }
  set(t, e) {
    this.dataIdsCount++, this.data.set(t, e);
  }
  has(t) {
    return this.data.has(t);
  }
  delete(t) {
    return this.dataIdsCount--, this.data.delete(t);
  }
  numDataIds() {
    return this.dataIdsCount;
  }
};
var Xd = class {
  refCount(t) {
    return _e("refCount");
  }
  incRef(t) {
    return _e("incRef");
  }
  timerAvailable() {
    return true;
  }
  time(t) {
    return _e("time");
  }
  read(t) {
    return _e("read");
  }
  readSync(t) {
    return _e("readSync");
  }
  readToGPU(t, e) {
    return _e("readToGPU");
  }
  numDataIds() {
    return _e("numDataIds");
  }
  disposeData(t, e) {
    return _e("disposeData");
  }
  write(t, e, s) {
    return _e("write");
  }
  move(t, e, s, o, r) {
    return _e("move");
  }
  createTensorFromGPUData(t, e, s) {
    return _e("createTensorFromGPUData");
  }
  memory() {
    return _e("memory");
  }
  /** Returns the highest precision for floats in bits (e.g. 16 or 32) */
  floatPrecision() {
    return _e("floatPrecision");
  }
  /** Returns the smallest representable number.  */
  epsilon() {
    return this.floatPrecision() === 32 ? EI : LI;
  }
  dispose() {
    return _e("dispose");
  }
};
function _e(n) {
  throw new Error(`'${n}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
}
function Pd(n) {
  let t = n.length, e = 0;
  for (; t > 0; )
    e = Math.random() * t | 0, t--, us(n, t, e);
}
function MI(n, t) {
  if (n.length !== t.length)
    throw new Error(`Array sizes must match to be shuffled together First array length was ${n.length}Second array length was ${t.length}`);
  let e = n.length, s = 0;
  for (; e > 0; )
    s = Math.random() * e | 0, e--, us(n, e, s), us(t, e, s);
}
function Fs(n, t, e) {
  return Math.max(n, Math.min(t, e));
}
function Wl(n) {
  return n % 2 === 0 ? n : n + 1;
}
function us(n, t, e) {
  const s = n[t];
  n[t] = n[e], n[e] = s;
}
function Wg(n) {
  let t = 0;
  for (let e = 0; e < n.length; e++)
    t += n[e];
  return t;
}
function WI(n, t) {
  const e = Math.random();
  return t * e + (1 - e) * n;
}
function DI(n, t) {
  let e = 0;
  for (let s = 0; s < n.length; s++) {
    const o = Number(n[s]) - Number(t[s]);
    e += o * o;
  }
  return e;
}
function v2(n, t) {
  if (!n)
    throw new Error(typeof t == "string" ? t : t());
}
function Ve(n, t, e = "") {
  v2(Rt(n, t), () => e + ` Shapes ${n} and ${t} must match`);
}
function Dl(n) {
  v2(n != null, () => "The input to the tensor constructor must be a non-null value.");
}
function O(n) {
  if (n.length === 0)
    return 1;
  let t = n[0];
  for (let e = 1; e < n.length; e++)
    t *= n[e];
  return t;
}
function FI(n) {
  return n.length === 0;
}
function Rt(n, t) {
  if (n === t)
    return true;
  if (n == null || t == null || n.length !== t.length)
    return false;
  for (let e = 0; e < n.length; e++)
    if (n[e] !== t[e])
      return false;
  return true;
}
function go(n) {
  return n % 1 === 0;
}
function VI(n) {
  if (Math.tanh != null)
    return Math.tanh(n);
  if (n === 1 / 0)
    return 1;
  if (n === -1 / 0)
    return -1;
  {
    const t = Math.exp(2 * n);
    return (t - 1) / (t + 1);
  }
}
function el(n) {
  const t = Math.ceil(Math.sqrt(n));
  return [t, Math.ceil(n / t)];
}
function zI(n) {
  const t = new Uint32Array(n);
  for (let e = 0; e < n; ++e)
    t[e] = e;
  return Pd(t), t;
}
function ho(n, t) {
  return t <= n.length ? n : n + " ".repeat(t - n.length);
}
function td(n, t = (o) => 0, e, s) {
  return new Promise((o, r) => {
    let i6 = 0;
    const a = () => {
      if (n()) {
        o();
        return;
      }
      i6++;
      const l = t(i6);
      if (e != null && i6 >= e) {
        r();
        return;
      }
      s != null ? s(a, l) : setTimeout(a, l);
    };
    a();
  });
}
function Ad(n, t) {
  let e = 1, s = -1;
  for (let r = 0; r < n.length; ++r)
    if (n[r] >= 0)
      e *= n[r];
    else if (n[r] === -1) {
      if (s !== -1)
        throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${s} and dim ${r}`);
      s = r;
    } else if (n[r] < 0)
      throw Error(`Shapes can not be < 0. Found ${n[r]} at dim ${r}`);
  if (s === -1) {
    if (t > 0 && t !== e)
      throw Error(`Size(${t}) must match the product of shape ${n}`);
    return n;
  }
  if (e === 0)
    throw Error(`Cannot infer the missing size in [${n}] when there are 0 elements`);
  if (t % e !== 0)
    throw Error(`The implicit shape can't be a fractional number. Got ${t} / ${e}`);
  const o = n.slice();
  return o[s] = t / e, o;
}
function Ct(n, t) {
  const e = t.length;
  return n = n == null ? t.map((s, o) => o) : [].concat(n), v2(n.every((s) => s >= -e && s < e), () => `All values in axis param must be in range [-${e}, ${e}) but got axis ${n}`), v2(n.every((s) => go(s)), () => `All values in axis param must be integers but got axis ${n}`), n.map((s) => s < 0 ? e + s : s);
}
function gs(n, t) {
  const e = [], s = [], o = t != null && Array.isArray(t) && t.length === 0, r = t == null || o ? null : Ct(t, n).sort();
  let i6 = 0;
  for (let a = 0; a < n.length; ++a) {
    if (r != null) {
      if (r[i6] === a && n[a] !== 1)
        throw new Error(`Can't squeeze axis ${a} since its dim '${n[a]}' is not 1`);
      (r[i6] == null || r[i6] > a) && n[a] === 1 && (e.push(n[a]), s.push(a)), r[i6] <= a && i6++;
    }
    n[a] !== 1 && (e.push(n[a]), s.push(a));
  }
  return { newShape: e, keptDims: s };
}
function xe(n, t) {
  let e = null;
  if (n == null || n === "float32")
    e = new Float32Array(t);
  else if (n === "int32")
    e = new Int32Array(t);
  else if (n === "bool")
    e = new Uint8Array(t);
  else
    throw new Error(`Unknown data type ${n}`);
  return e;
}
function oe(n, t) {
  let e = null;
  if (n == null || n === "float32")
    e = new Float32Array(t);
  else if (n === "int32")
    e = new Int32Array(t);
  else if (n === "bool")
    e = new Uint8Array(t);
  else if (n === "string")
    e = new Array(t);
  else
    throw new Error(`Unknown data type ${n}`);
  return e;
}
function Dg(n, t) {
  for (let e = 0; e < n.length; e++) {
    const s = n[e];
    if (isNaN(s) || !isFinite(s))
      throw Error(`A tensor of type ${t} being uploaded contains ${s}.`);
  }
}
function Fg(n) {
  return n === "bool" || n === "complex64" || n === "float32" || n === "int32" || n === "string";
}
function Od(n, t) {
  return !(t === "complex64" || t === "float32" && n !== "complex64" || t === "int32" && n !== "float32" && n !== "complex64" || t === "bool" && n === "bool");
}
function Ur(n) {
  if (n === "float32" || n === "int32")
    return 4;
  if (n === "complex64")
    return 8;
  if (n === "bool")
    return 1;
  throw new Error(`Unknown dtype ${n}`);
}
function Vg(n) {
  if (n == null)
    return 0;
  let t = 0;
  return n.forEach((e) => t += e.length), t;
}
function mr(n) {
  return typeof n == "string" || n instanceof String;
}
function zg(n) {
  return typeof n == "boolean";
}
function nl(n) {
  return typeof n == "number";
}
function gr(n) {
  return Array.isArray(n) ? gr(n[0]) : n instanceof Float32Array ? "float32" : n instanceof Int32Array || n instanceof Uint8Array || n instanceof Uint8ClampedArray ? "int32" : nl(n) ? "float32" : mr(n) ? "string" : zg(n) ? "bool" : "float32";
}
function Vs(n) {
  return !!(n && n.constructor && n.call && n.apply);
}
function sl(n, t) {
  for (let e = t; e < n; ++e)
    if (n % e === 0)
      return e;
  return n;
}
function dt(n) {
  const t = n.length;
  if (t < 2)
    return [];
  const e = new Array(t - 1);
  e[t - 2] = n[t - 1];
  for (let s = t - 3; s >= 0; --s)
    e[s] = e[s + 1] * n[s + 1];
  return e;
}
function Xg(n, t, e, s = false) {
  const o = new Array();
  if (t.length === 1) {
    const r = t[0] * (s ? 2 : 1);
    for (let i6 = 0; i6 < r; i6++)
      o[i6] = e[n + i6];
  } else {
    const r = t[0], i6 = t.slice(1), a = i6.reduce((l, c) => l * c) * (s ? 2 : 1);
    for (let l = 0; l < r; l++)
      o[l] = Xg(n + l * a, i6, e, s);
  }
  return o;
}
function Sn(n, t, e = false) {
  if (n.length === 0)
    return t[0];
  const s = n.reduce((o, r) => o * r) * (e ? 2 : 1);
  if (s === 0)
    return [];
  if (s !== t.length)
    throw new Error(`[${n}] does not match the input size ${t.length}${e ? " for a complex tensor" : ""}.`);
  return Xg(0, n, t, e);
}
function Pg(n, t) {
  if (Array.isArray(n))
    return n;
  if (t === "float32")
    return n instanceof Float32Array ? n : new Float32Array(n);
  if (t === "int32")
    return n instanceof Int32Array ? n : new Int32Array(n);
  if (t === "bool" || t === "string")
    return Uint8Array.from(new Int32Array(n));
  throw new Error(`Unknown dtype ${t}`);
}
function Fl(n, t) {
  const e = Se(n, t);
  for (let s = 0; s < e.length; s++)
    e[s] = 1;
  return e;
}
function Se(n, t) {
  if (t == null || t === "float32" || t === "complex64")
    return new Float32Array(n);
  if (t === "int32")
    return new Int32Array(n);
  if (t === "bool")
    return new Uint8Array(n);
  throw new Error(`Unknown data type ${t}`);
}
function Kd(n, t) {
  const e = n.reduce((s, o) => s * o, 1);
  if (t == null || t === "float32")
    return Sn(n, new Float32Array(e));
  if (t === "int32")
    return Sn(n, new Int32Array(e));
  if (t === "bool")
    return Sn(n, new Uint8Array(e));
  throw new Error(`Unknown data type ${t}`);
}
function is(n) {
  n.forEach((t) => {
    v2(Number.isInteger(t) && t >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${n}].`);
  });
}
function zn(n, t, e) {
  if (t === 0)
    return 0;
  if (t === 1)
    return n[0];
  let s = n[n.length - 1];
  for (let o = 0; o < n.length - 1; ++o)
    s += e[o] * n[o];
  return s;
}
function Mo(n, t, e) {
  if (t === 0)
    return [];
  if (t === 1)
    return [n];
  const s = new Array(t);
  for (let o = 0; o < s.length - 1; ++o)
    s[o] = Math.floor(n / e[o]), n -= s[o] * e[o];
  return s[s.length - 1] = n, s;
}
function ui(n) {
  return n && n.then && typeof n.then == "function";
}
var Bf = "tfjsflags";
var XI = class {
  // tslint:disable-next-line: no-any
  constructor(t) {
    this.global = t, this.flags = {}, this.flagRegistry = {}, this.urlFlags = {}, this.getQueryParams = PI, this.populateURLFlags();
  }
  setPlatform(t, e) {
    this.platform != null && (F().getBool("IS_TEST") || F().getBool("PROD") || console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${t}.`)), this.platformName = t, this.platform = e;
  }
  registerFlag(t, e, s) {
    if (this.flagRegistry[t] = { evaluationFn: e, setHook: s }, this.urlFlags[t] != null) {
      const o = this.urlFlags[t];
      F().getBool("IS_TEST") || F().getBool("PROD") || console.warn(`Setting feature override from URL ${t}: ${o}.`), this.set(t, o);
    }
  }
  async getAsync(t) {
    return t in this.flags ? this.flags[t] : (this.flags[t] = await this.evaluateFlag(t), this.flags[t]);
  }
  get(t) {
    if (t in this.flags)
      return this.flags[t];
    const e = this.evaluateFlag(t);
    if (ui(e))
      throw new Error(`Flag ${t} cannot be synchronously evaluated. Please use getAsync() instead.`);
    return this.flags[t] = e, this.flags[t];
  }
  getNumber(t) {
    return this.get(t);
  }
  getBool(t) {
    return this.get(t);
  }
  getFlags() {
    return this.flags;
  }
  // For backwards compatibility.
  get features() {
    return this.flags;
  }
  set(t, e) {
    if (this.flagRegistry[t] == null)
      throw new Error(`Cannot set flag ${t} as it has not been registered.`);
    this.flags[t] = e, this.flagRegistry[t].setHook != null && this.flagRegistry[t].setHook(e);
  }
  evaluateFlag(t) {
    if (this.flagRegistry[t] == null)
      throw new Error(`Cannot evaluate flag '${t}': no evaluation function found.`);
    return this.flagRegistry[t].evaluationFn();
  }
  setFlags(t) {
    this.flags = Object.assign({}, t);
  }
  reset() {
    this.flags = {}, this.urlFlags = {}, this.populateURLFlags();
  }
  populateURLFlags() {
    if (typeof this.global > "u" || typeof this.global.location > "u" || typeof this.global.location.search > "u")
      return;
    const t = this.getQueryParams(this.global.location.search);
    Bf in t && t[Bf].split(",").forEach((s) => {
      const [o, r] = s.split(":");
      this.urlFlags[o] = OI(o, r);
    });
  }
};
function PI(n) {
  const t = {};
  return n.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (e, ...s) => (AI(t, s[0], s[1]), s.join("="))), t;
}
function AI(n, t, e) {
  n[decodeURIComponent(t)] = decodeURIComponent(e || "");
}
function OI(n, t) {
  if (t = t.toLowerCase(), t === "true" || t === "false")
    return t === "true";
  if (`${+t}` === t)
    return +t;
  throw new Error(`Could not parse value flag value ${t} for flag ${n}.`);
}
function F() {
  return Ag;
}
var Ag = null;
function KI(n) {
  Ag = n;
}
var yu;
function Og() {
  if (yu == null) {
    let n;
    if (typeof window < "u")
      n = window;
    else if (typeof global < "u")
      n = global;
    else if (typeof process < "u")
      n = process;
    else if (typeof self < "u")
      n = self;
    else
      throw new Error("Could not find a global object");
    yu = n;
  }
  return yu;
}
function ZI() {
  const n = Og();
  return n._tfGlobals == null && (n._tfGlobals = /* @__PURE__ */ new Map()), n._tfGlobals;
}
function Zd(n, t) {
  const e = ZI();
  if (e.has(n))
    return e.get(n);
  {
    const s = t();
    return e.set(n, s), e.get(n);
  }
}
var Vl = "Abs";
var di = "Acos";
var hi = "Acosh";
var br = "Add";
var Bd = "AddN";
var Hd = "All";
var _d = "Any";
var zl = "ArgMax";
var Xl = "ArgMin";
var pi = "Asin";
var fi = "Asinh";
var mi = "Atan";
var gi = "Atanh";
var bi = "Atan2";
var Pl = "AvgPool";
var Ud = "AvgPoolGrad";
var Al = "AvgPool3D";
var Yd = "AvgPool3DGrad";
var Ol = "BatchMatMul";
var Kl = "BatchToSpaceND";
var Qd = "Bincount";
var BI = "BroadcastTo";
var Kg = "BroadcastArgs";
var xi = "Cast";
var yi = "Ceil";
var wi = "ClipByValue";
var Jd = "Complex";
var Zl = "ComplexAbs";
var Bl = "Concat";
var Hl = "Conv2D";
var jd = "Conv2DBackpropFilter";
var _l = "Conv2DBackpropInput";
var Ul = "Conv3D";
var qd = "Conv3DBackpropFilterV2";
var th = "Conv3DBackpropInputV2";
var Ii = "Cos";
var Ci = "Cosh";
var eh = "Cumprod";
var Yl = "Cumsum";
var nh = "CropAndResize";
var sh = "DenseBincount";
var oh = "DepthToSpace";
var Ql = "DepthwiseConv2dNative";
var rh = "DepthwiseConv2dNativeBackpropFilter";
var ih = "DepthwiseConv2dNativeBackpropInput";
var Zg = "Diag";
var Jl = "Dilation2D";
var ed = "Dilation2DBackpropInput";
var nd = "Dilation2DBackpropFilter";
var vi = "RealDiv";
var Bg = "Einsum";
var Si = "Elu";
var ah = "EluGrad";
var ki = "Erf";
var jl = "Equal";
var Ti = "Exp";
var ql = "ExpandDims";
var Ni = "Expm1";
var lh = "FFT";
var ch = "Fill";
var uh = "FlipLeftRight";
var Ri = "Floor";
var $i = "FloorDiv";
var tc = "FusedBatchNorm";
var ec = "GatherV2";
var Hg = "GatherNd";
var nc = "Greater";
var Gi = "GreaterEqual";
var Ei = "Identity";
var dh = "IFFT";
var hh = "Imag";
var Li = "IsFinite";
var Mi = "IsInf";
var Wi = "IsNan";
var sc = "LeakyRelu";
var oc = "Less";
var rc = "LessEqual";
var _g = "LinSpace";
var Di = "Log";
var Fi = "Log1p";
var ic = "LogicalAnd";
var ac = "LogicalNot";
var lc = "LogicalOr";
var $4 = "LogicalXor";
var HI = "LogSoftmax";
var G4 = "LowerBound";
var cc = "LRN";
var ph = "LRNGrad";
var uc = "Max";
var Vi = "Maximum";
var dc = "MaxPool";
var fh = "MaxPoolGrad";
var hc = "MaxPool3D";
var mh = "MaxPool3DGrad";
var Ug = "MaxPoolWithArgmax";
var pc = "Mean";
var fc = "Min";
var zi = "Minimum";
var mc = "MirrorPad";
var Xi = "Mod";
var Yg = "Multinomial";
var Pi = "Multiply";
var gc = "Neg";
var bc = "NotEqual";
var gh = "NonMaxSuppressionV3";
var bh = "NonMaxSuppressionV4";
var xh = "NonMaxSuppressionV5";
var xc = "OnesLike";
var yc = "OneHot";
var wc = "Pack";
var Ic = "PadV2";
var E4 = "Pool";
var Ai = "Pow";
var Cc = "Prelu";
var vc = "Prod";
var Qg = "RaggedGather";
var Jg = "RaggedRange";
var jg = "RaggedTensorToTensor";
var yh = "Range";
var wh = "Real";
var Oi = "Reciprocal";
var Ki = "Relu";
var Sc = "Reshape";
var kc = "ResizeNearestNeighbor";
var Ih = "ResizeNearestNeighborGrad";
var Tc = "ResizeBilinear";
var Ch = "ResizeBilinearGrad";
var Zi = "Relu6";
var Nc = "Reverse";
var Bi = "Round";
var Hi = "Rsqrt";
var qg = "ScatterNd";
var tb = "SearchSorted";
var Rc = "Select";
var _i = "Selu";
var $c = "Slice";
var Ui = "Sin";
var Yi = "Sinh";
var Qi = "Sign";
var Ji = "Sigmoid";
var ji = "Softplus";
var qi = "Sqrt";
var Gc = "Sum";
var Ec = "SpaceToBatchND";
var Lc = "SplitV";
var Mc = "Softmax";
var vh = "SparseFillEmptyRows";
var Sh = "SparseReshape";
var kh = "SparseSegmentMean";
var Th = "SparseSegmentSum";
var eb = "SparseToDense";
var ta = "SquaredDifference";
var Nh = "Square";
var Rh = "StridedSlice";
var $h = "StringNGrams";
var Gh = "StringSplit";
var Eh = "StringToHashBucketFast";
var ea = "Sub";
var na = "Tan";
var sa = "Tanh";
var oa = "Tile";
var Lh = "TopK";
var Mh = "Transform";
var Jo = "Transpose";
var Wh = "Unique";
var Wc = "Unpack";
var Dc = "UnsortedSegmentSum";
var L4 = "UpperBound";
var Fc = "ZerosLike";
var ra = "Step";
var sd = "FromPixels";
var Dh = "RotateWithOffset";
var ol = "_FusedMatMul";
var rl = "FusedConv2D";
var nb = "FusedDepthwiseConv2D";
function rn(...n) {
  F().getBool("IS_TEST") || F().getBool("PROD") || console.warn(...n);
}
function _I(...n) {
  F().getBool("IS_TEST") || F().getBool("PROD") || console.log(...n);
}
var sr = Zd("kernelRegistry", () => /* @__PURE__ */ new Map());
var Yr = Zd("gradRegistry", () => /* @__PURE__ */ new Map());
function od(n, t) {
  const e = Fh(n, t);
  return sr.get(e);
}
function Hf(n) {
  return Yr.get(n);
}
function rd(n) {
  const t = sr.entries(), e = [];
  for (; ; ) {
    const { done: s, value: o } = t.next();
    if (s)
      break;
    const [r, i6] = o, [a] = r.split("_");
    a === n && e.push(i6);
  }
  return e;
}
function en(n) {
  const { kernelName: t, backendName: e } = n, s = Fh(t, e);
  sr.has(s) && rn(`The kernel '${t}' for backend '${e}' is already registered`), sr.set(s, n);
}
function UI(n) {
  const { kernelName: t } = n;
  Yr.has(t) && F().getBool("DEBUG") && rn(`Overriding the gradient for '${t}'`), Yr.set(t, n);
}
function M4(n, t) {
  const e = Fh(n, t);
  if (!sr.has(e))
    throw new Error(`The kernel '${n}' for backend '${t}' is not registered`);
  sr.delete(e);
}
function W4(n) {
  if (!Yr.has(n))
    throw new Error(`The gradient '${n}' for backend is not registered`);
  Yr.delete(n);
}
function D4(n, t) {
  rd(n).forEach((s) => {
    const o = Object.assign({}, s, { backendName: t });
    en(o);
  });
}
function Fh(n, t) {
  return `${t}_${n}`;
}
var sb = Bt;
var yn = null;
try {
  yn = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
    0,
    97,
    115,
    109,
    1,
    0,
    0,
    0,
    1,
    13,
    2,
    96,
    0,
    1,
    127,
    96,
    4,
    127,
    127,
    127,
    127,
    1,
    127,
    3,
    7,
    6,
    0,
    1,
    1,
    1,
    1,
    1,
    6,
    6,
    1,
    127,
    1,
    65,
    0,
    11,
    7,
    50,
    6,
    3,
    109,
    117,
    108,
    0,
    1,
    5,
    100,
    105,
    118,
    95,
    115,
    0,
    2,
    5,
    100,
    105,
    118,
    95,
    117,
    0,
    3,
    5,
    114,
    101,
    109,
    95,
    115,
    0,
    4,
    5,
    114,
    101,
    109,
    95,
    117,
    0,
    5,
    8,
    103,
    101,
    116,
    95,
    104,
    105,
    103,
    104,
    0,
    0,
    10,
    191,
    1,
    6,
    4,
    0,
    35,
    0,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    126,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    127,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    128,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    129,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    130,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11
  ])), {}).exports;
} catch {
}
function Bt(n, t, e) {
  this.low = n | 0, this.high = t | 0, this.unsigned = !!e;
}
Bt.prototype.__isLong__;
Object.defineProperty(Bt.prototype, "__isLong__", { value: true });
function nn(n) {
  return (n && n.__isLong__) === true;
}
Bt.isLong = nn;
var _f = {};
var Uf = {};
function Wo(n, t) {
  var e, s, o;
  return t ? (n >>>= 0, (o = 0 <= n && n < 256) && (s = Uf[n], s) ? s : (e = Ht(n, (n | 0) < 0 ? -1 : 0, true), o && (Uf[n] = e), e)) : (n |= 0, (o = -128 <= n && n < 128) && (s = _f[n], s) ? s : (e = Ht(n, n < 0 ? -1 : 0, false), o && (_f[n] = e), e));
}
Bt.fromInt = Wo;
function wn(n, t) {
  if (isNaN(n))
    return t ? lo : In;
  if (t) {
    if (n < 0)
      return lo;
    if (n >= ob)
      return ab;
  } else {
    if (n <= -Qf)
      return Qe;
    if (n + 1 >= Qf)
      return ib;
  }
  return n < 0 ? wn(-n, t).neg() : Ht(n % or | 0, n / or | 0, t);
}
Bt.fromNumber = wn;
function Ht(n, t, e) {
  return new Bt(n, t, e);
}
Bt.fromBits = Ht;
var il = Math.pow;
function Vh(n, t, e) {
  if (n.length === 0)
    throw Error("empty string");
  if (n === "NaN" || n === "Infinity" || n === "+Infinity" || n === "-Infinity")
    return In;
  if (typeof t == "number" ? (e = t, t = false) : t = !!t, e = e || 10, e < 2 || 36 < e)
    throw RangeError("radix");
  var s;
  if ((s = n.indexOf("-")) > 0)
    throw Error("interior hyphen");
  if (s === 0)
    return Vh(n.substring(1), t, e).neg();
  for (var o = wn(il(e, 8)), r = In, i6 = 0; i6 < n.length; i6 += 8) {
    var a = Math.min(8, n.length - i6), l = parseInt(n.substring(i6, i6 + a), e);
    if (a < 8) {
      var c = wn(il(e, a));
      r = r.mul(c).add(wn(l));
    } else
      r = r.mul(o), r = r.add(wn(l));
  }
  return r.unsigned = t, r;
}
Bt.fromString = Vh;
function Bn(n, t) {
  return typeof n == "number" ? wn(n, t) : typeof n == "string" ? Vh(n, t) : Ht(n.low, n.high, typeof t == "boolean" ? t : n.unsigned);
}
Bt.fromValue = Bn;
var Yf = 65536;
var YI = 1 << 24;
var or = Yf * Yf;
var ob = or * or;
var Qf = ob / 2;
var Jf = Wo(YI);
var In = Wo(0);
Bt.ZERO = In;
var lo = Wo(0, true);
Bt.UZERO = lo;
var Yo = Wo(1);
Bt.ONE = Yo;
var rb = Wo(1, true);
Bt.UONE = rb;
var id = Wo(-1);
Bt.NEG_ONE = id;
var ib = Ht(-1, 2147483647, false);
Bt.MAX_VALUE = ib;
var ab = Ht(-1, -1, true);
Bt.MAX_UNSIGNED_VALUE = ab;
var Qe = Ht(0, -2147483648, false);
Bt.MIN_VALUE = Qe;
var tt = Bt.prototype;
tt.toInt = function() {
  return this.unsigned ? this.low >>> 0 : this.low;
};
tt.toNumber = function() {
  return this.unsigned ? (this.high >>> 0) * or + (this.low >>> 0) : this.high * or + (this.low >>> 0);
};
tt.toString = function(t) {
  if (t = t || 10, t < 2 || 36 < t)
    throw RangeError("radix");
  if (this.isZero())
    return "0";
  if (this.isNegative())
    if (this.eq(Qe)) {
      var e = wn(t), s = this.div(e), o = s.mul(e).sub(this);
      return s.toString(t) + o.toInt().toString(t);
    } else
      return "-" + this.neg().toString(t);
  for (var r = wn(il(t, 6), this.unsigned), i6 = this, a = ""; ; ) {
    var l = i6.div(r), c = i6.sub(l.mul(r)).toInt() >>> 0, u = c.toString(t);
    if (i6 = l, i6.isZero())
      return u + a;
    for (; u.length < 6; )
      u = "0" + u;
    a = "" + u + a;
  }
};
tt.getHighBits = function() {
  return this.high;
};
tt.getHighBitsUnsigned = function() {
  return this.high >>> 0;
};
tt.getLowBits = function() {
  return this.low;
};
tt.getLowBitsUnsigned = function() {
  return this.low >>> 0;
};
tt.getNumBitsAbs = function() {
  if (this.isNegative())
    return this.eq(Qe) ? 64 : this.neg().getNumBitsAbs();
  for (var t = this.high != 0 ? this.high : this.low, e = 31; e > 0 && !(t & 1 << e); e--)
    ;
  return this.high != 0 ? e + 33 : e + 1;
};
tt.isZero = function() {
  return this.high === 0 && this.low === 0;
};
tt.eqz = tt.isZero;
tt.isNegative = function() {
  return !this.unsigned && this.high < 0;
};
tt.isPositive = function() {
  return this.unsigned || this.high >= 0;
};
tt.isOdd = function() {
  return (this.low & 1) === 1;
};
tt.isEven = function() {
  return (this.low & 1) === 0;
};
tt.equals = function(t) {
  return nn(t) || (t = Bn(t)), this.unsigned !== t.unsigned && this.high >>> 31 === 1 && t.high >>> 31 === 1 ? false : this.high === t.high && this.low === t.low;
};
tt.eq = tt.equals;
tt.notEquals = function(t) {
  return !this.eq(
    /* validates */
    t
  );
};
tt.neq = tt.notEquals;
tt.ne = tt.notEquals;
tt.lessThan = function(t) {
  return this.comp(
    /* validates */
    t
  ) < 0;
};
tt.lt = tt.lessThan;
tt.lessThanOrEqual = function(t) {
  return this.comp(
    /* validates */
    t
  ) <= 0;
};
tt.lte = tt.lessThanOrEqual;
tt.le = tt.lessThanOrEqual;
tt.greaterThan = function(t) {
  return this.comp(
    /* validates */
    t
  ) > 0;
};
tt.gt = tt.greaterThan;
tt.greaterThanOrEqual = function(t) {
  return this.comp(
    /* validates */
    t
  ) >= 0;
};
tt.gte = tt.greaterThanOrEqual;
tt.ge = tt.greaterThanOrEqual;
tt.compare = function(t) {
  if (nn(t) || (t = Bn(t)), this.eq(t))
    return 0;
  var e = this.isNegative(), s = t.isNegative();
  return e && !s ? -1 : !e && s ? 1 : this.unsigned ? t.high >>> 0 > this.high >>> 0 || t.high === this.high && t.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(t).isNegative() ? -1 : 1;
};
tt.comp = tt.compare;
tt.negate = function() {
  return !this.unsigned && this.eq(Qe) ? Qe : this.not().add(Yo);
};
tt.neg = tt.negate;
tt.add = function(t) {
  nn(t) || (t = Bn(t));
  var e = this.high >>> 16, s = this.high & 65535, o = this.low >>> 16, r = this.low & 65535, i6 = t.high >>> 16, a = t.high & 65535, l = t.low >>> 16, c = t.low & 65535, u = 0, d = 0, h6 = 0, p6 = 0;
  return p6 += r + c, h6 += p6 >>> 16, p6 &= 65535, h6 += o + l, d += h6 >>> 16, h6 &= 65535, d += s + a, u += d >>> 16, d &= 65535, u += e + i6, u &= 65535, Ht(h6 << 16 | p6, u << 16 | d, this.unsigned);
};
tt.subtract = function(t) {
  return nn(t) || (t = Bn(t)), this.add(t.neg());
};
tt.sub = tt.subtract;
tt.multiply = function(t) {
  if (this.isZero())
    return In;
  if (nn(t) || (t = Bn(t)), yn) {
    var e = yn.mul(
      this.low,
      this.high,
      t.low,
      t.high
    );
    return Ht(e, yn.get_high(), this.unsigned);
  }
  if (t.isZero())
    return In;
  if (this.eq(Qe))
    return t.isOdd() ? Qe : In;
  if (t.eq(Qe))
    return this.isOdd() ? Qe : In;
  if (this.isNegative())
    return t.isNegative() ? this.neg().mul(t.neg()) : this.neg().mul(t).neg();
  if (t.isNegative())
    return this.mul(t.neg()).neg();
  if (this.lt(Jf) && t.lt(Jf))
    return wn(this.toNumber() * t.toNumber(), this.unsigned);
  var s = this.high >>> 16, o = this.high & 65535, r = this.low >>> 16, i6 = this.low & 65535, a = t.high >>> 16, l = t.high & 65535, c = t.low >>> 16, u = t.low & 65535, d = 0, h6 = 0, p6 = 0, f = 0;
  return f += i6 * u, p6 += f >>> 16, f &= 65535, p6 += r * u, h6 += p6 >>> 16, p6 &= 65535, p6 += i6 * c, h6 += p6 >>> 16, p6 &= 65535, h6 += o * u, d += h6 >>> 16, h6 &= 65535, h6 += r * c, d += h6 >>> 16, h6 &= 65535, h6 += i6 * l, d += h6 >>> 16, h6 &= 65535, d += s * u + o * c + r * l + i6 * a, d &= 65535, Ht(p6 << 16 | f, d << 16 | h6, this.unsigned);
};
tt.mul = tt.multiply;
tt.divide = function(t) {
  if (nn(t) || (t = Bn(t)), t.isZero())
    throw Error("division by zero");
  if (yn) {
    if (!this.unsigned && this.high === -2147483648 && t.low === -1 && t.high === -1)
      return this;
    var e = (this.unsigned ? yn.div_u : yn.div_s)(
      this.low,
      this.high,
      t.low,
      t.high
    );
    return Ht(e, yn.get_high(), this.unsigned);
  }
  if (this.isZero())
    return this.unsigned ? lo : In;
  var s, o, r;
  if (this.unsigned) {
    if (t.unsigned || (t = t.toUnsigned()), t.gt(this))
      return lo;
    if (t.gt(this.shru(1)))
      return rb;
    r = lo;
  } else {
    if (this.eq(Qe)) {
      if (t.eq(Yo) || t.eq(id))
        return Qe;
      if (t.eq(Qe))
        return Yo;
      var i6 = this.shr(1);
      return s = i6.div(t).shl(1), s.eq(In) ? t.isNegative() ? Yo : id : (o = this.sub(t.mul(s)), r = s.add(o.div(t)), r);
    } else if (t.eq(Qe))
      return this.unsigned ? lo : In;
    if (this.isNegative())
      return t.isNegative() ? this.neg().div(t.neg()) : this.neg().div(t).neg();
    if (t.isNegative())
      return this.div(t.neg()).neg();
    r = In;
  }
  for (o = this; o.gte(t); ) {
    s = Math.max(1, Math.floor(o.toNumber() / t.toNumber()));
    for (var a = Math.ceil(Math.log(s) / Math.LN2), l = a <= 48 ? 1 : il(2, a - 48), c = wn(s), u = c.mul(t); u.isNegative() || u.gt(o); )
      s -= l, c = wn(s, this.unsigned), u = c.mul(t);
    c.isZero() && (c = Yo), r = r.add(c), o = o.sub(u);
  }
  return r;
};
tt.div = tt.divide;
tt.modulo = function(t) {
  if (nn(t) || (t = Bn(t)), yn) {
    var e = (this.unsigned ? yn.rem_u : yn.rem_s)(
      this.low,
      this.high,
      t.low,
      t.high
    );
    return Ht(e, yn.get_high(), this.unsigned);
  }
  return this.sub(this.div(t).mul(t));
};
tt.mod = tt.modulo;
tt.rem = tt.modulo;
tt.not = function() {
  return Ht(~this.low, ~this.high, this.unsigned);
};
tt.and = function(t) {
  return nn(t) || (t = Bn(t)), Ht(this.low & t.low, this.high & t.high, this.unsigned);
};
tt.or = function(t) {
  return nn(t) || (t = Bn(t)), Ht(this.low | t.low, this.high | t.high, this.unsigned);
};
tt.xor = function(t) {
  return nn(t) || (t = Bn(t)), Ht(this.low ^ t.low, this.high ^ t.high, this.unsigned);
};
tt.shiftLeft = function(t) {
  return nn(t) && (t = t.toInt()), (t &= 63) === 0 ? this : t < 32 ? Ht(this.low << t, this.high << t | this.low >>> 32 - t, this.unsigned) : Ht(0, this.low << t - 32, this.unsigned);
};
tt.shl = tt.shiftLeft;
tt.shiftRight = function(t) {
  return nn(t) && (t = t.toInt()), (t &= 63) === 0 ? this : t < 32 ? Ht(this.low >>> t | this.high << 32 - t, this.high >> t, this.unsigned) : Ht(this.high >> t - 32, this.high >= 0 ? 0 : -1, this.unsigned);
};
tt.shr = tt.shiftRight;
tt.shiftRightUnsigned = function(t) {
  if (nn(t) && (t = t.toInt()), t &= 63, t === 0)
    return this;
  var e = this.high;
  if (t < 32) {
    var s = this.low;
    return Ht(s >>> t | e << 32 - t, e >>> t, this.unsigned);
  } else
    return t === 32 ? Ht(e, 0, this.unsigned) : Ht(e >>> t - 32, 0, this.unsigned);
};
tt.shru = tt.shiftRightUnsigned;
tt.shr_u = tt.shiftRightUnsigned;
tt.toSigned = function() {
  return this.unsigned ? Ht(this.low, this.high, false) : this;
};
tt.toUnsigned = function() {
  return this.unsigned ? this : Ht(this.low, this.high, true);
};
tt.toBytes = function(t) {
  return t ? this.toBytesLE() : this.toBytesBE();
};
tt.toBytesLE = function() {
  var t = this.high, e = this.low;
  return [
    e & 255,
    e >>> 8 & 255,
    e >>> 16 & 255,
    e >>> 24,
    t & 255,
    t >>> 8 & 255,
    t >>> 16 & 255,
    t >>> 24
  ];
};
tt.toBytesBE = function() {
  var t = this.high, e = this.low;
  return [
    t >>> 24,
    t >>> 16 & 255,
    t >>> 8 & 255,
    t & 255,
    e >>> 24,
    e >>> 16 & 255,
    e >>> 8 & 255,
    e & 255
  ];
};
Bt.fromBytes = function(t, e, s) {
  return s ? Bt.fromBytesLE(t, e) : Bt.fromBytesBE(t, e);
};
Bt.fromBytesLE = function(t, e) {
  return new Bt(
    t[0] | t[1] << 8 | t[2] << 16 | t[3] << 24,
    t[4] | t[5] << 8 | t[6] << 16 | t[7] << 24,
    e
  );
};
Bt.fromBytesBE = function(t, e) {
  return new Bt(
    t[4] << 24 | t[5] << 16 | t[6] << 8 | t[7],
    t[0] << 24 | t[1] << 16 | t[2] << 8 | t[3],
    e
  );
};
var lb = M(sb);
var QI = GI({
  __proto__: null,
  default: lb
}, [sb]);
var oo = (
  // tslint:disable-next-line
  lb || QI
);
function ia(n) {
  return oo.fromString(n, true, 16);
}
var cb = ia("c3a5c85c97cb3127");
var so = ia("b492b66fbe98f273");
var Me = ia("9ae16a3b2f90404f");
function ad(n) {
  return n.xor(n.shru(47));
}
function ub(n, t, e) {
  const s = n.slice(t, t + e);
  return oo.fromBytes(Array.from(s), true, true);
}
function Pt(n, t) {
  return ub(n, t, 8);
}
function jf(n, t) {
  return ub(n, t, 4);
}
function me(n, t) {
  return t === 0 ? n : n.shru(t).or(n.shl(64 - t));
}
function Ms(n, t, e = ia("9ddfea08eb382d69")) {
  let s = n.xor(t).mul(e);
  s = s.xor(s.shru(47));
  let o = t.xor(s).mul(e);
  return o = o.xor(o.shru(47)), o = o.mul(e), o;
}
function JI(n, t, e, s, o, r) {
  o = o.add(n), r = me(r.add(o).add(s), 21);
  const i6 = o;
  return o = o.add(t), o = o.add(e), r = r.add(me(o, 44)), [o.add(s), r.add(i6)];
}
function Wa(n, t, e, s) {
  return JI(Pt(n, t), Pt(n, t + 8), Pt(n, t + 16), Pt(n, t + 24), e, s);
}
function jI(n, t = n.length) {
  if (t >= 8) {
    const e = Me.add(t * 2), s = Pt(n, 0).add(Me), o = Pt(n, t - 8), r = me(o, 37).mul(e).add(s), i6 = me(s, 25).add(o).mul(e);
    return Ms(r, i6, e);
  }
  if (t >= 4) {
    const e = Me.add(t * 2), s = jf(n, 0);
    return Ms(s.shl(3).add(t), jf(n, t - 4), e);
  }
  if (t > 0) {
    const e = n[0], s = n[t >> 1], o = n[t - 1], r = e + (s << 8), i6 = t + (o << 2);
    return ad(Me.mul(r).xor(cb.mul(i6))).mul(Me);
  }
  return Me;
}
function qI(n, t = n.length) {
  const e = Me.add(t * 2), s = Pt(n, 0).mul(so), o = Pt(n, 8), r = Pt(n, t - 8).mul(e), i6 = Pt(n, t - 16).mul(Me);
  return Ms(me(s.add(o), 43).add(me(r, 30)).add(i6), s.add(me(o.add(Me), 18)).add(r), e);
}
function tC(n, t = n.length) {
  const e = Me.add(t * 2), s = Pt(n, 0).mul(Me), o = Pt(n, 8), r = Pt(n, t - 8).mul(e), i6 = Pt(n, t - 16).mul(Me), a = me(s.add(o), 43).add(me(r, 30)).add(i6), l = Ms(a, s.add(me(o.add(Me), 18)).add(r), e), c = Pt(n, 16).mul(e), u = Pt(n, 24), d = a.add(Pt(n, t - 32)).mul(e), h6 = l.add(Pt(n, t - 24)).mul(e);
  return Ms(me(c.add(u), 43).add(me(d, 30)).add(h6), c.add(me(u.add(s), 18)).add(d), e);
}
function db(n, t = n.length) {
  const e = oo.fromNumber(81, true);
  if (t <= 32)
    return t <= 16 ? jI(n, t) : qI(n, t);
  if (t <= 64)
    return tC(n, t);
  let s = e, o = e.mul(so).add(113), r = ad(o.mul(Me).add(113)).mul(Me), i6 = [oo.UZERO, oo.UZERO], a = [oo.UZERO, oo.UZERO];
  s = s.mul(Me).add(Pt(n, 0));
  let l = 0;
  const c = (t - 1 >> 6) * 64, u = c + (t - 1 & 63) - 63;
  do
    s = me(s.add(o).add(i6[0]).add(Pt(n, l + 8)), 37).mul(so), o = me(o.add(i6[1]).add(Pt(n, l + 48)), 42).mul(so), s = s.xor(a[1]), o = o.add(i6[0]).add(Pt(n, l + 40)), r = me(r.add(a[0]), 33).mul(so), i6 = Wa(n, l, i6[1].mul(so), s.add(a[0])), a = Wa(n, l + 32, r.add(a[1]), o.add(Pt(n, l + 16))), [r, s] = [s, r], l += 64;
  while (l !== c);
  const d = so.add(r.and(255).shl(1));
  return l = u, a[0] = a[0].add(t - 1 & 63), i6[0] = i6[0].add(a[0]), a[0] = a[0].add(i6[0]), s = me(s.add(o).add(i6[0]).add(Pt(n, l + 8)), 37).mul(d), o = me(o.add(i6[1]).add(Pt(n, l + 48)), 42).mul(d), s = s.xor(a[1].mul(9)), o = o.add(i6[0].mul(9).add(Pt(n, l + 40))), r = me(r.add(a[0]), 33).mul(d), i6 = Wa(n, l, i6[1].mul(d), s.add(a[0])), a = Wa(n, l + 32, r.add(a[1]), o.add(Pt(n, l + 16))), [r, s] = [s, r], Ms(Ms(i6[0], a[0], d).add(ad(o).mul(cb)).add(r), Ms(i6[1], a[1], d).add(s), d);
}
function bs(n, t) {
  return t === "string" ? hs(n) : Zs([n], t);
}
function eC(n, t) {
  return n instanceof Float32Array && t === "float32" || n instanceof Int32Array && t === "int32" || n instanceof Uint8Array && t === "bool";
}
function Zs(n, t) {
  if (t === "string")
    throw new Error("Cannot convert a string[] to a TypedArray");
  if (Array.isArray(n) && (n = zs(n)), F().getBool("DEBUG") && Dg(n, t), eC(n, t))
    return n;
  if (t == null || t === "float32" || t === "complex64")
    return new Float32Array(n);
  if (t === "int32")
    return new Int32Array(n);
  if (t === "bool") {
    const e = new Uint8Array(n.length);
    for (let s = 0; s < e.length; ++s)
      Math.round(n[s]) !== 0 && (e[s] = 1);
    return e;
  } else
    throw new Error(`Unknown data type ${t}`);
}
function Ce() {
  return F().platform.now();
}
function nC(n, t) {
  return F().platform.fetch(n, t);
}
function hs(n, t = "utf-8") {
  return t = t || "utf-8", F().platform.encode(n, t);
}
function ps(n, t = "utf-8") {
  return t = t || "utf-8", F().platform.decode(n, t);
}
function dn(n) {
  return F().platform.isTypedArray(n);
}
function zs(n, t = [], e = false) {
  if (t == null && (t = []), typeof n == "boolean" || typeof n == "number" || typeof n == "string" || ui(n) || n == null || dn(n) && e)
    t.push(n);
  else if (Array.isArray(n) || dn(n))
    for (let s = 0; s < n.length; ++s)
      zs(n[s], t, e);
  else {
    let s = -1;
    for (const o of Object.keys(n))
      /^([1-9]+[0-9]*|0)$/.test(o) && (s = Math.max(s, Number(o)));
    for (let o = 0; o <= s; o++)
      zs(n[o], t, e);
  }
  return t;
}
var F4 = Object.freeze(Object.defineProperty({
  __proto__: null,
  arraysEqual: Rt,
  assert: v2,
  assertNonNegativeIntegerDimensions: is,
  assertNonNull: Dl,
  assertShapesMatch: Ve,
  bytesFromStringArray: Vg,
  bytesPerElement: Ur,
  checkConversionForErrors: Dg,
  clamp: Fs,
  computeStrides: dt,
  convertBackendValuesAndArrayBuffer: Pg,
  createScalarValue: bs,
  createShuffledIndices: zI,
  decodeString: ps,
  distSquared: DI,
  encodeString: hs,
  fetch: nC,
  fingerPrint64: db,
  flatten: zs,
  getArrayFromDType: oe,
  getTypedArrayFromDType: xe,
  hasEncodingLoss: Od,
  hexToLong: ia,
  indexToLoc: Mo,
  inferDtype: gr,
  inferFromImplicitShape: Ad,
  isBoolean: zg,
  isFunction: Vs,
  isInt: go,
  isNumber: nl,
  isPromise: ui,
  isScalarShape: FI,
  isString: mr,
  isTypedArray: dn,
  isValidDtype: Fg,
  locToIndex: zn,
  makeOnesTypedArray: Fl,
  makeZerosNestedTypedArray: Kd,
  makeZerosTypedArray: Se,
  nearestDivisor: sl,
  nearestLargerEven: Wl,
  now: Ce,
  parseAxisParam: Ct,
  randUniform: WI,
  repeatedTry: td,
  rightPad: ho,
  shuffle: Pd,
  shuffleCombo: MI,
  sizeFromShape: O,
  sizeToSquarishShape: el,
  squeezeShape: gs,
  sum: Wg,
  swap: us,
  tanh: VI,
  toNestedArray: Sn,
  toTypedArray: Zs
}, Symbol.toStringTag, { value: "Module" }));
var sC = class {
  constructor(t, e) {
    this.backendTimer = t, this.logger = e, e == null && (this.logger = new rC());
  }
  profileKernel(t, e, s) {
    let o;
    const r = () => {
      o = s();
    };
    let i6;
    const a = Ce();
    if (this.backendTimer.timerAvailable())
      i6 = this.backendTimer.time(r);
    else {
      r();
      for (const c of o)
        c.dataSync();
      i6 = Promise.resolve({ kernelMs: Ce() - a });
    }
    if (F().getBool("CHECK_COMPUTATION_FOR_ERRORS"))
      for (let c = 0; c < o.length; c++) {
        const u = o[c];
        u.data().then((d) => {
          oC(d, u.dtype, t);
        });
      }
    return {
      kernelName: t,
      outputs: o,
      inputs: e,
      timeMs: i6.then((c) => c.kernelMs),
      extraInfo: i6.then((c) => c.getExtraProfileInfo != null ? c.getExtraProfileInfo() : "")
    };
  }
  logKernelProfile(t) {
    const { kernelName: e, outputs: s, timeMs: o, inputs: r, extraInfo: i6 } = t;
    s.forEach((a) => {
      Promise.all([a.data(), o, i6]).then((l) => {
        this.logger.logKernelProfile(e, a, l[0], l[1], r, l[2]);
      });
    });
  }
};
function oC(n, t, e) {
  if (t !== "float32")
    return false;
  for (let s = 0; s < n.length; s++) {
    const o = n[s];
    if (isNaN(o) || !isFinite(o))
      return console.warn(`Found ${o} in the result of '${e}'`), true;
  }
  return false;
}
var rC = class {
  logKernelProfile(t, e, s, o, r, i6) {
    const a = typeof o == "number" ? ho(`${o}ms`, 9) : o.error, l = ho(t, 25), c = e.rank, u = e.size, d = ho(e.shape.toString(), 14);
    let h6 = "";
    for (const p6 in r) {
      const f = r[p6];
      if (f != null) {
        const m = f.shape || e.shape, g6 = m.length;
        h6 += `${p6}: ${g6}D ${g6 > 0 ? m : ""} `;
      }
    }
    console.log(`%c${l}	%c${a}	%c${c}D ${d}	%c${u}	%c${h6}	%c${i6}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
  }
};
function iC(n, t, e) {
  const s = {}, o = {};
  for (let l = 0; l < t.length; l++)
    s[t[l].id] = true;
  for (let l = 0; l < n.length; l++) {
    const c = n[l], u = c.inputs;
    for (const d in u) {
      const h6 = u[d];
      let p6 = false;
      for (let f = 0; f < t.length; f++)
        if (s[h6.id]) {
          c.outputs.forEach((m) => s[m.id] = true), p6 = true, o[c.id] = true;
          break;
        }
      if (p6)
        break;
    }
  }
  const r = {};
  r[e.id] = true;
  const i6 = {};
  for (let l = n.length - 1; l >= 0; l--) {
    const c = n[l], u = c.inputs;
    for (let d = 0; d < c.outputs.length; d++)
      if (r[c.outputs[d].id]) {
        for (const h6 in u)
          r[u[h6].id] = true, i6[c.id] = true;
        break;
      }
  }
  const a = [];
  for (let l = 0; l < n.length; l++) {
    const c = n[l];
    if (o[c.id] && i6[c.id]) {
      const u = {};
      for (const h6 in c.inputs) {
        const p6 = c.inputs[h6];
        s[p6.id] && (u[h6] = p6);
      }
      const d = Object.assign({}, c);
      d.inputs = u, d.outputs = c.outputs, a.push(d);
    }
  }
  return a;
}
function aC(n, t, e, s) {
  for (let o = t.length - 1; o >= 0; o--) {
    const r = t[o], i6 = [];
    if (r.outputs.forEach((l) => {
      const c = n[l.id];
      c != null ? i6.push(c) : i6.push(null);
    }), r.gradient == null)
      throw new Error(`Cannot compute gradient: gradient function not found for ${r.kernelName}.`);
    const a = r.gradient(i6);
    for (const l in r.inputs) {
      if (!(l in a))
        throw new Error(`Cannot backprop through input ${l}. Available gradients found: ${Object.keys(a)}.`);
      const c = e(() => a[l]());
      if (c.dtype !== "float32")
        throw new Error(`Error in gradient for op ${r.kernelName}. The gradient of input ${l} must have 'float32' dtype, but has '${c.dtype}'`);
      const u = r.inputs[l];
      if (!Rt(c.shape, u.shape))
        throw new Error(`Error in gradient for op ${r.kernelName}. The gradient of input '${l}' has shape '${c.shape}', which does not match the shape of the input '${u.shape}'`);
      if (n[u.id] == null)
        n[u.id] = c;
      else {
        const d = n[u.id];
        n[u.id] = s(d, c), d.dispose();
      }
    }
  }
}
var qf = 20;
var Mr = 3;
var wu = 7;
function lC(n, t, e, s) {
  const o = dt(t), r = cC(n, t, e, o), i6 = t.length, a = Ja(n, t, e, o, r), l = ["Tensor"];
  return s && (l.push(`  dtype: ${e}`), l.push(`  rank: ${i6}`), l.push(`  shape: [${t}]`), l.push("  values:")), l.push(a.map((c) => "    " + c).join(`
`)), l.join(`
`);
}
function cC(n, t, e, s) {
  const o = O(t), r = s[s.length - 1], i6 = new Array(r).fill(0), a = t.length, l = e === "complex64" ? Pr(n) : n;
  if (a > 1)
    for (let c = 0; c < o / r; c++) {
      const u = c * r;
      for (let d = 0; d < r; d++)
        i6[d] = Math.max(i6[d], Xr(l[u + d], 0, e).length);
    }
  return i6;
}
function Xr(n, t, e) {
  let s;
  return Array.isArray(n) ? s = `${parseFloat(n[0].toFixed(wu))} + ${parseFloat(n[1].toFixed(wu))}j` : mr(n) ? s = `'${n}'` : e === "bool" ? s = hb(n) : s = parseFloat(n.toFixed(wu)).toString(), ho(s, t);
}
function hb(n) {
  return n === 0 ? "false" : "true";
}
function Ja(n, t, e, s, o, r = true) {
  const i6 = e === "complex64" ? 2 : 1, a = t[0], l = t.length;
  if (l === 0) {
    if (e === "complex64") {
      const m = Pr(n);
      return [Xr(m[0], 0, e)];
    }
    return e === "bool" ? [hb(n[0])] : [n[0].toString()];
  }
  if (l === 1) {
    if (a > qf) {
      const g6 = Mr * i6;
      let b6 = Array.from(n.slice(0, g6)), x6 = Array.from(n.slice((a - Mr) * i6, a * i6));
      return e === "complex64" && (b6 = Pr(b6), x6 = Pr(x6)), [
        "[" + b6.map((w6, y6) => Xr(w6, o[y6], e)).join(", ") + ", ..., " + x6.map((w6, y6) => Xr(w6, o[a - Mr + y6], e)).join(", ") + "]"
      ];
    }
    return [
      "[" + (e === "complex64" ? Pr(n) : Array.from(n)).map((g6, b6) => Xr(g6, o[b6], e)).join(", ") + "]"
    ];
  }
  const c = t.slice(1), u = s.slice(1), d = s[0] * i6, h6 = [];
  if (a > qf) {
    for (let m = 0; m < Mr; m++) {
      const g6 = m * d, b6 = g6 + d;
      h6.push(...Ja(
        n.slice(g6, b6),
        c,
        e,
        u,
        o,
        false
        /* isLast */
      ));
    }
    h6.push("...");
    for (let m = a - Mr; m < a; m++) {
      const g6 = m * d, b6 = g6 + d;
      h6.push(...Ja(
        n.slice(g6, b6),
        c,
        e,
        u,
        o,
        m === a - 1
        /* isLast */
      ));
    }
  } else
    for (let m = 0; m < a; m++) {
      const g6 = m * d, b6 = g6 + d;
      h6.push(...Ja(
        n.slice(g6, b6),
        c,
        e,
        u,
        o,
        m === a - 1
        /* isLast */
      ));
    }
  const p6 = l === 2 ? "," : "";
  h6[0] = "[" + (a > 0 ? h6[0] + p6 : "");
  for (let m = 1; m < h6.length - 1; m++)
    h6[m] = " " + h6[m] + p6;
  let f = `,
`;
  for (let m = 2; m < l; m++)
    f += `
`;
  return h6[h6.length - 1] = " " + h6[h6.length - 1] + "]" + (r ? "" : f), h6;
}
function Pr(n) {
  const t = [];
  for (let e = 0; e < n.length; e += 2)
    t.push([n[e], n[e + 1]]);
  return t;
}
var $e = class {
  constructor(t, e, s) {
    if (this.dtype = e, this.shape = t.slice(), this.size = O(t), s != null) {
      const o = s.length;
      v2(o === this.size, () => `Length of values '${o}' does not match the size inferred by the shape '${this.size}'.`);
    }
    if (e === "complex64")
      throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
    this.values = s || oe(e, this.size), this.strides = dt(t);
  }
  /**
   * Sets a value in the buffer at a given location.
   *
   * @param value The value to set.
   * @param locs  The location indices.
   *
   * @doc {heading: 'Tensors', subheading: 'Creation'}
   */
  set(t, ...e) {
    e.length === 0 && (e = [0]), v2(e.length === this.rank, () => `The number of provided coordinates (${e.length}) must match the rank (${this.rank})`);
    const s = this.locToIndex(e);
    this.values[s] = t;
  }
  /**
   * Returns the value in the buffer at the provided location.
   *
   * @param locs The location indices.
   *
   * @doc {heading: 'Tensors', subheading: 'Creation'}
   */
  get(...t) {
    t.length === 0 && (t = [0]);
    let e = 0;
    for (const o of t) {
      if (o < 0 || o >= this.shape[e]) {
        const r = `Requested out of range element at ${t}.   Buffer shape=${this.shape}`;
        throw new Error(r);
      }
      e++;
    }
    let s = t[t.length - 1];
    for (let o = 0; o < t.length - 1; ++o)
      s += this.strides[o] * t[o];
    return this.values[s];
  }
  locToIndex(t) {
    if (this.rank === 0)
      return 0;
    if (this.rank === 1)
      return t[0];
    let e = t[t.length - 1];
    for (let s = 0; s < t.length - 1; ++s)
      e += this.strides[s] * t[s];
    return e;
  }
  indexToLoc(t) {
    if (this.rank === 0)
      return [];
    if (this.rank === 1)
      return [t];
    const e = new Array(this.shape.length);
    for (let s = 0; s < e.length - 1; ++s)
      e[s] = Math.floor(t / this.strides[s]), t -= e[s] * this.strides[s];
    return e[e.length - 1] = t, e;
  }
  get rank() {
    return this.shape.length;
  }
  /**
   * Creates an immutable `tf.Tensor` object from the buffer.
   *
   * @doc {heading: 'Tensors', subheading: 'Creation'}
   */
  toTensor() {
    return Dn().makeTensor(this.values, this.shape, this.dtype);
  }
};
var Dn = null;
var _o = null;
function uC(n) {
  Dn = n;
}
function dC(n) {
  _o = n;
}
var Lt = class {
  constructor(t, e, s, o) {
    this.kept = false, this.isDisposedInternal = false, this.shape = t.slice(), this.dtype = e || "float32", this.size = O(t), this.strides = dt(t), this.dataId = s, this.id = o, this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
  }
  get rank() {
    return this.shape.length;
  }
  /**
   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  async buffer() {
    const t = await this.data();
    return _o.buffer(this.shape, this.dtype, t);
  }
  /**
   * Returns a `tf.TensorBuffer` that holds the underlying data.
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  bufferSync() {
    return _o.buffer(this.shape, this.dtype, this.dataSync());
  }
  /**
   * Returns the tensor data as a nested array. The transfer of data is done
   * asynchronously.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  async array() {
    const t = await this.data();
    return Sn(this.shape, t, this.dtype === "complex64");
  }
  /**
   * Returns the tensor data as a nested array. The transfer of data is done
   * synchronously.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  arraySync() {
    return Sn(this.shape, this.dataSync(), this.dtype === "complex64");
  }
  /**
   * Asynchronously downloads the values from the `tf.Tensor`. Returns a
   * promise of `TypedArray` that resolves when the computation has finished.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  async data() {
    this.throwIfDisposed();
    const t = Dn().read(this.dataId);
    if (this.dtype === "string") {
      const e = await t;
      try {
        return e.map((s) => ps(s));
      } catch {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    }
    return t;
  }
  /**
   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`
   * and `data()`, this method prevents data from being downloaded to CPU.
   *
   * For WebGL backend, the data will be stored on a densely packed texture.
   * This means that the texture will use the RGBA channels to store value.
   *
   * For WebGPU backend, the data will be stored on a buffer. There is no
   * parameter, so can not use a user-defined size to create the buffer.
   *
   * @param options:
   *     For WebGL,
   *         - customTexShape: Optional. If set, will use the user defined
   *     texture shape to create the texture.
   *
   * @returns For WebGL backend, a GPUData contains the new texture and
   *     its information.
   *     {
   *        tensorRef: The tensor that is associated with this texture,
   *        texture: WebGLTexture,
   *        texShape: [number, number] // [height, width]
   *     }
   *
   *     For WebGPU backend, a GPUData contains the new buffer and
   *     its information.
   *     {
   *        tensorRef: The tensor that is associated with this buffer,
   *        buffer: GPUBuffer,
   *        bufSize: number
   *     }
   *
   *     Remember to dispose the GPUData after it is used by
   *     `res.tensorRef.dispose()`.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  dataToGPU(t) {
    return this.throwIfDisposed(), Dn().readToGPU(this.dataId, t);
  }
  /**
   * Synchronously downloads the values from the `tf.Tensor`. This blocks the
   * UI thread until the values are ready, which can cause performance issues.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  dataSync() {
    this.throwIfDisposed();
    const t = Dn().readSync(this.dataId);
    if (this.dtype === "string")
      try {
        return t.map((e) => ps(e));
      } catch {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    return t;
  }
  /** Returns the underlying bytes of the tensor's data. */
  async bytes() {
    this.throwIfDisposed();
    const t = await Dn().read(this.dataId);
    return this.dtype === "string" ? t : new Uint8Array(t.buffer);
  }
  /**
   * Disposes `tf.Tensor` from memory.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  dispose() {
    this.isDisposed || (Dn().disposeTensor(this), this.isDisposedInternal = true);
  }
  get isDisposed() {
    return this.isDisposedInternal;
  }
  throwIfDisposed() {
    if (this.isDisposed)
      throw new Error("Tensor is disposed.");
  }
  /**
   * Prints the `tf.Tensor`. See `tf.print` for details.
   *
   * @param verbose Whether to print verbose information about the tensor,
   *    including dtype and size.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  print(t = false) {
    return _o.print(this, t);
  }
  /**
   * Returns a copy of the tensor. See `tf.clone` for details.
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  clone() {
    return this.throwIfDisposed(), _o.clone(this);
  }
  /**
   * Returns a human-readable description of the tensor. Useful for logging.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  toString(t = false) {
    const e = this.dataSync();
    return lC(e, this.shape, this.dtype, t);
  }
  cast(t) {
    return this.throwIfDisposed(), _o.cast(this, t);
  }
  variable(t = true, e, s) {
    return this.throwIfDisposed(), Dn().makeVariable(this, t, e, s);
  }
};
Object.defineProperty(Lt, Symbol.hasInstance, {
  value: (n) => !!n && n.data != null && n.dataSync != null && n.throwIfDisposed != null
});
function K() {
  return Zd("Tensor", () => Lt);
}
K();
var al = class extends Lt {
  constructor(t, e, s, o) {
    super(t.shape, t.dtype, t.dataId, o), this.trainable = e, this.name = s;
  }
  /**
   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have
   * the same shape and dtype as the old `tf.Tensor`.
   *
   * @param newValue New tensor to be assigned to this variable.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  assign(t) {
    if (t.dtype !== this.dtype)
      throw new Error(`dtype of the new value (${t.dtype}) and previous value (${this.dtype}) must match`);
    if (!Rt(t.shape, this.shape))
      throw new Error(`shape of the new value (${t.shape}) and previous value (${this.shape}) must match`);
    Dn().disposeTensor(this), this.dataId = t.dataId, Dn().incRef(
      this,
      null
      /* backend */
    );
  }
  dispose() {
    Dn().disposeVariable(this), this.isDisposedInternal = true;
  }
};
Object.defineProperty(al, Symbol.hasInstance, {
  value: (n) => n instanceof Lt && n.assign != null && n.assign instanceof Function
});
var tm;
(function(n) {
  n.R0 = "R0", n.R1 = "R1", n.R2 = "R2", n.R3 = "R3", n.R4 = "R4", n.R5 = "R5", n.R6 = "R6";
})(tm || (tm = {}));
var ld;
(function(n) {
  n.float32 = "float32", n.int32 = "int32", n.bool = "int32", n.complex64 = "complex64";
})(ld || (ld = {}));
var cd;
(function(n) {
  n.float32 = "float32", n.int32 = "int32", n.bool = "bool", n.complex64 = "complex64";
})(cd || (cd = {}));
var ud;
(function(n) {
  n.float32 = "float32", n.int32 = "float32", n.bool = "float32", n.complex64 = "complex64";
})(ud || (ud = {}));
var dd;
(function(n) {
  n.float32 = "complex64", n.int32 = "complex64", n.bool = "complex64", n.complex64 = "complex64";
})(dd || (dd = {}));
var hC = {
  float32: ud,
  int32: ld,
  bool: cd,
  complex64: dd
};
function je(n, t) {
  if (n === "string" || t === "string") {
    if (n === "string" && t === "string")
      return "string";
    throw new Error(`Can not upcast ${n} with ${t}`);
  }
  return hC[n][t];
}
function zh(n) {
  return je(n, "int32");
}
function ne(n, t) {
  if (n.dtype === t.dtype)
    return [n, t];
  const e = je(n.dtype, t.dtype);
  return [n.cast(e), t.cast(e)];
}
function pC(n, t) {
  v2(n.dtype === t.dtype, () => `The dtypes of the first(${n.dtype}) and second(${t.dtype}) input must match`);
}
function Vc(n, t) {
  return t.some((e) => e.id === n.id);
}
function fs(n) {
  const t = [];
  return pb(n, t, /* @__PURE__ */ new Set()), t;
}
function pb(n, t, e) {
  if (n == null)
    return;
  if (n instanceof Lt) {
    t.push(n);
    return;
  }
  if (!fC(n))
    return;
  const s = n;
  for (const o in s) {
    const r = s[o];
    e.has(r) || (e.add(r), pb(r, t, e));
  }
}
function fC(n) {
  return Array.isArray(n) || typeof n == "object";
}
var V4 = Object.freeze(Object.defineProperty({
  __proto__: null,
  assertTypesMatch: pC,
  getTensorsInContainer: fs,
  isTensorInList: Vc,
  makeTypesMatch: ne
}, Symbol.toStringTag, { value: "Module" }));
function Iu(n) {
  return n.kernelName != null;
}
var em = class {
  constructor() {
    this.registeredVariables = {}, this.nextTapeNodeId = 0, this.numBytes = 0, this.numTensors = 0, this.numStringTensors = 0, this.numDataBuffers = 0, this.gradientDepth = 0, this.kernelDepth = 0, this.scopeStack = [], this.numDataMovesStack = [], this.nextScopeId = 0, this.tensorInfo = /* @__PURE__ */ new WeakMap(), this.profiling = false, this.activeProfile = {
      newBytes: 0,
      newTensors: 0,
      peakBytes: 0,
      kernels: [],
      result: null,
      get kernelNames() {
        return Array.from(new Set(this.kernels.map((t) => t.name)));
      }
    };
  }
  dispose() {
    for (const t in this.registeredVariables)
      this.registeredVariables[t].dispose();
  }
};
var rr = class {
  constructor(t) {
    this.ENV = t, this.registry = {}, this.registryFactory = {}, this.pendingBackendInitId = 0, this.state = new em();
  }
  async ready() {
    if (this.pendingBackendInit != null)
      return this.pendingBackendInit.then(() => {
      });
    if (this.backendInstance != null)
      return;
    const t = this.getSortedBackends();
    for (let e = 0; e < t.length; e++) {
      const s = t[e];
      if (await this.initializeBackend(s).success) {
        await this.setBackend(s);
        return;
      }
    }
    throw new Error("Could not initialize any backends, all backend initializations failed.");
  }
  get backend() {
    if (this.pendingBackendInit != null)
      throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
    if (this.backendInstance == null) {
      const { name: t, asyncInit: e } = this.initializeBackendsAndReturnBest();
      if (e)
        throw new Error(`The highest priority backend '${t}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
      this.setBackend(t);
    }
    return this.backendInstance;
  }
  backendNames() {
    return Object.keys(this.registryFactory);
  }
  findBackend(t) {
    if (!(t in this.registry))
      if (t in this.registryFactory) {
        const { asyncInit: e } = this.initializeBackend(t);
        if (e)
          return null;
      } else
        return null;
    return this.registry[t];
  }
  findBackendFactory(t) {
    return t in this.registryFactory ? this.registryFactory[t].factory : null;
  }
  registerBackend(t, e, s = 1) {
    return t in this.registryFactory ? (rn(`${t} backend was already registered. Reusing existing backend factory.`), false) : (this.registryFactory[t] = { factory: e, priority: s }, true);
  }
  async setBackend(t) {
    if (this.registryFactory[t] == null)
      throw new Error(`Backend name '${t}' not found in registry`);
    if (this.backendName = t, this.registry[t] == null) {
      this.backendInstance = null;
      const { success: e, asyncInit: s } = this.initializeBackend(t);
      if (!(s ? await e : e))
        return false;
    }
    return this.backendInstance = this.registry[t], this.setupRegisteredKernels(), this.profiler = new sC(this.backendInstance), true;
  }
  setupRegisteredKernels() {
    rd(this.backendName).forEach((e) => {
      e.setupFunc != null && e.setupFunc(this.backendInstance);
    });
  }
  disposeRegisteredKernels(t) {
    rd(t).forEach((s) => {
      s.disposeFunc != null && s.disposeFunc(this.registry[t]);
    });
  }
  /**
   * Initializes a backend by looking up the backend name in the factory
   * registry and calling the factory method. Returns a boolean representing
   * whether the initialization of the backend suceeded. Throws an error if
   * there is no backend in the factory registry.
   */
  initializeBackend(t) {
    const e = this.registryFactory[t];
    if (e == null)
      throw new Error(`Cannot initialize backend ${t}, no registration found.`);
    try {
      const s = e.factory();
      if (s && !(s instanceof Xd) && typeof s.then == "function") {
        const o = ++this.pendingBackendInitId, r = s.then((i6) => o < this.pendingBackendInitId ? false : (this.registry[t] = i6, this.pendingBackendInit = null, true)).catch((i6) => (o < this.pendingBackendInitId || (this.pendingBackendInit = null, rn(`Initialization of backend ${t} failed`), rn(i6.stack || i6.message)), false));
        return this.pendingBackendInit = r, { success: r, asyncInit: true };
      } else
        return this.registry[t] = s, { success: true, asyncInit: false };
    } catch (s) {
      return rn(`Initialization of backend ${t} failed`), rn(s.stack || s.message), { success: false, asyncInit: false };
    }
  }
  removeBackend(t) {
    if (!(t in this.registryFactory))
      throw new Error(`${t} backend not found in registry`);
    this.backendName === t && this.pendingBackendInit != null && this.pendingBackendInitId++, t in this.registry && (this.disposeRegisteredKernels(t), this.registry[t].dispose(), delete this.registry[t]), delete this.registryFactory[t], this.backendName === t && (this.pendingBackendInit = null, this.backendName = null, this.backendInstance = null);
  }
  getSortedBackends() {
    if (Object.keys(this.registryFactory).length === 0)
      throw new Error("No backend found in registry.");
    return Object.keys(this.registryFactory).sort((t, e) => this.registryFactory[e].priority - this.registryFactory[t].priority);
  }
  initializeBackendsAndReturnBest() {
    const t = this.getSortedBackends();
    for (let e = 0; e < t.length; e++) {
      const s = t[e], { success: o, asyncInit: r } = this.initializeBackend(s);
      if (r || o)
        return { name: s, asyncInit: r };
    }
    throw new Error("Could not initialize any backends, all backend initializations failed.");
  }
  moveData(t, e) {
    const s = this.state.tensorInfo.get(e), o = s.backend, r = this.readSync(e), i6 = o.refCount(e);
    o.disposeData(e, true), s.backend = t, t.move(e, r, s.shape, s.dtype, i6), this.shouldCheckForMemLeaks() && this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
  }
  tidy(t, e) {
    let s = null;
    if (e == null) {
      if (typeof t != "function")
        throw new Error("Please provide a function to tidy()");
      e = t;
    } else {
      if (typeof t != "string" && !(t instanceof String))
        throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
      if (typeof e != "function")
        throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
      s = t;
    }
    let o;
    return this.scopedRun(() => this.startScope(s), () => this.endScope(o), () => (o = e(), o instanceof Promise && console.error("Cannot return a Promise inside of tidy."), o));
  }
  scopedRun(t, e, s) {
    t();
    try {
      const o = s();
      return e(), o;
    } catch (o) {
      throw e(), o;
    }
  }
  nextTensorId() {
    return rr.nextTensorId++;
  }
  nextVariableId() {
    return rr.nextVariableId++;
  }
  /**
   * This method is called instead of the public-facing tensor.clone() when
   * saving a tensor for backwards pass. It makes sure to add the clone
   * operation to the tape regardless of being called inside a kernel
   * execution.
   */
  clone(t) {
    const e = $.runKernel(Ei, { x: t }), s = { x: t }, o = (i6) => ({
      x: () => {
        const a = "float32", l = { x: i6 }, c = { dtype: a };
        return $.runKernel(
          xi,
          l,
          // tslint:disable-next-line: no-unnecessary-type-assertion
          c
        );
      }
    }), r = [];
    return this.addTapeNode(this.state.activeScope.name, s, [e], o, r, {}), e;
  }
  /**
   * Execute a kernel with the given name and return the output tensor.
   *
   * @param kernelName The name of the kernel to execute.
   * @param inputs A map of input names to tensors.
   * @param attrs A map of attribute names to their values. An attribute is a
   *     primitive (non-tensor) input to the kernel.
   * @param inputsToSave A list of tensors, inputs to save for the backprop
   *     computation.
   * @param outputsToSave A list of booleans, specifying which output to save
   *     for the backprop computation. These are booleans since the output
   * tensors are not visible to the user.
   */
  runKernel(t, e, s) {
    if (this.backendName == null && this.backend, !(od(t, this.backendName) != null))
      throw new Error(`Kernel '${t}' not registered for backend '${this.backendName}'`);
    return this.runKernelFunc({ kernelName: t, inputs: e, attrs: s });
  }
  shouldCheckForMemLeaks() {
    return this.ENV.getBool("IS_TEST");
  }
  checkKernelForMemLeak(t, e, s) {
    const o = this.backend.numDataIds();
    let r = 0;
    s.forEach((l) => {
      r += l.dtype === "complex64" ? 3 : 1;
    });
    const i6 = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1], a = o - e - r - i6;
    if (a > 0)
      throw new Error(`Backend '${this.backendName}' has an internal memory leak (${a} data ids) after running '${t}'`);
  }
  /**
   * Internal helper method to execute a kernel Func
   *
   * Use `runKernel` to execute kernels from outside of engine.
   */
  runKernelFunc(t) {
    let e, s = [];
    const o = this.isTapeOn(), r = this.state.numBytes, i6 = this.state.numTensors;
    this.shouldCheckForMemLeaks() && this.state.numDataMovesStack.push(0);
    let a;
    this.backendName == null && this.backend;
    let l;
    const c = Iu(t) ? t.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
    if (Iu(t)) {
      const { kernelName: f, inputs: m, attrs: g6 } = t;
      this.backendName == null && this.backend;
      const b6 = od(f, this.backendName);
      v2(b6 != null, () => `Cannot find registered kernel '${f}' for backend '${this.backendName}'`), a = () => {
        const x6 = this.backend.numDataIds();
        l = b6.kernelFunc({ inputs: m, attrs: g6, backend: this.backend });
        const w6 = Array.isArray(l) ? l : [l];
        this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(f, x6, w6);
        const y6 = w6.map((I) => I.rank != null ? I : this.makeTensorFromTensorInfo(I));
        if (o) {
          const I = this.getTensorsForGradient(f, m, y6);
          s = this.saveTensorsForBackwardMode(I);
        }
        return y6;
      };
    } else {
      const { forwardFunc: f } = t, m = (g6) => {
        o && (s = g6.map((b6) => this.keep(this.clone(b6))));
      };
      a = () => {
        const g6 = this.backend.numDataIds();
        l = this.tidy(() => f(this.backend, m));
        const b6 = Array.isArray(l) ? l : [l];
        return this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(c, g6, b6), b6;
      };
    }
    const { inputs: u, attrs: d } = t, h6 = Iu(t) ? null : t.backwardsFunc;
    let p6;
    return this.scopedRun(
      // Stop recording to a tape when running a kernel.
      () => this.state.kernelDepth++,
      () => this.state.kernelDepth--,
      () => {
        !this.ENV.getBool("DEBUG") && !this.state.profiling ? e = a() : (p6 = this.profiler.profileKernel(c, u, () => a()), this.ENV.getBool("DEBUG") && this.profiler.logKernelProfile(p6), e = p6.outputs);
      }
    ), o && this.addTapeNode(c, u, e, h6, s, d), this.state.profiling && this.state.activeProfile.kernels.push({
      name: c,
      bytesAdded: this.state.numBytes - r,
      totalBytesSnapshot: this.state.numBytes,
      tensorsAdded: this.state.numTensors - i6,
      totalTensorsSnapshot: this.state.numTensors,
      inputShapes: Object.keys(u).map((f) => u[f] != null ? u[f].shape : null),
      outputShapes: e.map((f) => f.shape),
      kernelTimeMs: p6.timeMs,
      extraInfo: p6.extraInfo
    }), Array.isArray(l) ? e : e[0];
  }
  /**
   * Saves tensors used in forward mode for use in backward mode.
   *
   * @param tensors the list of tensors to save.
   */
  saveTensorsForBackwardMode(t) {
    return t.map((s) => this.keep(this.clone(s)));
  }
  /**
   * Returns a list of tensors to save for a given gradient calculation.
   *
   * @param kernelName name of kernel to look up gradient for.
   * @param inputs a map of input tensors.
   * @param outputs an array of output tensors from forward mode of kernel.
   */
  getTensorsForGradient(t, e, s) {
    const o = Hf(t);
    if (o != null) {
      const r = o.inputsToSave || [], i6 = o.outputsToSave || [];
      let a;
      o.saveAllInputs ? (v2(Array.isArray(e), () => "saveAllInputs is true, expected inputs to be an array."), a = Object.keys(e).map((c) => e[c])) : a = r.map((c) => e[c]);
      const l = s.filter((c, u) => i6[u]);
      return a.concat(l);
    }
    return [];
  }
  /**
   * Internal method used by public APIs for tensor creation. Makes a new
   * tensor with the provided shape, dtype and values. It always
   * creates a new data id and writes the values to the underlying backend.
   */
  makeTensor(t, e, s, o) {
    if (t == null)
      throw new Error("Values passed to engine.makeTensor() are null");
    s = s || "float32", o = o || this.backend;
    let r = t;
    s === "string" && mr(t[0]) && (r = t.map((l) => hs(l)));
    const i6 = o.write(r, e, s), a = new Lt(e, s, i6, this.nextTensorId());
    if (this.trackTensor(a, o), s === "string") {
      const l = this.state.tensorInfo.get(i6), c = Vg(r);
      this.state.numBytes += c - l.bytes, l.bytes = c;
    }
    return a;
  }
  /**
   * Internal method used by backends. Makes a new tensor
   * that is a wrapper around an existing data id. It doesn't create
   * a new data id, only increments the ref count used in memory tracking.
   * @deprecated
   */
  makeTensorFromDataId(t, e, s, o) {
    s = s || "float32";
    const r = { dataId: t, shape: e, dtype: s };
    return this.makeTensorFromTensorInfo(r, o);
  }
  /**
   * Internal method used by backends. Makes a new tensor that is a wrapper
   * around an existing data id in TensorInfo. It doesn't create a new data id,
   * only increments the ref count used in memory tracking.
   */
  makeTensorFromTensorInfo(t, e) {
    const { dataId: s, shape: o, dtype: r } = t, i6 = new Lt(o, r, s, this.nextTensorId());
    return this.trackTensor(i6, e), i6;
  }
  makeVariable(t, e = true, s, o) {
    s = s || this.nextVariableId().toString(), o != null && o !== t.dtype && (t = t.cast(o));
    const r = new al(t, e, s, this.nextTensorId());
    if (this.state.registeredVariables[r.name] != null)
      throw new Error(`Variable with name ${r.name} was already registered`);
    return this.state.registeredVariables[r.name] = r, this.incRef(r, this.backend), r;
  }
  trackTensor(t, e) {
    this.state.numTensors++, t.dtype === "string" && this.state.numStringTensors++;
    let s = 0;
    t.dtype !== "complex64" && t.dtype !== "string" && (s = t.size * Ur(t.dtype)), this.state.numBytes += s, this.state.tensorInfo.has(t.dataId) || (this.state.numDataBuffers++, this.state.tensorInfo.set(t.dataId, {
      backend: e || this.backend,
      dtype: t.dtype,
      shape: t.shape,
      bytes: s
    })), t instanceof al || this.track(t);
  }
  // Track the tensor by dataId and increase the refCount for the dataId in the
  // backend.
  // TODO(pyu10055): This is currently used by makeVariable method, to increase
  // refCount on the backend for the dataId. It can potentially be replaced with
  // Identity op indead of calling backend directly.
  incRef(t, e) {
    this.trackTensor(t, e), this.backend.incRef(t.dataId);
  }
  removeDataId(t, e) {
    this.state.tensorInfo.has(t) && this.state.tensorInfo.get(t).backend === e && (this.state.tensorInfo.delete(t), this.state.numDataBuffers--);
  }
  disposeTensor(t) {
    if (!this.state.tensorInfo.has(t.dataId))
      return;
    const e = this.state.tensorInfo.get(t.dataId);
    if (this.state.numTensors--, t.dtype === "string" && (this.state.numStringTensors--, this.state.numBytes -= e.bytes), t.dtype !== "complex64" && t.dtype !== "string") {
      const s = t.size * Ur(t.dtype);
      this.state.numBytes -= s;
    }
    e.backend.disposeData(t.dataId) && this.removeDataId(t.dataId, e.backend);
  }
  disposeVariables() {
    for (const t in this.state.registeredVariables) {
      const e = this.state.registeredVariables[t];
      this.disposeVariable(e);
    }
  }
  disposeVariable(t) {
    this.disposeTensor(t), this.state.registeredVariables[t.name] != null && delete this.state.registeredVariables[t.name];
  }
  memory() {
    const t = this.backend.memory();
    return t.numTensors = this.state.numTensors, t.numDataBuffers = this.state.numDataBuffers, t.numBytes = this.state.numBytes, this.state.numStringTensors > 0 && (t.unreliable = true, t.reasons == null && (t.reasons = []), t.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")), t;
  }
  async profile(t) {
    this.state.profiling = true;
    const e = this.state.numBytes, s = this.state.numTensors;
    this.state.activeProfile.kernels = [], this.state.activeProfile.result = await t(), this.state.profiling = false, this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((o) => o.totalBytesSnapshot)), this.state.activeProfile.newBytes = this.state.numBytes - e, this.state.activeProfile.newTensors = this.state.numTensors - s;
    for (const o of this.state.activeProfile.kernels)
      o.kernelTimeMs = await o.kernelTimeMs, o.extraInfo = await o.extraInfo;
    return this.state.activeProfile;
  }
  isTapeOn() {
    return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
  }
  addTapeNode(t, e, s, o, r, i6) {
    const a = { id: this.state.nextTapeNodeId++, kernelName: t, inputs: e, outputs: s, saved: r }, l = Hf(t);
    l != null && (o = l.gradFunc), o != null && (a.gradient = (c) => (c = c.map((u, d) => {
      if (u == null) {
        const h6 = s[d], p6 = Se(h6.size, h6.dtype);
        return this.makeTensor(p6, h6.shape, h6.dtype);
      }
      return u;
    }), o(c.length > 1 ? c : c[0], r, i6))), this.state.activeTape.push(a);
  }
  keep(t) {
    return t.kept = true, t;
  }
  startTape() {
    this.state.gradientDepth === 0 && (this.state.activeTape = []), this.state.gradientDepth++;
  }
  endTape() {
    this.state.gradientDepth--;
  }
  /**
   * Start a scope. Use this with endScope() to achieve the same functionality
   * as scope() without the need for a function closure.
   */
  startScope(t) {
    const e = {
      track: [],
      name: "unnamed scope",
      id: this.state.nextScopeId++
    };
    t && (e.name = t), this.state.scopeStack.push(e), this.state.activeScope = e;
  }
  /**
   * End a scope. Use this with startScope() to achieve the same functionality
   * as scope() without the need for a function closure.
   */
  endScope(t) {
    const e = fs(t), s = new Set(e.map((r) => r.id));
    for (let r = 0; r < this.state.activeScope.track.length; r++) {
      const i6 = this.state.activeScope.track[r];
      !i6.kept && !s.has(i6.id) && i6.dispose();
    }
    const o = this.state.scopeStack.pop();
    this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1], e.forEach((r) => {
      !r.kept && r.scopeId === o.id && this.track(r);
    });
  }
  /**
   * Returns gradients of `f` with respect to each of the `xs`. The gradients
   * returned are of the same length as `xs`, but some might be null if `f`
   * was not a function of that `x`. It also takes optional dy to multiply the
   * gradient, which defaults to `1`.
   */
  gradients(t, e, s, o = false) {
    if (v2(e.length > 0, () => "gradients() received an empty list of xs."), s != null && s.dtype !== "float32")
      throw new Error(`dy must have 'float32' dtype, but has '${s.dtype}'`);
    const r = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", t));
    v2(r instanceof Lt, () => "The result y returned by f() must be a tensor.");
    const i6 = iC(this.state.activeTape, e, r);
    if (!o && i6.length === 0 && e.length > 0)
      throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
    return this.tidy("backward", () => {
      const a = {};
      a[r.id] = s ?? mC(r.shape), aC(
        a,
        i6,
        // Pass the tidy function to avoid circular dep with `tape.ts`.
        (c) => this.tidy(c),
        // Pass an add function to avoide a circular dep with `tape.ts`.
        gC
      );
      const l = e.map((c) => a[c.id]);
      return this.state.gradientDepth === 0 && (this.state.activeTape.forEach((c) => {
        for (const u of c.saved)
          u.dispose();
      }), this.state.activeTape = null), { value: r, grads: l };
    });
  }
  customGrad(t) {
    return v2(Vs(t), () => "The f passed in customGrad(f) must be a function."), (...e) => {
      v2(e.every((a) => a instanceof Lt), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
      let s;
      const o = {};
      e.forEach((a, l) => {
        o[l] = a;
      });
      const r = (a, l) => (s = t(...e, l), v2(s.value instanceof Lt, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor"), v2(Vs(s.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function."), s.value), i6 = (a, l) => {
        const c = s.gradFunc(a, l), u = Array.isArray(c) ? c : [c];
        v2(u.length === e.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...)."), v2(u.every((h6) => h6 instanceof Lt), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
        const d = {};
        return u.forEach((h6, p6) => {
          d[p6] = () => h6;
        }), d;
      };
      return this.runKernelFunc({
        forwardFunc: r,
        backwardsFunc: i6,
        inputs: o
      });
    };
  }
  readSync(t) {
    return this.state.tensorInfo.get(t).backend.readSync(t);
  }
  read(t) {
    return this.state.tensorInfo.get(t).backend.read(t);
  }
  readToGPU(t, e) {
    return this.state.tensorInfo.get(t).backend.readToGPU(t, e);
  }
  async time(t) {
    const e = Ce(), s = await this.backend.time(t);
    return s.wallMs = Ce() - e, s;
  }
  /**
   * Tracks a Tensor in the current scope to be automatically cleaned up
   * when the current scope ends, and returns the value.
   *
   * @param result The Tensor to track in the current scope.
   */
  track(t) {
    return this.state.activeScope != null && (t.scopeId = this.state.activeScope.id, this.state.activeScope.track.push(t)), t;
  }
  get registeredVariables() {
    return this.state.registeredVariables;
  }
  /**
   * Resets the engine state. Removes all backends but does not remove
   * registered backend factories.
   */
  reset() {
    this.pendingBackendInitId++, this.state.dispose(), this.ENV.reset(), this.state = new em();
    for (const t in this.registry)
      this.disposeRegisteredKernels(t), this.registry[t].dispose(), delete this.registry[t];
    this.backendName = null, this.backendInstance = null, this.pendingBackendInit = null;
  }
};
rr.nextTensorId = 0;
rr.nextVariableId = 0;
function mC(n) {
  const t = Fl(O(n), "float32");
  return $.makeTensor(t, n, "float32");
}
function fb() {
  const n = Og();
  if (n._tfengine == null) {
    const t = new XI(n);
    n._tfengine = new rr(t);
  }
  return KI(n._tfengine.ENV), uC(() => n._tfengine), n._tfengine;
}
var $ = fb();
function gC(n, t) {
  const e = { a: n, b: t };
  return $.runKernel(br, e);
}
function bC() {
  return typeof navigator < "u" && navigator != null;
}
var hd;
function xC(n) {
  hd = n;
}
function Xh(n) {
  if (hd !== void 0)
    return hd;
  if (n || bC()) {
    if (n || (n = navigator), n.product === "ReactNative")
      return true;
    const t = n.userAgent || n.vendor || // tslint:disable-next-line:no-any
    (typeof window < "u" ? window.opera : "");
    if (!t) {
      const e = n;
      return e.userAgentData && e.userAgentData.mobile;
    }
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t) || // tslint:disable-next-line:max-line-length
    /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0, 4));
  }
  return false;
}
function Ph() {
  return typeof window < "u" && window.document != null || //@ts-ignore
  typeof WorkerGlobalScope < "u";
}
var z4 = Object.freeze(Object.defineProperty({
  __proto__: null,
  isBrowser: Ph,
  isMobile: Xh,
  mockIsMobile: xC
}, Symbol.toStringTag, { value: "Module" }));
var hn = F();
hn.registerFlag("DEBUG", () => false, (n) => {
  n && console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
});
hn.registerFlag("IS_BROWSER", () => Ph());
hn.registerFlag("IS_NODE", () => typeof process < "u" && typeof process.versions < "u" && typeof process.versions.node < "u");
hn.registerFlag("IS_CHROME", () => typeof navigator < "u" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
hn.registerFlag("PROD", () => false);
hn.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => hn.getBool("DEBUG"));
hn.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
hn.registerFlag("IS_TEST", () => false);
hn.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => true);
hn.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);
hn.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", () => false);
hn.registerFlag("USE_SETTIMEOUTCUSTOM", () => false);
function aa(n, t) {
  let e = n;
  if (dn(n))
    return t === "string" ? [] : [n.length];
  if (typeof n == "object") {
    if ("texture" in n) {
      const r = n.channels || "RGBA";
      return [n.height, n.width * r.length];
    } else if ("buffer" in n && !(n.buffer instanceof ArrayBuffer))
      return [n.buffer.size / (t == null ? 4 : Ur(t))];
  }
  if (!Array.isArray(n))
    return [];
  const o = [];
  for (; Array.isArray(e) || dn(e) && t !== "string"; )
    o.push(e.length), e = e[0];
  return Array.isArray(n) && F().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY") && mb(n, o, []), o;
}
function mb(n, t, e) {
  if (e = e || [], !Array.isArray(n) && !dn(n)) {
    v2(t.length === 0, () => `Element arr[${e.join("][")}] is a primitive, but should be an array/TypedArray of ${t[0]} elements`);
    return;
  }
  v2(t.length > 0, () => `Element arr[${e.join("][")}] should be a primitive, but is an array of ${n.length} elements`), v2(n.length === t[0], () => `Element arr[${e.join("][")}] should have ${t[0]} elements, but has ${n.length} elements`);
  const s = t.slice(1);
  for (let o = 0; o < n.length; ++o)
    mb(n[o], s, e.concat(o));
}
function nm(n, t, e, s) {
  if (n !== "string_or_numeric") {
    if (n == null)
      throw new Error("Expected dtype cannot be null.");
    if (n !== "numeric" && n !== t || n === "numeric" && t === "string")
      throw new Error(`Argument '${e}' passed to '${s}' must be ${n} tensor, but got ${t} tensor`);
  }
}
function T(n, t, e, s = "numeric") {
  if (n instanceof Lt)
    return nm(s, n.dtype, t, e), n;
  let o = gr(n);
  if (o !== "string" && ["bool", "int32", "float32"].indexOf(s) >= 0 && (o = s), nm(s, o, t, e), n == null || !dn(n) && !Array.isArray(n) && typeof n != "number" && typeof n != "boolean" && typeof n != "string") {
    const l = n == null ? "null" : n.constructor.name;
    throw new Error(`Argument '${t}' passed to '${e}' must be a Tensor or TensorLike, but got '${l}'`);
  }
  const r = aa(n, o);
  !dn(n) && !Array.isArray(n) && (n = [n]);
  const a = o !== "string" ? Zs(n, o) : zs(n, [], true);
  return $.makeTensor(a, r, o);
}
function Ah(n, t, e, s = "numeric") {
  if (!Array.isArray(n))
    throw new Error(`Argument ${t} passed to ${e} must be a \`Tensor[]\` or \`TensorLike[]\``);
  return n.map((r, i6) => T(r, `${t}[${i6}]`, e, s));
}
var yC = "__op";
function L(n) {
  const t = Object.keys(n);
  if (t.length !== 1)
    throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${t.length} keys.`);
  let e = t[0];
  const s = n[e];
  e.endsWith("_") && (e = e.substring(0, e.length - 1)), e = e + yC;
  const o = (...r) => {
    $.startScope(e);
    try {
      const i6 = s(...r);
      return ui(i6) && console.error("Cannot return a Promise inside of tidy."), $.endScope(i6), i6;
    } catch (i6) {
      throw $.endScope(null), i6;
    }
  };
  return Object.defineProperty(o, "name", { value: e, configurable: true }), o;
}
function wC(n, t) {
  const e = T(n, "real", "complex"), s = T(t, "imag", "complex");
  Ve(e.shape, s.shape, `real and imag shapes, ${e.shape} and ${s.shape}, must match in call to tf.complex().`);
  const o = { real: e, imag: s };
  return $.runKernel(Jd, o);
}
var bo = L({ complex_: wC });
function la(n, t, e, s) {
  if (s == null)
    s = gr(n);
  else if (s === "complex64")
    throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
  if (typeof n == "object" && ("texture" in n || "buffer" in n && !(n.buffer instanceof ArrayBuffer))) {
    if (s !== "float32" && s !== "int32")
      throw new Error(`Creating tensor from GPU data only supports 'float32'|'int32' dtype, while the dtype is ${s}.`);
    return $.backend.createTensorFromGPUData(n, t || e, s);
  }
  if (!dn(n) && !Array.isArray(n) && typeof n != "number" && typeof n != "boolean" && typeof n != "string")
    throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
  if (t != null) {
    is(t);
    const o = O(t), r = O(e);
    v2(o === r, () => `Based on the provided shape, [${t}], the tensor should have ${o} values but has ${r}`);
    for (let i6 = 0; i6 < e.length; ++i6) {
      const a = e[i6], l = i6 === e.length - 1 ? a !== O(t.slice(i6)) : true;
      v2(e[i6] === t[i6] || !l, () => `Error creating a new Tensor. Inferred shape (${e}) does not match the provided shape (${t}). `);
    }
  }
  return !dn(n) && !Array.isArray(n) && (n = [n]), t = t || e, n = s !== "string" ? Zs(n, s) : zs(n, [], true), $.makeTensor(n, t, s);
}
function Re(n, t, e) {
  const s = aa(n, e);
  return la(n, t, s, e);
}
var pd = {
  float32: 4,
  float16: 2,
  int32: 4,
  uint16: 2,
  uint8: 1,
  bool: 1,
  complex64: 8
};
var ll = 4;
async function sm(n, t) {
  const e = [], s = [], o = Array.isArray(n) ? n.map((i6) => i6.name) : Object.keys(n);
  for (let i6 = 0; i6 < o.length; ++i6) {
    const a = o[i6], l = Array.isArray(n) ? n[i6].tensor : n[a];
    if (l.dtype !== "float32" && l.dtype !== "int32" && l.dtype !== "bool" && l.dtype !== "string" && l.dtype !== "complex64")
      throw new Error(`Unsupported dtype in weight '${a}': ${l.dtype}`);
    const c = { name: a, shape: l.shape, dtype: l.dtype };
    if (l.dtype === "string") {
      const u = new Promise(async (d) => {
        const h6 = await l.bytes(), p6 = h6.reduce((g6, b6) => g6 + b6.length, 0) + ll * h6.length, f = new Uint8Array(p6);
        let m = 0;
        for (let g6 = 0; g6 < h6.length; g6++) {
          const b6 = h6[g6], x6 = new Uint8Array(new Uint32Array([b6.length]).buffer);
          f.set(x6, m), m += ll, f.set(b6, m), m += b6.length;
        }
        d(f);
      });
      s.push(u);
    } else
      s.push(l.data());
    t != null && (c.group = t), e.push(c);
  }
  const r = await Promise.all(s);
  return { data: IC(r), specs: e };
}
function gb(n, t) {
  const e = {};
  let s, o = 0;
  for (const r of t) {
    const i6 = r.name, a = r.dtype, l = r.shape, c = O(l);
    let u;
    if ("quantization" in r) {
      const d = r.quantization;
      if (d.dtype === "uint8" || d.dtype === "uint16") {
        if (!("min" in d && "scale" in d))
          throw new Error(`Weight ${r.name} with quantization ${d.dtype} doesn't have corresponding metadata min and scale.`);
      } else if (d.dtype === "float16") {
        if (a !== "float32")
          throw new Error(`Weight ${r.name} is quantized with ${d.dtype} which only supports weights of type float32 not ${a}.`);
      } else
        throw new Error(`Weight ${r.name} has unknown quantization dtype ${d.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
      const h6 = pd[d.dtype], p6 = n.slice(o, o + c * h6), f = d.dtype === "uint8" ? new Uint8Array(p6) : new Uint16Array(p6);
      if (a === "float32")
        if (d.dtype === "uint8" || d.dtype === "uint16") {
          u = new Float32Array(f.length);
          for (let m = 0; m < f.length; m++) {
            const g6 = f[m];
            u[m] = g6 * d.scale + d.min;
          }
        } else if (d.dtype === "float16")
          s === void 0 && (s = EC()), u = s(f);
        else
          throw new Error(`Unsupported quantization type ${d.dtype} for weight type float32.`);
      else if (a === "int32") {
        if (d.dtype !== "uint8" && d.dtype !== "uint16")
          throw new Error(`Unsupported quantization type ${d.dtype} for weight type int32.`);
        u = new Int32Array(f.length);
        for (let m = 0; m < f.length; m++) {
          const g6 = f[m];
          u[m] = Math.round(g6 * d.scale + d.min);
        }
      } else
        throw new Error(`Unsupported dtype in weight '${i6}': ${a}`);
      o += c * h6;
    } else if (a === "string") {
      const d = O(r.shape);
      u = [];
      for (let h6 = 0; h6 < d; h6++) {
        const p6 = new Uint32Array(n.slice(o, o + ll))[0];
        o += ll;
        const f = new Uint8Array(n.slice(o, o + p6));
        u.push(f), o += p6;
      }
    } else {
      const d = pd[a], h6 = n.slice(o, o + c * d);
      if (a === "float32")
        u = new Float32Array(h6);
      else if (a === "int32")
        u = new Int32Array(h6);
      else if (a === "bool")
        u = new Uint8Array(h6);
      else if (a === "complex64") {
        u = new Float32Array(h6);
        const p6 = new Float32Array(u.length / 2), f = new Float32Array(u.length / 2);
        for (let b6 = 0; b6 < p6.length; b6++)
          p6[b6] = u[b6 * 2], f[b6] = u[b6 * 2 + 1];
        const m = Re(p6, l, "float32"), g6 = Re(f, l, "float32");
        e[i6] = bo(m, g6), m.dispose(), g6.dispose();
      } else
        throw new Error(`Unsupported dtype in weight '${i6}': ${a}`);
      o += c * d;
    }
    a !== "complex64" && (e[i6] = Re(u, l, a));
  }
  return e;
}
function IC(n) {
  if (n === null)
    throw new Error(`Invalid input value: ${JSON.stringify(n)}`);
  let t = 0;
  const e = [];
  n.forEach((r) => {
    if (t += r.byteLength, e.push(r.byteLength === r.buffer.byteLength ? r : new r.constructor(r)), !(r instanceof Float32Array || r instanceof Int32Array || r instanceof Uint8Array))
      throw new Error(`Unsupported TypedArray subtype: ${r.constructor.name}`);
  });
  const s = new Uint8Array(t);
  let o = 0;
  return e.forEach((r) => {
    s.set(new Uint8Array(r.buffer), o), o += r.byteLength;
  }), s.buffer;
}
var Oh = typeof Buffer < "u" && (typeof Blob > "u" || typeof atob > "u" || typeof btoa > "u");
function om(n) {
  return Oh ? Buffer.byteLength(n) : new Blob([n]).size;
}
function CC(n) {
  if (Oh)
    return Buffer.from(n).toString("base64");
  const t = new Uint8Array(n);
  let e = "";
  for (let s = 0, o = t.length; s < o; s++)
    e += String.fromCharCode(t[s]);
  return btoa(e);
}
function vC(n) {
  if (Oh) {
    const s = Buffer.from(n, "base64");
    return s.buffer.slice(s.byteOffset, s.byteOffset + s.byteLength);
  }
  const t = atob(n), e = new Uint8Array(t.length);
  for (let s = 0; s < t.length; ++s)
    e.set([t.charCodeAt(s)], s);
  return e.buffer;
}
function bb(n) {
  if (n.length === 1)
    return n[0];
  let t = 0;
  n.forEach((o) => {
    t += o.byteLength;
  });
  const e = new Uint8Array(t);
  let s = 0;
  return n.forEach((o) => {
    e.set(new Uint8Array(o), s), s += o.byteLength;
  }), e.buffer;
}
function X4(n) {
  const t = "/";
  for (n = n.trim(); n.endsWith(t); )
    n = n.slice(0, n.length - 1);
  const e = n.split(t);
  return e[e.length - 1];
}
function SC(n, t) {
  const e = {
    modelTopology: n.modelTopology,
    format: n.format,
    generatedBy: n.generatedBy,
    convertedBy: n.convertedBy,
    weightsManifest: t
  };
  return n.signature != null && (e.signature = n.signature), n.userDefinedMetadata != null && (e.userDefinedMetadata = n.userDefinedMetadata), n.modelInitializer != null && (e.modelInitializer = n.modelInitializer), n.initializerSignature != null && (e.initializerSignature = n.initializerSignature), n.trainingConfig != null && (e.trainingConfig = n.trainingConfig), e;
}
function kC(n, t, e) {
  const s = {
    modelTopology: n.modelTopology,
    format: n.format,
    generatedBy: n.generatedBy,
    convertedBy: n.convertedBy
  };
  if (n.trainingConfig != null && (s.trainingConfig = n.trainingConfig), n.weightsManifest != null) {
    if (!t)
      throw new Error("modelJSON has weightsManifest but weightSpecs is null");
    if (!e)
      throw new Error("modelJSON has weightsManifest but weightData is null");
    s.weightSpecs = t, s.weightData = e;
  }
  return n.signature != null && (s.signature = n.signature), n.userDefinedMetadata != null && (s.userDefinedMetadata = n.userDefinedMetadata), n.modelInitializer != null && (s.modelInitializer = n.modelInitializer), n.initializerSignature != null && (s.initializerSignature = n.initializerSignature), s;
}
async function TC(n, t) {
  let e, s;
  return n.weightsManifest != null && ([e, s] = await t(n.weightsManifest)), kC(n, e, s);
}
function Kh(n) {
  if (n.modelTopology instanceof ArrayBuffer)
    throw new Error("Expected JSON model topology, received ArrayBuffer.");
  return {
    dateSaved: /* @__PURE__ */ new Date(),
    modelTopologyType: "JSON",
    modelTopologyBytes: n.modelTopology == null ? 0 : om(JSON.stringify(n.modelTopology)),
    weightSpecsBytes: n.weightSpecs == null ? 0 : om(JSON.stringify(n.weightSpecs)),
    weightDataBytes: n.weightData == null ? 0 : n.weightData.byteLength
  };
}
function NC(n) {
  const t = [];
  for (const e of n)
    t.push(...e.weights);
  return t;
}
function RC() {
  const n = (e) => {
    let s = e << 13, o = 0;
    for (; !(s & 8388608); )
      o -= 8388608, s <<= 1;
    return s &= -8388609, o += 947912704, s | o;
  }, t = new Uint32Array(2048);
  t[0] = 0;
  for (let e = 1; e < 1024; e++)
    t[e] = n(e);
  for (let e = 1024; e < 2048; e++)
    t[e] = 939524096 + (e - 1024 << 13);
  return t;
}
function $C() {
  const n = new Uint32Array(64);
  n[0] = 0, n[31] = 1199570944, n[32] = 2147483648, n[63] = 3347054592;
  for (let t = 1; t < 31; t++)
    n[t] = t << 23;
  for (let t = 33; t < 63; t++)
    n[t] = 2147483648 + (t - 32 << 23);
  return n;
}
function GC() {
  const n = new Uint32Array(64);
  for (let t = 0; t < 64; t++)
    n[t] = 1024;
  return n[0] = n[32] = 0, n;
}
function EC() {
  const n = RC(), t = $C(), e = GC();
  return (s) => {
    const o = new ArrayBuffer(4 * s.length), r = new Uint32Array(o);
    for (let i6 = 0; i6 < s.length; i6++) {
      const a = s[i6], l = n[e[a >> 10] + (a & 1023)] + t[a >> 10];
      r[i6] = l;
    }
    return new Float32Array(o);
  };
}
var ee = class {
  constructor() {
    this.saveRouters = [], this.loadRouters = [];
  }
  static getInstance() {
    return ee.instance == null && (ee.instance = new ee()), ee.instance;
  }
  /**
   * Register a save-handler router.
   *
   * @param saveRouter A function that maps a URL-like string onto an instance
   * of `IOHandler` with the `save` method defined or `null`.
   */
  static registerSaveRouter(t) {
    ee.getInstance().saveRouters.push(t);
  }
  /**
   * Register a load-handler router.
   *
   * @param loadRouter A function that maps a URL-like string onto an instance
   * of `IOHandler` with the `load` method defined or `null`.
   */
  static registerLoadRouter(t) {
    ee.getInstance().loadRouters.push(t);
  }
  /**
   * Look up IOHandler for saving, given a URL-like string.
   *
   * @param url
   * @returns If only one match is found, an instance of IOHandler with the
   * `save` method defined. If no match is found, `null`.
   * @throws Error, if more than one match is found.
   */
  static getSaveHandlers(t) {
    return ee.getHandlers(t, "save");
  }
  /**
   * Look up IOHandler for loading, given a URL-like string.
   *
   * @param url
   * @param loadOptions Optional, custom load options.
   * @returns All valid handlers for `url`, given the currently registered
   *   handler routers.
   */
  static getLoadHandlers(t, e) {
    return ee.getHandlers(t, "load", e);
  }
  static getHandlers(t, e, s) {
    const o = [];
    return (e === "load" ? ee.getInstance().loadRouters : ee.getInstance().saveRouters).forEach((i6) => {
      const a = i6(t, s);
      a !== null && o.push(a);
    }), o;
  }
};
var P4 = (n) => ee.registerSaveRouter(n);
var A4 = (n) => ee.registerLoadRouter(n);
var LC = (n) => ee.getSaveHandlers(n);
var MC = (n, t) => ee.getLoadHandlers(n, t);
var fd = "tensorflowjs";
var md = 1;
var co = "models_store";
var Rs = "model_info_store";
function xb() {
  if (!F().getBool("IS_BROWSER"))
    throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  const n = typeof window > "u" ? self : window, t = n.indexedDB || n.mozIndexedDB || n.webkitIndexedDB || n.msIndexedDB || n.shimIndexedDB;
  if (t == null)
    throw new Error("The current browser does not appear to support IndexedDB.");
  return t;
}
function gd(n) {
  const t = n.result;
  t.createObjectStore(co, { keyPath: "modelPath" }), t.createObjectStore(Rs, { keyPath: "modelPath" });
}
var xo = class {
  constructor(t) {
    if (this.indexedDB = xb(), t == null || !t)
      throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
    this.modelPath = t;
  }
  async save(t) {
    if (t.modelTopology instanceof ArrayBuffer)
      throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    return this.databaseAction(this.modelPath, t);
  }
  async load() {
    return this.databaseAction(this.modelPath);
  }
  /**
   * Perform database action to put model artifacts into or read model artifacts
   * from IndexedDB object store.
   *
   * Whether the action is put or get depends on whether `modelArtifacts` is
   * specified. If it is specified, the action will be put; otherwise the action
   * will be get.
   *
   * @param modelPath A unique string path for the model.
   * @param modelArtifacts If specified, it will be the model artifacts to be
   *   stored in IndexedDB.
   * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`
   *   of `ModelArtifacts`, if the action is get.
   */
  databaseAction(t, e) {
    return new Promise((s, o) => {
      const r = this.indexedDB.open(fd, md);
      r.onupgradeneeded = () => gd(r), r.onsuccess = () => {
        const i6 = r.result;
        if (e == null) {
          const a = i6.transaction(co, "readonly"), c = a.objectStore(co).get(this.modelPath);
          c.onsuccess = () => {
            if (c.result == null)
              return i6.close(), o(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
            s(c.result.modelArtifacts);
          }, c.onerror = (u) => (i6.close(), o(c.error)), a.oncomplete = () => i6.close();
        } else {
          const a = Kh(e), l = i6.transaction(Rs, "readwrite");
          let c = l.objectStore(Rs);
          const u = c.put({ modelPath: this.modelPath, modelArtifactsInfo: a });
          let d;
          u.onsuccess = () => {
            d = i6.transaction(co, "readwrite");
            const p6 = d.objectStore(co).put({
              modelPath: this.modelPath,
              modelArtifacts: e,
              modelArtifactsInfo: a
            });
            p6.onsuccess = () => s({ modelArtifactsInfo: a }), p6.onerror = (f) => {
              c = l.objectStore(Rs);
              const m = c.delete(this.modelPath);
              m.onsuccess = () => (i6.close(), o(p6.error)), m.onerror = (g6) => (i6.close(), o(p6.error));
            };
          }, u.onerror = (h6) => (i6.close(), o(u.error)), l.oncomplete = () => {
            d == null ? i6.close() : d.oncomplete = () => i6.close();
          };
        }
      }, r.onerror = (i6) => o(r.error);
    });
  }
};
xo.URL_SCHEME = "indexeddb://";
var yb = (n) => F().getBool("IS_BROWSER") && !Array.isArray(n) && n.startsWith(xo.URL_SCHEME) ? WC(n.slice(xo.URL_SCHEME.length)) : null;
ee.registerSaveRouter(yb);
ee.registerLoadRouter(yb);
function WC(n) {
  return new xo(n);
}
function DC(n) {
  return n.startsWith(xo.URL_SCHEME) ? n.slice(xo.URL_SCHEME.length) : n;
}
var FC = class {
  constructor() {
    this.indexedDB = xb();
  }
  async listModels() {
    return new Promise((t, e) => {
      const s = this.indexedDB.open(fd, md);
      s.onupgradeneeded = () => gd(s), s.onsuccess = () => {
        const o = s.result, r = o.transaction(Rs, "readonly"), a = r.objectStore(Rs).getAll();
        a.onsuccess = () => {
          const l = {};
          for (const c of a.result)
            l[c.modelPath] = c.modelArtifactsInfo;
          t(l);
        }, a.onerror = (l) => (o.close(), e(a.error)), r.oncomplete = () => o.close();
      }, s.onerror = (o) => e(s.error);
    });
  }
  async removeModel(t) {
    return t = DC(t), new Promise((e, s) => {
      const o = this.indexedDB.open(fd, md);
      o.onupgradeneeded = () => gd(o), o.onsuccess = () => {
        const r = o.result, i6 = r.transaction(Rs, "readwrite"), a = i6.objectStore(Rs), l = a.get(t);
        let c;
        l.onsuccess = () => {
          if (l.result == null)
            return r.close(), s(new Error(`Cannot find model with path '${t}' in IndexedDB.`));
          {
            const u = a.delete(t), d = () => {
              c = r.transaction(co, "readwrite");
              const p6 = c.objectStore(co).delete(t);
              p6.onsuccess = () => e(l.result.modelArtifactsInfo), p6.onerror = (f) => s(l.error);
            };
            u.onsuccess = d, u.onerror = (h6) => (d(), r.close(), s(l.error));
          }
        }, l.onerror = (u) => (r.close(), s(l.error)), i6.oncomplete = () => {
          c == null ? r.close() : c.oncomplete = () => r.close();
        };
      }, o.onerror = (r) => s(o.error);
    });
  }
};
var ds = "/";
var Uo = "tensorflowjs_models";
var wb = "info";
var VC = "model_topology";
var zC = "weight_specs";
var XC = "weight_data";
var PC = "model_metadata";
function Ib(n) {
  return {
    info: [Uo, n, wb].join(ds),
    topology: [Uo, n, VC].join(ds),
    weightSpecs: [Uo, n, zC].join(ds),
    weightData: [Uo, n, XC].join(ds),
    modelMetadata: [Uo, n, PC].join(ds)
  };
}
function Cb(n) {
  for (const t of Object.values(n))
    window.localStorage.removeItem(t);
}
function AC(n) {
  const t = n.split(ds);
  if (t.length < 3)
    throw new Error(`Invalid key format: ${n}`);
  return t.slice(1, t.length - 1).join(ds);
}
function OC(n) {
  return n.startsWith(yo.URL_SCHEME) ? n.slice(yo.URL_SCHEME.length) : n;
}
var yo = class {
  constructor(t) {
    if (!F().getBool("IS_BROWSER") || typeof window > "u" || typeof window.localStorage > "u")
      throw new Error("The current environment does not support local storage.");
    if (this.LS = window.localStorage, t == null || !t)
      throw new Error("For local storage, modelPath must not be null, undefined or empty.");
    this.modelPath = t, this.keys = Ib(this.modelPath);
  }
  /**
   * Save model artifacts to browser local storage.
   *
   * See the documentation to `browserLocalStorage` for details on the saved
   * artifacts.
   *
   * @param modelArtifacts The model artifacts to be stored.
   * @returns An instance of SaveResult.
   */
  async save(t) {
    if (t.modelTopology instanceof ArrayBuffer)
      throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    {
      const e = JSON.stringify(t.modelTopology), s = JSON.stringify(t.weightSpecs), o = Kh(t);
      try {
        this.LS.setItem(this.keys.info, JSON.stringify(o)), this.LS.setItem(this.keys.topology, e), this.LS.setItem(this.keys.weightSpecs, s), this.LS.setItem(this.keys.weightData, CC(t.weightData));
        const r = {
          format: t.format,
          generatedBy: t.generatedBy,
          convertedBy: t.convertedBy,
          signature: t.signature != null ? t.signature : void 0,
          userDefinedMetadata: t.userDefinedMetadata != null ? t.userDefinedMetadata : void 0,
          modelInitializer: t.modelInitializer != null ? t.modelInitializer : void 0,
          initializerSignature: t.initializerSignature != null ? t.initializerSignature : void 0,
          trainingConfig: t.trainingConfig != null ? t.trainingConfig : void 0
        };
        return this.LS.setItem(this.keys.modelMetadata, JSON.stringify(r)), { modelArtifactsInfo: o };
      } catch {
        throw Cb(this.keys), new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${o.modelTopologyBytes}, weightSpecsBytes=${o.weightSpecsBytes}, weightDataBytes=${o.weightDataBytes}.`);
      }
    }
  }
  /**
   * Load a model from local storage.
   *
   * See the documentation to `browserLocalStorage` for details on the saved
   * artifacts.
   *
   * @returns The loaded model (if loading succeeds).
   */
  async load() {
    const t = JSON.parse(this.LS.getItem(this.keys.info));
    if (t == null)
      throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
    if (t.modelTopologyType !== "JSON")
      throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
    const e = {}, s = JSON.parse(this.LS.getItem(this.keys.topology));
    if (s == null)
      throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
    e.modelTopology = s;
    const o = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
    if (o == null)
      throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
    e.weightSpecs = o;
    const r = this.LS.getItem(this.keys.modelMetadata);
    if (r != null) {
      const a = JSON.parse(r);
      e.format = a.format, e.generatedBy = a.generatedBy, e.convertedBy = a.convertedBy, a.signature != null && (e.signature = a.signature), a.userDefinedMetadata != null && (e.userDefinedMetadata = a.userDefinedMetadata), a.modelInitializer != null && (e.modelInitializer = a.modelInitializer), a.initializerSignature != null && (e.initializerSignature = a.initializerSignature), a.trainingConfig != null && (e.trainingConfig = a.trainingConfig);
    }
    const i6 = this.LS.getItem(this.keys.weightData);
    if (i6 == null)
      throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
    return e.weightData = vC(i6), e;
  }
};
yo.URL_SCHEME = "localstorage://";
var vb = (n) => F().getBool("IS_BROWSER") && !Array.isArray(n) && n.startsWith(yo.URL_SCHEME) ? KC(n.slice(yo.URL_SCHEME.length)) : null;
ee.registerSaveRouter(vb);
ee.registerLoadRouter(vb);
function KC(n) {
  return new yo(n);
}
var ZC = class {
  constructor() {
    v2(F().getBool("IS_BROWSER"), () => "Current environment is not a web browser"), v2(typeof window > "u" || typeof window.localStorage < "u", () => "Current browser does not appear to support localStorage"), this.LS = window.localStorage;
  }
  async listModels() {
    const t = {}, e = Uo + ds, s = ds + wb;
    for (let o = 0; o < this.LS.length; ++o) {
      const r = this.LS.key(o);
      if (r.startsWith(e) && r.endsWith(s)) {
        const i6 = AC(r);
        t[i6] = JSON.parse(this.LS.getItem(r));
      }
    }
    return t;
  }
  async removeModel(t) {
    t = OC(t);
    const e = Ib(t);
    if (this.LS.getItem(e.info) == null)
      throw new Error(`Cannot find model at path '${t}'`);
    const s = JSON.parse(this.LS.getItem(e.info));
    return Cb(e), s;
  }
};
var jo = "://";
var Le = class {
  constructor() {
    this.managers = {};
  }
  static getInstance() {
    return Le.instance == null && (Le.instance = new Le()), Le.instance;
  }
  /**
   * Register a save-handler router.
   *
   * @param saveRouter A function that maps a URL-like string onto an instance
   * of `IOHandler` with the `save` method defined or `null`.
   */
  static registerManager(t, e) {
    v2(t != null, () => "scheme must not be undefined or null."), t.endsWith(jo) && (t = t.slice(0, t.indexOf(jo))), v2(t.length > 0, () => "scheme must not be an empty string.");
    const s = Le.getInstance();
    v2(s.managers[t] == null, () => `A model store manager is already registered for scheme '${t}'.`), s.managers[t] = e;
  }
  static getManager(t) {
    const e = Le.getInstance().managers[t];
    if (e == null)
      throw new Error(`Cannot find model manager for scheme '${t}'`);
    return e;
  }
  static getSchemes() {
    return Object.keys(Le.getInstance().managers);
  }
};
function ja(n) {
  if (n.indexOf(jo) === -1)
    throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${Le.getSchemes().join(",")}`);
  return {
    scheme: n.split(jo)[0],
    path: n.split(jo)[1]
  };
}
async function Sb(n, t, e = false) {
  v2(n !== t, () => `Old path and new path are the same: '${n}'`);
  const s = ee.getLoadHandlers(n);
  v2(s.length > 0, () => `Copying failed because no load handler is found for source URL ${n}.`), v2(s.length < 2, () => `Copying failed because more than one (${s.length}) load handlers for source URL ${n}.`);
  const o = s[0], r = ee.getSaveHandlers(t);
  v2(r.length > 0, () => `Copying failed because no save handler is found for destination URL ${t}.`), v2(r.length < 2, () => `Copying failed because more than one (${s.length}) save handlers for destination URL ${t}.`);
  const i6 = r[0], a = ja(n).scheme, l = ja(n).path, c = a === ja(n).scheme, u = await o.load();
  e && c && await Le.getManager(a).removeModel(l);
  const d = await i6.save(u);
  return e && !c && await Le.getManager(a).removeModel(l), d.modelArtifactsInfo;
}
async function O4() {
  const n = Le.getSchemes(), t = {};
  for (const e of n) {
    const s = await Le.getManager(e).listModels();
    for (const o in s) {
      const r = e + jo + o;
      t[r] = s[o];
    }
  }
  return t;
}
async function K4(n) {
  const t = ja(n);
  return Le.getManager(t.scheme).removeModel(t.path);
}
async function Z4(n, t) {
  return Sb(n, t, false);
}
async function B4(n, t) {
  return Sb(n, t, true);
}
var BC = class {
  constructor() {
    this.messageName = "setTimeoutCustom", this.functionRefs = [], this.handledMessageCount = 0, this.hasEventListener = false;
  }
  fetch(t, e) {
    return fetch(t, e);
  }
  now() {
    return performance.now();
  }
  encode(t, e) {
    if (e !== "utf-8" && e !== "utf8")
      throw new Error(`Browser's encoder only supports utf-8, but got ${e}`);
    return this.textEncoder == null && (this.textEncoder = new TextEncoder()), this.textEncoder.encode(t);
  }
  decode(t, e) {
    return new TextDecoder(e).decode(t);
  }
  // If the setTimeout nesting level is greater than 5 and timeout is less
  // than 4ms, timeout will be clamped to 4ms, which hurts the perf.
  // Interleaving window.postMessage and setTimeout will trick the browser and
  // avoid the clamp.
  setTimeoutCustom(t, e) {
    if (typeof window > "u" || !F().getBool("USE_SETTIMEOUTCUSTOM")) {
      setTimeout(t, e);
      return;
    }
    this.functionRefs.push(t), setTimeout(() => {
      window.postMessage({ name: this.messageName, index: this.functionRefs.length - 1 }, "*");
    }, e), this.hasEventListener || (this.hasEventListener = true, window.addEventListener("message", (s) => {
      if (s.source === window && s.data.name === this.messageName) {
        s.stopPropagation();
        const o = this.functionRefs[s.data.index];
        o(), this.handledMessageCount++, this.handledMessageCount === this.functionRefs.length && (this.functionRefs = [], this.handledMessageCount = 0);
      }
    }, true));
  }
  isTypedArray(t) {
    return t instanceof Float32Array || t instanceof Int32Array || t instanceof Uint8Array || t instanceof Uint8ClampedArray;
  }
};
if (F().get("IS_BROWSER")) {
  F().setPlatform("browser", new BC());
  try {
    Le.registerManager(yo.URL_SCHEME, new ZC());
  } catch {
  }
  try {
    Le.registerManager(xo.URL_SCHEME, new FC());
  } catch {
  }
}
var HC = {
  // tslint:disable-next-line:no-require-imports
  importFetch: () => require_browser()
};
var Cu;
var _C = class {
  constructor() {
    this.util = require_util(), this.textEncoder = new this.util.TextEncoder();
  }
  fetch(t, e) {
    return F().global.fetch != null ? F().global.fetch(t, e) : (Cu == null && (Cu = HC.importFetch()), Cu(t, e));
  }
  now() {
    const t = process.hrtime();
    return t[0] * 1e3 + t[1] / 1e6;
  }
  encode(t, e) {
    if (e !== "utf-8" && e !== "utf8")
      throw new Error(`Node built-in encoder only supports utf-8, but got ${e}`);
    return this.textEncoder.encode(t);
  }
  decode(t, e) {
    return t.length === 0 ? "" : new this.util.TextDecoder(e).decode(t);
  }
  isTypedArray(t) {
    return this.util.types.isFloat32Array(t) || this.util.types.isInt32Array(t) || this.util.types.isUint8Array(t) || this.util.types.isUint8ClampedArray(t);
  }
};
F().get("IS_NODE") && !F().get("IS_BROWSER") && F().setPlatform("node", new _C());
function vt(n, t = "float32", e) {
  return t = t || "float32", is(n), new $e(n, t, e);
}
function UC(n, t) {
  const e = T(n, "x", "cast");
  if (!Fg(t))
    throw new Error(`Failed to cast to unknown dtype ${t}`);
  if (t === "string" && e.dtype !== "string" || t !== "string" && e.dtype === "string")
    throw new Error("Only strings can be casted to strings");
  const s = { x: e }, o = { dtype: t };
  return $.runKernel(xi, s, o);
}
var et = L({ cast_: UC });
function YC(n) {
  const e = { x: T(n, "x", "clone", "string_or_numeric") };
  return $.runKernel(Ei, e);
}
var po = L({ clone_: YC });
function QC(n, t = false) {
  console.log(n.toString(t));
}
fb();
var JC = {
  buffer: vt,
  cast: et,
  clone: po,
  print: QC
};
dC(JC);
function H4() {
  F().set("PROD", true);
}
function _4() {
  F().set("DEBUG", true);
}
function U4() {
  F().set("DEPRECATION_WARNINGS_ENABLED", false), console.warn("TensorFlow.js deprecation warnings have been disabled.");
}
function Y4(n) {
  F().getBool("DEPRECATION_WARNINGS_ENABLED") && console.warn(n + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
}
function Q4() {
  $.disposeVariables();
}
function Xt() {
  return $;
}
function cl() {
  return $.memory();
}
function J4(n) {
  return $.profile(n);
}
function D(n, t) {
  return $.tidy(n, t);
}
function yt(n) {
  fs(n).forEach((e) => e.dispose());
}
function cn(n) {
  return $.keep(n);
}
function j4(n) {
  return $.time(n);
}
function q4(n) {
  return $.setBackend(n);
}
function tY() {
  return $.ready();
}
function eY() {
  return $.backendName;
}
function nY(n) {
  $.removeBackend(n);
}
function sY(n) {
  return $.findBackend(n);
}
function oY(n) {
  return $.findBackendFactory(n);
}
function kb(n, t, e = 1) {
  return $.registerBackend(n, t, e);
}
function $s() {
  return $.backend;
}
function rY(n, t) {
  F().setPlatform(n, t);
}
function jC(n, t) {
  let e = T(n, "a", "add"), s = T(t, "b", "add");
  [e, s] = ne(e, s);
  const o = { a: e, b: s };
  return $.runKernel(br, o);
}
var U = L({ add_: jC });
function qC(n, t) {
  let e = T(n, "a", "floorDiv"), s = T(t, "b", "floorDiv");
  [e, s] = ne(e, s);
  const o = { a: e, b: s };
  return $.runKernel($i, o);
}
var Tb = L({ floorDiv_: qC });
function t2(n, t) {
  let e = T(n, "a", "div"), s = T(t, "b", "div");
  if ([e, s] = ne(e, s), e.dtype === "int32" && s.dtype === "int32")
    return Tb(e, s);
  const o = { a: e, b: s }, r = {};
  return $.runKernel(vi, o, r);
}
var ut = L({ div_: t2 });
function e2(n, t) {
  let e = T(n, "a", "mul"), s = T(t, "b", "mul");
  [e, s] = ne(e, s);
  const o = { a: e, b: s };
  return $.runKernel(Pi, o);
}
var G = L({ mul_: e2 });
function n2(n) {
  const t = T(n, "x", "abs");
  if (t.dtype === "complex64") {
    const e = { x: t };
    return $.runKernel(Zl, e);
  } else {
    const e = { x: t };
    return $.runKernel(Vl, e);
  }
}
var fe = L({ abs_: n2 });
function s2(n) {
  const e = { x: T(n, "x", "acos") };
  return $.runKernel(di, e);
}
var o2 = L({ acos_: s2 });
function r2(n) {
  const e = { x: T(n, "x", "acosh") };
  return $.runKernel(hi, e);
}
var i2 = L({ acosh_: r2 });
function a2(n, t = null, e = false) {
  const o = { x: T(n, "x", "all", "bool") }, r = { axis: t, keepDims: e };
  return $.runKernel(Hd, o, r);
}
var Nb = L({ all_: a2 });
function l2(n, t = null, e = false) {
  const o = { x: T(n, "x", "any", "bool") }, r = { axis: t, keepDims: e };
  return $.runKernel(_d, o, r);
}
var bd = L({ any_: l2 });
function c2(n, t = 0) {
  const s = { x: T(n, "x", "argMax") }, o = { axis: t };
  return $.runKernel(zl, s, o);
}
var Qr = L({ argMax_: c2 });
function u2(n, t = 0) {
  const s = { x: T(n, "x", "argMin") }, o = { axis: t };
  return $.runKernel(Xl, s, o);
}
var d2 = L({ argMin_: u2 });
function h2(n) {
  const e = { x: T(n, "x", "asin") };
  return $.runKernel(pi, e);
}
var p2 = L({ asin_: h2 });
function f2(n) {
  const e = { x: T(n, "x", "asinh") };
  return $.runKernel(fi, e);
}
var m2 = L({ asinh_: f2 });
function g2(n) {
  const e = { x: T(n, "x", "atan") };
  return $.runKernel(mi, e);
}
var b2 = L({ atan_: g2 });
function x2(n, t) {
  let e = T(n, "a", "atan2"), s = T(t, "b", "atan2");
  [e, s] = ne(e, s);
  const o = { a: e, b: s };
  return $.runKernel(bi, o);
}
var y2 = L({ atan2_: x2 });
function w2(n) {
  const e = { x: T(n, "x", "atanh") };
  return $.runKernel(gi, e);
}
var I2 = L({ atanh_: w2 });
function ca(n, t, e, s, o = "NHWC", r) {
  const i6 = n[3], a = [...t, i6], l = ys(o);
  return ke(n, a, e, r, s, null, null, l);
}
function $n(n, t, e, s, o, r, i6 = "channelsLast") {
  const [a, l] = Jr(t);
  let c;
  if (i6 === "channelsLast")
    c = [a, l, n[3], n[3]];
  else if (i6 === "channelsFirst")
    c = [a, l, n[1], n[1]];
  else
    throw new Error(`Unknown dataFormat ${i6}`);
  return ke(n, c, e, s, o, r, false, i6);
}
function xs(n, t, e, s, o, r, i6 = "NDHWC") {
  const [a, l, c] = xd(t);
  let u, d;
  if (i6 === "NDHWC")
    d = "channelsLast", u = [a, l, c, n[4], n[4]];
  else if (i6 === "NCDHW")
    d = "channelsFirst", u = [a, l, c, n[1], n[1]];
  else
    throw new Error(`Unknown dataFormat ${i6}`);
  return Bs(n, u, e, s, o, false, d, r);
}
function ke(n, t, e, s, o, r, i6 = false, a = "channelsLast") {
  let [l, c, u, d] = [-1, -1, -1, -1];
  if (a === "channelsLast")
    [l, c, u, d] = n;
  else if (a === "channelsFirst")
    [l, d, c, u] = n;
  else
    throw new Error(`Unknown dataFormat ${a}`);
  const [h6, p6, , f] = t, [m, g6] = Jr(e), [b6, x6] = Jr(s), w6 = qo(h6, b6), y6 = qo(p6, x6), { padInfo: I, outHeight: C6, outWidth: k7 } = S2(o, c, u, m, g6, w6, y6, r, a), S = i6 ? f * d : f;
  let N;
  return a === "channelsFirst" ? N = [l, S, C6, k7] : a === "channelsLast" && (N = [l, C6, k7, S]), {
    batchSize: l,
    dataFormat: a,
    inHeight: c,
    inWidth: u,
    inChannels: d,
    outHeight: C6,
    outWidth: k7,
    outChannels: S,
    padInfo: I,
    strideHeight: m,
    strideWidth: g6,
    filterHeight: h6,
    filterWidth: p6,
    effectiveFilterHeight: w6,
    effectiveFilterWidth: y6,
    dilationHeight: b6,
    dilationWidth: x6,
    inShape: n,
    outShape: N,
    filterShape: t
  };
}
function Bs(n, t, e, s, o, r = false, i6 = "channelsLast", a) {
  let [l, c, u, d, h6] = [-1, -1, -1, -1, -1];
  if (i6 === "channelsLast")
    [l, c, u, d, h6] = n;
  else if (i6 === "channelsFirst")
    [l, h6, c, u, d] = n;
  else
    throw new Error(`Unknown dataFormat ${i6}`);
  const [p6, f, m, , g6] = t, [b6, x6, w6] = xd(e), [y6, I, C6] = xd(s), k7 = qo(p6, y6), S = qo(f, I), N = qo(m, C6), { padInfo: R, outDepth: M6, outHeight: V, outWidth: z } = k2(o, c, u, d, b6, x6, w6, k7, S, N, a), X = r ? g6 * h6 : g6;
  let P6;
  return i6 === "channelsFirst" ? P6 = [l, X, M6, V, z] : i6 === "channelsLast" && (P6 = [l, M6, V, z, X]), {
    batchSize: l,
    dataFormat: i6,
    inDepth: c,
    inHeight: u,
    inWidth: d,
    inChannels: h6,
    outDepth: M6,
    outHeight: V,
    outWidth: z,
    outChannels: X,
    padInfo: R,
    strideDepth: b6,
    strideHeight: x6,
    strideWidth: w6,
    filterDepth: p6,
    filterHeight: f,
    filterWidth: m,
    effectiveFilterDepth: k7,
    effectiveFilterHeight: S,
    effectiveFilterWidth: N,
    dilationDepth: y6,
    dilationHeight: I,
    dilationWidth: C6,
    inShape: n,
    outShape: P6,
    filterShape: t
  };
}
function C2(n, t, e, s, o) {
  s == null && (s = Zh(n, t, e));
  const r = n[0], i6 = n[1], a = jr((r - t + 2 * s) / e + 1, o), l = jr((i6 - t + 2 * s) / e + 1, o);
  return [a, l];
}
function v22(n, t, e, s, o, r) {
  o == null && (o = Zh(n, t[0], s[0]));
  const i6 = [0, 0, 0, e];
  for (let a = 0; a < 3; a++)
    n[a] + 2 * o >= t[a] && (i6[a] = jr((n[a] - t[a] + 2 * o) / s[a] + 1, r));
  return i6;
}
function Zh(n, t, e, s = 1) {
  const o = qo(t, s);
  return Math.floor((n[0] * (e - 1) - e + o) / 2);
}
function Jr(n) {
  return typeof n == "number" ? [n, n, n] : n.length === 2 ? [n[0], n[1], 1] : n;
}
function xd(n) {
  return typeof n == "number" ? [n, n, n] : n;
}
function qo(n, t) {
  return t <= 1 ? n : n + (n - 1) * (t - 1);
}
function S2(n, t, e, s, o, r, i6, a, l) {
  let c, u, d;
  if (typeof n == "number") {
    c = { top: n, bottom: n, left: n, right: n, type: n === 0 ? "VALID" : "NUMBER" };
    const p6 = C2([t, e], r, s, n, a);
    u = p6[0], d = p6[1];
  } else if (n === "same") {
    u = Math.ceil(t / s), d = Math.ceil(e / o);
    const h6 = Math.max(0, (u - 1) * s + r - t), p6 = Math.max(0, (d - 1) * o + i6 - e), f = Math.floor(h6 / 2), m = h6 - f, g6 = Math.floor(p6 / 2), b6 = p6 - g6;
    c = { top: f, bottom: m, left: g6, right: b6, type: "SAME" };
  } else if (n === "valid")
    c = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" }, u = Math.ceil((t - r + 1) / s), d = Math.ceil((e - i6 + 1) / o);
  else if (typeof n == "object") {
    const h6 = l === "channelsLast" ? n[1][0] : n[2][0], p6 = l === "channelsLast" ? n[1][1] : n[2][1], f = l === "channelsLast" ? n[2][0] : n[3][0], m = l === "channelsLast" ? n[2][1] : n[3][1];
    c = { top: h6, bottom: p6, left: f, right: m, type: h6 === 0 && p6 === 0 && f === 0 && m === 0 ? "VALID" : "EXPLICIT" }, u = jr((t - r + h6 + p6) / s + 1, a), d = jr((e - i6 + f + m) / o + 1, a);
  } else
    throw Error(`Unknown padding parameter: ${n}`);
  return { padInfo: c, outHeight: u, outWidth: d };
}
function k2(n, t, e, s, o, r, i6, a, l, c, u) {
  let d, h6, p6, f;
  if (n === "valid" && (n = 0), typeof n == "number") {
    d = {
      top: n,
      bottom: n,
      left: n,
      right: n,
      front: n,
      back: n,
      type: n === 0 ? "VALID" : "NUMBER"
    };
    const g6 = v22([t, e, s, 1], [a, l, c], 1, [o, r, i6], n, u);
    h6 = g6[0], p6 = g6[1], f = g6[2];
  } else if (n === "same") {
    h6 = Math.ceil(t / o), p6 = Math.ceil(e / r), f = Math.ceil(s / i6);
    const m = (h6 - 1) * o + a - t, g6 = (p6 - 1) * r + l - e, b6 = (f - 1) * i6 + c - s, x6 = Math.floor(m / 2), w6 = m - x6, y6 = Math.floor(g6 / 2), I = g6 - y6, C6 = Math.floor(b6 / 2), k7 = b6 - C6;
    d = { top: y6, bottom: I, left: C6, right: k7, front: x6, back: w6, type: "SAME" };
  } else
    throw Error(`Unknown padding parameter: ${n}`);
  return { padInfo: d, outDepth: h6, outHeight: p6, outWidth: f };
}
function jr(n, t) {
  if (!t)
    return Math.trunc(n);
  switch (t) {
    case "round":
      return Math.round(n);
    case "ceil":
      return Math.ceil(n);
    case "floor":
      return Math.floor(n);
    default:
      throw new Error(`Unknown roundingMode ${t}`);
  }
}
function wo(n) {
  const [t, e, s] = Jr(n);
  return t === 1 && e === 1 && s === 1;
}
function Ee(n, t) {
  return wo(n) || wo(t);
}
function Io(n) {
  return Jr(n).every((t) => t > 0);
}
function ys(n) {
  if (n === "NHWC")
    return "channelsLast";
  if (n === "NCHW")
    return "channelsFirst";
  throw new Error(`Unknown dataFormat ${n}`);
}
function Be(n, t, e) {
  if (e != null) {
    if (typeof t == "string")
      throw Error(`Error in ${n}: pad must be an integer when using dimRoundingMode ${e} but got pad ${t}.`);
    if (typeof t == "number")
      v2(go(t), () => `Error in ${n}: pad must be an integer when using dimRoundingMode ${e} but got pad ${t}.`);
    else if (typeof t == "object")
      t.forEach((s) => {
        s.forEach((o) => {
          v2(go(o), () => `Error in ${n}: pad must be an integer when using dimRoundingMode ${e} but got pad ${o}.`);
        });
      });
    else
      throw Error(`Error in ${n}: Unknown padding parameter: ${t}`);
  }
}
function T2(n, t) {
  const s = { x: T(n, "x", "reshape", "string_or_numeric") }, o = { shape: t };
  return $.runKernel(Sc, s, o);
}
var W = L({ reshape_: T2 });
function N2(n, t, e, s, o) {
  const r = T(n, "x", "avgPool", "float32"), i6 = 1;
  v2(Ee(e, i6), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${e} and dilations '${i6}'`);
  let a = r, l = false;
  r.rank === 3 && (l = true, a = W(r, [1, r.shape[0], r.shape[1], r.shape[2]])), v2(a.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${a.rank}.`), Be("avgPool", s, o);
  const c = { x: a }, u = { filterSize: t, strides: e, pad: s, dimRoundingMode: o };
  let d = $.runKernel(Pl, c, u);
  return d = et(d, r.dtype), l ? W(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}
var Bh = L({ avgPool_: N2 });
function R2(n, t, e, s, o, r = "NDHWC") {
  const i6 = T(n, "x", "avgPool3d", "float32");
  let a = i6, l = false;
  i6.rank === 4 && (l = true, a = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2], i6.shape[3]])), v2(a.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${a.rank}.`), v2(r === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${r}`), v2(typeof e == "number" && e > 0 || Array.isArray(e) && e[0] > 0 && e[1] > 0 && e[2] > 0, () => `Error in avgPool3d: Stride must be > 0, but got '${e}'`), Be("avgPool3d", s, o);
  const c = { x: a }, u = { filterSize: t, strides: e, pad: s, dimRoundingMode: o, dataFormat: r };
  let d = $.runKernel(Al, c, u);
  return d = et(d, a.dtype), l ? W(d, [d.shape[1], d.shape[2], d.shape[3], d.shape[4]]) : d;
}
var $2 = L({ avgPool3d_: R2 });
function G2(n, t = 0) {
  v2(n.length >= 1, () => "Pass at least one tensor to concat");
  const e = Ah(n, "tensors", "concat", "string_or_numeric");
  if (e[0].dtype === "complex64" && e.forEach((r) => {
    if (r.dtype !== "complex64")
      throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${r.dtype}. `);
  }), e.length === 1)
    return po(e[0]);
  const s = e, o = { axis: t };
  return $.runKernel(Bl, s, o);
}
var Ge = L({ concat_: G2 });
function E2(n, t, e = false, s = false) {
  let o = T(n, "a", "matMul"), r = T(t, "b", "matMul");
  [o, r] = ne(o, r);
  const i6 = { a: o, b: r }, a = { transposeA: e, transposeB: s };
  return $.runKernel(Ol, i6, a);
}
var Gt = L({ matMul_: E2 });
function L2(n) {
  const e = { x: T(n, "x", "sigmoid", "float32") };
  return $.runKernel(Ji, e);
}
var xr = L({ sigmoid_: L2 });
function M2(n, t, e) {
  const s = T(n, "x", "slice", "string_or_numeric");
  if (s.rank === 0)
    throw new Error("Slicing scalar is not possible");
  const o = { x: s }, r = { begin: t, size: e };
  return $.runKernel($c, o, r);
}
var Dt = L({ slice_: M2 });
function W2(n) {
  const e = { x: T(n, "x", "tanh", "float32") };
  return $.runKernel(sa, e);
}
var Hh = L({ tanh_: W2 });
function D2(n, t, e) {
  const s = T(n, "x", "batchToSpaceND"), o = t.reduce((a, l) => a * l);
  v2(s.rank >= 1 + t.length, () => `input rank is ${s.rank} but should be > than blockShape.length ${t.length}`), v2(e.length === t.length, () => `crops.length is ${e.length} but should be equal to blockShape.length  ${t.length}`), v2(s.shape[0] % o === 0, () => `input tensor batch is ${s.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${o}`);
  const r = { x: s }, i6 = { blockShape: t, crops: e };
  return $.runKernel(Kl, r, i6);
}
var _h = L({ batchToSpaceND_: D2 });
function F2(n) {
  let t;
  return n.rank === 0 || n.rank === 1 ? t = W(n, [1, 1, 1, n.size]) : n.rank === 2 ? t = W(n, [1, 1, n.shape[0], n.shape[1]]) : n.rank === 3 ? t = W(n, [1, n.shape[0], n.shape[1], n.shape[2]]) : t = n, t;
}
function V2(n, t, e, s, o, r) {
  r == null && (r = 1e-3);
  const i6 = T(n, "x", "batchNorm"), a = T(t, "mean", "batchNorm"), l = T(e, "variance", "batchNorm");
  let c;
  o != null && (c = T(o, "scale", "batchNorm"));
  let u;
  s != null && (u = T(s, "offset", "batchNorm")), v2(a.rank === l.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks."), v2(u == null || a.rank === u.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks."), v2(c == null || a.rank === c.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  const h6 = {
    x: F2(i6),
    scale: c,
    offset: u,
    mean: a,
    variance: l
  }, p6 = { varianceEpsilon: r }, f = $.runKernel(tc, h6, p6);
  return W(f, i6.shape);
}
var zc = L({ batchNorm_: V2 });
function z2(n, t, e, s, o, r) {
  const i6 = T(n, "x", "batchNorm"), a = T(t, "mean", "batchNorm"), l = T(e, "variance", "batchNorm");
  let c;
  o != null && (c = T(o, "scale", "batchNorm"));
  let u;
  return s != null && (u = T(s, "offset", "batchNorm")), v2(i6.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${i6.rank}.`), v2(a.rank === 2 || a.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${a.rank}.`), v2(l.rank === 2 || l.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`), c != null && v2(c.rank === 2 || c.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${c.rank}.`), u != null && v2(u.rank === 2 || u.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${u.rank}.`), zc(i6, a, l, u, c, r);
}
var X2 = L({ batchNorm2d_: z2 });
function P2(n, t, e, s, o, r) {
  const i6 = T(n, "x", "batchNorm"), a = T(t, "mean", "batchNorm"), l = T(e, "variance", "batchNorm");
  let c;
  o != null && (c = T(o, "scale", "batchNorm"));
  let u;
  return s != null && (u = T(s, "offset", "batchNorm")), v2(i6.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${i6.rank}.`), v2(a.rank === 3 || a.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${a.rank}.`), v2(l.rank === 3 || l.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`), c != null && v2(c.rank === 3 || c.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${c.rank}.`), u != null && v2(u.rank === 3 || u.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${u.rank}.`), zc(i6, a, l, u, c, r);
}
var A2 = L({ batchNorm3d_: P2 });
function O2(n, t, e, s, o, r) {
  const i6 = T(n, "x", "batchNorm"), a = T(t, "mean", "batchNorm"), l = T(e, "variance", "batchNorm");
  let c;
  o != null && (c = T(o, "scale", "batchNorm"));
  let u;
  return s != null && (u = T(s, "offset", "batchNorm")), v2(i6.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${i6.rank}.`), v2(a.rank === 4 || a.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${a.rank}.`), v2(l.rank === 4 || l.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`), c != null && v2(c.rank === 4 || c.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${c.rank}.`), u != null && v2(u.rank === 4 || u.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${u.rank}.`), zc(i6, a, l, u, c, r);
}
var K2 = L({ batchNorm4d_: O2 });
function Z2(n, t, e) {
  const s = T(n, "x", "bincount"), o = T(t, "weights", "bincount");
  v2(s.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${s.dtype}`), v2(e >= 0, () => `size must be non-negative, but got ${e}.`), v2(o.size === s.size || o.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${s.shape}, weights shape: ${o.shape}.`);
  const r = { x: s, weights: o }, i6 = { size: e };
  return $.runKernel(Qd, r, i6);
}
var B2 = L({ bincount_: Z2 });
function H2(n, t) {
  let e = T(n, "broadcastTo", "x");
  const s = e.shape;
  if (is(t), t.length < e.rank)
    throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${e.rank}.`);
  if (t.length > e.rank) {
    const c = e.shape.slice();
    for (; c.length < t.length; )
      c.unshift(1);
    e = W(e, c);
  }
  const o = e.shape, r = Array.from(t);
  for (let c = t.length - 1; c >= 0; c--)
    if (o[c] === t[c])
      r[c] = 1;
    else if (e.shape[c] !== 1)
      throw new Error(`broadcastTo(): [${s}] cannot be broadcast to [${t}].`);
  if (r.map((c, u) => c > 1 ? u : -1).filter((c) => c >= 0).length === 0)
    return po(e);
  const a = { x: e }, l = { reps: r };
  return $.runKernel(oa, a, l);
}
var Br = L({ broadcastTo_: H2 });
function _2(n) {
  const e = { x: T(n, "x", "ceil", "float32") };
  return $.runKernel(yi, e);
}
var U2 = L({ ceil_: _2 });
function ua(n, t, e) {
  is(n);
  const s = { shape: n, value: t, dtype: e };
  return $.runKernel(ch, {}, s);
}
function Y2(n, t, e) {
  const s = T(n, "x", "clipByValue");
  if (v2(t <= e, () => `Error in clip: min (${t}) must be less than or equal to max (${e}).`), t === e)
    return ua(s.shape, t, s.dtype);
  const o = { x: s }, r = { clipValueMin: t, clipValueMax: e };
  return $.runKernel(wi, o, r);
}
var pn = L({ clipByValue_: Y2 });
function Q2(n) {
  return Ge(
    n,
    0
    /* axis */
  );
}
var J2 = L({ concat1d_: Q2 });
function j2(n, t) {
  return Ge(n, t);
}
var q2 = L({ concat2d_: j2 });
function tv(n, t) {
  return Ge(n, t);
}
var ev = L({ concat3d_: tv });
function nv(n, t) {
  return Ge(n, t);
}
var sv = L({ concat4d_: nv });
function ov(n, t, e, s, o = "NHWC", r = [1, 1], i6) {
  const a = T(n, "x", "conv2d", "float32"), l = T(t, "filter", "conv2d", "float32");
  let c = a, u = false;
  a.rank === 3 && (u = true, c = W(a, [1, a.shape[0], a.shape[1], a.shape[2]])), v2(c.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${c.rank}.`), v2(l.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`), Be("conv2d", s, i6);
  const d = o === "NHWC" ? c.shape[3] : c.shape[1];
  v2(d === l.shape[2], () => `Error in conv2d: depth of input (${d}) must match input depth for filter ${l.shape[2]}.`), v2(Ee(e, r), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${e} and dilations '${r}'`), v2(Io(r), () => "Error in conv2D: Dilated rates should be larger than 0."), v2(Io(e), () => "Error in conv2D: Strides should be larger than 0.");
  const h6 = { x: c, filter: l }, p6 = { strides: e, pad: s, dataFormat: o, dilations: r, dimRoundingMode: i6 }, f = $.runKernel(Hl, h6, p6);
  return u ? W(f, [f.shape[1], f.shape[2], f.shape[3]]) : f;
}
var Co = L({ conv2d_: ov });
function rv(n, t, e, s, o = "NWC", r = 1, i6) {
  const a = T(n, "x", "conv1d"), l = T(t, "filter", "conv1d");
  let c = a, u = false;
  a.rank === 2 && (u = true, c = W(a, [1, a.shape[0], a.shape[1]])), v2(c.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${c.rank}.`), v2(l.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`), Be("conv1d", s, i6), v2(c.shape[2] === l.shape[1], () => `Error in conv1d: depth of input (${c.shape[2]}) must match input depth for filter ${l.shape[1]}.`), v2(Ee(e, r), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${e} and dilation '${r}'`), v2(Io(r), () => "Error in conv1D: Dilated rates should be larger than 0."), v2(Io(e), () => "Error in conv1D: Stride should be larger than 0."), v2(o === "NWC", () => `Error in conv1d: got dataFormat of ${o} but only NWC is currently supported.`);
  const d = W(l, [1, l.shape[0], l.shape[1], l.shape[2]]), h6 = W(c, [c.shape[0], 1, c.shape[1], c.shape[2]]), g6 = Co(h6, d, [1, e], s, "NHWC", [1, r], i6);
  return u ? W(g6, [g6.shape[2], g6.shape[3]]) : W(g6, [g6.shape[0], g6.shape[2], g6.shape[3]]);
}
var Rb = L({ conv1d_: rv });
function iv(n, t, e, s, o, r = "NHWC", i6) {
  v2(n.length === t.rank, () => `Length of inShape (${n.length}) and rank of dy (${t.rank}) must match`);
  let a = n, l = t, c = false;
  t.rank === 3 && (c = true, l = W(t, [1, t.shape[0], t.shape[1], t.shape[2]]), a = [1, n[0], n[1], n[2]]), v2(a.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${a.length}.`), v2(l.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`), v2(e.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${e.rank}`);
  const u = r === "NHWC" ? a[3] : a[1], d = r === "NHWC" ? l.shape[3] : l.shape[1];
  v2(u === e.shape[2], () => `Error in conv2dDerInput: depth of input (${u}) must match input depth for filter ${e.shape[2]}.`), v2(d === e.shape[3], () => `Error in conv2dDerInput: depth of output (${d}) must match output depth for filter ${e.shape[3]}.`), Be("conv2dDerInput", o, i6);
  const h6 = { dy: l, filter: e }, p6 = { strides: s, pad: o, dataFormat: r, dimRoundingMode: i6, inputShape: a }, f = $.runKernel(_l, h6, p6);
  return c ? W(f, [f.shape[1], f.shape[2], f.shape[3]]) : f;
}
var Uh = L({ conv2DBackpropInput_: iv });
function av(n, t, e, s, o, r) {
  const i6 = T(n, "x", "conv2dTranspose"), a = T(t, "filter", "conv2dTranspose");
  return Uh(e, i6, a, s, o, "NHWC", r);
}
var $b = L({ conv2dTranspose_: av });
function lv(n, t, e, s, o = "NDHWC", r = [1, 1, 1]) {
  const i6 = T(n, "x", "conv3d"), a = T(t, "filter", "conv3d");
  let l = i6, c = false;
  i6.rank === 4 && (c = true, l = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2], i6.shape[3]])), v2(l.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${l.rank}.`), v2(a.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${a.rank}.`), v2(l.shape[4] === a.shape[3], () => `Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${a.shape[3]}.`), v2(Ee(e, r), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${e} and dilations '${r}'`), v2(o === "NDHWC", () => `Error in conv3d: got dataFormat of ${o} but only NDHWC is currently supported.`), v2(Io(r), () => "Error in conv3D: Dilated rates should be larger than 0."), v2(Io(e), () => "Error in conv3D: Strides should be larger than 0.");
  const u = { x: l, filter: a }, d = { strides: e, pad: s, dataFormat: o, dilations: r }, h6 = $.runKernel(Ul, u, d);
  return c ? W(h6, [h6.shape[1], h6.shape[2], h6.shape[3], h6.shape[4]]) : h6;
}
var cv = L({ conv3d_: lv });
function uv(n, t, e, s, o) {
  v2(n.length === t.rank, () => `Length of inShape (${n.length}) and rank of dy (${t.rank}) must match`);
  let r = n, i6 = t, a = false;
  t.rank === 4 && (a = true, i6 = W(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]]), r = [1, n[0], n[1], n[2], n[3]]);
  const l = r[4], c = i6.shape[4];
  v2(r.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${r.length}.`), v2(i6.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${i6.rank}`), v2(e.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${e.rank}`), v2(l === e.shape[3], () => `Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${e.shape[3]}.`), v2(c === e.shape[4], () => `Error in conv3dDerInput: depth of output (${c}) must match output depth for filter ${e.shape[4]}.`);
  const u = { dy: i6, filter: e }, d = { pad: o, strides: s, inputShape: r }, h6 = $.runKernel(th, u, d);
  return a ? W(h6, [h6.shape[1], h6.shape[2], h6.shape[3], h6.shape[4]]) : h6;
}
var Gb = L({ conv3DBackpropInput_: uv });
function dv(n, t, e, s, o) {
  const r = T(n, "x", "conv3dTranspose"), i6 = T(t, "filter", "conv3dTranspose");
  return Gb(e, r, i6, s, o);
}
var hv = L({ conv3dTranspose_: dv });
function pv(n) {
  const e = { x: T(n, "x", "cos", "float32") };
  return $.runKernel(Ii, e);
}
var Yh = L({ cos_: pv });
function fv(n) {
  const e = { x: T(n, "x", "cosh", "float32") };
  return $.runKernel(Ci, e);
}
var Eb = L({ cosh_: fv });
function mv(n, t = 0, e = false, s = false) {
  const r = { x: T(n, "x", "cumprod") }, i6 = { axis: t, exclusive: e, reverse: s };
  return $.runKernel(eh, r, i6);
}
var yd = L({ cumprod_: mv });
function gv(n, t = 0, e = false, s = false) {
  const r = { x: T(n, "x", "cumsum") }, i6 = { axis: t, exclusive: e, reverse: s };
  return $.runKernel(Yl, r, i6);
}
var Lb = L({ cumsum_: gv });
function bv(n, t, e, s = false) {
  const o = T(n, "x", "denseBincount"), r = T(t, "weights", "denseBincount");
  v2(o.dtype === "int32", () => `Error in denseBincount: input dtype must be int32, but got ${o.dtype}`), v2(o.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got rank ${o.rank}.`), v2(e >= 0, () => `size must be non-negative, but got ${e}.`), v2(r.size === o.size || r.size === 0, () => `Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${o.shape}, weights shape: ${r.shape}.`);
  const i6 = { x: o, weights: r }, a = { size: e, binaryOutput: s };
  return $.runKernel(sh, i6, a);
}
var rm = L({ denseBincount_: bv });
function xv(n, t, e = "NHWC") {
  const s = T(n, "x", "depthToSpace", "float32"), o = e === "NHWC" ? s.shape[1] : s.shape[2], r = e === "NHWC" ? s.shape[2] : s.shape[3], i6 = e === "NHWC" ? s.shape[3] : s.shape[1];
  v2(t > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${t}`), v2(o * t >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${o} and ${t}  for depthToSpace with input shape
    ${s.shape}`), v2(r * t >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${r} and ${t} for depthToSpace with input shape
        ${s.shape}`), v2(i6 % (t * t) === 0, () => `Dimension size must be evenly divisible by ${t * t} but is ${i6} for depthToSpace with input shape ${s.shape}`);
  const a = { x: s }, l = { blockSize: t, dataFormat: e };
  return $.runKernel(oh, a, l);
}
var yv = L({ depthToSpace_: xv });
function wv(n, t, e, s, o = "NHWC", r = [1, 1], i6) {
  const a = T(n, "x", "depthwiseConv2d", "float32"), l = T(t, "filter", "depthwiseConv2d", "float32");
  let c = a, u = false;
  a.rank === 3 && (u = true, c = W(a, [1, a.shape[0], a.shape[1], a.shape[2]])), v2(c.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${c.rank}.`), v2(l.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`);
  const d = o === "NHWC" ? c.shape[3] : c.shape[1];
  v2(d === l.shape[2], () => `Error in depthwiseConv2d: number of input channels (${d}) must match the inChannels dimension in filter ${l.shape[2]}.`), Be("depthwiseConv2d", s, i6);
  const h6 = { x: c, filter: l }, p6 = { strides: e, pad: s, dataFormat: o, dilations: r, dimRoundingMode: i6 }, f = $.runKernel(Ql, h6, p6);
  return u ? W(f, [f.shape[1], f.shape[2], f.shape[3]]) : f;
}
var Qh = L({ depthwiseConv2d_: wv });
function Iv(n, t, e, s, o = [1, 1], r = "NHWC") {
  const i6 = T(n, "x", "dilation2d"), a = T(t, "filter", "dilation2d");
  v2(i6.rank === 3 || i6.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${i6.rank}.`), v2(a.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${a.rank}.`), v2(r === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${r}`);
  let l = i6, c = false;
  i6.rank === 3 && (l = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2]]), c = true), v2(l.shape[3] === a.shape[2], () => `Error in dilation2d:  input and filter must have the same depth: ${l.shape[3]} vs ${a.shape[2]}`);
  const u = { x: l, filter: a }, d = { strides: e, pad: s, dilations: o }, h6 = $.runKernel(Jl, u, d);
  return c ? W(h6, [h6.shape[1], h6.shape[2], h6.shape[3]]) : h6;
}
var Cv = L({ dilation2d_: Iv });
function vo(n, t) {
  const e = n.length, s = [];
  for (let o = 0; o < e; o++) {
    const r = e - 1 - o, i6 = n[r] || 1;
    (t[t.length - 1 - o] || 1) > 1 && i6 === 1 && s.unshift(r);
  }
  return s;
}
function le(n, t) {
  const e = [];
  for (let s = 0; s < t.length; s++) {
    const o = n[n.length - s - 1], r = t.length - s - 1, i6 = t[r];
    (o == null || o === 1 && i6 > 1) && e.unshift(r);
  }
  return e;
}
function bt(n, t) {
  const e = [], s = Math.max(n.length, t.length);
  for (let o = 0; o < s; o++) {
    let r = n[n.length - o - 1];
    r == null && (r = 1);
    let i6 = t[t.length - o - 1];
    if (i6 == null && (i6 = 1), r === 1)
      e.unshift(i6);
    else if (i6 === 1)
      e.unshift(r);
    else if (r !== i6) {
      const a = `Operands could not be broadcast together with shapes ${n} and ${t}.`;
      throw Error(a);
    } else
      e.unshift(r);
  }
  return e;
}
var iY = Object.freeze(Object.defineProperty({
  __proto__: null,
  assertAndGetBroadcastShape: bt,
  getBroadcastDims: vo,
  getReductionAxes: le
}, Symbol.toStringTag, { value: "Module" }));
function vv(n, t) {
  let e = T(n, "a", "equal", "string_or_numeric"), s = T(t, "b", "equal", "string_or_numeric");
  [e, s] = ne(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(jl, o);
}
var kn = L({ equal_: vv });
function Sv(n, t, e) {
  const s = T(t, "a", "where"), o = T(e, "b", "where"), r = T(n, "condition", "where", "bool"), i6 = bt(bt(r.shape, s.shape), o.shape), a = Br(r, i6), l = Br(s, i6), c = Br(o, i6), u = {
    condition: a,
    t: l,
    e: c
  };
  return $.runKernel(Rc, u);
}
var Oe = L({ where_: Sv });
function kv(n) {
  const e = { x: T(n, "x", "zerosLike") };
  return $.runKernel(Fc, e);
}
var Tt = L({ zerosLike_: kv });
function Tv(n, t) {
  let e = T(n, "a", "div"), s = T(t, "b", "div");
  [e, s] = ne(e, s);
  const o = ut(e, s), r = Tt(o), i6 = kn(s, r);
  return Oe(i6, r, o);
}
var Nv = L({ divNoNan_: Tv });
function Rv(n, t) {
  const e = T(n, "t1", "dot"), s = T(t, "t2", "dot");
  v2((e.rank === 1 || e.rank === 2) && (s.rank === 1 || s.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${e.rank} and ${s.rank}.`);
  const o = e.rank === 1 ? e.size : e.shape[1], r = s.rank === 1 ? s.size : s.shape[0];
  if (v2(o === r, () => `Error in dot: inner dimensions of inputs must match, but got ${o} and ${r}.`), e.rank === 1 && s.rank === 1) {
    const i6 = W(e, [1, -1]), a = W(s, [-1, 1]), l = Gt(i6, a);
    return W(l, []);
  } else if (e.rank === 1 && s.rank === 2) {
    const i6 = W(e, [1, -1]), a = W(s, [s.shape[0], s.shape[1]]), l = Gt(i6, a);
    return W(l, [l.size]);
  } else if (e.rank === 2 && s.rank === 1) {
    const i6 = W(s, [-1, 1]), a = Gt(e, i6);
    return W(a, [a.size]);
  } else {
    const i6 = W(s, [s.shape[0], s.shape[1]]);
    return Gt(e, i6);
  }
}
var $v = L({ dot_: Rv });
function Gv(n) {
  const e = { x: T(n, "x", "elu", "float32") };
  return $.runKernel(Si, e);
}
var Xc = L({ elu_: Gv });
function Ev(n) {
  let t = T(n, "x", "erf");
  v2(t.dtype === "int32" || t.dtype === "float32", () => "Input dtype must be `int32` or `float32`."), t.dtype === "int32" && (t = et(t, "float32"));
  const e = { x: t };
  return $.runKernel(ki, e);
}
var Lv = L({ erf_: Ev });
function Jh(n, t) {
  for (let e = 0; e < n.length; ++e)
    if (n[n.length - e - 1] !== t - 1 - e)
      return false;
  return true;
}
function Mb(n, t, e) {
  const s = n.length + t.length, o = [];
  let r = 0, i6 = 0;
  for (let a = 0; a < s; a++)
    e.indexOf(a) === -1 ? o.push(n[r++]) : o.push(t[i6++]);
  return o;
}
function ye(n, t) {
  const e = [], s = n.length;
  for (let r = 0; r < s; r++)
    t.indexOf(r) === -1 && e.push(n[r]);
  const o = t.map((r) => n[r]);
  return [e, o];
}
function re(n, t) {
  const e = t.map((s) => 1);
  return Mb(n, e, t);
}
function Te(n, t, e) {
  v2(Jh(t, e), () => `${n} supports only inner-most axes for now. Got axes ${t} and rank-${e} input.`);
}
function qt(n, t) {
  if (Jh(n, t))
    return null;
  const e = [];
  for (let s = 0; s < t; ++s)
    n.indexOf(s) === -1 && e.push(s);
  return n.forEach((s) => e.push(s)), e;
}
function Hs(n) {
  return n.map((t, e) => [e, t]).sort((t, e) => t[1] - e[1]).map((t) => t[0]);
}
function ie(n, t) {
  const e = [];
  for (let s = t - n; s < t; ++s)
    e.push(s);
  return e;
}
function Mv(n, t = null, e = false) {
  const o = { x: T(n, "x", "max") }, r = { reductionIndices: t, keepDims: e };
  return $.runKernel(uc, o, r);
}
var Xn = L({ max_: Mv });
function Wv(n, t = null, e = false) {
  const o = { x: T(n, "x", "min") }, r = { axis: t, keepDims: e };
  return $.runKernel(fc, o, r);
}
var ul = L({ min_: Wv });
function Dv(n, t) {
  let e = T(n, "base", "pow"), s = T(t, "exp", "pow");
  [e, s] = ne(e, s);
  const o = { a: e, b: s };
  return $.runKernel(Ai, o);
}
var ir = L({ pow_: Dv });
function gt(n, t) {
  if ((dn(n) && t !== "string" || Array.isArray(n)) && t !== "complex64")
    throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  if (t === "string" && dn(n) && !(n instanceof Uint8Array))
    throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  return la(n, [], [], t);
}
function Fv(n) {
  const e = { x: T(n, "x", "sqrt", "float32") };
  return $.runKernel(qi, e);
}
var De = L({ sqrt_: Fv });
function Vv(n) {
  const t = T(n, "x", "square"), e = {};
  return $.runKernel("Square", { x: t }, e);
}
var At = L({ square_: Vv });
function zv(n, t = null, e = false) {
  let s = T(n, "x", "sum");
  s.dtype === "bool" && (s = et(s, "int32"));
  const o = { x: s }, r = { axis: t, keepDims: e };
  return $.runKernel(Gc, o, r);
}
var at = L({ sum_: zv });
function Xv(n, t = "euclidean", e = null, s = false) {
  n = T(n, "x", "norm");
  const o = Wb(n, t, e);
  let r = o.shape;
  if (s) {
    const i6 = Ct(e, n.shape);
    r = re(o.shape, i6);
  }
  return W(o, r);
}
function Wb(n, t, e = null) {
  if (n.rank === 0)
    return fe(n);
  if (n.rank !== 1 && e === null)
    return Wb(W(n, [-1]), t, e);
  if (n.rank === 1 || typeof e == "number" || Array.isArray(e) && e.length === 1) {
    if (t === 1)
      return at(fe(n), e);
    if (t === 1 / 0)
      return Xn(fe(n), e);
    if (t === -1 / 0)
      return ul(fe(n), e);
    if (t === "euclidean" || t === 2)
      return De(at(ir(fe(n), gt(2, "int32")), e));
    throw new Error(`Error in norm: invalid ord value: ${t}`);
  }
  if (Array.isArray(e) && e.length === 2) {
    if (t === 1)
      return Xn(at(fe(n), e[0]), e[1] - 1);
    if (t === 1 / 0)
      return Xn(at(fe(n), e[1]), e[0]);
    if (t === -1 / 0)
      return ul(at(fe(n), e[1]), e[0]);
    if (t === "fro" || t === "euclidean")
      return De(at(At(n), e));
    throw new Error(`Error in norm: invalid ord value: ${t}`);
  }
  throw new Error(`Error in norm: invalid axis: ${e}`);
}
var Pc = L({ norm_: Xv });
function Pv(n, t = null, e = false) {
  return Pc(n, "euclidean", t, e);
}
var Av = L({ euclideanNorm_: Pv });
function Ov(n) {
  const e = { x: T(n, "x", "exp") };
  return $.runKernel(Ti, e);
}
var Tn = L({ exp_: Ov });
function Kv(n, t = 0) {
  const e = T(n, "x", "expandDims", "string_or_numeric");
  v2(t <= e.rank, () => "Axis must be <= rank of the tensor");
  const s = { input: e }, o = { dim: t };
  return $.runKernel(ql, s, o);
}
var Ue = L({ expandDims_: Kv });
function Zv(n) {
  const e = { x: T(n, "x", "expm1") };
  return $.runKernel(Ni, e);
}
var Bv = L({ expm1_: Zv });
function Hv(n, t) {
  const e = T(n, "x", "tile", "string_or_numeric");
  v2(e.rank === t.length, () => `Error in transpose: rank of input ${e.rank} must match length of reps ${t}.`);
  const s = { x: e }, o = { reps: t };
  return $.runKernel(oa, s, o);
}
var Vn = L({ tile_: Hv });
function _v(n, t, e, s = "float32") {
  t == null && (t = n);
  const o = vt([n, t], s), r = n <= t ? n : t;
  for (let a = 0; a < r; ++a)
    o.set(1, a, a);
  const i6 = W(o.toTensor(), [n, t]);
  if (e == null)
    return i6;
  if (e.length === 1)
    return Vn(Ue(i6, 0), [e[0], 1, 1]);
  if (e.length === 2)
    return Vn(Ue(Ue(i6, 0), 0), [e[0], e[1], 1, 1]);
  if (e.length === 3)
    return Vn(Ue(Ue(Ue(i6, 0), 0), 0), [
      e[0],
      e[1],
      e[2],
      1,
      1
    ]);
  throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${e.length}D.`);
}
var Db = L({ eye_: _v });
function Uv(n) {
  const e = { x: T(n, "x", "floor", "float32") };
  return $.runKernel(Ri, e);
}
var Ac = L({ floor_: Uv });
function Yv(n, t, e = 0, s = 0) {
  const o = T(n, "x", "gather"), r = T(t, "indices", "gather", "int32"), i6 = { x: o, indices: r }, a = { axis: e, batchDims: s };
  return $.runKernel(ec, i6, a);
}
var jh = L({ gather_: Yv });
function Qv(n, t) {
  let e = T(n, "a", "greater", "string_or_numeric"), s = T(t, "b", "greater", "string_or_numeric");
  [e, s] = ne(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(nc, o);
}
var sn = L({ greater_: Qv });
function Jv(n, t) {
  let e = T(n, "a", "greaterEqual", "string_or_numeric"), s = T(t, "b", "greaterEqual", "string_or_numeric");
  [e, s] = ne(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(Gi, o);
}
var Do = L({ greaterEqual_: Jv });
function jv(n) {
  const e = { input: T(n, "input", "imag") };
  return $.runKernel(hh, e);
}
var qh = L({ imag_: jv });
function qv(n) {
  const e = { x: T(n, "x", "isFinite") };
  return $.runKernel(Li, e);
}
var tS = L({ isFinite_: qv });
function eS(n) {
  const e = { x: T(n, "x", "isInf") };
  return $.runKernel(Mi, e);
}
var nS = L({ isInf_: eS });
function sS(n) {
  const e = { x: T(n, "x", "isNaN") };
  return $.runKernel(Wi, e);
}
var oS = L({ isNaN_: sS });
function rS(n, t = 0.2) {
  const s = { x: T(n, "x", "leakyRelu") }, o = { alpha: t };
  return $.runKernel(sc, s, o);
}
var tp = L({ leakyRelu_: rS });
function iS(n, t) {
  let e = T(n, "a", "less", "string_or_numeric"), s = T(t, "b", "less", "string_or_numeric");
  [e, s] = ne(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(oc, o);
}
var Fb = L({ less_: iS });
function aS(n, t) {
  let e = T(n, "a", "lessEqual", "string_or_numeric"), s = T(t, "b", "lessEqual", "string_or_numeric");
  [e, s] = ne(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(rc, o);
}
var yr = L({ lessEqual_: aS });
function lS(n, t = 5, e = 1, s = 1, o = 0.5) {
  const r = T(n, "x", "localResponseNormalization");
  v2(r.rank === 4 || r.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${r.rank}.`), v2(go(t), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`);
  let i6 = r, a = false;
  r.rank === 3 && (a = true, i6 = W(r, [1, r.shape[0], r.shape[1], r.shape[2]]));
  const l = { x: i6 }, c = { depthRadius: t, bias: e, alpha: s, beta: o }, u = $.runKernel(cc, l, c);
  return a ? W(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;
}
var cS = L({ localResponseNormalization_: lS });
function uS(n) {
  const e = { x: T(n, "x", "log", "float32") };
  return $.runKernel(Di, e);
}
var Nn = L({ log_: uS });
function dS(n) {
  const e = { x: T(n, "x", "log1p") };
  return $.runKernel(Fi, e);
}
var ep = L({ log1p_: dS });
function aY(n) {
  return v2(Vs(n), () => "The f passed in grad(f) must be a function"), (t, e) => {
    const s = T(t, "x", "tf.grad", "string_or_numeric"), o = e != null ? T(e, "dy", "tf.grad") : null;
    return $.tidy(() => {
      const { value: r, grads: i6 } = $.gradients(() => n(s), [s], o);
      return o != null && Ve(r.shape, o.shape, "The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)"), Oc(i6), i6[0];
    });
  };
}
function lY(n) {
  return v2(Vs(n), () => "The f passed in grads(f) must be a function"), (t, e) => {
    v2(Array.isArray(t), () => "The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s");
    const s = Ah(t, "args", "tf.grads", "string_or_numeric"), o = e != null ? T(e, "dy", "tf.grads") : null;
    return $.tidy(() => {
      const { value: r, grads: i6 } = $.gradients(() => n(...s), s, o);
      return o != null && Ve(r.shape, o.shape, "The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])"), Oc(i6), i6;
    });
  };
}
function cY(n) {
  return v2(Vs(n), () => "The f passed in valueAndGrad(f) must be a function"), (t, e) => {
    v2(t instanceof Lt, () => "The x passed in valueAndGrad(f)(x) must be a tensor"), v2(e == null || e instanceof Lt, () => "The dy passed in valueAndGrad(f)(x, dy) must be a tensor");
    const { grads: s, value: o } = $.gradients(() => n(t), [t], e);
    return Oc(s), { grad: s[0], value: o };
  };
}
function uY(n) {
  return v2(Vs(n), () => "The f passed in valueAndGrads(f) must be a function"), (t, e) => {
    v2(Array.isArray(t) && t.every((o) => o instanceof Lt), () => "The args passed in valueAndGrads(f)(args) must be array of tensors"), v2(e == null || e instanceof Lt, () => "The dy passed in valueAndGrads(f)(args, dy) must be a tensor");
    const s = $.gradients(() => n(...t), t, e);
    return e != null && Ve(s.value.shape, e.shape, "The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])"), Oc(s.grads), s;
  };
}
function hS(n, t) {
  v2(Vs(n), () => "The f passed in variableGrads(f) must be a function"), v2(t == null || Array.isArray(t) && t.every((c) => c instanceof al), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  const e = t != null;
  if (!e) {
    t = [];
    for (const c in $.registeredVariables)
      t.push($.registeredVariables[c]);
  }
  const s = e ? t.filter((c) => !c.trainable) : null, o = t.length;
  t = t.filter((c) => c.trainable), v2(t.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${o} variables is trainable.`);
  const r = true, { value: i6, grads: a } = $.gradients(n, t, null, r);
  v2(a.some((c) => c != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize()."), v2(i6.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${i6.rank} tensor`);
  const l = {};
  return t.forEach((c, u) => {
    a[u] != null && (l[c.name] = a[u]);
  }), s != null && s.forEach((c) => l[c.name] = null), { value: i6, grads: l };
}
function So(n) {
  return $.customGrad(n);
}
function Oc(n) {
  if (n.filter((e) => e == null).length > 0)
    throw new Error(`Cannot compute gradient of y=f(x) with respect to x. Make sure that
    the f you passed encloses all operations that lead from x to y.`);
}
function pS(n) {
  const e = { x: T(n, "x", "neg") };
  return $.runKernel(gc, e);
}
var jt = L({ neg_: pS });
function fS(n) {
  const e = { x: T(n, "x", "softplus") };
  return $.runKernel(ji, e);
}
var da = L({ softplus_: fS });
function mS(n) {
  const t = T(n, "x", "logSigmoid");
  return So((s) => ({ value: jt(da(jt(s))), gradFunc: (i6) => G(i6, xr(jt(s))) }))(t);
}
var gS = L({ logSigmoid_: mS });
function bS(n, t) {
  let e = T(n, "a", "sub"), s = T(t, "b", "sub");
  [e, s] = ne(e, s);
  const o = { a: e, b: s };
  return $.runKernel(ea, o);
}
var lt = L({ sub_: bS });
function xS(n, t = -1) {
  const e = T(n, "logits", "logSoftmax");
  if (t === -1 && (t = e.rank - 1), t !== e.rank - 1)
    throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${e.rank} and axis was ${t}`);
  return So((o, r) => {
    const a = Xn(o, t, true), l = lt(o, a), c = lt(et(l, "float32"), Nn(at(Tn(l), t, true)));
    return r([c]), { value: c, gradFunc: (d, h6) => {
      const [p6] = h6, f = true, m = Tn(p6);
      return lt(d, G(at(d, t, f), m));
    } };
  })(e);
}
var Vb = L({ logSoftmax_: xS });
function yS(n, t = null, e = false) {
  const s = T(n, "x", "logSumExp"), o = Ct(t, s.shape), r = Xn(
    s,
    o,
    true
    /* keepDims */
  ), i6 = lt(s, r), a = Tn(i6), l = at(a, o), c = Nn(l), u = U(W(r, c.shape), c);
  if (e) {
    const d = re(u.shape, o);
    return W(u, d);
  }
  return u;
}
var zb = L({ logSumExp_: yS });
function wS(n, t) {
  const e = T(n, "a", "logicalAnd", "bool"), s = T(t, "b", "logicalAnd", "bool");
  bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(ic, o);
}
var ss = L({ logicalAnd_: wS });
function IS(n) {
  const e = { x: T(n, "x", "logicalNot", "bool") };
  return $.runKernel(ac, e);
}
var np = L({ logicalNot_: IS });
function CS(n, t) {
  const e = T(n, "a", "logicalOr", "bool"), s = T(t, "b", "logicalOr", "bool");
  bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(lc, o);
}
var Xb = L({ logicalOr_: CS });
function vS(n, t) {
  const e = T(n, "a", "logicalXor", "bool"), s = T(t, "b", "logicalXor", "bool");
  return bt(e.shape, s.shape), ss(Xb(n, t), np(ss(n, t)));
}
var SS = L({ logicalXor_: vS });
function kS(n, t, e, s, o) {
  const r = T(n, "x", "maxPool"), i6 = 1;
  let a = r, l = false;
  r.rank === 3 && (l = true, a = W(r, [1, r.shape[0], r.shape[1], r.shape[2]])), v2(a.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${a.rank}.`), v2(Ee(e, i6), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${e} and dilations '${i6}'`), Be("maxPool", s, o);
  const c = { x: a }, u = { filterSize: t, strides: e, pad: s, dimRoundingMode: o }, d = $.runKernel(dc, c, u);
  return l ? W(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}
var sp = L({ maxPool_: kS });
function TS(n, t = [1, 1, 1], e, s, o, r = "NDHWC") {
  const i6 = T(n, "x", "maxPool3d");
  let a = i6, l = false;
  i6.rank === 4 && (l = true, a = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2], i6.shape[3]])), v2(a.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${a.rank}.`), v2(r === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${r}`), Be("maxPool3d", s, o);
  const c = { x: a }, u = { filterSize: t, strides: e, pad: s, dimRoundingMode: o, dataFormat: r }, d = $.runKernel(hc, c, u);
  return l ? W(d, [d.shape[1], d.shape[2], d.shape[3], d.shape[4]]) : d;
}
var NS = L({ maxPool3d_: TS });
function RS(n, t) {
  let e = T(n, "a", "maximum"), s = T(t, "b", "maximum");
  [e, s] = ne(e, s), e.dtype === "bool" && (e = et(e, "int32"), s = et(s, "int32")), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(Vi, o);
}
var _s = L({ maximum_: RS });
function $S(n, t = null, e = false) {
  const o = { x: T(n, "x", "mean") }, r = { axis: t, keepDims: e };
  return $.runKernel(pc, o, r);
}
var se = L({ mean_: $S });
function ge(n, t = "float32") {
  if (is(n), t === "complex64") {
    const s = ge(n, "float32"), o = ge(n, "float32");
    return bo(s, o);
  }
  const e = Se(O(n), t);
  return $.makeTensor(e, n, t);
}
function Us(n, t = "float32") {
  if (is(n), t === "complex64") {
    const s = Us(n, "float32"), o = ge(n, "float32");
    return bo(s, o);
  }
  const e = Fl(O(n), t);
  return $.makeTensor(e, n, t);
}
function GS(n, t) {
  let e = T(n, "a", "minimum"), s = T(t, "b", "minimum");
  [e, s] = ne(e, s), e.dtype === "bool" && (e = et(e, "int32"), s = et(s, "int32")), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(zi, o);
}
var Kc = L({ minimum_: GS });
function ES(n, t, e) {
  v2(e === "reflect" || e === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${e}.`);
  const s = T(n, "x", "mirrorPad");
  if (s.rank === 0)
    throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  v2(t.length === s.rank, () => `Padding doesn't match input. Must be ${s.rank}. Got ${t.length}.`);
  const o = e === "reflect" ? 1 : 0;
  for (let a = 0; a < s.rank; a++)
    v2(t[a].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), v2(t[a][0] >= 0 && t[a][0] <= s.shape[a] - o && t[a][1] >= 0 && t[a][1] <= s.shape[a] - o, () => `Padding in dimension ${a} cannot be greater than or equal to ${s.shape[a] - o} or less than 0 for input of shape ${s.shape}`);
  const r = { paddings: t, mode: e }, i6 = { x: s };
  return $.runKernel(mc, i6, r);
}
var LS = L({ mirrorPad_: ES });
function MS(n, t) {
  let e = T(n, "a", "mod"), s = T(t, "b", "mod");
  [e, s] = ne(e, s);
  const o = { a: e, b: s };
  return $.runKernel(Xi, o);
}
var WS = L({ mod_: MS });
function DS(n, t = null, e = false) {
  n = T(n, "x", "moments");
  const s = Ct(t, n.shape), o = se(n, s, e);
  let r = o.shape;
  e || (r = re(o.shape, s));
  const i6 = At(lt(et(n, "float32"), W(o, r))), a = se(i6, s, e);
  return { mean: o, variance: a };
}
var op = L({ moments_: DS });
function FS(n, t) {
  let e = T(n, "a", "notEqual", "string_or_numeric"), s = T(t, "b", "notEqual", "string_or_numeric");
  [e, s] = ne(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(bc, o);
}
var qr = L({ notEqual_: FS });
function VS(n, t, e = 1, s = 0, o = "int32") {
  if (t < 2)
    throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);
  const i6 = { indices: T(n, "indices", "oneHot", "int32") }, a = { dtype: o, depth: t, onValue: e, offValue: s };
  return $.runKernel(yc, i6, a);
}
var Pb = L({ oneHot_: VS });
function zS(n) {
  const e = { x: T(n, "x", "onesLike") };
  return $.runKernel(xc, e);
}
var Rn = L({ onesLike_: zS });
function XS(n, t, e = 0) {
  const s = T(n, "x", "pad");
  if (s.rank === 0)
    throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  const o = { paddings: t, constantValue: e }, r = { x: s };
  return $.runKernel(Ic, r, o);
}
var rp = L({ pad_: XS });
function PS(n, t, e) {
  const s = T(n, "x", "spaceToBatchND");
  v2(s.rank >= 1 + t.length, () => `input rank ${s.rank} should be > than [blockShape] ${t.length}`), v2(e.length === t.length, () => `paddings.shape[0] ${e.length} must be equal to [blockShape] ${t.length}`), v2(s.shape.reduce((i6, a, l) => l > 0 && l <= t.length ? i6 && (a + e[l - 1][0] + e[l - 1][1]) % t[l - 1] === 0 : i6, true), () => `input spatial dimensions ${s.shape.slice(1)} with paddings ${e.toString()} must be divisible by blockShapes ${t.toString()}`);
  const o = { x: s }, r = { blockShape: t, paddings: e };
  return $.runKernel(Ec, o, r);
}
var ip = L({ spaceToBatchND_: PS });
function AS(n, t, e, s, o, r, i6) {
  o == null && (o = [1, 1]), r == null && (r = 1), s === 0 && (s = "valid");
  const a = T(n, "x", "maxPool");
  let l = a, c = false;
  a.rank === 3 && (c = true, l = W(a, [1, a.shape[0], a.shape[1], a.shape[2]])), v2(Ee(r, o), () => `Error in pool: Either strides or dilations must be 1. Got strides ${r} and dilations '${o}'`);
  const u = $n(l.shape, t, r, o, s), d = [u.dilationHeight, u.dilationWidth];
  let h6;
  s === "same" ? h6 = KS([u.filterHeight, u.filterWidth], d) : h6 = [[0, 0], [0, 0]];
  const p6 = d[0] === 1 && d[1] === 1, [f, m] = OS([u.inHeight, u.inWidth], d, h6), g6 = p6 ? s : "valid", b6 = p6 ? l : ip(l, d, f), w6 = (e === "avg" ? () => Bh(b6, t, r, g6, i6) : () => sp(b6, t, r, g6, i6))(), y6 = p6 ? w6 : _h(w6, d, m);
  return c ? W(y6, [y6.shape[1], y6.shape[2], y6.shape[3]]) : y6;
}
function OS(n, t, e) {
  const s = e.map((u) => u[0]), o = e.map((u) => u[1]), r = n.concat(s, o), i6 = t.map((u, d) => (u - r[d] % u) % u), a = o.map((u, d) => u + i6[d]), l = t.map((u, d) => [s[d], a[d]]), c = t.map((u, d) => [0, i6[d]]);
  return [l, c];
}
function KS(n, t) {
  const s = n.map((i6, a) => i6 + (i6 - 1) * (t[a] - 1)).map((i6) => i6 - 1), o = s.map((i6) => Math.floor(i6 / 2)), r = s.map((i6, a) => i6 - o[a]);
  return s.map((i6, a) => [o[a], r[a]]);
}
var ZS = L({ pool_: AS });
function BS(n, t) {
  const e = T(n, "x", "prelu"), s = T(t, "alpha", "prelu"), o = { x: e, alpha: s };
  return $.runKernel(Cc, o);
}
var ap = L({ prelu_: BS });
function HS(n, t = null, e = false) {
  let s = T(n, "x", "prod");
  s.dtype === "bool" && (s = et(s, "int32"));
  const o = { x: s }, r = { axis: t, keepDims: e };
  return $.runKernel(vc, o, r);
}
var _S = L({ prod_: HS });
var lp = { exports: {} };
lp.exports;
(function(n) {
  (function(t, e, s) {
    function o(l) {
      var c = this, u = a();
      c.next = function() {
        var d = 2091639 * c.s0 + c.c * 23283064365386963e-26;
        return c.s0 = c.s1, c.s1 = c.s2, c.s2 = d - (c.c = d | 0);
      }, c.c = 1, c.s0 = u(" "), c.s1 = u(" "), c.s2 = u(" "), c.s0 -= u(l), c.s0 < 0 && (c.s0 += 1), c.s1 -= u(l), c.s1 < 0 && (c.s1 += 1), c.s2 -= u(l), c.s2 < 0 && (c.s2 += 1), u = null;
    }
    function r(l, c) {
      return c.c = l.c, c.s0 = l.s0, c.s1 = l.s1, c.s2 = l.s2, c;
    }
    function i6(l, c) {
      var u = new o(l), d = c && c.state, h6 = u.next;
      return h6.int32 = function() {
        return u.next() * 4294967296 | 0;
      }, h6.double = function() {
        return h6() + (h6() * 2097152 | 0) * 11102230246251565e-32;
      }, h6.quick = h6, d && (typeof d == "object" && r(d, u), h6.state = function() {
        return r(u, {});
      }), h6;
    }
    function a() {
      var l = 4022871197, c = function(u) {
        u = String(u);
        for (var d = 0; d < u.length; d++) {
          l += u.charCodeAt(d);
          var h6 = 0.02519603282416938 * l;
          l = h6 >>> 0, h6 -= l, h6 *= l, l = h6 >>> 0, h6 -= l, l += h6 * 4294967296;
        }
        return (l >>> 0) * 23283064365386963e-26;
      };
      return c;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.alea = i6;
  })(
    x,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(lp);
var US = lp.exports;
var cp = { exports: {} };
cp.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this, c = "";
      l.x = 0, l.y = 0, l.z = 0, l.w = 0, l.next = function() {
        var d = l.x ^ l.x << 11;
        return l.x = l.y, l.y = l.z, l.z = l.w, l.w ^= l.w >>> 19 ^ d ^ d >>> 8;
      }, a === (a | 0) ? l.x = a : c += a;
      for (var u = 0; u < c.length + 64; u++)
        l.x ^= c.charCodeAt(u) | 0, l.next();
    }
    function r(a, l) {
      return l.x = a.x, l.y = a.y, l.z = a.z, l.w = a.w, l;
    }
    function i6(a, l) {
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h6 = c.next() >>> 11, p6 = (c.next() >>> 0) / 4294967296, f = (h6 + p6) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (typeof u == "object" && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.xor128 = i6;
  })(
    x,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(cp);
var YS = cp.exports;
var up = { exports: {} };
up.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this, c = "";
      l.next = function() {
        var d = l.x ^ l.x >>> 2;
        return l.x = l.y, l.y = l.z, l.z = l.w, l.w = l.v, (l.d = l.d + 362437 | 0) + (l.v = l.v ^ l.v << 4 ^ (d ^ d << 1)) | 0;
      }, l.x = 0, l.y = 0, l.z = 0, l.w = 0, l.v = 0, a === (a | 0) ? l.x = a : c += a;
      for (var u = 0; u < c.length + 64; u++)
        l.x ^= c.charCodeAt(u) | 0, u == c.length && (l.d = l.x << 10 ^ l.x >>> 4), l.next();
    }
    function r(a, l) {
      return l.x = a.x, l.y = a.y, l.z = a.z, l.w = a.w, l.v = a.v, l.d = a.d, l;
    }
    function i6(a, l) {
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h6 = c.next() >>> 11, p6 = (c.next() >>> 0) / 4294967296, f = (h6 + p6) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (typeof u == "object" && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.xorwow = i6;
  })(
    x,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(up);
var QS = up.exports;
var dp = { exports: {} };
dp.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this;
      l.next = function() {
        var u = l.x, d = l.i, h6, p6;
        return h6 = u[d], h6 ^= h6 >>> 7, p6 = h6 ^ h6 << 24, h6 = u[d + 1 & 7], p6 ^= h6 ^ h6 >>> 10, h6 = u[d + 3 & 7], p6 ^= h6 ^ h6 >>> 3, h6 = u[d + 4 & 7], p6 ^= h6 ^ h6 << 7, h6 = u[d + 7 & 7], h6 = h6 ^ h6 << 13, p6 ^= h6 ^ h6 << 9, u[d] = p6, l.i = d + 1 & 7, p6;
      };
      function c(u, d) {
        var h6, p6 = [];
        if (d === (d | 0))
          p6[0] = d;
        else
          for (d = "" + d, h6 = 0; h6 < d.length; ++h6)
            p6[h6 & 7] = p6[h6 & 7] << 15 ^ d.charCodeAt(h6) + p6[h6 + 1 & 7] << 13;
        for (; p6.length < 8; )
          p6.push(0);
        for (h6 = 0; h6 < 8 && p6[h6] === 0; ++h6)
          ;
        for (h6 == 8 ? p6[7] = -1 : p6[h6], u.x = p6, u.i = 0, h6 = 256; h6 > 0; --h6)
          u.next();
      }
      c(l, a);
    }
    function r(a, l) {
      return l.x = a.x.slice(), l.i = a.i, l;
    }
    function i6(a, l) {
      a == null && (a = +/* @__PURE__ */ new Date());
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h6 = c.next() >>> 11, p6 = (c.next() >>> 0) / 4294967296, f = (h6 + p6) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (u.x && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.xorshift7 = i6;
  })(
    x,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(dp);
var JS = dp.exports;
var hp = { exports: {} };
hp.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this;
      l.next = function() {
        var u = l.w, d = l.X, h6 = l.i, p6, f;
        return l.w = u = u + 1640531527 | 0, f = d[h6 + 34 & 127], p6 = d[h6 = h6 + 1 & 127], f ^= f << 13, p6 ^= p6 << 17, f ^= f >>> 15, p6 ^= p6 >>> 12, f = d[h6] = f ^ p6, l.i = h6, f + (u ^ u >>> 16) | 0;
      };
      function c(u, d) {
        var h6, p6, f, m, g6, b6 = [], x6 = 128;
        for (d === (d | 0) ? (p6 = d, d = null) : (d = d + "\0", p6 = 0, x6 = Math.max(x6, d.length)), f = 0, m = -32; m < x6; ++m)
          d && (p6 ^= d.charCodeAt((m + 32) % d.length)), m === 0 && (g6 = p6), p6 ^= p6 << 10, p6 ^= p6 >>> 15, p6 ^= p6 << 4, p6 ^= p6 >>> 13, m >= 0 && (g6 = g6 + 1640531527 | 0, h6 = b6[m & 127] ^= p6 + g6, f = h6 == 0 ? f + 1 : 0);
        for (f >= 128 && (b6[(d && d.length || 0) & 127] = -1), f = 127, m = 4 * 128; m > 0; --m)
          p6 = b6[f + 34 & 127], h6 = b6[f = f + 1 & 127], p6 ^= p6 << 13, h6 ^= h6 << 17, p6 ^= p6 >>> 15, h6 ^= h6 >>> 12, b6[f] = p6 ^ h6;
        u.w = g6, u.X = b6, u.i = f;
      }
      c(l, a);
    }
    function r(a, l) {
      return l.i = a.i, l.w = a.w, l.X = a.X.slice(), l;
    }
    function i6(a, l) {
      a == null && (a = +/* @__PURE__ */ new Date());
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h6 = c.next() >>> 11, p6 = (c.next() >>> 0) / 4294967296, f = (h6 + p6) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (u.X && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.xor4096 = i6;
  })(
    x,
    // window object or global
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(hp);
var jS = hp.exports;
var pp = { exports: {} };
pp.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this, c = "";
      l.next = function() {
        var d = l.b, h6 = l.c, p6 = l.d, f = l.a;
        return d = d << 25 ^ d >>> 7 ^ h6, h6 = h6 - p6 | 0, p6 = p6 << 24 ^ p6 >>> 8 ^ f, f = f - d | 0, l.b = d = d << 20 ^ d >>> 12 ^ h6, l.c = h6 = h6 - p6 | 0, l.d = p6 << 16 ^ h6 >>> 16 ^ f, l.a = f - d | 0;
      }, l.a = 0, l.b = 0, l.c = -1640531527, l.d = 1367130551, a === Math.floor(a) ? (l.a = a / 4294967296 | 0, l.b = a | 0) : c += a;
      for (var u = 0; u < c.length + 20; u++)
        l.b ^= c.charCodeAt(u) | 0, l.next();
    }
    function r(a, l) {
      return l.a = a.a, l.b = a.b, l.c = a.c, l.d = a.d, l;
    }
    function i6(a, l) {
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h6 = c.next() >>> 11, p6 = (c.next() >>> 0) / 4294967296, f = (h6 + p6) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (typeof u == "object" && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.tychei = i6;
  })(
    x,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(pp);
var qS = pp.exports;
var Ab = { exports: {} };
var tk = {};
var ek = Object.freeze(Object.defineProperty({
  __proto__: null,
  default: tk
}, Symbol.toStringTag, { value: "Module" }));
var nk = w(ek);
(function(n) {
  (function(t, e, s) {
    var o = 256, r = 6, i6 = 52, a = "random", l = s.pow(o, r), c = s.pow(2, i6), u = c * 2, d = o - 1, h6;
    function p6(y6, I, C6) {
      var k7 = [];
      I = I == true ? { entropy: true } : I || {};
      var S = b6(g6(
        I.entropy ? [y6, w6(e)] : y6 ?? x6(),
        3
      ), k7), N = new f(k7), R = function() {
        for (var M6 = N.g(r), V = l, z = 0; M6 < c; )
          M6 = (M6 + z) * o, V *= o, z = N.g(1);
        for (; M6 >= u; )
          M6 /= 2, V /= 2, z >>>= 1;
        return (M6 + z) / V;
      };
      return R.int32 = function() {
        return N.g(4) | 0;
      }, R.quick = function() {
        return N.g(4) / 4294967296;
      }, R.double = R, b6(w6(N.S), e), (I.pass || C6 || function(M6, V, z, X) {
        return X && (X.S && m(X, N), M6.state = function() {
          return m(N, {});
        }), z ? (s[a] = M6, V) : M6;
      })(
        R,
        S,
        "global" in I ? I.global : this == s,
        I.state
      );
    }
    function f(y6) {
      var I, C6 = y6.length, k7 = this, S = 0, N = k7.i = k7.j = 0, R = k7.S = [];
      for (C6 || (y6 = [C6++]); S < o; )
        R[S] = S++;
      for (S = 0; S < o; S++)
        R[S] = R[N = d & N + y6[S % C6] + (I = R[S])], R[N] = I;
      (k7.g = function(M6) {
        for (var V, z = 0, X = k7.i, P6 = k7.j, A6 = k7.S; M6--; )
          V = A6[X = d & X + 1], z = z * o + A6[d & (A6[X] = A6[P6 = d & P6 + V]) + (A6[P6] = V)];
        return k7.i = X, k7.j = P6, z;
      })(o);
    }
    function m(y6, I) {
      return I.i = y6.i, I.j = y6.j, I.S = y6.S.slice(), I;
    }
    function g6(y6, I) {
      var C6 = [], k7 = typeof y6, S;
      if (I && k7 == "object")
        for (S in y6)
          try {
            C6.push(g6(y6[S], I - 1));
          } catch {
          }
      return C6.length ? C6 : k7 == "string" ? y6 : y6 + "\0";
    }
    function b6(y6, I) {
      for (var C6 = y6 + "", k7, S = 0; S < C6.length; )
        I[d & S] = d & (k7 ^= I[d & S] * 19) + C6.charCodeAt(S++);
      return w6(I);
    }
    function x6() {
      try {
        var y6;
        return h6 && (y6 = h6.randomBytes) ? y6 = y6(o) : (y6 = new Uint8Array(o), (t.crypto || t.msCrypto).getRandomValues(y6)), w6(y6);
      } catch {
        var I = t.navigator, C6 = I && I.plugins;
        return [+/* @__PURE__ */ new Date(), t, C6, t.screen, w6(e)];
      }
    }
    function w6(y6) {
      return String.fromCharCode.apply(0, y6);
    }
    if (b6(s.random(), e), n.exports) {
      n.exports = p6;
      try {
        h6 = nk;
      } catch {
      }
    } else
      s["seed" + a] = p6;
  })(
    // global: `self` in browsers (including strict mode and web workers),
    // otherwise `this` in Node and other environments
    typeof self < "u" ? self : x,
    [],
    // pool: entropy pool starts empty
    Math
    // math: package containing random, pow, and seedrandom
  );
})(Ab);
var sk = Ab.exports;
var ok = US;
var rk = YS;
var ik = QS;
var ak = JS;
var lk = jS;
var ck = qS;
var Fo = sk;
Fo.alea = ok;
Fo.xor128 = rk;
Fo.xorwow = ik;
Fo.xorshift7 = ak;
Fo.xor4096 = lk;
Fo.tychei = ck;
var wr = Fo;
var fp = class {
  constructor(t, e, s, o, r) {
    this.mean = t, this.stdDev = e, this.dtype = s, this.nextVal = NaN, this.truncated = o, this.truncated && (this.upper = this.mean + this.stdDev * 2, this.lower = this.mean - this.stdDev * 2);
    const i6 = r || Math.random();
    this.random = wr.alea(i6.toString());
  }
  /** Returns next sample from a Gaussian distribution. */
  nextValue() {
    if (!isNaN(this.nextVal)) {
      const o = this.nextVal;
      return this.nextVal = NaN, o;
    }
    let t, e, s = false;
    for (; !s; ) {
      let o, r, i6;
      do
        o = 2 * this.random() - 1, r = 2 * this.random() - 1, i6 = o * o + r * r;
      while (i6 >= 1 || i6 === 0);
      const a = Math.sqrt(-2 * Math.log(i6) / i6);
      t = this.mean + this.stdDev * o * a, e = this.mean + this.stdDev * r * a, (!this.truncated || this.isValidTruncated(t)) && (s = true);
    }
    return (!this.truncated || this.isValidTruncated(e)) && (this.nextVal = this.convertValue(e)), this.convertValue(t);
  }
  /** Handles proper rounding for non-floating-point numbers. */
  convertValue(t) {
    return this.dtype == null || this.dtype === "float32" ? t : Math.round(t);
  }
  /** Returns true if less than 2-standard-deviations from the mean. */
  isValidTruncated(t) {
    return t <= this.upper && t >= this.lower;
  }
};
var dY = class {
  constructor(t, e, s, o) {
    this.alpha = t, this.beta = 1 / e, this.dtype = s;
    const r = o || Math.random();
    this.randu = wr.alea(r.toString()), this.randn = new fp(0, 1, s, false, this.randu()), t < 1 ? this.d = t + 2 / 3 : this.d = t - 1 / 3, this.c = 1 / Math.sqrt(9 * this.d);
  }
  /** Returns next sample from a gamma distribution. */
  nextValue() {
    let t, e, s, o, r, i6;
    for (; ; ) {
      do
        o = this.randn.nextValue(), i6 = 1 + this.c * o;
      while (i6 <= 0);
      if (i6 *= i6 * i6, t = o * o, e = 1 - 0.331 * t * t, s = 0.5 * t + this.d * (1 - i6 + Math.log(i6)), r = this.randu(), r < e || Math.log(r) < s)
        break;
    }
    return i6 = 1 / this.beta * this.d * i6, this.alpha < 1 && (i6 *= Math.pow(this.randu(), 1 / this.alpha)), this.convertValue(i6);
  }
  /** Handles proper rounding for non-floating-point numbers. */
  convertValue(t) {
    return this.dtype === "float32" ? t : Math.round(t);
  }
};
var uk = class {
  constructor(t = 0, e = 1, s, o) {
    if (this.canReturnFloat = () => this.dtype == null || this.dtype === "float32", this.min = t, this.range = e - t, this.dtype = s, o == null && (o = Math.random()), typeof o == "number" && (o = o.toString()), !this.canReturnFloat() && this.range <= 1)
      throw new Error(`The difference between ${t} - ${e} <= 1 and dtype is not float`);
    this.random = wr.alea(o);
  }
  convertValue(t) {
    return this.canReturnFloat() ? t : Math.round(t);
  }
  nextValue() {
    return this.convertValue(this.min + this.range * this.random());
  }
};
function dk(n, t = 0, e = 1, s, o) {
  if (is(n), s != null && s === "bool")
    throw new Error(`Unsupported data type ${s}`);
  const r = new fp(t, e, s, false, o), i6 = vt(n, s);
  for (let a = 0; a < i6.values.length; a++)
    i6.values[a] = r.nextValue();
  return i6.toTensor();
}
var hk = L({ randomNormal_: dk });
function pk(n, t = 0, e = 1, s = "float32", o) {
  is(n);
  const r = vt(n, s), i6 = new uk(t, e, null, o);
  for (let a = 0; a < r.values.length; a++)
    r.values[a] = i6.nextValue();
  return r.toTensor();
}
var Zc = L({ randomUniform_: pk });
function ti(n, t, e = 1, s = "float32") {
  if (e === 0)
    throw new Error("Cannot have a step of zero");
  const o = { start: n, stop: t, step: e, dtype: s };
  return $.runKernel(yh, {}, o);
}
function fk(n) {
  const e = { input: T(n, "input", "real") };
  return $.runKernel(wh, e);
}
var dl = L({ real_: fk });
function mk(n) {
  const e = { x: T(n, "x", "reciprocal") };
  return $.runKernel(Oi, e);
}
var gk = L({ reciprocal_: mk });
function bk(n) {
  const e = { x: T(n, "x", "relu") };
  return $.runKernel(Ki, e);
}
var ws = L({ relu_: bk });
function xk(n) {
  const e = { x: T(n, "x", "relu6") };
  return $.runKernel(Zi, e);
}
var Ob = L({ relu6_: xk });
function yk(n, t) {
  const s = { x: T(n, "x", "reverse") }, o = { dims: t };
  return $.runKernel(Nc, s, o);
}
var ko = L({ reverse_: yk });
function wk(n) {
  const e = { x: T(n, "x", "round") };
  return $.runKernel(Bi, e);
}
var Kb = L({ round_: wk });
function Ik(n) {
  const e = { x: T(n, "x", "rsqrt", "float32") };
  return $.runKernel(Hi, e);
}
var Zb = L({ rsqrt_: Ik });
function Ck(n) {
  const e = { x: T(n, "x", "selu") };
  return $.runKernel(_i, e);
}
var Bb = L({ selu_: Ck });
function vk(n, t, e, s, o, r = [1, 1], i6 = "NHWC") {
  const a = T(n, "x", "separableConv2d"), l = T(t, "depthwiseFilter", "separableConv2d"), c = T(e, "pointwiseFilter", "separableConv2d");
  let u = a, d = false;
  if (a.rank === 3 && (d = true, u = W(a, [1, a.shape[0], a.shape[1], a.shape[2]])), i6 === "NCHW")
    throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  v2(u.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${u.rank}.`), v2(l.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`), v2(c.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`), v2(c.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${c.shape[0]}.`), v2(c.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${c.shape[1]}.`);
  const h6 = l.shape[2], p6 = l.shape[3];
  v2(c.shape[2] === h6 * p6, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${h6 * p6}, but got ${c.shape[2]}.`);
  const f = Qh(u, l, s, o, i6, r), g6 = Co(f, c, 1, "valid", i6);
  return d ? W(g6, [g6.shape[1], g6.shape[2], g6.shape[3]]) : g6;
}
var Hb = L({ separableConv2d_: vk });
function Sk(n) {
  const e = { x: T(n, "x", "sign") };
  return $.runKernel(Qi, e);
}
var kk = L({ sign_: Sk });
function Tk(n) {
  const e = { x: T(n, "x", "sin", "float32") };
  return $.runKernel(Ui, e);
}
var _b = L({ sin_: Tk });
function Nk(n) {
  const e = { x: T(n, "x", "sinh") };
  return $.runKernel(Yi, e);
}
var Ub = L({ sinh_: Nk });
function Rk(n, t, e) {
  const s = T(n, "x", "slice1d");
  return v2(s.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${s.rank} tensor`), Dt(s, [t], [e]);
}
var mp = L({ slice1d_: Rk });
function $k(n, t, e) {
  const s = T(n, "x", "slice2d");
  return v2(s.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${s.rank} tensor`), Dt(s, t, e);
}
var Yb = L({ slice2d_: $k });
function Gk(n, t, e) {
  const s = T(n, "x", "slice3d");
  return v2(s.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${s.rank} tensor`), Dt(s, t, e);
}
var gp = L({ slice3d_: Gk });
function Ek(n, t, e) {
  const s = T(n, "x", "slice4d");
  return v2(s.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${s.rank} tensor`), Dt(s, t, e);
}
var hl = L({ slice4d_: Ek });
function Lk(n, t = -1) {
  const e = T(n, "logits", "softmax", "float32");
  if (t === -1 && (t = e.rank - 1), t !== e.rank - 1)
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${e.rank} and dim was ${t}`);
  const s = { logits: e }, o = { dim: t };
  return $.runKernel(Mc, s, o);
}
var bp = L({ softmax_: Lk });
function Mk(n) {
  v2(n.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${n.dtype}.`);
  const t = { input: n };
  return $.runKernel(lh, t);
}
var xp = L({ fft_: Mk });
function Wk(n) {
  v2(n.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${n.dtype}.`);
  const t = { input: n };
  return $.runKernel(dh, t);
}
var pl = L({ ifft_: Wk });
function Dk(n) {
  const t = n.shape[n.shape.length - 1], e = n.size / t;
  let s;
  if (t <= 2) {
    const o = W(n, [e, t]);
    s = pl(o);
  } else {
    const o = [e, 2 * (t - 1)], r = W(dl(n), [e, t]), i6 = W(qh(n), [e, t]), a = ko(Dt(r, [0, 1], [e, t - 2]), 1), l = G(ko(Dt(i6, [0, 1], [e, t - 2]), 1), gt(-1)), c = Ge([r, a], 1), u = Ge([i6, l], 1), d = W(bo(c, u), [o[0], o[1]]);
    s = pl(d);
  }
  if (s = dl(s), n.rank === 3 && n.shape[0] !== 0) {
    const o = s, r = n.shape[0];
    s = W(s, [r, s.shape[0] / r, s.shape[1]]), o.dispose();
  }
  return s;
}
var Qb = L({ irfft_: Dk });
function Fk(n, t, e = 0) {
  const o = { x: T(n, "x", "split") }, r = { numOrSizeSplits: t, axis: e };
  return $.runKernel(Lc, o, r);
}
var un = L({ split_: Fk });
function Vk(n, t) {
  v2(n.dtype === "float32", () => `The dtype for rfft() must be real value but got ${n.dtype}`);
  let e = n.shape[n.shape.length - 1];
  const s = n.size / e;
  let o;
  if (t != null && t < e) {
    const f = n.shape.map((g6) => 0), m = n.shape.map((g6) => g6);
    m[n.shape.length - 1] = t, o = Dt(n, f, m), e = t;
  } else if (t != null && t > e) {
    const f = n.shape.map((m) => m);
    f[n.shape.length - 1] = t - e, o = Ge([n, ge(f)], n.shape.length - 1), e = t;
  } else
    o = n;
  const r = Tt(o), i6 = W(bo(o, r), [s, e]), a = xp(i6), l = Math.floor(e / 2) + 1, c = dl(a), u = qh(a), d = un(c, [l, e - l], c.shape.length - 1), h6 = un(u, [l, e - l], u.shape.length - 1), p6 = o.shape.slice();
  return p6[o.shape.length - 1] = l, W(bo(d[0], h6[0]), p6);
}
var yp = L({ rfft_: Vk });
function zk(n, t) {
  let e = T(n, "a", "squaredDifference"), s = T(t, "b", "squaredDifference");
  [e, s] = ne(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s }, r = {};
  return $.runKernel(ta, o, r);
}
var Jb = L({ squaredDifference_: zk });
function Xk(n, t) {
  const e = T(n, "x", "squeeze", "string_or_numeric");
  return W(e, gs(e.shape, t).newShape);
}
var ha = L({ squeeze_: Xk });
function Pk(n, t = 0) {
  const e = Ah(n, "tensors", "stack", "string_or_numeric");
  v2(e.length >= 1, () => "Pass at least one tensor to tf.stack"), e.length > 0 && v2(t <= e[0].rank, () => "Axis must be <= rank of the tensor");
  const s = e, o = { axis: t };
  return $.runKernel(wc, s, o);
}
var os = L({ stack_: Pk });
function Ak(n, t = 0) {
  const s = { x: T(n, "x", "step") }, o = { alpha: t };
  return $.runKernel(ra, s, o);
}
var pa = L({ step_: Ak });
function Ok(n, t, e, s, o = 0, r = 0, i6 = 0, a = 0, l = 0) {
  const u = { x: T(n, "x", "stridedSlice", "string_or_numeric") }, d = {
    begin: t,
    end: e,
    strides: s,
    beginMask: o,
    endMask: r,
    ellipsisMask: i6,
    newAxisMask: a,
    shrinkAxisMask: l
  };
  return $.runKernel(Rh, u, d);
}
var Kk = L({ stridedSlice_: Ok });
function Zk(n) {
  const e = { x: T(n, "x", "tan", "float32") };
  return $.runKernel(na, e);
}
var Bk = L({ tan_: Zk });
function Je(n, t) {
  Dl(n);
  const e = aa(n, t);
  if (e.length !== 1)
    throw new Error("tensor1d() requires values to be a flat/TypedArray");
  return la(n, null, e, t);
}
function qa(n, t, e) {
  if (Dl(n), t != null && t.length !== 2)
    throw new Error("tensor2d() requires shape to have two numbers");
  const s = aa(n, e);
  if (s.length !== 2 && s.length !== 1)
    throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  if (s.length === 1 && t == null)
    throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  return la(n, t, s, e);
}
function Hk(n, t, e) {
  if (Dl(n), t != null && t.length !== 3)
    throw new Error("tensor3d() requires shape to have three numbers");
  const s = aa(n, e);
  if (s.length !== 3 && s.length !== 1)
    throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  if (s.length === 1 && t == null)
    throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  return la(n, t, s, e);
}
function _k(n, t = 1, e = true) {
  const s = T(n, "x", "topk");
  if (s.rank === 0)
    throw new Error("topk() expects the input to be of rank 1 or higher");
  const o = s.shape[s.shape.length - 1];
  if (t < 0)
    throw new Error(`'k' passed to topk() must be >= 0 but got ${t}`);
  if (t > o)
    throw new Error(`'k' passed to topk() must be <= the last dimension (${o}) but got ${t}`);
  const r = { x: s }, i6 = { k: t, sorted: e }, [a, l] = $.runKernel(Lh, r, i6);
  return { values: a, indices: l };
}
var Uk = L({ topk_: _k });
function Yk(n, t = 0, e = 1, s, o) {
  if (is(n), s != null && s === "bool")
    throw new Error("Unsupported data type $ { dtype }");
  const r = new fp(t, e, s, true, o), i6 = vt(n, s);
  for (let a = 0; a < i6.values.length; a++)
    i6.values[a] = r.nextValue();
  return i6.toTensor();
}
var jb = L({ truncatedNormal_: Yk });
function Qk(n, t = 0) {
  const e = T(n, "x", "unique", "string_or_numeric");
  v2(e.rank > 0, () => "The input tensor must be at least 1D");
  const s = { x: e }, o = { axis: t }, [r, i6] = $.runKernel(Wh, s, o);
  return { values: r, indices: i6 };
}
var Jk = L({ unique_: Qk });
function jk(n, t, e) {
  const s = T(n, "x", "unsortedSegmentSum"), o = T(t, "segmentIds", "unsortedSegmentSum", "int32");
  v2(go(e), () => "numSegments must be of dtype int");
  const r = { x: s, segmentIds: o }, i6 = { numSegments: e };
  return $.runKernel(Dc, r, i6);
}
var qb = L({ unsortedSegmentSum_: jk });
function qk(n, t = 0) {
  const e = T(n, "x", "unstack", "string_or_numeric");
  v2(t >= -e.shape.length && t < e.shape.length, () => `Axis = ${t} is not in [-${e.shape.length}, ${e.shape.length})`);
  const s = { value: e }, o = { axis: t };
  return $.runKernel(Wc, s, o);
}
var To = L({ unstack_: qk });
function tT(n, t = true, e, s) {
  return $.makeVariable(n, t, e, s);
}
function t0(n, t) {
  const e = [];
  for (let r = 0; r < t.length; r++)
    t[r] && e.push(r);
  const s = vt(n, "int32"), o = vt([e.length, n.length], "int32");
  for (let r = 0; r < e.length; r++) {
    const i6 = s.indexToLoc(e[r]), a = r * n.length;
    o.values.set(i6, a);
  }
  return o.toTensor();
}
function eT(n, t, e) {
  const s = T(n, "x", "transpose");
  if (t == null && (t = s.shape.map((i6, a) => a).reverse()), v2(s.rank === t.length, () => `Error in transpose: rank of input ${s.rank} must match length of perm ${t}.`), t.forEach((i6) => {
    v2(i6 >= 0 && i6 < s.rank, () => `All entries in 'perm' must be between 0 and ${s.rank - 1} but got ${t}`);
  }), s.rank <= 1)
    return s.clone();
  const o = { x: s }, r = { perm: t };
  return s.dtype === "complex64" ? D(() => {
    let i6 = dl(s), a = qh(s);
    return i6 = $.runKernel(Jo, { x: i6 }, r), a = $.runKernel(Jo, { x: a }, r), e && (a = jt(a)), bo(i6, a);
  }) : $.runKernel(Jo, o, r);
}
var kt = L({ transpose_: eT });
function wp(n, t, e) {
  const s = t.rank > 1 ? t.shape[t.rank - 1] : 1, o = t.rank > 1 ? t.rank - 1 : 1, r = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${e.shape}, indices.shape: ${t.shape}, shape: ${n}, sliceDim: ${s}, and batchDim: ${o}.`;
  if (e.rank < o)
    throw new Error(r + ` update.rank < ${o}. `);
  if (n.length < s + (e.rank - o))
    throw new Error(r + ` Output shape length < ${s + (e.rank - o)}`);
  if (e.rank !== o + n.length - s)
    throw new Error(r + ` update.rank != ${o + n.length - s}`);
  for (let i6 = 0; i6 < o; ++i6)
    if (e.shape[i6] !== t.shape[i6])
      throw new Error(r + ` updates.shape[${i6}] (${e.shape[i6]}) != indices.shape[${i6}] (${t.shape[i6]}).`);
  for (let i6 = 0; i6 < e.rank - o; ++i6)
    if (e.shape[i6 + o] !== n[i6 + s])
      throw new Error(r + ` updates.shape[${i6 + o}] (${e.shape[i6 + o]}) != shape[${i6 + o}] (${n[i6 + o]})`);
}
function e0(n, t, e) {
  if (t.rank < 1)
    throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t.rank}.`);
  if (n.rank < 1)
    throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${n.rank}.`);
  if (t.dtype !== "int32")
    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t.dtype}`);
  if (e.length < 1)
    throw new Error(`Output rank must be greater or equal to 1, but got shape: ${e}`);
  if (e.length === 0) {
    if (t.size === 0)
      throw new Error(`Indices specified for empty output. indices shape: ${t.shape}`);
    if (n.size === 0)
      throw new Error(`Updates specified for empty output. updates shape: ${n.shape}`);
  }
  wp(e, t, n);
}
function Ir(n, t, e) {
  const s = t.shape.length, o = s > 1 ? t.shape[s - 1] : 1, r = e.length;
  let i6 = 1;
  for (let d = o; d < r; ++d)
    i6 *= e[d];
  const a = o < 1 ? 1 : o, l = O(t.shape) / a, c = [...dt(e.slice(0, o)), 1], u = O(e);
  return { sliceRank: o, numUpdates: l, sliceSize: i6, strides: c, outputSize: u };
}
var hY = Object.freeze(Object.defineProperty({
  __proto__: null,
  calculateShapes: Ir,
  validateInput: e0,
  validateUpdateShape: wp
}, Symbol.toStringTag, { value: "Module" }));
function nT(n, t) {
  if (t == null)
    return n.shape.slice();
  if (Rt(n.shape, t))
    return t;
  if (n.shape.length === t.length) {
    const e = [];
    for (let s = 0; s < n.shape.length; s++)
      t[s] == null && n.shape[s] != null ? e.push(n.shape[s]) : e.push(t[s]);
    return e;
  }
  return t;
}
function sT(n, t, e, s) {
  const o = T(n, "x", "dropout");
  if (v2(o.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${o.dtype} tensor instead.`), v2(t >= 0 && t < 1, () => `rate must be a float in the range [0, 1), but got ${t}.`), t === 0)
    return n instanceof Lt ? o.clone() : o;
  const r = nT(o, e), i6 = 1 - t, a = ut(Ac(U(Zc(r, 0, 1, "float32", s), i6)), i6);
  return G(o, a);
}
var oT = L({ dropout_: sT });
function rT(n) {
  return Math.floor(Math.pow(2, Math.ceil(Math.log(n) / Math.log(2))));
}
function n0(n, t, e) {
  const s = 1 - n % 2, o = new Float32Array(n);
  for (let r = 0; r < n; ++r) {
    const i6 = 2 * Math.PI * r / (n + s - 1);
    o[r] = t - e * Math.cos(i6);
  }
  return Je(o, "float32");
}
function iT(n, t, e, s, o, r = "NHWC", i6) {
  let a = n;
  n.rank === 3 && (a = W(n, [1, n.shape[0], n.shape[1], n.shape[2]]));
  let l = t;
  l.rank === 3 && (l = W(t, [1, t.shape[0], t.shape[1], t.shape[2]])), v2(a.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${a.shape}.`), v2(l.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`), v2(e.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${e}.`);
  const c = r === "NHWC" ? a.shape[3] : a.shape[1], u = r === "NHWC" ? l.shape[3] : l.shape[1];
  v2(c === e[2], () => `Error in conv2dDerFilter: depth of input ${c}) must match input depth in filter (${e[2]}.`), v2(u === e[3], () => `Error in conv2dDerFilter: depth of dy (${u}) must match output depth for filter (${e[3]}).`), Be("conv2dDerFilter", o, i6);
  const d = { x: a, dy: l }, h6 = { strides: s, pad: o, dataFormat: r, dimRoundingMode: i6, filterShape: e };
  return $.runKernel(jd, d, h6);
}
var Ip = L({ conv2DBackpropFilter_: iT });
function Cp(n, t, e) {
  if (e == null || e === "linear")
    return n;
  if (e === "relu")
    return G(n, pa(t));
  throw new Error(`Cannot compute gradient for fused activation ${e}.`);
}
function vp(n, t) {
  let e = t;
  const s = le(n.shape, t.shape);
  return s.length > 0 && (e = at(e, s)), W(e, n.shape);
}
function Sp(n, t, e, s) {
  if (t === "linear")
    return n;
  if (t === "relu")
    return ws(n);
  if (t === "elu")
    return Xc(n);
  if (t === "relu6")
    return Ob(n);
  if (t === "prelu")
    return ap(n, e);
  if (t === "leakyrelu")
    return tp(n, s);
  if (t === "sigmoid")
    return xr(n);
  throw new Error(`Unknown fused activation ${t}.`);
}
var kp = (n, t) => !(n > 0) || t === "linear";
function aT({ x: n, filter: t, strides: e, pad: s, dataFormat: o = "NHWC", dilations: r = [1, 1], dimRoundingMode: i6, bias: a, activation: l = "linear", preluActivationWeights: c, leakyreluAlpha: u }) {
  if (l = l || "linear", kp($.state.gradientDepth, l) === false) {
    v2(o === "NHWC", () => `Error in fused conv2d: got dataFormat of ${o} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`);
    let C6 = Co(n, t, e, s, o, r, i6);
    return a != null && (C6 = U(C6, a)), Sp(C6, l, c, u);
  }
  const d = T(n, "x", "conv2d", "float32"), h6 = T(t, "filter", "conv2d", "float32");
  let p6 = d, f = false;
  d.rank === 3 && (f = true, p6 = W(d, [1, d.shape[0], d.shape[1], d.shape[2]])), v2(p6.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${p6.rank}.`), v2(h6.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${h6.rank}.`), Be("fused conv2d", s, i6);
  const m = o === "NHWC" ? p6.shape[3] : p6.shape[1];
  v2(h6.shape[2] === m, () => `Error in conv2d: depth of input (${m}) must match input depth for filter ${h6.shape[2]}.`), v2(Ee(e, r), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${e} and dilations '${r}'`);
  const g6 = ke(p6.shape, h6.shape, e, r, s, i6);
  let b6;
  a != null && (b6 = T(a, "bias", "fused conv2d"), [b6] = ne(b6, d), o === "NHWC" ? bt(g6.outShape, b6.shape) : (v2(b6.shape.length <= 1, () => `Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${b6.shape.length}.`), v2(b6.shape.length === 0 || b6.shape[0] === g6.outChannels || b6.shape[0] === 1, () => `Error in fused conv2d: bias shape (${b6.shape}) is not compatible with the number of output channels (${g6.outChannels})`)));
  let x6;
  if (c != null) {
    const C6 = c.shape;
    if (v2(C6.length <= 1 || C6.length === 3, () => `Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${C6.length}.`), C6.length === 1)
      v2(C6[0] === 1 || C6[0] === g6.outChannels, () => `Error in fused conv2d: PReLU activation weights (${C6}) is not compatible with the number of output channels (${g6.outChannels}).`);
    else if (C6.length === 3)
      try {
        bt(C6, g6.outShape);
      } catch {
        const S = `Error in fused conv2d: PReLU activation weights (${C6}) is not compatible with the output shape of the conv2d (${g6.outShape}).`;
        throw Error(S);
      }
    x6 = T(c, "prelu weights", "fused conv2d");
  }
  const w6 = (C6, k7) => {
    v2(o === "NHWC", () => `Error in gradient of fused conv2D: got dataFormat of ${o} but only NHWC is currently supported.`);
    const [S, N, R, M6] = k7, V = Cp(C6, R, l);
    v2(wo(r), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${r}'`);
    const z = Uh(N.shape, V, S, e, s), X = Ip(N, V, S.shape, e, s), P6 = [z, X];
    if (M6 != null) {
      const A6 = vp(M6, V);
      P6.push(A6);
    }
    return P6;
  }, y6 = {
    x: p6,
    filter: h6,
    bias: b6,
    preluActivationWeights: x6
  }, I = {
    strides: e,
    pad: s,
    dataFormat: o,
    dilations: r,
    dimRoundingMode: i6,
    activation: l,
    leakyreluAlpha: u
  };
  return a == null ? So((k7, S, N) => {
    let R = (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(rl, y6, I)
    );
    return N([S, k7, R]), f && (R = W(R, [R.shape[1], R.shape[2], R.shape[3]])), { value: R, gradFunc: w6 };
  })(p6, h6) : So((k7, S, N, R) => {
    let M6 = $.runKernel(rl, y6, I);
    return R([S, k7, M6, N]), f && (M6 = W(M6, [M6.shape[1], M6.shape[2], M6.shape[3]])), { value: M6, gradFunc: w6 };
  })(p6, h6, b6);
}
var lT = L({ fusedConv2d_: aT });
function cT(n, t, e, s, o, r = [1, 1], i6) {
  let a = n;
  n.rank === 3 && (a = W(n, [1, n.shape[0], n.shape[1], n.shape[2]]));
  let l = t;
  l.rank === 3 && (l = W(t, [1, t.shape[0], t.shape[1], t.shape[2]]));
  const c = { x: a, dy: l }, u = { strides: s, pad: o, dimRoundingMode: i6, dilations: r, filterShape: e };
  return $.runKernel(rh, c, u);
}
var uT = L({ depthwiseConv2dNativeBackpropFilter_: cT });
function dT(n, t, e, s, o, r = [1, 1], i6) {
  let a = t, l = false;
  t.rank === 3 && (l = true, a = W(t, [1, t.shape[0], t.shape[1], t.shape[2]]));
  const c = { dy: a, filter: e }, u = { strides: s, pad: o, dimRoundingMode: i6, dilations: r, inputShape: n }, d = (
    // tslint:disable-next-line: no-unnecessary-type-assertion
    $.runKernel(ih, c, u)
  );
  return l ? W(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}
var hT = L({ depthwiseConv2dNativeBackpropInput_: dT });
function pT({ a: n, b: t, transposeA: e = false, transposeB: s = false, bias: o, activation: r = "linear", preluActivationWeights: i6, leakyreluAlpha: a = 0.2 }) {
  if (kp($.state.gradientDepth, r) === false) {
    let M6 = Gt(n, t, e, s);
    return o != null && (M6 = U(M6, o)), Sp(M6, r, i6, a);
  }
  let l = T(n, "a", "fused matMul"), c = T(t, "b", "fused matMul");
  [l, c] = ne(l, c);
  const u = e ? l.shape[l.rank - 2] : l.shape[l.rank - 1], d = s ? c.shape[c.rank - 1] : c.shape[c.rank - 2], h6 = e ? l.shape[l.rank - 1] : l.shape[l.rank - 2], p6 = s ? c.shape[c.rank - 2] : c.shape[c.rank - 1], f = l.shape.slice(0, -2), m = c.shape.slice(0, -2), g6 = O(f), b6 = O(m);
  v2(u === d, () => `Error in fused matMul: inner shapes (${u}) and (${d}) of Tensors with shapes ${l.shape} and ${c.shape} and transposeA=${e} and transposeB=${s} must match.`);
  const w6 = bt(l.shape.slice(0, -2), c.shape.slice(0, -2)).concat([h6, p6]), y6 = e ? W(l, [g6, u, h6]) : W(l, [g6, h6, u]), I = s ? W(c, [b6, p6, d]) : W(c, [b6, d, p6]);
  let C6;
  o != null && (C6 = T(o, "bias", "fused matMul"), [C6] = ne(C6, l), bt(w6, C6.shape));
  let k7;
  i6 != null && (k7 = T(i6, "prelu weights", "fused matMul"));
  const S = (M6, V) => {
    const [z, X, P6, A6] = V, B6 = Cp(W(M6, P6.shape), P6, r);
    let Z, H6;
    if (!e && !s ? (Z = Gt(B6, X, false, true), H6 = Gt(z, B6, true, false)) : !e && s ? (Z = Gt(B6, X, false, false), H6 = Gt(B6, z, true, false)) : e && !s ? (Z = Gt(X, B6, false, true), H6 = Gt(z, B6, false, false)) : (Z = Gt(X, B6, true, true), H6 = Gt(B6, z, true, true)), o != null) {
      const Y = vp(A6, B6);
      return [Z, H6, Y];
    } else
      return [Z, H6];
  }, N = {
    a: y6,
    b: I,
    bias: C6,
    preluActivationWeights: k7
  }, R = { transposeA: e, transposeB: s, activation: r, leakyreluAlpha: a };
  return o == null ? So((V, z, X) => {
    const P6 = (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(ol, N, R)
    );
    return X([V, z, P6]), { value: W(P6, w6), gradFunc: S };
  })(y6, I) : So((V, z, X, P6) => {
    const A6 = (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(ol, N, R)
    );
    return P6([V, z, A6, X]), { value: W(A6, w6), gradFunc: S };
  })(y6, I, C6);
}
var im = L({ fusedMatMul_: pT });
function fT(n) {
  return n0(n, 0.54, 0.46);
}
var mT = L({ hammingWindow_: fT });
function gT(n) {
  return n0(n, 0.5, 0.5);
}
var s0 = L({ hannWindow_: gT });
function bT(n, t, e, s = false, o = 0) {
  let r = 0;
  const i6 = [];
  for (; r + t <= n.size; )
    i6.push(Dt(n, r, t)), r += e;
  if (s)
    for (; r < n.size; ) {
      const a = r + t - n.size, l = Ge([
        Dt(n, r, t - a),
        ua([a], o)
      ]);
      i6.push(l), r += e;
    }
  return i6.length === 0 ? qa([], [0, t]) : W(Ge(i6), [i6.length, t]);
}
var o0 = L({ frame_: bT });
function xT(n, t, e, s, o = s0) {
  s == null && (s = rT(t));
  const r = o0(n, t, e), i6 = G(r, o(t));
  return yp(i6, s);
}
var yT = L({ stft_: xT });
function wT(n, t, e, s, o = "bilinear", r = 0) {
  const i6 = T(n, "image", "cropAndResize"), a = T(t, "boxes", "cropAndResize", "float32"), l = T(e, "boxInd", "cropAndResize", "int32"), c = a.shape[0];
  v2(i6.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${i6.rank}.`), v2(a.rank === 2 && a.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${c},4] but had shape ${a.shape}.`), v2(l.rank === 1 && l.shape[0] === c, () => `Error in cropAndResize: boxInd must be have size [${c}] but had shape ${a.shape}.`), v2(s.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${s.length}.`), v2(s[0] >= 1 && s[1] >= 1, () => `cropSize must be atleast [1,1], but was ${s}`), v2(o === "bilinear" || o === "nearest", () => `method must be bilinear or nearest, but was ${o}`);
  const u = { image: i6, boxes: a, boxInd: l }, d = { method: o, extrapolationValue: r, cropSize: s };
  return $.runKernel(nh, u, d);
}
var IT = L({ cropAndResize_: wT });
function CT(n) {
  const t = T(n, "image", "flipLeftRight", "float32");
  v2(t.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`);
  const e = { image: t };
  return $.runKernel(uh, e, {});
}
var vT = L({ flipLeftRight_: CT });
function ST(n) {
  const t = T(n, "image", "grayscaleToRGB"), e = t.rank - 1, s = t.shape[e];
  v2(t.rank >= 2, () => `Error in grayscaleToRGB: images must be at least rank 2, but got rank ${t.rank}.`), v2(s === 1, () => `Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${s}.`);
  const o = new Array(t.rank);
  return o.fill(1, 0, e), o[e] = 3, Vn(t, o);
}
var kT = L({ grayscaleToRGB_: ST });
function TT(n, t, e = 0, s = 0.5) {
  const o = T(n, "image", "rotateWithOffset", "float32");
  v2(o.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${o.rank}.`);
  const r = { image: o }, i6 = { radians: t, fillValue: e, center: s };
  return $.runKernel(Dh, r, i6);
}
var NT = L({ rotateWithOffset_: TT });
function Cr(n, t, e, s, o, r) {
  s == null && (s = 0.5), o == null && (o = Number.NEGATIVE_INFINITY), r == null && (r = 0);
  const i6 = n.shape[0];
  return e = Math.min(e, i6), v2(0 <= s && s <= 1, () => `iouThreshold must be in [0, 1], but was '${s}'`), v2(n.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${n.rank}'`), v2(n.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${n.shape[1]}`), v2(t.rank === 1, () => "scores must be a 1D tensor"), v2(t.shape[0] === i6, () => `scores has incompatible shape with boxes. Expected ${i6}, but was ${t.shape[0]}`), v2(0 <= r && r <= 1, () => `softNmsSigma must be in [0, 1], but was '${r}'`), { maxOutputSize: e, iouThreshold: s, scoreThreshold: o, softNmsSigma: r };
}
function RT(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY) {
  const r = T(n, "boxes", "nonMaxSuppression", "float32"), i6 = T(t, "scores", "nonMaxSuppression", "float32"), a = Cr(r, i6, e, s, o);
  e = a.maxOutputSize, s = a.iouThreshold, o = a.scoreThreshold;
  const l = { maxOutputSize: e, iouThreshold: s, scoreThreshold: o };
  return $.runKernel(gh, { boxes: r, scores: i6 }, l);
}
var $T = L({ nonMaxSuppression_: RT });
function GT(n, t, e) {
  const s = ET(n, t, e), o = s < 0 ? -(s + 1) : s;
  n.splice(o, 0, t);
}
function ET(n, t, e) {
  return MT(n, t, e || LT);
}
function LT(n, t) {
  return n > t ? 1 : n < t ? -1 : 0;
}
function MT(n, t, e) {
  let s = 0, o = n.length, r = 0, i6 = false;
  for (; s < o; ) {
    r = s + (o - s >>> 1);
    const a = e(t, n[r]);
    a > 0 ? s = r + 1 : (o = r, i6 = !a);
  }
  return i6 ? s : -s - 1;
}
function Tp(n, t, e, s, o) {
  return $p(
    n,
    t,
    e,
    s,
    o,
    0
    /* softNmsSigma */
  );
}
function Np(n, t, e, s, o, r) {
  return $p(
    n,
    t,
    e,
    s,
    o,
    0,
    false,
    r,
    true
    /* returnValidOutputs */
  );
}
function Rp(n, t, e, s, o, r) {
  return $p(
    n,
    t,
    e,
    s,
    o,
    r,
    true
    /* returnScoresTensor */
  );
}
function $p(n, t, e, s, o, r, i6 = false, a = false, l = false) {
  const c = [];
  for (let g6 = 0; g6 < t.length; g6++)
    t[g6] > o && c.push({ score: t[g6], boxIndex: g6, suppressBeginIndex: 0 });
  c.sort(am);
  const u = r > 0 ? -0.5 / r : 0, d = [], h6 = [];
  for (; d.length < e && c.length > 0; ) {
    const g6 = c.pop(), { score: b6, boxIndex: x6, suppressBeginIndex: w6 } = g6;
    if (b6 < o)
      break;
    let y6 = false;
    for (let I = d.length - 1; I >= w6; --I) {
      const C6 = WT(n, x6, d[I]);
      if (C6 >= s) {
        y6 = true;
        break;
      }
      if (g6.score = g6.score * DT(s, u, C6), g6.score <= o)
        break;
    }
    g6.suppressBeginIndex = d.length, y6 || (g6.score === b6 ? (d.push(x6), h6.push(g6.score)) : g6.score > o && GT(c, g6, am));
  }
  const p6 = d.length, f = e - p6;
  a && f > 0 && (d.push(...new Array(f).fill(0)), h6.push(...new Array(f).fill(0)));
  const m = { selectedIndices: d };
  return i6 && (m.selectedScores = h6), l && (m.validOutputs = p6), m;
}
function WT(n, t, e) {
  const s = n.subarray(t * 4, t * 4 + 4), o = n.subarray(e * 4, e * 4 + 4), r = Math.min(s[0], s[2]), i6 = Math.min(s[1], s[3]), a = Math.max(s[0], s[2]), l = Math.max(s[1], s[3]), c = Math.min(o[0], o[2]), u = Math.min(o[1], o[3]), d = Math.max(o[0], o[2]), h6 = Math.max(o[1], o[3]), p6 = (a - r) * (l - i6), f = (d - c) * (h6 - u);
  if (p6 <= 0 || f <= 0)
    return 0;
  const m = Math.max(r, c), g6 = Math.max(i6, u), b6 = Math.min(a, d), x6 = Math.min(l, h6), w6 = Math.max(b6 - m, 0) * Math.max(x6 - g6, 0);
  return w6 / (p6 + f - w6);
}
function DT(n, t, e) {
  const s = Math.exp(t * e * e);
  return e <= n ? s : 0;
}
function am(n, t) {
  return n.score - t.score || n.score === t.score && t.boxIndex - n.boxIndex;
}
async function FT(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY) {
  const r = T(n, "boxes", "nonMaxSuppressionAsync"), i6 = T(t, "scores", "nonMaxSuppressionAsync"), a = Cr(r, i6, e, s, o);
  e = a.maxOutputSize, s = a.iouThreshold, o = a.scoreThreshold;
  const l = await Promise.all([r.data(), i6.data()]), c = l[0], u = l[1], { selectedIndices: d } = Tp(c, u, e, s, o);
  return r !== n && r.dispose(), i6 !== t && i6.dispose(), Je(d, "int32");
}
var VT = FT;
function zT(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY, r = 0) {
  const i6 = T(n, "boxes", "nonMaxSuppression"), a = T(t, "scores", "nonMaxSuppression"), l = Cr(i6, a, e, s, o, r);
  e = l.maxOutputSize, s = l.iouThreshold, o = l.scoreThreshold, r = l.softNmsSigma;
  const c = { boxes: i6, scores: a }, u = { maxOutputSize: e, iouThreshold: s, scoreThreshold: o, softNmsSigma: r }, d = $.runKernel(xh, c, u);
  return { selectedIndices: d[0], selectedScores: d[1] };
}
var XT = L({ nonMaxSuppressionWithScore_: zT });
async function PT(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY, r = 0) {
  const i6 = T(n, "boxes", "nonMaxSuppressionAsync"), a = T(t, "scores", "nonMaxSuppressionAsync"), l = Cr(i6, a, e, s, o, r);
  e = l.maxOutputSize, s = l.iouThreshold, o = l.scoreThreshold, r = l.softNmsSigma;
  const c = await Promise.all([i6.data(), a.data()]), u = c[0], d = c[1], { selectedIndices: h6, selectedScores: p6 } = Rp(u, d, e, s, o, r);
  return i6 !== n && i6.dispose(), a !== t && a.dispose(), {
    selectedIndices: Je(h6, "int32"),
    selectedScores: Je(p6)
  };
}
var AT = PT;
function OT(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY, r = false) {
  const i6 = T(n, "boxes", "nonMaxSuppression"), a = T(t, "scores", "nonMaxSuppression"), l = Cr(
    i6,
    a,
    e,
    s,
    o,
    null
    /* softNmsSigma */
  ), c = l.maxOutputSize, u = l.iouThreshold, d = l.scoreThreshold, h6 = { boxes: i6, scores: a }, p6 = {
    maxOutputSize: c,
    iouThreshold: u,
    scoreThreshold: d,
    padToMaxOutputSize: r
  }, f = $.runKernel(bh, h6, p6);
  return { selectedIndices: f[0], validOutputs: f[1] };
}
var KT = L({ nonMaxSuppressionPadded_: OT });
async function ZT(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY, r = false) {
  const i6 = T(n, "boxes", "nonMaxSuppressionAsync"), a = T(t, "scores", "nonMaxSuppressionAsync"), l = Cr(
    i6,
    a,
    e,
    s,
    o,
    null
    /* softNmsSigma */
  ), c = l.maxOutputSize, u = l.iouThreshold, d = l.scoreThreshold, [h6, p6] = await Promise.all([i6.data(), a.data()]), { selectedIndices: f, validOutputs: m } = Np(h6, p6, c, u, d, r);
  return i6 !== n && i6.dispose(), a !== t && a.dispose(), {
    selectedIndices: Je(f, "int32"),
    validOutputs: gt(m, "int32")
  };
}
var BT = ZT;
function HT(n, t, e = false, s = false) {
  const o = T(n, "images", "resizeBilinear");
  v2(o.rank === 3 || o.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${o.rank}.`), v2(t.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${t}.`), v2(s === false || e === false, () => "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.");
  let r = o, i6 = false;
  o.rank === 3 && (i6 = true, r = W(o, [1, o.shape[0], o.shape[1], o.shape[2]]));
  const a = { images: r }, l = { alignCorners: e, halfPixelCenters: s, size: t }, c = $.runKernel(Tc, a, l);
  return i6 ? W(c, [c.shape[1], c.shape[2], c.shape[3]]) : c;
}
var r0 = L({ resizeBilinear_: HT });
function _T(n, t, e = false, s = false) {
  const o = T(n, "images", "resizeNearestNeighbor");
  v2(o.rank === 3 || o.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${o.rank}.`), v2(t.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`), v2(o.dtype === "float32" || o.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype"), v2(s === false || e === false, () => "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.");
  let r = o, i6 = false;
  o.rank === 3 && (i6 = true, r = W(o, [1, o.shape[0], o.shape[1], o.shape[2]]));
  const a = { images: r }, l = { alignCorners: e, halfPixelCenters: s, size: t }, c = $.runKernel(kc, a, l);
  return i6 ? W(c, [c.shape[1], c.shape[2], c.shape[3]]) : c;
}
var i0 = L({ resizeNearestNeighbor_: _T });
function UT(n, t = "binary", e = false, s = 0.5) {
  const o = T(n, "image", "threshold"), r = 0.2989, i6 = 0.587, a = 0.114, l = o.shape[0] * o.shape[1];
  let c = G(Je([s]), 255), u, d, h6, p6;
  if (v2(o.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${o.rank}.`), v2(o.shape[2] === 3 || o.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${o.shape[2]}.`), v2(o.dtype === "int32" || o.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${o.dtype}.`), v2(t === "otsu" || t === "binary", () => `Method must be binary or otsu, but was ${t}`), o.shape[2] === 3) {
    [u, d, h6] = un(o, [1, 1, 1], -1);
    const g6 = G(u, r), b6 = G(d, i6), x6 = G(h6, a);
    p6 = U(U(g6, b6), x6);
  } else
    p6 = n;
  if (t === "otsu") {
    const g6 = B2(et(Kb(p6), "int32"), Re([]), 256);
    c = YT(g6, l);
  }
  const f = e ? yr(p6, c) : sn(p6, c);
  return et(G(f, 255), "int32");
}
function YT(n, t) {
  let e = Je([-1]), s = Je([0]), o = Je([0]), r, i6, a, l, c, u;
  for (let d = 0; d < n.size - 1; d++) {
    r = Dt(n, 0, d + 1), i6 = Dt(n, d + 1), c = ut(at(r), t), u = ut(at(i6), t);
    const h6 = at(G(r, ti(0, r.size)));
    a = ut(h6, at(r));
    const p6 = ua(i6.shape, r.size), f = U(ti(0, i6.size), p6), m = G(i6, f);
    l = ut(at(m), at(i6));
    const g6 = lt(a, l), b6 = lt(a, l), x6 = G(c, u);
    o = G(G(x6, g6), b6);
    const w6 = sn(o, s);
    s = Oe(w6, o, s), e = Oe(w6, Je([d]), e);
  }
  return e;
}
var QT = L({ threshold_: UT });
function JT(n, t, e = "nearest", s = "constant", o = 0, r) {
  const i6 = T(n, "image", "transform", "float32"), a = T(t, "transforms", "transform", "float32");
  v2(i6.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${i6.rank}.`), v2(a.rank === 2 && (a.shape[0] === i6.shape[0] || a.shape[0] === 1) && a.shape[1] === 8, () => "Error in transform: Input transform should be batch x 8 or 1 x 8"), v2(r == null || r.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${r}.`);
  const l = { image: i6, transforms: a }, c = { interpolation: e, fillMode: s, fillValue: o, outputShape: r };
  return $.runKernel(Mh, l, c);
}
var jT = L({ transform_: JT });
function qT(n, t, e) {
  v2(t % 1 === 0, () => `bandPart(): numLower must be an integer, got ${t}.`), v2(e % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${e}.`);
  const s = T(n, "a", "bandPart");
  v2(s.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${s.rank}.`);
  const o = s.shape, [r, i6] = s.shape.slice(-2);
  if (!(t <= r))
    throw new Error(`bandPart(): numLower (${t}) must not be greater than the number of rows (${r}).`);
  if (!(e <= i6))
    throw new Error(`bandPart(): numUpper (${e}) must not be greater than the number of columns (${i6}).`);
  t < 0 && (t = r), e < 0 && (e = i6);
  const a = W(ti(0, r, 1, "int32"), [-1, 1]), l = ti(0, i6, 1, "int32"), c = lt(a, l), u = ss(yr(c, gt(+t, "int32")), Do(c, gt(-e, "int32"))), d = ge([r, i6], s.dtype);
  return W(os(To(W(s, [-1, r, i6])).map((h6) => Oe(u, h6, d))), o);
}
var tN = L({ bandPart_: qT });
function eN(n) {
  let t;
  if (Array.isArray(n)) {
    t = false, v2(n != null && n.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
    const o = n[0].shape[0];
    for (let r = 1; r < n.length; ++r)
      v2(n[r].shape[0] === o, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${n[r].shape[0]} vs. ${o})`);
  } else
    t = true, n = un(n, n.shape[0], 0).map((o) => ha(o, [0]));
  v2(n.length <= n[0].shape[0], () => `Gram-Schmidt: Number of vectors (${n.length}) exceeds number of dimensions (${n[0].shape[0]}).`);
  const e = [], s = n;
  for (let o = 0; o < n.length; ++o)
    e.push($.tidy(() => {
      let r = s[o];
      if (o > 0)
        for (let i6 = 0; i6 < o; ++i6) {
          const a = G(at(G(e[i6], r)), e[i6]);
          r = lt(r, a);
        }
      return ut(r, Pc(r, "euclidean"));
    }));
  return t ? os(e, 0) : e;
}
var nN = L({ gramSchmidt_: eN });
function sN(n, t = false) {
  if (v2(n.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${n.rank}`), n.rank === 2)
    return lm(n, t);
  {
    const e = n.shape.slice(0, n.shape.length - 2).reduce((l, c) => l * c), s = To(W(n, [
      e,
      n.shape[n.shape.length - 2],
      n.shape[n.shape.length - 1]
    ]), 0), o = [], r = [];
    s.forEach((l) => {
      const [c, u] = lm(l, t);
      o.push(c), r.push(u);
    });
    const i6 = W(os(o, 0), n.shape), a = W(os(r, 0), n.shape);
    return [i6, a];
  }
}
function lm(n, t = false) {
  return $.tidy(() => {
    v2(n.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${n.shape.length}D Tensor.`);
    const e = n.shape[0], s = n.shape[1];
    let o = Db(e), r = po(n);
    const i6 = qa([[1]], [1, 1]);
    let a = po(i6);
    const l = e >= s ? s : e;
    for (let c = 0; c < l; ++c) {
      const u = r, d = a, h6 = o;
      [a, r, o] = $.tidy(() => {
        const p6 = Dt(r, [c, c], [e - c, 1]), f = Pc(p6), m = Dt(r, [c, c], [1, 1]), g6 = Oe(sn(m, 0), qa([[-1]]), qa([[1]])), b6 = lt(m, G(g6, f)), x6 = ut(p6, b6);
        x6.shape[0] === 1 ? a = po(i6) : a = Ge([
          i6,
          Dt(x6, [1, 0], [x6.shape[0] - 1, x6.shape[1]])
        ], 0);
        const w6 = jt(ut(Gt(g6, b6), f)), y6 = Dt(r, [c, 0], [e - c, s]), I = G(w6, a), C6 = kt(a);
        if (c === 0)
          r = lt(y6, Gt(I, Gt(C6, y6)));
        else {
          const N = lt(y6, Gt(I, Gt(C6, y6)));
          r = Ge([Dt(r, [0, 0], [c, s]), N], 0);
        }
        const k7 = kt(I), S = Dt(o, [0, c], [e, o.shape[1] - c]);
        if (c === 0)
          o = lt(S, Gt(Gt(S, a), k7));
        else {
          const N = lt(S, Gt(Gt(S, a), k7));
          o = Ge([Dt(o, [0, 0], [e, c]), N], 1);
        }
        return [a, r, o];
      }), yt([u, d, h6]);
    }
    return !t && e > s && (o = Dt(o, [0, 0], [e, s]), r = Dt(r, [0, 0], [s, s])), [o, r];
  });
}
var oN = L({ qr_: sN });
var Ae;
(function(n) {
  n[n.NONE = 0] = "NONE", n[n.MEAN = 1] = "MEAN", n[n.SUM = 2] = "SUM", n[n.SUM_BY_NONZERO_WEIGHTS = 3] = "SUM_BY_NONZERO_WEIGHTS";
})(Ae || (Ae = {}));
function rN(n, t, e = Ae.SUM_BY_NONZERO_WEIGHTS) {
  const s = T(n, "losses", "computeWeightedLoss");
  let o = null;
  t != null && (o = T(t, "weights", "computeWeightedLoss"));
  const r = o == null ? s : G(s, o);
  if (e === Ae.NONE)
    return r;
  if (e === Ae.SUM)
    return at(r);
  if (e === Ae.MEAN) {
    if (o == null)
      return se(r);
    {
      const i6 = s.size / o.size, a = ut(at(r), at(o));
      return i6 > 1 ? ut(a, gt(i6)) : a;
    }
  }
  if (e === Ae.SUM_BY_NONZERO_WEIGHTS) {
    if (o == null)
      return ut(at(r), gt(s.size));
    {
      const i6 = G(o, Us(s.shape)), a = et(at(qr(i6, gt(0))), "float32");
      return ut(at(r), a);
    }
  }
  throw Error(`Unknown reduction: ${e}`);
}
var Is = L({ computeWeightedLoss_: rN });
function iN(n, t, e, s = Ae.SUM_BY_NONZERO_WEIGHTS) {
  const o = T(n, "labels", "absoluteDifference"), r = T(t, "predictions", "absoluteDifference");
  let i6 = null;
  e != null && (i6 = T(e, "weights", "absoluteDifference")), Ve(o.shape, r.shape, "Error in absoluteDifference: ");
  const a = fe(lt(o, r));
  return Is(a, i6, s);
}
var aN = L({ absoluteDifference_: iN });
function lN(n, t, e, s, o = Ae.SUM_BY_NONZERO_WEIGHTS) {
  const r = T(n, "labels", "cosineDistance"), i6 = T(t, "predictions", "cosineDistance");
  let a = null;
  s != null && (a = T(s, "weights", "cosineDistance")), Ve(r.shape, i6.shape, "Error in cosineDistance: ");
  const l = gt(1), c = lt(l, at(G(r, i6), e, true));
  return Is(c, a, o);
}
var cN = L({ cosineDistance_: lN });
function uN(n, t, e, s = Ae.SUM_BY_NONZERO_WEIGHTS) {
  let o = T(n, "labels", "hingeLoss");
  const r = T(t, "predictions", "hingeLoss");
  let i6 = null;
  e != null && (i6 = T(e, "weights", "hingeLoss")), Ve(o.shape, r.shape, "Error in hingeLoss: ");
  const a = gt(1);
  o = lt(G(gt(2), o), a);
  const l = ws(lt(a, G(o, r)));
  return Is(l, i6, s);
}
var dN = L({ hingeLoss_: uN });
function hN(n, t, e, s = 1, o = Ae.SUM_BY_NONZERO_WEIGHTS) {
  const r = T(n, "labels", "huberLoss"), i6 = T(t, "predictions", "huberLoss");
  let a = null;
  e != null && (a = T(e, "weights", "huberLoss")), Ve(r.shape, i6.shape, "Error in huberLoss: ");
  const l = gt(s), c = fe(lt(i6, r)), u = Kc(c, l), d = lt(c, u), h6 = U(G(gt(0.5), At(u)), G(l, d));
  return Is(h6, a, o);
}
var pN = L({ huberLoss_: hN });
function fN(n, t, e, s = 1e-7, o = Ae.SUM_BY_NONZERO_WEIGHTS) {
  const r = T(n, "labels", "logLoss"), i6 = T(t, "predictions", "logLoss");
  let a = null;
  e != null && (a = T(e, "weights", "logLoss")), Ve(r.shape, i6.shape, "Error in logLoss: ");
  const l = gt(1), c = gt(s), u = jt(G(r, Nn(U(i6, c)))), d = G(lt(l, r), Nn(U(lt(l, i6), c))), h6 = lt(u, d);
  return Is(h6, a, o);
}
var mN = L({ logLoss_: fN });
function gN(n, t, e, s = Ae.SUM_BY_NONZERO_WEIGHTS) {
  const o = T(n, "labels", "meanSquaredError"), r = T(t, "predictions", "meanSquaredError");
  let i6 = null;
  e != null && (i6 = T(e, "weights", "meanSquaredError")), Ve(o.shape, r.shape, "Error in meanSquaredError: ");
  const a = Jb(o, r);
  return Is(a, i6, s);
}
var bN = L({ meanSquaredError_: gN });
function xN(n, t) {
  const e = T(n, "labels", "sigmoidCrossEntropyWithLogits"), s = T(t, "logits", "sigmoidCrossEntropyWithLogits");
  Ve(e.shape, s.shape, "Error in sigmoidCrossEntropyWithLogits: ");
  const o = ws(s), r = G(s, e), i6 = ep(Tn(jt(fe(s))));
  return U(lt(o, r), i6);
}
function yN(n, t, e, s = 0, o = Ae.SUM_BY_NONZERO_WEIGHTS) {
  let r = T(n, "multiClassLabels", "sigmoidCrossEntropy");
  const i6 = T(t, "logits", "sigmoidCrossEntropy");
  let a = null;
  if (e != null && (a = T(e, "weights", "sigmoidCrossEntropy")), Ve(r.shape, i6.shape, "Error in sigmoidCrossEntropy: "), s > 0) {
    const c = gt(s), u = gt(1), d = gt(0.5);
    r = U(G(r, lt(u, c)), G(d, c));
  }
  const l = xN(r, i6);
  return Is(l, a, o);
}
var wN = L({ sigmoidCrossEntropy_: yN });
function IN(n, t, e = -1) {
  if (e === -1 && (e = t.rank - 1), e !== t.rank - 1)
    throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${t.rank} and dim was ${e}`);
  return So((o, r, i6) => {
    const l = zb(r, [e], true), c = lt(et(r, "float32"), l);
    i6([o, c]);
    const u = jt(G(c, o));
    return { value: at(u, [e]), gradFunc: (p6, f) => {
      const [m, g6] = f, b6 = re(p6.shape, [e]);
      return [
        G(W(p6, b6), lt(et(m, "float32"), Tn(g6))),
        G(W(p6, b6), lt(Tn(g6), et(m, "float32")))
      ];
    } };
  })(n, t);
}
function CN(n, t, e, s = 0, o = Ae.SUM_BY_NONZERO_WEIGHTS) {
  let r = T(n, "onehotLabels", "softmaxCrossEntropy");
  const i6 = T(t, "logits", "softmaxCrossEntropy");
  let a = null;
  if (e != null && (a = T(e, "weights", "softmaxCrossEntropy")), Ve(r.shape, i6.shape, "Error in softmaxCrossEntropy: "), s > 0) {
    const c = gt(s), u = gt(1), d = gt(r.shape[1]);
    r = U(G(r, lt(u, c)), ut(c, d));
  }
  const l = IN(r, i6);
  return Is(l, a, o);
}
var vN = L({ softmaxCrossEntropy_: CN });
function SN(n, t, e, s) {
  const o = T(n, "indices", "sparseFillEmptyRows", "int32"), r = T(t, "values", "sparseFillEmptyRows"), i6 = T(e, "denseShape", "sparseFillEmptyRows", "int32"), a = T(s, "defaultValue", "sparseFillEmptyRows", r.dtype);
  if (o.rank !== 2)
    throw new Error(`Indices should be Tensor2D but received shape
        ${o.shape}`);
  if (r.rank !== 1)
    throw new Error(`Values should be Tensor1D but received shape ${r.shape}`);
  if (i6.rank !== 1)
    throw new Error(`Dense shape should be Tensor1D but received shape ${i6.shape}`);
  if (a.rank !== 0)
    throw new Error(`Default value should be a scalar but received shape ${a.shape}`);
  const l = {
    indices: o,
    values: r,
    denseShape: i6,
    defaultValue: a
  }, c = $.runKernel(vh, l);
  return {
    outputIndices: c[0],
    outputValues: c[1],
    emptyRowIndicator: c[2],
    reverseIndexMap: c[3]
  };
}
var kN = L({ sparseFillEmptyRows_: SN });
function TN(n, t, e) {
  const s = T(n, "inputIndices", "sparseReshape", "int32"), o = T(t, "inputShape", "sparseReshape", "int32"), r = T(e, "newShape", "sparseReshape", "int32");
  if (s.rank !== 2)
    throw new Error(`Input indices should be Tensor2D but received shape
        ${s.shape}`);
  if (o.rank !== 1)
    throw new Error(`Input shape should be Tensor1D but received shape ${o.shape}`);
  if (r.rank !== 1)
    throw new Error(`New shape should be Tensor1D but received shape ${r.shape}`);
  const i6 = {
    inputIndices: s,
    inputShape: o,
    newShape: r
  }, a = $.runKernel(Sh, i6);
  return { outputIndices: a[0], outputShape: a[1] };
}
var NN = L({ sparseReshape_: TN });
function RN(n, t, e) {
  const s = T(n, "data", "sparseSegmentMean"), o = T(t, "indices", "sparseSegmentMean", "int32"), r = T(e, "segmentIds", "sparseSegmentMean", "int32");
  if (s.rank < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.rank !== 1)
    throw new Error(`Indices should be Tensor1D but received shape
          ${o.shape}`);
  if (r.rank !== 1)
    throw new Error(`Segment ids should be Tensor1D but received shape
          ${r.shape}`);
  const i6 = {
    data: s,
    indices: o,
    segmentIds: r
  };
  return $.runKernel(kh, i6);
}
var $N = L({ sparseSegmentMean_: RN });
function GN(n, t, e) {
  const s = T(n, "data", "sparseSegmentSum"), o = T(t, "indices", "sparseSegmentSum", "int32"), r = T(e, "segmentIds", "sparseSegmentSum", "int32");
  if (s.rank < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.rank !== 1)
    throw new Error(`Indices should be Tensor1D but received shape
         ${o.shape}`);
  if (r.rank !== 1)
    throw new Error(`Segment ids should be Tensor1D but received shape
         ${r.shape}`);
  const i6 = {
    data: s,
    indices: o,
    segmentIds: r
  };
  return $.runKernel(Th, i6);
}
var EN = L({ sparseSegmentSum_: GN });
function LN(n, t, e, s, o, r, i6, a) {
  const l = T(n, "data", "stringNGrams", "string");
  if (l.dtype !== "string")
    throw new Error("Data must be of datatype string");
  if (l.shape.length !== 1)
    throw new Error(`Data must be a vector, saw: ${l.shape}`);
  const c = T(t, "dataSplits", "stringNGrams");
  if (c.dtype !== "int32")
    throw new Error("Data splits must be of datatype int32");
  const u = {
    separator: e,
    nGramWidths: s,
    leftPad: o,
    rightPad: r,
    padWidth: i6,
    preserveShortSequences: a
  }, d = { data: l, dataSplits: c }, h6 = $.runKernel($h, d, u);
  return { nGrams: h6[0], nGramsSplits: h6[1] };
}
var MN = L({ stringNGrams_: LN });
function WN(n, t, e = true) {
  const s = T(n, "input", "stringSplit", "string"), o = T(t, "delimiter", "stringSplit", "string");
  if (s.rank !== 1)
    throw new Error(`Input should be Tensor1D but received shape ${s.shape}`);
  if (o.rank !== 0)
    throw new Error(`Delimiter should be a scalar but received shape ${o.shape}`);
  const r = { skipEmpty: e }, i6 = { input: s, delimiter: o }, a = $.runKernel(Gh, i6, r);
  return { indices: a[0], values: a[1], shape: a[2] };
}
var DN = L({ stringSplit_: WN });
function FN(n, t) {
  const e = T(n, "input", "stringToHashBucketFast", "string"), s = { numBuckets: t };
  if (t <= 0)
    throw new Error("Number of buckets must be at least 1");
  const o = { input: e };
  return $.runKernel(Eh, o, s);
}
var VN = L({ stringToHashBucketFast_: FN });
var pY = {
  fft: xp,
  ifft: pl,
  rfft: yp,
  irfft: Qb
};
var fY = {
  hammingWindow: mT,
  hannWindow: s0,
  frame: o0,
  stft: yT
};
var uo = {
  flipLeftRight: vT,
  grayscaleToRGB: kT,
  resizeNearestNeighbor: i0,
  resizeBilinear: r0,
  rotateWithOffset: NT,
  cropAndResize: IT,
  nonMaxSuppression: $T,
  nonMaxSuppressionAsync: VT,
  nonMaxSuppressionWithScore: XT,
  nonMaxSuppressionWithScoreAsync: AT,
  nonMaxSuppressionPadded: KT,
  nonMaxSuppressionPaddedAsync: BT,
  threshold: QT,
  transform: jT
};
var zN = {
  bandPart: tN,
  gramSchmidt: nN,
  qr: oN
};
var mY = {
  absoluteDifference: aN,
  computeWeightedLoss: Is,
  cosineDistance: cN,
  hingeLoss: dN,
  huberLoss: pN,
  logLoss: mN,
  meanSquaredError: bN,
  sigmoidCrossEntropy: wN,
  softmaxCrossEntropy: vN
};
var gY = {
  sparseFillEmptyRows: kN,
  sparseReshape: NN,
  sparseSegmentMean: $N,
  sparseSegmentSum: EN
};
var bY = {
  stringNGrams: MN,
  stringSplit: DN,
  stringToHashBucketFast: VN
};
var Vo = class {
  /**
   * Return the class name for this class to use in serialization contexts.
   *
   * Generally speaking this will be the same thing that constructor.name
   * would have returned.  However, the class name needs to be robust
   * against minification for serialization/deserialization to work properly.
   *
   * There's also places such as initializers.VarianceScaling, where
   * implementation details between different languages led to different
   * class hierarchies and a non-leaf node is used for serialization purposes.
   */
  getClassName() {
    return this.constructor.className;
  }
  /**
   * Creates an instance of T from a ConfigDict.
   *
   * This works for most descendants of serializable.  A few need to
   * provide special handling.
   * @param cls A Constructor for the class to instantiate.
   * @param config The Configuration for the object.
   */
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e);
  }
};
var an = class {
  constructor() {
    this.classNameMap = {};
  }
  /**
   * Returns the singleton instance of the map.
   */
  static getMap() {
    return an.instance == null && (an.instance = new an()), an.instance;
  }
  /**
   * Registers the class as serializable.
   */
  static register(t) {
    an.getMap().classNameMap[t.className] = [t, t.fromConfig];
  }
};
function _(n) {
  v2(n.className != null, () => "Class being registered does not have the static className property defined."), v2(typeof n.className == "string", () => "className is required to be a string, but got type " + typeof n.className), v2(n.className.length > 0, () => "Class being registered has an empty-string as its className, which is disallowed."), an.register(n);
}
var xY = Object.freeze(Object.defineProperty({
  __proto__: null,
  Serializable: Vo,
  SerializationMap: an,
  registerClass: _
}, Symbol.toStringTag, { value: "Module" }));
var Ys = class extends Vo {
  /**
   * Executes `f()` and minimizes the scalar output of `f()` by computing
   * gradients of y with respect to the list of trainable variables provided by
   * `varList`. If no list is provided, it defaults to all trainable variables.
   *
   * @param f The function to execute and whose output to minimize.
   * @param returnCost Whether to return the scalar cost value produced by
   * executing `f()`.
   * @param varList An optional list of variables to update. If specified, only
   * the trainable variables in varList will be updated by minimize. Defaults to
   * all trainable variables.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers'}
   */
  minimize(t, e = false, s) {
    const { value: o, grads: r } = this.computeGradients(t, s);
    if (s != null) {
      const i6 = s.map((a) => ({ name: a.name, tensor: r[a.name] }));
      this.applyGradients(i6);
    } else
      this.applyGradients(r);
    return yt(r), e ? o : (o.dispose(), null);
  }
  /**
   * The number of iterations that this optimizer instance has been invoked for.
   */
  get iterations() {
    return this.iterations_ == null && (this.iterations_ = 0), this.iterations_;
  }
  incrementIterations() {
    this.iterations_ = this.iterations + 1;
  }
  /**
   * Executes f() and computes the gradient of the scalar output of f() with
   * respect to the list of trainable variables provided by `varList`. If no
   * list is provided, it defaults to all trainable variables.
   *
   * @param f The function to execute and whose output to use for computing
   * gradients with respect to variables.
   * @param varList An optional list of variables to compute gradients with
   * respect to. If specified, only the trainable variables in varList will have
   * gradients computed with respect to. Defaults to all trainable variables.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers'}
   */
  computeGradients(t, e) {
    return hS(t, e);
  }
  /**
   * Dispose the variables (if any) owned by this optimizer instance.
   */
  dispose() {
    this.iterations_ != null && yt(this.iterations_);
  }
  async saveIterations() {
    return this.iterations_ == null && (this.iterations_ = 0), {
      name: "iter",
      // TODO(cais): Use 'int64' type when available.
      tensor: gt(this.iterations_, "int32")
    };
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for this optimizer yet.");
  }
  async setWeights(t) {
    throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
  }
  /**
   * Extract the first element of the weight values and set it
   * as the iterations counter variable of this instance of optimizer.
   *
   * @param weightValues
   * @returns Weight values with the first element consumed and excluded.
   */
  async extractIterations(t) {
    return this.iterations_ = (await t[0].tensor.data())[0], t.slice(1);
  }
};
Object.defineProperty(Ys, Symbol.hasInstance, {
  value: (n) => n.minimize != null && n.computeGradients != null && n.applyGradients != null
});
var a0 = class extends Ys {
  constructor(t, e, s = null) {
    super(), this.learningRate = t, this.rho = e, this.epsilon = s, this.accumulatedGrads = [], this.accumulatedUpdates = [], s == null && (this.epsilon = $.backend.epsilon());
  }
  /** @nocollapse */
  static get className() {
    return "Adadelta";
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = $.registeredVariables[s], i6 = false;
      this.accumulatedGrads[o] == null && (this.accumulatedGrads[o] = {
        originalName: `${s}/accum_grad`,
        variable: D(() => Tt(r).variable(i6))
      }), this.accumulatedUpdates[o] == null && (this.accumulatedUpdates[o] = {
        originalName: `${s}/accum_var`,
        variable: D(() => Tt(r).variable(i6))
      });
      const a = Array.isArray(t) ? t[o].tensor : t[s];
      if (a == null)
        return;
      const l = this.accumulatedGrads[o].variable, c = this.accumulatedUpdates[o].variable;
      D(() => {
        const u = U(G(l, this.rho), G(At(a), 1 - this.rho)), d = G(ut(De(U(c, this.epsilon)), De(U(l, this.epsilon))), a), h6 = U(G(c, this.rho), G(At(d), 1 - this.rho));
        l.assign(u), c.assign(h6);
        const p6 = U(G(d, -this.learningRate), r);
        r.assign(p6);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedUpdates != null && (yt(this.accumulatedGrads.map((t) => t.variable)), yt(this.accumulatedUpdates.map((t) => t.variable)));
  }
  async getWeights() {
    const t = [...this.accumulatedGrads, ...this.accumulatedUpdates];
    return [await this.saveIterations()].concat(t.map((e) => ({ name: e.originalName, tensor: e.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t);
    const e = t.length / 2, s = false;
    this.accumulatedGrads = t.slice(0, e).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })), this.accumulatedUpdates = t.slice(e, e * 2).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    }));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      rho: this.rho,
      epsilon: this.epsilon
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.rho, e.epsilon);
  }
};
var l0 = class extends Ys {
  constructor(t, e = 0.1) {
    super(), this.learningRate = t, this.initialAccumulatorValue = e, this.accumulatedGrads = [];
  }
  /** @nocollapse */
  static get className() {
    return "Adagrad";
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = $.registeredVariables[s];
      this.accumulatedGrads[o] == null && (this.accumulatedGrads[o] = {
        originalName: `${s}/accumulator`,
        variable: D(() => ua(r.shape, this.initialAccumulatorValue).variable(false))
      });
      const i6 = Array.isArray(t) ? t[o].tensor : t[s];
      if (i6 == null)
        return;
      const a = this.accumulatedGrads[o].variable;
      D(() => {
        const l = U(a, At(i6));
        a.assign(l);
        const c = U(G(ut(i6, De(U(l, $.backend.epsilon()))), -this.learningRate), r);
        r.assign(c);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedGrads != null && yt(this.accumulatedGrads.map((t) => t.variable));
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulatedGrads.map((t) => ({ name: t.originalName, tensor: t.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t);
    const e = false;
    this.accumulatedGrads = t.map((s) => ({ originalName: s.name, variable: s.tensor.variable(e) }));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      initialAccumulatorValue: this.initialAccumulatorValue
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.initialAccumulatorValue);
  }
};
var c0 = class extends Ys {
  constructor(t, e, s, o = null) {
    super(), this.learningRate = t, this.beta1 = e, this.beta2 = s, this.epsilon = o, this.accumulatedFirstMoment = [], this.accumulatedSecondMoment = [], D(() => {
      this.accBeta1 = gt(e).variable(), this.accBeta2 = gt(s).variable();
    }), o == null && (this.epsilon = $.backend.epsilon());
  }
  /** @nocollapse */
  static get className() {
    return "Adam";
  }
  applyGradients(t) {
    const e = Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t);
    D(() => {
      const s = lt(1, this.accBeta1), o = lt(1, this.accBeta2);
      e.forEach((r, i6) => {
        const a = $.registeredVariables[r], l = false;
        this.accumulatedFirstMoment[i6] == null && (this.accumulatedFirstMoment[i6] = {
          originalName: `${r}/m`,
          variable: D(() => Tt(a).variable(l))
        }), this.accumulatedSecondMoment[i6] == null && (this.accumulatedSecondMoment[i6] = {
          originalName: `${r}/v`,
          variable: D(() => Tt(a).variable(l))
        });
        const c = Array.isArray(t) ? t[i6].tensor : t[r];
        if (c == null)
          return;
        const u = this.accumulatedFirstMoment[i6].variable, d = this.accumulatedSecondMoment[i6].variable, h6 = U(G(u, this.beta1), G(c, 1 - this.beta1)), p6 = U(G(d, this.beta2), G(At(c), 1 - this.beta2)), f = ut(h6, s), m = ut(p6, o);
        u.assign(h6), d.assign(p6);
        const g6 = U(G(ut(f, U(De(m), this.epsilon)), -this.learningRate), a);
        a.assign(g6);
      }), this.accBeta1.assign(G(this.accBeta1, this.beta1)), this.accBeta2.assign(G(this.accBeta2, this.beta2));
    }), this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose(), this.accBeta2.dispose(), this.accumulatedFirstMoment != null && yt(this.accumulatedFirstMoment.map((t) => t.variable)), this.accumulatedSecondMoment != null && yt(this.accumulatedSecondMoment.map((t) => t.variable));
  }
  async getWeights() {
    const t = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
    return [await this.saveIterations()].concat(t.map((e) => ({ name: e.originalName, tensor: e.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t), D(() => {
      this.accBeta1.assign(ir(this.beta1, this.iterations_ + 1)), this.accBeta2.assign(ir(this.beta2, this.iterations_ + 1));
    });
    const e = t.length / 2, s = false;
    this.accumulatedFirstMoment = t.slice(0, e).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })), this.accumulatedSecondMoment = t.slice(e, e * 2).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    }));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      beta1: this.beta1,
      beta2: this.beta2,
      epsilon: this.epsilon
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.beta1, e.beta2, e.epsilon);
  }
};
var u0 = class extends Ys {
  constructor(t, e, s, o = null, r = 0) {
    super(), this.learningRate = t, this.beta1 = e, this.beta2 = s, this.epsilon = o, this.decay = r, this.accumulatedFirstMoment = [], this.accumulatedWeightedInfNorm = [], D(() => {
      this.iteration = gt(0).variable(), this.accBeta1 = gt(e).variable();
    }), o == null && (this.epsilon = $.backend.epsilon());
  }
  /** @nocollapse */
  static get className() {
    return "Adamax";
  }
  applyGradients(t) {
    const e = Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t);
    D(() => {
      const s = lt(1, this.accBeta1), o = ut(-this.learningRate, U(G(this.iteration, this.decay), 1));
      e.forEach((r, i6) => {
        const a = $.registeredVariables[r], l = false;
        this.accumulatedFirstMoment[i6] == null && (this.accumulatedFirstMoment[i6] = {
          originalName: `${r}/m`,
          variable: Tt(a).variable(l)
        }), this.accumulatedWeightedInfNorm[i6] == null && (this.accumulatedWeightedInfNorm[i6] = {
          originalName: `${r}/v`,
          variable: Tt(a).variable(l)
        });
        const c = Array.isArray(t) ? t[i6].tensor : t[r];
        if (c == null)
          return;
        const u = this.accumulatedFirstMoment[i6].variable, d = this.accumulatedWeightedInfNorm[i6].variable, h6 = U(G(u, this.beta1), G(c, 1 - this.beta1)), p6 = G(d, this.beta2), f = fe(c), m = _s(p6, f);
        u.assign(h6), d.assign(m);
        const g6 = U(G(ut(o, s), ut(h6, U(m, this.epsilon))), a);
        a.assign(g6);
      }), this.iteration.assign(U(this.iteration, 1)), this.accBeta1.assign(G(this.accBeta1, this.beta1));
    }), this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose(), this.iteration.dispose(), this.accumulatedFirstMoment != null && yt(this.accumulatedFirstMoment.map((t) => t.variable)), this.accumulatedWeightedInfNorm != null && yt(this.accumulatedWeightedInfNorm.map((t) => t.variable));
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for Adamax yet.");
  }
  async setWeights(t) {
    throw new Error("setWeights() is not implemented for Adamax yet.");
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      beta1: this.beta1,
      beta2: this.beta2,
      epsilon: this.epsilon,
      decay: this.decay
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.beta1, e.beta2, e.epsilon, e.decay);
  }
};
var Gp = class extends Ys {
  constructor(t) {
    super(), this.learningRate = t, this.setLearningRate(t);
  }
  /** @nocollapse */
  static get className() {
    return "SGD";
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = Array.isArray(t) ? t[o].tensor : t[s];
      if (r == null)
        return;
      const i6 = $.registeredVariables[s];
      D(() => {
        const a = U(G(this.c, r), i6);
        i6.assign(a);
      });
    }), this.incrementIterations();
  }
  /**
   * Sets the learning rate of the optimizer.
   */
  setLearningRate(t) {
    this.learningRate = t, this.c != null && this.c.dispose(), this.c = cn(gt(-t));
  }
  dispose() {
    this.c.dispose();
  }
  async getWeights() {
    return [await this.saveIterations()];
  }
  async setWeights(t) {
    if (t = await this.extractIterations(t), t.length !== 0)
      throw new Error("SGD optimizer does not have settable weights.");
  }
  getConfig() {
    return { learningRate: this.learningRate };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate);
  }
};
var d0 = class extends Gp {
  constructor(t, e, s = false) {
    super(t), this.learningRate = t, this.momentum = e, this.useNesterov = s, this.accumulations = [], this.m = gt(this.momentum);
  }
  /** @nocollapse */
  // Name matters for Python compatibility.
  static get className() {
    return "Momentum";
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = $.registeredVariables[s];
      this.accumulations[o] == null && (this.accumulations[o] = {
        originalName: `${s}/momentum`,
        variable: D(() => Tt(r).variable(false))
      });
      const i6 = this.accumulations[o].variable, a = Array.isArray(t) ? t[o].tensor : t[s];
      a != null && D(() => {
        let l;
        const c = U(G(this.m, i6), a);
        this.useNesterov ? l = U(G(this.c, U(a, G(c, this.m))), r) : l = U(G(this.c, c), r), i6.assign(c), r.assign(l);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.m.dispose(), this.accumulations != null && yt(this.accumulations.map((t) => t.variable));
  }
  /**
   * Sets the momentum of the optimizer.
   *
   * @param momentum
   */
  setMomentum(t) {
    this.momentum = t;
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulations.map((t) => ({ name: t.originalName, tensor: t.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t);
    const e = false;
    this.accumulations = t.map((s) => ({ originalName: s.name, variable: s.tensor.variable(e) }));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      momentum: this.momentum,
      useNesterov: this.useNesterov
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.momentum, e.useNesterov);
  }
};
var h0 = class extends Ys {
  constructor(t, e = 0.9, s = 0, o = null, r = false) {
    if (super(), this.learningRate = t, this.decay = e, this.momentum = s, this.epsilon = o, this.accumulatedMeanSquares = [], this.accumulatedMoments = [], this.accumulatedMeanGrads = [], this.centered = r, o == null && (this.epsilon = $.backend.epsilon()), t == null)
      throw new Error("learningRate for RMSPropOptimizer must be defined.");
  }
  /** @nocollapse */
  static get className() {
    return "RMSProp";
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = $.registeredVariables[s], i6 = false;
      this.accumulatedMeanSquares[o] == null && (this.accumulatedMeanSquares[o] = {
        originalName: `${s}/rms`,
        variable: D(() => Tt(r).variable(i6))
      }), this.accumulatedMoments[o] == null && (this.accumulatedMoments[o] = {
        originalName: `${s}/momentum`,
        variable: D(() => Tt(r).variable(i6))
      }), this.accumulatedMeanGrads[o] == null && this.centered && (this.accumulatedMeanGrads[o] = {
        originalName: `${s}/mg`,
        variable: D(() => Tt(r).variable(i6))
      });
      const a = Array.isArray(t) ? t[o].tensor : t[s];
      if (a == null)
        return;
      const l = this.accumulatedMeanSquares[o].variable, c = this.accumulatedMoments[o].variable;
      D(() => {
        const u = U(G(l, this.decay), G(At(a), 1 - this.decay));
        if (this.centered) {
          const d = this.accumulatedMeanGrads[o].variable, h6 = U(G(d, this.decay), G(a, 1 - this.decay)), p6 = ut(G(a, this.learningRate), De(lt(u, U(At(h6), this.epsilon)))), f = U(G(c, this.momentum), p6);
          l.assign(u), d.assign(h6), c.assign(f);
          const m = lt(r, f);
          r.assign(m);
        } else {
          const d = U(G(l, this.decay), G(At(a), 1 - this.decay)), h6 = U(G(c, this.momentum), ut(G(a, this.learningRate), De(U(d, this.epsilon))));
          l.assign(d), c.assign(h6);
          const p6 = lt(r, h6);
          r.assign(p6);
        }
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedMeanSquares != null && yt(this.accumulatedMeanSquares.map((t) => t.variable)), this.accumulatedMeanGrads != null && this.centered && yt(this.accumulatedMeanGrads.map((t) => t.variable)), this.accumulatedMoments != null && yt(this.accumulatedMoments.map((t) => t.variable));
  }
  async getWeights() {
    const t = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
    return this.centered && t.push(...this.accumulatedMeanGrads), [await this.saveIterations()].concat(t.map((e) => ({ name: e.originalName, tensor: e.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t);
    const e = this.centered ? t.length / 3 : t.length / 2, s = false;
    this.accumulatedMeanSquares = t.slice(0, e).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })), this.accumulatedMoments = t.slice(e, e * 2).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })), this.centered && (this.accumulatedMeanGrads = t.slice(e * 2, e * 3).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      decay: this.decay,
      momentum: this.momentum,
      epsilon: this.epsilon,
      centered: this.centered
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.decay, e.momentum, e.epsilon, e.centered);
  }
};
var XN = [
  a0,
  l0,
  c0,
  u0,
  d0,
  h0,
  Gp
];
function PN() {
  for (const n of XN)
    _(n);
}
function cm(n, t, e, s) {
  i6(n), e = e ?? 0, s = s ?? 1, a(e, s);
  let o = 0;
  const r = (l) => (l.then((c) => {
    const u = e + ++o / n.length * (s - e);
    return t(u), c;
  }), l);
  function i6(l) {
    v2(l != null && Array.isArray(l) && l.length > 0, () => "promises must be a none empty array");
  }
  function a(l, c) {
    v2(l >= 0 && l <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${l}`), v2(c >= 0 && c <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${c}`), v2(c >= l, () => `startFraction must be no more than endFraction, but got startFraction ${l} and endFraction ${c}`);
  }
  return Promise.all(n.map(r));
}
async function p0(n, t) {
  t == null && (t = {});
  const e = t.fetchFunc == null ? F().platform.fetch : t.fetchFunc, s = n.map((d) => e(d, t.requestInit, { isBinary: true })), o = 0, r = 0.5, a = (t.onProgress == null ? await Promise.all(s) : await cm(s, t.onProgress, o, r)).map((d) => d.arrayBuffer()), l = 0.5, c = 1;
  return t.onProgress == null ? await Promise.all(a) : await cm(a, t.onProgress, l, c);
}
async function AN(n, t = "", e, s) {
  return ON((i6) => p0(i6, { requestInit: s }))(n, t, e);
}
function ON(n) {
  return async (t, e = "", s) => {
    const o = t.map(() => false), r = {}, i6 = s != null ? s.map(() => false) : [], a = [];
    if (t.forEach((p6, f) => {
      let m = 0;
      p6.weights.forEach((g6) => {
        const b6 = "quantization" in g6 ? g6.quantization.dtype : g6.dtype, x6 = pd[b6] * O(g6.shape), w6 = () => {
          o[f] = true, r[f] == null && (r[f] = []), r[f].push({
            manifestEntry: g6,
            groupOffset: m,
            sizeBytes: x6
          });
        };
        s != null ? s.forEach((y6, I) => {
          y6 === g6.name && (w6(), i6[I] = true);
        }) : w6(), a.push(g6.name), m += x6;
      });
    }), !i6.every((p6) => p6)) {
      const p6 = s.filter((f, m) => !i6[m]);
      throw new Error(`Could not find weights in manifest with names: ${p6.join(", ")}. 
Manifest JSON has weights with names: ${a.join(", ")}.`);
    }
    const l = o.reduce((p6, f, m) => (f && p6.push(m), p6), []), c = [];
    l.forEach((p6) => {
      t[p6].paths.forEach((f) => {
        const m = e + (e.endsWith("/") ? "" : "/") + f;
        c.push(m);
      });
    });
    const u = await n(c), d = {};
    let h6 = 0;
    return l.forEach((p6) => {
      const f = t[p6].paths.length;
      let m = 0;
      for (let y6 = 0; y6 < f; y6++)
        m += u[h6 + y6].byteLength;
      const g6 = new ArrayBuffer(m), b6 = new Uint8Array(g6);
      let x6 = 0;
      for (let y6 = 0; y6 < f; y6++) {
        const I = new Uint8Array(u[h6 + y6]);
        b6.set(I, x6), x6 += I.byteLength;
      }
      r[p6].forEach((y6) => {
        const I = g6.slice(y6.groupOffset, y6.groupOffset + y6.sizeBytes), C6 = gb(I, [y6.manifestEntry]);
        for (const k7 in C6)
          d[k7] = C6[k7];
      }), h6 += f;
    }), d;
  };
}
var KN = "application/octet-stream";
var ZN = "application/json";
var Ep = class {
  constructor(t, e) {
    if (this.DEFAULT_METHOD = "POST", e == null && (e = {}), this.weightPathPrefix = e.weightPathPrefix, this.onProgress = e.onProgress, this.weightUrlConverter = e.weightUrlConverter, e.fetchFunc != null ? (v2(typeof e.fetchFunc == "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"), this.fetch = e.fetchFunc) : this.fetch = F().platform.fetch, v2(t != null && t.length > 0, () => "URL path for http must not be null, undefined or empty."), Array.isArray(t) && v2(t.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${t.length}).`), this.path = t, e.requestInit != null && e.requestInit.body != null)
      throw new Error("requestInit is expected to have no pre-existing body, but has one.");
    this.requestInit = e.requestInit || {};
  }
  async save(t) {
    if (t.modelTopology instanceof ArrayBuffer)
      throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
    const e = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
    e.body = new FormData();
    const s = [{
      paths: ["./model.weights.bin"],
      weights: t.weightSpecs
    }], o = SC(t, s);
    e.body.append("model.json", new Blob([JSON.stringify(o)], { type: ZN }), "model.json"), t.weightData != null && e.body.append("model.weights.bin", new Blob([t.weightData], { type: KN }), "model.weights.bin");
    const r = await this.fetch(this.path, e);
    if (r.ok)
      return {
        modelArtifactsInfo: Kh(t),
        responses: [r]
      };
    throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${r.status}.`);
  }
  /**
   * Load model artifacts via HTTP request(s).
   *
   * See the documentation to `tf.io.http` for details on the saved
   * artifacts.
   *
   * @returns The loaded model artifacts (if loading succeeds).
   */
  async load() {
    const t = await this.fetch(this.path, this.requestInit);
    if (!t.ok)
      throw new Error(`Request to ${this.path} failed with status code ${t.status}. Please verify this URL points to the model JSON of the model to load.`);
    let e;
    try {
      e = await t.json();
    } catch {
      let i6 = `Failed to parse model JSON of response from ${this.path}.`;
      throw this.path.endsWith(".pb") ? i6 += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository." : i6 += " Please make sure the server is serving valid JSON for this request.", new Error(i6);
    }
    const s = e.modelTopology, o = e.weightsManifest;
    if (s == null && o == null)
      throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
    return TC(e, (r) => this.loadWeights(r));
  }
  async loadWeights(t) {
    const e = Array.isArray(this.path) ? this.path[1] : this.path, [s, o] = BN(e), r = this.weightPathPrefix || s, i6 = NC(t), a = [], l = [];
    for (const u of t)
      for (const d of u.paths)
        this.weightUrlConverter != null ? l.push(this.weightUrlConverter(d)) : a.push(r + d + o);
    this.weightUrlConverter && a.push(...await Promise.all(l));
    const c = await p0(a, {
      requestInit: this.requestInit,
      fetchFunc: this.fetch,
      onProgress: this.onProgress
    });
    return [i6, bb(c)];
  }
};
Ep.URL_SCHEME_REGEX = /^https?:\/\//;
function BN(n) {
  const t = n.lastIndexOf("/"), e = n.lastIndexOf("?"), s = n.substring(0, t), o = e > t ? n.substring(e) : "";
  return [s + "/", o];
}
function um(n) {
  return n.match(Ep.URL_SCHEME_REGEX) != null;
}
var f0 = (n, t) => {
  if (typeof fetch > "u" && (t == null || t.fetchFunc == null))
    return null;
  {
    let e = true;
    if (Array.isArray(n) ? e = n.every((s) => um(s)) : e = um(n), e)
      return m0(n, t);
  }
  return null;
};
ee.registerSaveRouter(f0);
ee.registerLoadRouter(f0);
function m0(n, t) {
  return new Ep(n, t);
}
function HN(n, t) {
  return m0(n, t);
}
var to;
function g0(n, t = 3) {
  if (t > 4)
    throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
  if (n == null)
    throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  let e = false, s = false, o = false, r = false, i6 = false, a = false;
  if (n.data instanceof Uint8Array)
    e = true;
  else if (typeof ImageData < "u" && n instanceof ImageData)
    s = true;
  else if (typeof HTMLVideoElement < "u" && n instanceof HTMLVideoElement)
    o = true;
  else if (typeof HTMLImageElement < "u" && n instanceof HTMLImageElement)
    r = true;
  else if (n.getContext != null)
    i6 = true;
  else if (typeof ImageBitmap < "u" && n instanceof ImageBitmap)
    a = true;
  else
    throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${n.constructor.name}`);
  if (od(sd, $.backendName) != null) {
    const f = { pixels: n }, m = { numChannels: t };
    return $.runKernel(sd, f, m);
  }
  const [c, u] = o ? [
    n.videoWidth,
    n.videoHeight
  ] : [n.width, n.height];
  let d;
  if (i6)
    d = // tslint:disable-next-line:no-any
    n.getContext("2d").getImageData(0, 0, c, u).data;
  else if (s || e)
    d = n.data;
  else if (r || o || a) {
    if (to == null)
      if (typeof document > "u")
        if (typeof OffscreenCanvas < "u" && typeof OffscreenCanvasRenderingContext2D < "u")
          to = new OffscreenCanvas(1, 1).getContext("2d");
        else
          throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
      else
        to = document.createElement("canvas").getContext("2d", { willReadFrequently: true });
    to.canvas.width = c, to.canvas.height = u, to.drawImage(n, 0, 0, c, u), d = to.getImageData(0, 0, c, u).data;
  }
  let h6;
  if (t === 4)
    h6 = new Int32Array(d);
  else {
    const f = c * u;
    h6 = new Int32Array(f * t);
    for (let m = 0; m < f; m++)
      for (let g6 = 0; g6 < t; ++g6)
        h6[m * t + g6] = d[m * 4 + g6];
  }
  return Hk(h6, [u, c, t], "int32");
}
function _N(n) {
  return n != null && n.data instanceof Uint8Array;
}
function UN() {
  return typeof window < "u" && typeof ImageBitmap < "u" && window.hasOwnProperty("createImageBitmap");
}
function YN(n) {
  return n != null && n.width !== 0 && n.height !== 0;
}
function QN(n) {
  return UN() && !(n instanceof ImageBitmap) && YN(n) && !_N(n);
}
async function JN(n, t = 3) {
  let e = null;
  if (F().getBool("WRAP_TO_IMAGEBITMAP") && QN(n)) {
    let s;
    try {
      s = await createImageBitmap(n, { premultiplyAlpha: "none" });
    } catch {
      s = null;
    }
    s != null && s.width === n.width && s.height === n.height ? e = s : e = n;
  } else
    e = n;
  return g0(e, t);
}
async function jN(n, t) {
  let e = T(n, "img", "toPixels");
  if (!(n instanceof Lt)) {
    const c = e;
    e = et(c, "int32"), c.dispose();
  }
  if (e.rank !== 2 && e.rank !== 3)
    throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${e.rank}.`);
  const [s, o] = e.shape.slice(0, 2), r = e.rank === 2 ? 1 : e.shape[2];
  if (r > 4 || r === 2)
    throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${r}`);
  if (e.dtype !== "float32" && e.dtype !== "int32")
    throw new Error(`Unsupported type for toPixels: ${e.dtype}. Please use float32 or int32 tensors.`);
  const i6 = await e.data(), a = e.dtype === "float32" ? 255 : 1, l = new Uint8ClampedArray(o * s * 4);
  for (let c = 0; c < s * o; ++c) {
    const u = [0, 0, 0, 255];
    for (let h6 = 0; h6 < r; h6++) {
      const p6 = i6[c * r + h6];
      if (e.dtype === "float32") {
        if (p6 < 0 || p6 > 1)
          throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${p6}.`);
      } else if (e.dtype === "int32" && (p6 < 0 || p6 > 255))
        throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${p6}.`);
      r === 1 ? (u[0] = p6 * a, u[1] = p6 * a, u[2] = p6 * a) : u[h6] = p6 * a;
    }
    const d = c * 4;
    l[d + 0] = Math.round(u[0]), l[d + 1] = Math.round(u[1]), l[d + 2] = Math.round(u[2]), l[d + 3] = Math.round(u[3]);
  }
  if (t != null) {
    t.width = o, t.height = s;
    const c = t.getContext("2d"), u = new ImageData(l, o, s);
    c.putImageData(u, 0, 0);
  }
  return e !== n && e.dispose(), l;
}
var b0 = L({ fromPixels_: g0 });
var yY = Object.freeze(Object.defineProperty({
  __proto__: null,
  fromPixels: b0,
  fromPixelsAsync: JN,
  toPixels: jN
}, Symbol.toStringTag, { value: "Module" }));
function Bc(n, t) {
  const e = n.shape.length, s = t.shape.length;
  if (e < 1)
    throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${e}.`);
  if (s < 1)
    throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${s}.`);
  if (t.dtype !== "int32")
    throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);
  if (t.shape[s - 1] > e)
    throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${t.shape[s - 1]} vs. ${e}`);
  if (O(n.shape) === 0)
    throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${n.shape}.`);
  const o = t.shape, r = o[o.length - 1];
  let i6 = 1;
  for (let d = 0; d < o.length - 1; ++d)
    i6 *= o[d];
  const a = n.shape, l = o.slice();
  l.pop();
  let c = 1;
  for (let d = r; d < e; ++d)
    c *= a[d], l.push(a[d]);
  const u = [
    ...dt(n.shape).map((d) => d / c),
    1
  ].slice(0, r);
  return [l, i6, c, u];
}
var wY = Object.freeze(Object.defineProperty({
  __proto__: null,
  prepareAndValidate: Bc
}, Symbol.toStringTag, { value: "Module" }));
var wd = -2;
var qN = -1;
function Lp(n, t, e) {
  const s = n.shape.length;
  v2(s === t.length, () => `Error in slice${s}D: Length of begin ${t} must match the rank of the array (${s}).`), v2(s === e.length, () => `Error in slice${s}D: Length of size ${e} must match the rank of the array (${s}).`);
  for (let o = 0; o < s; ++o)
    v2(t[o] + e[o] <= n.shape[o], () => `Error in slice${s}D: begin[${o}] + size[${o}] (${t[o] + e[o]}) would overflow input.shape[${o}] (${n.shape[o]})`);
}
function tR(n) {
  const t = [];
  let e = 0;
  for (; n > 0; )
    n & 1 && t.push(e), n /= 2, e++;
  return t;
}
function Mp(n, t, e) {
  const s = [];
  for (let o = 0; o < n.length; o++)
    s[o] = Math.ceil((t[o] - n[o]) / e[o]);
  return s;
}
function x0(n, t, e, s) {
  const o = [...n];
  for (let r = o.length; r < s.length; r++)
    o.push(1);
  for (let r = 0; r < e; r++)
    r === 0 ? o[t] = 1 : (o.splice(
      t,
      0,
      1
      /* element to add */
    ), o.pop());
  return o;
}
function y0(n, t, e) {
  return e <= n ? e : e - (t - 1);
}
function w0(n, t) {
  const e = [];
  for (let s = 0; s < n; s++)
    e.push(t + s);
  return e;
}
function eR(n, t, e, s, o, r, i6, a, l) {
  const c = n.length;
  let u = new Array(c), d = new Array(c), h6 = new Array(c);
  if (t.length && e > 0) {
    const p6 = t[0], f = e + 1;
    u = I0(i6, p6, f, s, n), d = C0(a, p6, f, o, n), h6 = x0(r, p6, f, n);
  } else
    for (let p6 = 0; p6 < c; p6++)
      u[p6] = S0(i6, s, r, n, p6, l), d[p6] = k0(a, o, r, n, p6, l), h6[p6] = v0(r, p6, l);
  return {
    begin: u,
    end: d,
    strides: h6
  };
}
function I0(n, t, e, s, o) {
  const r = [...o], i6 = w0(e, t);
  for (let a = 0; a < r.length; a++)
    if (i6.indexOf(a) > -1)
      r[a] = 0;
    else {
      const l = y0(t, e, a);
      let c = s[l];
      n & 1 << l && (c = 0), r[a] = c;
    }
  return r;
}
function C0(n, t, e, s, o) {
  const r = [...o], i6 = w0(e, t);
  for (let a = 0; a < r.length; a++)
    if (i6.indexOf(a) > -1)
      r[a] = Number.MAX_SAFE_INTEGER;
    else {
      const l = y0(t, e, a);
      let c = s[l];
      n & 1 << l && (c = Number.MAX_SAFE_INTEGER), r[a] = c;
    }
  for (let a = 0; a < r.length; a++) {
    const l = o[a];
    r[a] < 0 && (r[a] += l), r[a] = Fs(0, r[a], o[a]);
  }
  return r;
}
function v0(n, t, e) {
  let s = n[t];
  return (e & 1 << t || s == null) && (s = 1), s;
}
function S0(n, t, e, s, o, r) {
  let i6 = t[o];
  const a = e[o] || 1;
  (n & 1 << o || r & 1 << o || i6 == null) && (a > 0 ? i6 = Number.MIN_SAFE_INTEGER : i6 = Number.MAX_SAFE_INTEGER);
  const l = s[o];
  return i6 < 0 && (i6 += l), i6 = Fs(0, i6, l - 1), i6;
}
function k0(n, t, e, s, o, r) {
  let i6 = t[o];
  const a = e[o] || 1;
  (n & 1 << o || r & 1 << o || i6 == null) && (a > 0 ? i6 = Number.MAX_SAFE_INTEGER : i6 = Number.MIN_SAFE_INTEGER);
  const l = s[o];
  return i6 < 0 && (i6 += l), a > 0 ? i6 = Fs(0, i6, l) : i6 = Fs(-1, i6, l - 1), i6;
}
function Wp(n, t, e) {
  let s = e.length;
  for (let o = 0; o < e.length; o++)
    if (e[o] > 1) {
      s = o;
      break;
    }
  for (let o = s + 1; o < e.length; o++)
    if (t[o] > 0 || e[o] !== n[o])
      return false;
  return true;
}
function Dp(n, t) {
  let e = n.length > 0 ? n[n.length - 1] : 1;
  for (let s = 0; s < n.length - 1; s++)
    e += n[s] * t[s];
  return e;
}
function Hc(n, t, e) {
  let s;
  const o = n.shape.length;
  typeof t == "number" ? s = [t, ...new Array(o - 1).fill(0)] : t.length < o ? s = t.concat(new Array(o - t.length).fill(0)) : s = t.slice(), s.forEach((i6) => {
    v2(i6 !== -1, () => "slice() does not support negative begin indexing.");
  });
  let r;
  return e == null ? r = new Array(o).fill(-1) : typeof e == "number" ? r = [e, ...new Array(o - 1).fill(-1)] : e.length < o ? r = e.concat(new Array(o - e.length).fill(-1)) : r = e, r = r.map((i6, a) => i6 >= 0 ? i6 : (v2(i6 === -1, () => `Negative size values should be exactly -1 but got ${i6} for the slice() size at index ${a}.`), n.shape[a] - s[a])), [s, r];
}
function Fp(n, t, e, s, o, r, i6, a, l) {
  let c;
  if (s == null ? (c = new Array(t.length), c.fill(1)) : c = s, i6 != null && i6 & i6 - 1)
    throw new Error("Multiple ellipses in slice is not allowed.");
  let u = false;
  const d = {
    dims: c.length,
    numAddAxisAfterEllipsis: 0,
    begin: t.slice(),
    end: e.slice(),
    strides: c.slice(),
    beginMask: o,
    endMask: r,
    ellipsisMask: i6,
    newAxisMask: a,
    shrinkAxisMask: l
  };
  for (let w6 = 0; w6 < d.dims; w6++)
    u && 1 << w6 & a && d.numAddAxisAfterEllipsis++, 1 << w6 & i6 && (u = true);
  u || (d.ellipsisMask |= 1 << d.dims, d.dims++);
  const h6 = {
    dims: n.length,
    beginMask: 0,
    endMask: 0,
    beginValid: false,
    endValid: false
  };
  nR(d, h6);
  let p6 = true, f = true, m = true;
  const g6 = [], b6 = [];
  for (let w6 = 0; w6 < n.length; ++w6) {
    if (h6.strides[w6] === 0)
      throw Error(`strides[${w6}] must be non-zero`);
    const y6 = !!(h6.shrinkAxisMask & 1 << w6), I = n[w6];
    if (I === -1) {
      g6.push(y6 ? 1 : -1);
      continue;
    }
    const C6 = [h6.beginMask & 1 << w6, h6.endMask & 1 << w6], k7 = [
      h6.strides[w6] > 0 ? 0 : -1,
      h6.strides[w6] > 0 ? I : I - 1
    ];
    if (y6 && h6.strides[w6] <= 0)
      throw Error("only stride 1 allowed on non-range indexing.");
    m = m && h6.strides[w6] === 1;
    const S = !!(h6.beginMask & 1 << w6 && h6.endMask & 1 << w6);
    if (h6.beginValid && h6.endValid) {
      if (y6) {
        const V = h6.begin[w6] < 0 ? I + h6.begin[w6] : h6.begin[w6];
        if (h6.begin[w6] = V, h6.end[w6] = h6.begin[w6] + 1, V < 0 || V >= I)
          throw Error(`slice index ${h6.begin[w6]} of dimension ${w6} out of bounds.`);
      } else
        h6.begin[w6] = dm(h6.begin[w6], 0, h6.strides[w6], I, C6, k7), h6.end[w6] = dm(h6.end[w6], 1, h6.strides[w6], I, C6, k7);
      const M6 = h6.strides[w6] === 1 && h6.begin[w6] === 0 && h6.end[w6] === I;
      p6 = p6 && M6, f = f && (w6 === 0 && h6.strides[w6] === 1 || M6);
    } else
      p6 = p6 && h6.strides[w6] === 1 && S, f = f && (w6 === 0 && h6.strides[w6] === 1 || S);
    let N, R = false;
    if (h6.beginValid && h6.endValid ? (N = h6.end[w6] - h6.begin[w6], R = true) : y6 ? (N = 1, R = true) : S && I >= 0 && (h6.strides[w6] < 0 ? N = -I : N = I, R = true), R) {
      let M6;
      N === 0 || N < 0 != h6.strides[w6] < 0 ? M6 = 0 : M6 = Math.trunc(N / h6.strides[w6]) + (N % h6.strides[w6] !== 0 ? 1 : 0), g6.push(M6);
    } else
      g6.push(-1);
  }
  for (let w6 = 0; w6 < h6.finalShapeGatherIndices.length; ++w6) {
    const y6 = h6.finalShapeGatherIndices[w6];
    y6 >= 0 ? b6.push(g6[y6]) : y6 === wd && b6.push(1);
  }
  return {
    finalShapeSparse: b6.filter((w6, y6) => h6.finalShapeGatherIndices[y6] !== wd),
    finalShape: b6,
    isIdentity: p6,
    sliceDim0: f,
    isSimpleSlice: m,
    begin: h6.begin,
    end: h6.end,
    strides: h6.strides
  };
}
function nR(n, t) {
  t.beginMask = 0, t.endMask = 0, t.shrinkAxisMask = 0;
  let e = 0;
  t.beginValid = n.begin != null, t.endValid = n.end != null, t.begin = new Array(t.dims), t.end = new Array(t.dims), t.strides = new Array(t.dims), t.finalShapeGatherIndices = [], t.finalShapeGatherIndicesSparse = [], t.inputShapeGatherIndicesSparse = new Array(t.dims);
  for (let s = 0; s < n.dims; s++)
    if (1 << s & n.ellipsisMask) {
      const o = Math.min(t.dims - (n.dims - s) + 1 + n.numAddAxisAfterEllipsis, t.dims);
      for (; e < o; e++)
        t.begin[e] = 0, t.end[e] = 0, t.strides[e] = 1, t.beginMask |= 1 << e, t.endMask |= 1 << e, t.finalShapeGatherIndices.push(e), t.finalShapeGatherIndicesSparse.push(-1), t.inputShapeGatherIndicesSparse[e] = s;
    } else if (1 << s & n.newAxisMask)
      t.finalShapeGatherIndices.push(wd), t.finalShapeGatherIndicesSparse.push(-1);
    else {
      if (e === t.begin.length)
        throw Error(`Index out of range using input dim ${e}; input has only ${t.dims} dims, ${t.begin.length}.`);
      n.begin != null && (t.begin[e] = n.begin[s]), n.end != null && (t.end[e] = n.end[s]), t.strides[e] = n.strides[s], n.beginMask & 1 << s && (t.beginMask |= 1 << e), n.endMask & 1 << s && (t.endMask |= 1 << e), n.shrinkAxisMask & 1 << s ? (t.finalShapeGatherIndices.push(qN), t.finalShapeGatherIndicesSparse.push(-1), t.shrinkAxisMask |= 1 << e) : (t.finalShapeGatherIndices.push(e), t.finalShapeGatherIndicesSparse.push(s)), t.inputShapeGatherIndicesSparse[e] = s, e++;
    }
}
function dm(n, t, e, s, o, r) {
  if (o[t])
    return e > 0 ? r[t] : r[t + 1 & 1];
  {
    const i6 = n < 0 ? s + n : n;
    return i6 < r[0] ? r[0] : i6 > r[1] ? r[1] : i6;
  }
}
var sR = Object.freeze(Object.defineProperty({
  __proto__: null,
  assertParamsValid: Lp,
  computeFlatOffset: Dp,
  computeOutShape: Mp,
  getNormalizedAxes: eR,
  isSliceContinous: Wp,
  maskToAxes: tR,
  parseSliceParams: Hc,
  sliceInfo: Fp,
  startForAxis: S0,
  startIndicesWithElidedDims: I0,
  stopForAxis: k0,
  stopIndicesWithElidedDims: C0,
  stridesForAxis: v0,
  stridesWithElidedDims: x0
}, Symbol.toStringTag, { value: "Module" }));
var oR = class {
  /**
   * Constructs a `tf.SGDOptimizer` that uses stochastic gradient descent.
   *
   * ```js
   * // Fit a quadratic function by learning the coefficients a, b, c.
   * const xs = tf.tensor1d([0, 1, 2, 3]);
   * const ys = tf.tensor1d([1.1, 5.9, 16.8, 33.9]);
   *
   * const a = tf.scalar(Math.random()).variable();
   * const b = tf.scalar(Math.random()).variable();
   * const c = tf.scalar(Math.random()).variable();
   *
   * // y = a * x^2 + b * x + c.
   * const f = x => a.mul(x.square()).add(b.mul(x)).add(c);
   * const loss = (pred, label) => pred.sub(label).square().mean();
   *
   * const learningRate = 0.01;
   * const optimizer = tf.train.sgd(learningRate);
   *
   * // Train the model.
   * for (let i = 0; i < 10; i++) {
   *   optimizer.minimize(() => loss(f(xs), ys));
   * }
   *
   * // Make predictions.
   * console.log(
   *     `a: ${a.dataSync()}, b: ${b.dataSync()}, c: ${c.dataSync()}`);
   * const preds = f(xs).dataSync();
   * preds.forEach((pred, i) => {
   *   console.log(`x: ${i}, pred: ${pred}`);
   * });
   * ```
   *
   * @param learningRate The learning rate to use for the SGD algorithm.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static sgd(t) {
    return new Gp(t);
  }
  /**
   * Constructs a `tf.MomentumOptimizer` that uses momentum gradient
   * descent.
   *
   * See
   * [http://proceedings.mlr.press/v28/sutskever13.pdf](
   * http://proceedings.mlr.press/v28/sutskever13.pdf)
   *
   * @param learningRate The learning rate to use for the Momentum gradient
   * descent algorithm.
   * @param momentum The momentum to use for the momentum gradient descent
   * algorithm.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static momentum(t, e, s = false) {
    return new d0(t, e, s);
  }
  /**
   * Constructs a `tf.RMSPropOptimizer` that uses RMSProp gradient
   * descent. This implementation uses plain momentum and is not centered
   * version of RMSProp.
   *
   * See
   * [http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](
   * http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
   *
   * @param learningRate The learning rate to use for the RMSProp gradient
   * descent algorithm.
   * @param decay The discounting factor for the history/coming gradient.
   * @param momentum The momentum to use for the RMSProp gradient descent
   * algorithm.
   * @param epsilon Small value to avoid zero denominator.
   * @param centered If true, gradients are normalized by the estimated
   * variance of the gradient.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static rmsprop(t, e = 0.9, s = 0, o = null, r = false) {
    return new h0(t, e, s, o, r);
  }
  /**
   * Constructs a `tf.AdamOptimizer` that uses the Adam algorithm.
   * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
   *
   * @param learningRate The learning rate to use for the Adam gradient
   * descent algorithm.
   * @param beta1 The exponential decay rate for the 1st moment estimates.
   * @param beta2 The exponential decay rate for the 2nd moment estimates.
   * @param epsilon A small constant for numerical stability.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static adam(t = 1e-3, e = 0.9, s = 0.999, o = null) {
    return new c0(t, e, s, o);
  }
  /**
   * Constructs a `tf.AdadeltaOptimizer` that uses the Adadelta algorithm.
   * See [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)
   *
   * @param learningRate The learning rate to use for the Adadelta gradient
   * descent algorithm.
   * @param rho The learning rate decay over each update.
   * @param epsilon A constant epsilon used to better condition the grad
   * update.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static adadelta(t = 1e-3, e = 0.95, s = null) {
    return new a0(t, e, s);
  }
  /**
   * Constructs a `tf.AdamaxOptimizer` that uses the Adamax algorithm.
   * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
   *
   * @param learningRate The learning rate to use for the Adamax gradient
   * descent algorithm.
   * @param beta1 The exponential decay rate for the 1st moment estimates.
   * @param beta2 The exponential decay rate for the 2nd moment estimates.
   * @param epsilon A small constant for numerical stability.
   * @param decay The learning rate decay over each update.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static adamax(t = 2e-3, e = 0.9, s = 0.999, o = null, r = 0) {
    return new u0(t, e, s, o, r);
  }
  /**
   * Constructs a `tf.AdagradOptimizer` that uses the Adagrad algorithm.
   * See
   * [http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](
   * http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)
   * or
   * [http://ruder.io/optimizing-gradient-descent/index.html#adagrad](
   * http://ruder.io/optimizing-gradient-descent/index.html#adagrad)
   *
   * @param learningRate The learning rate to use for the Adagrad gradient
   * descent algorithm.
   * @param initialAccumulatorValue Starting value for the accumulators, must be
   * positive.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static adagrad(t, e = 0.1) {
    return new l0(t, e);
  }
};
var Ko = oR;
var rR = (() => typeof requestAnimationFrame < "u" ? requestAnimationFrame : typeof setImmediate < "u" ? setImmediate : (n) => n())();
function _c() {
  return new Promise((n) => rR(() => n()));
}
function Vp(n, t) {
  const e = n[0].length;
  n.forEach((o, r) => {
    v2(o.length === e, () => `Error in concat${e}D: rank of tensors[${r}] must be the same as the rank of the rest (${e})`);
  }), v2(t >= 0 && t < e, () => `Error in concat${e}D: axis must be between 0 and ${e - 1}.`);
  const s = n[0];
  n.forEach((o, r) => {
    for (let i6 = 0; i6 < e; i6++)
      v2(i6 === t || o[i6] === s[i6], () => `Error in concat${e}D: Shape of tensors[${r}] (${o}) does not match the shape of the rest (${s}) along the non-concatenated axis ${r}.`);
  });
}
function ts(n, t) {
  const e = n[0].slice();
  for (let s = 1; s < n.length; s++)
    e[t] += n[s][t];
  return e;
}
var Fn;
(function(n) {
  n[n.FIRST_DIM_SIZE = 0] = "FIRST_DIM_SIZE", n[n.VALUE_ROWIDS = 1] = "VALUE_ROWIDS", n[n.ROW_LENGTHS = 2] = "ROW_LENGTHS", n[n.ROW_SPLITS = 3] = "ROW_SPLITS", n[n.ROW_LIMITS = 4] = "ROW_LIMITS", n[n.ROW_STARTS = 5] = "ROW_STARTS";
})(Fn || (Fn = {}));
function T0(n, t, e) {
  let s = new Array();
  if (e == null && t == null)
    return s;
  if (t == null)
    for (; s.length < n + e.length; )
      s.push(-1);
  else
    s = t.slice();
  if (e == null)
    return s;
  if (n + e.length !== s.length)
    throw new Error(`rt input.shape and shape=${t} are incompatible: rt input.rank = ${n + e.length}, but shape.rank = ${s.length}`);
  for (let o = 1; o < e.length; ++o) {
    const r = e[o], i6 = s[s.length - e.length + o], a = s[i6];
    if (r >= 0)
      if (a >= 0) {
        if (a !== r)
          throw new Error(`rt input.shape and shape=${t} are incompatible: rt input.shape[${o + n}] = ${r} but shape[${o + n}] = ${a}`);
      } else
        s[i6] = r;
  }
  return s;
}
function N0(n) {
  const t = {
    FIRST_DIM_SIZE: Fn.FIRST_DIM_SIZE,
    VALUE_ROWIDS: Fn.VALUE_ROWIDS,
    ROW_LENGTHS: Fn.ROW_LENGTHS,
    ROW_SPLITS: Fn.ROW_SPLITS,
    ROW_LIMITS: Fn.ROW_LIMITS,
    ROW_STARTS: Fn.ROW_STARTS
  }, e = [];
  for (const s of n)
    if (s in t)
      e.push(t[s]);
    else
      break;
  return e;
}
function R0(n) {
  return n.length === 0 ? 0 : n[0] === Fn.FIRST_DIM_SIZE ? n.length - 1 : n.length;
}
function $0(n, t) {
  if (n == null || t == null)
    return;
  const e = n.length, s = t.length;
  if (e >= s)
    throw new Error(`defaultValue.shape=${n} and ragged tensor flatValues.shape=${t}, are incompatible: defaultValue.rank = ${e} must be less than ragged tensor input flatValues.rank = ${s})`);
  for (let o = 0; o < Math.min(e, s - 1); ++o) {
    const r = n[o], i6 = t[o + 1];
    if (r >= 0 && i6 >= 0 && r !== 1 && r !== i6)
      throw new Error(`defaultValue.shape=${n}, and ragged tensor input flatValues.shape=${t} are incompatible: defaultValue.shape[${o - n.length}] = ${r} but ragged tensor input.flatValues.shape[${o - n.length}] = ${i6}`);
  }
}
var zp = 30;
function Uc(n) {
  return n <= zp ? n : sl(n, Math.floor(Math.sqrt(n)));
}
function Xp(n, t, e) {
  const s = e * (typeof n == "number" ? n : n[0]), o = t * (typeof n == "number" ? n : n[1]);
  return [s, o];
}
function fa(n, t, e, s = true) {
  let o = [];
  if (s)
    o = o.concat(t.slice(0)), o.push(n[0] / e), o = o.concat(n.slice(1));
  else {
    o = o.concat(n[0]);
    const r = t.length;
    for (let i6 = 0; i6 < r; ++i6)
      o = o.concat([n[i6 + 1] / t[i6], t[i6]]);
    o = o.concat(n.slice(r + 1));
  }
  return o;
}
function ma(n, t, e = true) {
  const s = [];
  if (e) {
    s.push(t);
    for (let o = t + 1; o < n; ++o)
      o <= 2 * t ? (s.push(o), s.push(o - (t + 1))) : s.push(o);
  } else {
    const o = [], r = [];
    for (let i6 = 1; i6 < n; ++i6)
      i6 >= t * 2 + 1 || i6 % 2 === 1 ? r.push(i6) : o.push(i6);
    s.push(...o), s.push(0), s.push(...r);
  }
  return s;
}
function ga(n, t, e, s = true) {
  const o = [];
  s ? o.push(n[0] / e) : o.push(n[0] * e);
  for (let r = 1; r < n.length; ++r)
    r <= t.length ? s ? o.push(t[r - 1] * n[r]) : o.push(n[r] / t[r - 1]) : o.push(n[r]);
  return o;
}
function Pp(n, t) {
  const e = [0];
  for (let s = 0; s < t; ++s)
    e.push(n[s][0]);
  return e;
}
function Ap(n, t, e) {
  const s = n.slice(0, 1);
  for (let o = 0; o < e; ++o)
    s.push(n[o + 1] - t[o][0] - t[o][1]);
  return s;
}
var Yc = 1.7580993408473768;
var Qc = 1.0507009873554805;
var Op = 0.3275911;
var Kp = 0.254829592;
var Zp = -0.284496736;
var Bp = 1.421413741;
var Hp = -1.453152027;
var _p = 1.061405429;
function ms(n, t) {
  if (n.length !== t.length)
    throw new Error(`Cannot merge real and imag arrays of different lengths. real:${n.length}, imag: ${t.length}.`);
  const e = new Float32Array(n.length * 2);
  for (let s = 0; s < e.length; s += 2)
    e[s] = n[s / 2], e[s + 1] = t[s / 2];
  return e;
}
function G0(n) {
  const t = new Float32Array(n.length / 2), e = new Float32Array(n.length / 2);
  for (let s = 0; s < n.length; s += 2)
    t[s / 2] = n[s], e[s / 2] = n[s + 1];
  return { real: t, imag: e };
}
function E0(n) {
  const t = Math.ceil(n.length / 4), e = new Float32Array(t), s = new Float32Array(t);
  for (let o = 0; o < n.length; o += 4)
    e[Math.floor(o / 4)] = n[o], s[Math.floor(o / 4)] = n[o + 1];
  return { real: e, imag: s };
}
function L0(n) {
  const t = Math.floor(n.length / 4), e = new Float32Array(t), s = new Float32Array(t);
  for (let o = 2; o < n.length; o += 4)
    e[Math.floor(o / 4)] = n[o], s[Math.floor(o / 4)] = n[o + 1];
  return { real: e, imag: s };
}
function Up(n, t) {
  const e = n[t * 2], s = n[t * 2 + 1];
  return { real: e, imag: s };
}
function M0(n, t, e, s) {
  n[s * 2] = t, n[s * 2 + 1] = e;
}
function W0(n, t) {
  const e = new Float32Array(n / 2), s = new Float32Array(n / 2);
  for (let o = 0; o < Math.ceil(n / 2); o++) {
    const r = (t ? 2 : -2) * Math.PI * (o / n);
    e[o] = Math.cos(r), s[o] = Math.sin(r);
  }
  return { real: e, imag: s };
}
function D0(n, t, e) {
  const s = (e ? 2 : -2) * Math.PI * (n / t), o = Math.cos(s), r = Math.sin(s);
  return { real: o, imag: r };
}
var vu = "->";
var iR = /->/g;
var hm = ",";
var pm = "...";
function Yp(n, t) {
  n = n.replace(/\s/g, "");
  const e = (n.length - n.replace(iR, "").length) / vu.length;
  if (e < 1)
    throw new Error("Equations without an arrow are not supported.");
  if (e > 1)
    throw new Error(`Equation must contain exactly one arrow ("${vu}").`);
  const [s, o] = n.split(vu);
  v2(s.indexOf(pm) === -1, () => `The ellipsis notation ("${pm}") is not supported yet.`);
  const r = s.split(hm), i6 = r.length;
  if (t !== i6)
    throw new Error(`Expected ${i6} input tensors, received ${t}`);
  if (i6 > 2)
    throw new Error("Support for more than 2 input tensors is not implemented yet.");
  const a = [];
  for (let h6 = 0; h6 < o.length; ++h6) {
    const p6 = o[h6];
    if (!r.some((f) => f.indexOf(p6) !== -1))
      throw new Error(`Output subscripts contain the label ${p6} not present in the input subscripts.`);
    a.indexOf(p6) === -1 && a.push(p6);
  }
  for (let h6 = 0; h6 < s.length; ++h6) {
    const p6 = s[h6];
    a.indexOf(p6) === -1 && p6 !== hm && a.push(p6);
  }
  const l = new Array(r.length);
  for (let h6 = 0; h6 < i6; ++h6) {
    if (new Set(r[h6].split("")).size !== r[h6].length)
      throw new Error(`Found duplicate axes in input component ${r[h6]}. Support for duplicate axes in input is not implemented yet.`);
    l[h6] = [];
    for (let p6 = 0; p6 < r[h6].length; ++p6)
      l[h6].push(a.indexOf(r[h6][p6]));
  }
  const c = a.length, u = o.length, d = [];
  for (let h6 = u; h6 < c; ++h6)
    d.push(h6);
  return { allDims: a, summedDims: d, idDims: l };
}
function Qp(n, t) {
  let e = new Array(n);
  e.fill(-1);
  for (let o = 0; o < t.length; ++o)
    e[t[o]] = o;
  const s = [];
  for (let o = 0; o < n; ++o)
    e[o] === -1 && s.push(o);
  return e = e.filter((o) => o !== -1), { permutationIndices: e, expandDims: s };
}
function Jp(n, t, e) {
  const s = new Array(n);
  for (let o = 0; o < e.length; ++o) {
    const r = e[o].shape;
    for (let i6 = 0; i6 < t[o].length; ++i6)
      s[t[o][i6]] === void 0 ? s[t[o][i6]] = r[i6] : v2(s[t[o][i6]] === r[i6], () => `Expected dimension ${s[t[o][i6]]} at axis ${i6} of input shaped ${JSON.stringify(r)}, but got dimension ${r[i6]}`);
  }
}
function jp(n, t) {
  const e = n, s = [];
  let o = 0;
  n.length === 0 && e.push(-1), o = n.length + 1;
  for (let i6 = 0; i6 < o; ++i6)
    s.push([]);
  const r = [];
  for (let i6 = 0; i6 < e.length; ++i6) {
    const a = e[i6], l = aR(t, a);
    for (const c of l)
      r.indexOf(c) === -1 && (s[i6].push(c), r.push(c));
  }
  return { path: e, steps: s };
}
function qp(n) {
  return n.every((t, e) => t === e);
}
function aR(n, t) {
  const e = [];
  for (let s = 0; s < n.length; ++s)
    (n[s].length === 0 || n[s].indexOf(t) !== -1 || t === -1) && e.push(s);
  return e;
}
function tf(n, t, e = 0) {
  let s = [];
  if (typeof t == "number")
    v2(n.shape[e] % t === 0, () => "Number of splits must evenly divide the axis."), s = new Array(t).fill(n.shape[e] / t);
  else {
    const o = t.reduce((i6, a) => (a === -1 && (i6 += 1), i6), 0);
    v2(o <= 1, () => "There should be only one negative value in split array.");
    const r = t.indexOf(-1);
    if (r !== -1) {
      const i6 = t.reduce((a, l) => l > 0 ? a + l : a);
      t[r] = n.shape[e] - i6;
    }
    v2(n.shape[e] === t.reduce((i6, a) => i6 + a), () => "The sum of sizes must match the size of the axis dimension."), s = t;
  }
  return s;
}
function F0(n) {
  return `Received SparseTensor with denseShape[0] = 0 but
  indices.shape[0] = ${n}`;
}
function V0(n, t) {
  return `indices(${n}, 0) is invalid: ${t} < 0`;
}
function z0(n, t, e) {
  return `indices(${n}, 0) is invalid: ${t} >= ${e}`;
}
function X0(n, t) {
  return `only one output dimension may be -1, not both ${n} and ${t}`;
}
function P0(n, t) {
  return `size ${n} must be non-negative, not ${t}`;
}
function A0() {
  return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero";
}
function O0(n, t) {
  const e = O(n), s = O(t);
  return `Input to reshape is a SparseTensor with ${e}
  dense values, but the requested shape requires a multiple of ${s}. inputShape=${n} outputShape= ${t}`;
}
function K0(n, t) {
  const e = O(n), s = O(t);
  return `Input to reshape is a tensor with ${e} dense values, but the requested shape has ${s}. inputShape=${n} outputShape=${t}`;
}
function Id() {
  return "segment ids must be >= 0";
}
function Z0() {
  return "segment ids are not increasing";
}
function B0(n, t) {
  return `Segment id ${n} out of range [0, ${t}), possibly because segmentIds input is not sorted.`;
}
function H0(n, t, e) {
  return `Bad: indices[${n}] == ${t} out of range [0, ${e})`;
}
function _0(n, t) {
  let e = false, s;
  for (n <= zp ? (s = n, e = true) : s = sl(n, Math.floor(Math.sqrt(n))); !e; )
    s > t || s === n ? e = true : s = sl(n, s + 1);
  return s;
}
function U0(n, t, e) {
  const s = [], o = n.length;
  for (let r = 0; r < o; r++)
    r !== t ? s.push(n[r]) : s.push(e);
  return s;
}
function ef(n, t, e, s) {
  const o = t.shape.length, r = n.shape.length;
  if (s !== 0 && (s < -o || s > o))
    throw new Error(`Expect batchDims in the range of [-${o}, ${o}], but got ${s}`);
  if (s < 0 && (s += o), s > r)
    throw new Error(`batchDims (${s}) must be less than rank(x) (
    ${r}).`);
  if (e < s)
    throw new Error(`batchDims (${s}) must be less than or equal to axis (${e}).`);
  for (let d = 0; d < s; ++d)
    if (n.shape[d] !== t.shape[d])
      throw new Error(`x.shape[${d}]: ${n.shape[d]} should be equal to indices.shape[${d}]: ${t.shape[d]}.`);
  const i6 = n.shape[e], a = [];
  let l = 1, c = 1, u = 1;
  for (let d = 0; d < s; ++d)
    a.push(n.shape[d]), l *= n.shape[d];
  for (let d = s; d < e; d++)
    a.push(n.shape[d]), c *= n.shape[d];
  for (let d = s; d < o; d++)
    a.push(t.shape[d]);
  for (let d = e + 1; d < r; d++)
    a.push(n.shape[d]), u *= n.shape[d];
  return { batchSize: l, sliceSize: u, outerSize: c, dimSize: i6, outputShape: a };
}
var lR = Object.freeze(Object.defineProperty({
  __proto__: null,
  collectGatherOpShapeInfo: ef,
  computeOutShape: U0,
  segOpComputeOptimalWindowSize: _0
}, Symbol.toStringTag, { value: "Module" }));
function No(n) {
  try {
    return n.map((t) => ps(t));
  } catch (t) {
    throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${t}`);
  }
}
function Y0(n) {
  return n.map((t) => hs(t));
}
var cR = Object.freeze(Object.defineProperty({
  __proto__: null,
  ERF_A1: Kp,
  ERF_A2: Zp,
  ERF_A3: Bp,
  ERF_A4: Hp,
  ERF_A5: _p,
  ERF_P: Op,
  PARALLELIZE_THRESHOLD: zp,
  get RowPartitionType() {
    return Fn;
  },
  SELU_SCALE: Qc,
  SELU_SCALEALPHA: Yc,
  applyActivation: Sp,
  assertAndGetBroadcastShape: bt,
  assertAxesAreInnerMostDims: Te,
  assertParamsConsistent: Vp,
  assignToTypedArray: M0,
  axesAreInnerMostDims: Jh,
  calculateShapes: Ir,
  checkEinsumDimSizes: Jp,
  checkPadOnDimRoundingMode: Be,
  combineLocations: Mb,
  combineRaggedTensorToTensorShapes: T0,
  complexWithEvenIndex: E0,
  complexWithOddIndex: L0,
  computeConv2DInfo: ke,
  computeConv3DInfo: Bs,
  computeDefaultPad: Zh,
  computeDilation2DInfo: ca,
  computeOptimalWindowSize: Uc,
  computeOutAndReduceShapes: ye,
  computeOutShape: ts,
  computePool2DInfo: $n,
  computePool3DInfo: xs,
  convertConv2DDataFormat: ys,
  decodeEinsumEquation: Yp,
  eitherStridesOrDilationsAreOne: Ee,
  expandShapeToKeepDim: re,
  exponent: D0,
  exponents: W0,
  fromStringArrayToUint8: Y0,
  fromUint8ToStringArray: No,
  getAxesPermutation: qt,
  getBroadcastDims: vo,
  getComplexWithIndex: Up,
  getEinsumComputePath: jp,
  getEinsumPermutation: Qp,
  getFusedBiasGradient: vp,
  getFusedDyActivation: Cp,
  getImageCenter: Xp,
  getInnerMostAxes: ie,
  getPermuted: ma,
  getRaggedRank: R0,
  getReductionAxes: le,
  getReshaped: fa,
  getReshapedPermuted: ga,
  getRowPartitionTypesHelper: N0,
  getSliceBeginCoords: Pp,
  getSliceSize: Ap,
  getSparseFillEmptyRowsIndicesDenseShapeMismatch: F0,
  getSparseFillEmptyRowsNegativeIndexErrorMessage: V0,
  getSparseFillEmptyRowsOutOfRangeIndexErrorMessage: z0,
  getSparseReshapeEmptyTensorZeroOutputDimErrorMessage: A0,
  getSparseReshapeInputOutputMismatchErrorMessage: K0,
  getSparseReshapeInputOutputMultipleErrorMessage: O0,
  getSparseReshapeMultipleNegativeOneOutputDimErrorMessage: X0,
  getSparseReshapeNegativeOutputDimErrorMessage: P0,
  getSparseSegmentReductionIndicesOutOfRangeErrorMessage: H0,
  getSparseSegmentReductionNegativeSegmentIdsErrorMessage: Id,
  getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage: Z0,
  getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage: B0,
  getUndoAxesPermutation: Hs,
  isIdentityPermutation: qp,
  log: _I,
  mergeRealAndImagArrays: ms,
  prepareAndValidate: Bc,
  prepareSplitSize: tf,
  segment_util: lR,
  shouldFuse: kp,
  slice_util: sR,
  splitRealAndImagArrays: G0,
  stridesOrDilationsArePositive: Io,
  tupleValuesAreOne: wo,
  upcastType: je,
  validateDefaultValueShape: $0,
  validateInput: e0,
  validateUpdateShape: wp,
  warn: rn
}, Symbol.toStringTag, { value: "Module" }));
PN();
var Q0 = {
  kernelName: Vl,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, pa(et(e, "float32"), -1)) };
  }
};
var uR = {
  kernelName: di,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      x: () => {
        const s = At(et(e, "float32")), o = De(lt(gt(1), s));
        return jt(ut(n, o));
      }
    };
  }
};
var dR = {
  kernelName: hi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      x: () => {
        const s = De(lt(At(et(e, "float32")), 1));
        return ut(n, s);
      }
    };
  }
};
var hR = {
  kernelName: br,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      let a = n;
      const l = le(e.shape, o);
      return l.length > 0 && (a = at(a, l)), W(a, e.shape);
    }, b: () => {
      let a = n;
      const l = le(s.shape, o);
      return l.length > 0 && (a = at(a, l)), W(a, s.shape);
    } };
  }
};
var pR = {
  kernelName: Bd,
  saveAllInputs: true,
  gradFunc: (n, t) => {
    const e = {};
    return t.forEach((s, o) => {
      e[o] = () => n.clone();
    }), e;
  }
};
var fR = {
  kernelName: zl,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => Tt(e) };
  }
};
var mR = {
  kernelName: Xl,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => Tt(e) };
  }
};
var gR = {
  kernelName: pi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, De(lt(gt(1), At(et(e, "float32"))))) };
  }
};
var bR = {
  kernelName: fi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      x: () => {
        const s = De(U(gt(1), At(et(e, "float32"))));
        return ut(n, s);
      }
    };
  }
};
var xR = {
  kernelName: bi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = U(At(e), At(s));
      let l = G(n, ut(s, a));
      const c = le(e.shape, o);
      return c.length > 0 && (l = at(l, c)), W(l, e.shape);
    }, b: () => {
      const a = U(At(e), At(s));
      let l = jt(G(n, ut(e, a)));
      const c = le(s.shape, o);
      return c.length > 0 && (l = at(l, c)), W(l, s.shape);
    } };
  }
};
var yR = {
  kernelName: mi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, U(At(et(e, "float32")), 1)) };
  }
};
var wR = {
  kernelName: gi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, lt(gt(1), At(et(e, "float32")))) };
  }
};
function IR(n, t, e, s, o, r) {
  const i6 = T(n, "dy", "avgPool3dGrad"), a = T(t, "input", "avgPool3dGrad");
  let l = i6, c = a, u = false;
  a.rank === 4 && (u = true, l = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2], i6.shape[3]]), c = W(a, [
    1,
    a.shape[0],
    a.shape[1],
    a.shape[2],
    a.shape[3]
  ])), v2(l.rank === 5, () => `Error in avgPool3dGrad: dy must be rank 5 but got rank ${l.rank}.`), v2(c.rank === 5, () => `Error in avgPool3dGrad: input must be rank 5 but got rank ${c.rank}.`), Be("avgPool3dGrad", o, r);
  const d = { dy: l, input: c }, h6 = { filterSize: e, strides: s, pad: o, dimRoundingMode: r }, p6 = $.runKernel(Yd, d, h6);
  return u ? W(p6, [p6.shape[1], p6.shape[2], p6.shape[3], p6.shape[4]]) : p6;
}
var CR = L({ avgPool3dGrad_: IR });
var vR = {
  kernelName: Al,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { filterSize: o, strides: r, pad: i6, dimRoundingMode: a } = e;
    return {
      x: () => CR(n, s, o, r, i6, a)
    };
  }
};
function SR(n, t, e, s, o) {
  const r = T(n, "dy", "avgPoolGrad"), i6 = T(t, "input", "avgPoolGrad");
  v2(i6.rank === r.rank, () => `Rank of input (${i6.rank}) does not match rank of dy (${r.rank})`);
  let a = i6, l = r, c = false;
  i6.rank === 3 && (c = true, a = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2]]), l = W(r, [1, r.shape[0], r.shape[1], r.shape[2]])), v2(l.rank === 4, () => `Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`), v2(a.rank === 4, () => `Error in avgPoolGrad: input must be rank 4 but got rank ${a.rank}.`);
  const u = { dy: l, input: a }, d = { filterSize: e, strides: s, pad: o }, h6 = $.runKernel(Ud, u, d);
  return c ? W(h6, [h6.shape[1], h6.shape[2], h6.shape[3]]) : h6;
}
var kR = L({ avgPoolGrad_: SR });
var TR = {
  kernelName: Pl,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { filterSize: o, strides: r, pad: i6 } = e;
    return { x: () => kR(n, s, o, r, i6) };
  }
};
var NR = {
  kernelName: Ol,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { transposeA: r, transposeB: i6 } = e;
    return !r && !i6 ? {
      a: () => Gt(n, o, false, true),
      b: () => Gt(s, n, true, false)
    } : !r && i6 ? {
      a: () => Gt(n, o, false, false),
      b: () => Gt(n, s, true, false)
    } : r && !i6 ? {
      a: () => Gt(o, n, false, true),
      b: () => Gt(s, n, false, false)
    } : {
      a: () => Gt(o, n, true, true),
      b: () => Gt(n, s, true, true)
    };
  }
};
var RR = {
  kernelName: Kl,
  gradFunc: (n, t, e) => {
    const { blockShape: s, crops: o } = e;
    return { x: () => ip(n, s, o) };
  }
};
var $R = {
  kernelName: BI,
  gradFunc: (n, t, e) => {
    const s = e, o = s.inputShape, r = s.shape, i6 = Array.from(r);
    for (let l = o.length - 1; l >= 0; l--)
      if (o[l] === r[l])
        i6[l] = 1;
      else if (o[l] !== 1)
        throw new Error(`broadcastTo(): [${o}] cannot be broadcast to [${r}].`);
    const a = [];
    for (let l = 0; l < i6.length; l++)
      i6[l] > 1 && a.push(l);
    return { x: () => at(
      n,
      a,
      true
      /* keepDims */
    ) };
  }
};
var GR = {
  kernelName: xi,
  gradFunc: (n) => ({ x: () => n.clone() })
};
var ER = {
  kernelName: yi,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var LR = {
  kernelName: wi,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { clipValueMin: o, clipValueMax: r } = e;
    return {
      x: () => Oe(ss(Do(s, o), yr(s, r)), n, Tt(n))
    };
  }
};
var MR = {
  kernelName: Zl,
  inputsToSave: ["x"],
  gradFunc: Q0.gradFunc
};
var WR = {
  kernelName: Bl,
  saveAllInputs: true,
  gradFunc: (n, t, e) => {
    const s = t.map((l) => l.shape), { axis: o } = e, r = Ct(o, t[0].shape)[0], i6 = s.map((l) => l[r]);
    return un(n, i6, r).map((l) => () => l);
  }
};
var DR = {
  kernelName: Hl,
  inputsToSave: ["x", "filter"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { dilations: r, strides: i6, pad: a, dataFormat: l } = e;
    return v2(wo(r), () => `Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${r}'`), {
      x: () => Uh(s.shape, n, o, i6, a, l),
      filter: () => Ip(s, n, o.shape, i6, a, l)
    };
  }
};
var FR = {
  kernelName: _l,
  inputsToSave: ["dy", "filter"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { strides: r, pad: i6, dataFormat: a, dimRoundingMode: l } = e;
    return {
      dy: () => Co(n, o, r, i6, a, 1, l),
      filter: () => Ip(n, s, o.shape, r, i6, a, l)
    };
  }
};
function VR(n, t, e, s, o) {
  let r = n;
  n.rank === 4 && (r = W(n, [1, n.shape[0], n.shape[1], n.shape[2], n.shape[3]]));
  let i6 = t;
  i6.rank === 4 && (i6 = W(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]])), v2(r.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ${r.shape}.`), v2(i6.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ${i6.shape}.`), v2(e.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ${e}.`), v2(r.shape[4] === e[3], () => `Error in conv3dDerFilter: depth of input ${r.shape[4]}) must match input depth in filter (${e[3]}.`), v2(i6.shape[4] === e[4], () => `Error in conv3dDerFilter: depth of dy (${i6.shape[4]}) must match output depth for filter (${e[4]}).`);
  const a = { x: r, dy: i6 }, l = { strides: s, pad: o, filterShape: e };
  return $.runKernel(qd, a, l);
}
var zR = L({ conv3DBackpropFilter_: VR });
var XR = {
  kernelName: Ul,
  inputsToSave: ["x", "filter"],
  gradFunc: (n, t, e) => {
    const { dilations: s, strides: o, pad: r } = e;
    v2(wo(s), () => `Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`);
    const [i6, a] = t;
    return {
      x: () => Gb(i6.shape, n, a, o, r),
      filter: () => zR(i6, n, a.shape, o, r)
    };
  }
};
var PR = {
  kernelName: Ii,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(jt(_b(et(e, "float32"))), n) };
  }
};
var AR = {
  kernelName: Ci,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(Ub(et(e, "float32")), n) };
  }
};
var OR = {
  kernelName: Yl,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { axis: o, exclusive: r, reverse: i6 } = e;
    return {
      x: () => {
        const a = qt([o], s.rank);
        let l = Lb(n, o, r, !i6);
        return a != null && (l = kt(l, a)), l;
      }
    };
  }
};
var KR = {
  kernelName: Ql,
  inputsToSave: ["x", "filter"],
  gradFunc: (n, t, e) => {
    const { dilations: s, strides: o, pad: r, dimRoundingMode: i6 } = e, a = s ?? [1, 1];
    v2(wo(a), () => `Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${a}'`);
    const [l, c] = t;
    return v2(l.rank === 4, () => `Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`), v2(c.rank === 4, () => `Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${c.rank}.`), v2(l.shape[3] === c.shape[2], () => `Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${c.shape[2]}.`), v2(Ee(o, a), () => `Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${o} and dilations '${a}'.`), Be("depthwiseConv2d", r, i6), {
      x: () => hT(l.shape, n, c, o, r, a, i6),
      filter: () => uT(l, n, c.shape, o, r, a, i6)
    };
  }
};
var ZR = {
  kernelName: Jl,
  inputsToSave: ["x", "filter"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, r = { x: s, filter: o, dy: n }, i6 = { x: s, filter: o, dy: n };
    return {
      x: () => $.runKernel(ed, r, e),
      filter: () => $.runKernel(nd, i6, e)
    };
  }
};
var BR = {
  kernelName: Si,
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e] = t, s = { dy: n, y: e };
    return { x: () => $.runKernel(ah, s) };
  }
};
var HR = {
  kernelName: ki,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t, s = G(Tn(jt(At(e))), 2 / Math.sqrt(Math.PI));
    return { x: () => G(n, s) };
  }
};
var _R = {
  kernelName: Ti,
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, e) };
  }
};
var UR = {
  kernelName: ql,
  inputsToSave: ["input"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { input: () => W(n, e.shape) };
  }
};
var YR = {
  kernelName: Ni,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, Tn(e)) };
  }
};
var QR = {
  kernelName: Ri,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var JR = {
  kernelName: $i,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = ut(n, et(s, "float32")), l = le(e.shape, o);
      return l.length > 0 ? W(at(a, l), e.shape) : a;
    }, b: () => {
      let a = G(n, et(e, "float32"));
      const l = le(s.shape, o);
      l.length > 0 && (a = W(at(a, l), s.shape));
      const c = At(s);
      return jt(ut(a, et(c, "float32")));
    } };
  }
};
var jR = {
  kernelName: tc,
  inputsToSave: ["x", "mean", "variance", "scale"],
  gradFunc: (n, t, e) => {
    const { varianceEpsilon: s } = e, [o, r, i6, a] = t, l = a ?? gt(1), c = le(r.shape, o.shape), u = [];
    if (r.rank === 1) {
      for (let y6 = 0; y6 < o.shape.length - 1; ++y6)
        u.push(o.shape[y6]);
      u.push(1);
    }
    const d = lt(o, r), h6 = G(n, l), p6 = Zb(U(i6, gt(s))), f = G(G(G(p6, p6), p6), gt(-0.5));
    return {
      x: () => r.rank === 1 ? W(G(G(n, Vn(W(p6, [1, 1, 1, r.shape[0]]), u)), l), o.shape) : W(G(G(n, p6), l), o.shape),
      mean: () => {
        let y6 = G(G(p6, gt(-1)), h6);
        return r.rank === 1 && (y6 = at(y6, c)), W(y6, r.shape);
      },
      variance: () => {
        let y6 = G(G(f, d), h6);
        return r.rank === 1 && (y6 = at(y6, c)), W(y6, r.shape);
      },
      scale: () => {
        const y6 = G(d, p6);
        let I = G(n, y6);
        return r.rank === 1 && (I = at(I, c)), W(I, r.shape);
      },
      offset: () => {
        let y6 = n;
        return r.rank === 1 && (y6 = at(y6, c)), W(y6, r.shape);
      }
    };
  }
};
var qR = {
  kernelName: ec,
  inputsToSave: ["x", "indices"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { axis: r } = e, i6 = Ct(r, s.shape)[0];
    return { x: () => {
      const l = s.shape, c = o.size, u = l.slice(0, i6), d = u.length, h6 = l.slice(r, l.length).slice(1), p6 = h6.length, f = fm(0, d), m = fm(d + 1, d + 1 + p6), g6 = mm([u, [c], h6]), b6 = W(n, g6), x6 = W(o, [c]), w6 = mm([[d], f, m]), y6 = kt(b6, w6);
      let I = qb(y6, x6, s.shape[i6]);
      const C6 = Hs(w6);
      return I = kt(I, C6), I;
    }, indices: () => o };
  }
};
function fm(n, t) {
  const e = [];
  for (let s = n; s < t; ++s)
    e.push(s);
  return e;
}
function mm(n) {
  const t = [];
  for (let e = 0; e < n.length; ++e)
    for (let s = 0; s < n[e].length; ++s)
      t.push(n[e][s]);
  return t;
}
var t$ = {
  kernelName: Gi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t;
    return { a: () => Tt(e), b: () => Tt(s) };
  }
};
var e$ = {
  kernelName: Ei,
  gradFunc: (n) => ({ x: () => et(n, "float32") })
};
var n$ = {
  kernelName: Li,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var s$ = {
  kernelName: Mi,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var o$ = {
  kernelName: Wi,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var r$ = {
  kernelName: sc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { alpha: o } = e, r = sn(s, 0);
    return { x: () => Oe(r, n, G(n, o)) };
  }
};
var i$ = {
  kernelName: Fi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, U(e, 1)) };
  }
};
var a$ = {
  kernelName: Di,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, et(e, "float32")) };
  }
};
var l$ = {
  kernelName: HI,
  inputsToSave: [],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s] = t, { axis: o } = e;
    return {
      logits: () => {
        const i6 = Tn(s);
        return lt(n, G(at(n, o, true), i6));
      }
    };
  }
};
function c$(n, t, e, s = 5, o = 1, r = 1, i6 = 0.5) {
  const a = { x: n, y: t, dy: e }, l = { depthRadius: s, bias: o, alpha: r, beta: i6 };
  return $.runKernel(ph, a, l);
}
var u$ = L({ localResponseNormalizationBackprop_: c$ });
var d$ = {
  kernelName: cc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { depthRadius: r, bias: i6, alpha: a, beta: l } = e;
    return {
      x: () => u$(s, o, n, r, i6, a, l)
    };
  }
};
function J0(n, t, e, s) {
  return t.rank < e.rank && (t = W(t, re(t.shape, s))), n.rank < e.rank && (n = W(n, re(n.shape, s))), {
    x: () => G(n, et(kn(e, t), n.dtype))
  };
}
var gm = {
  kernelName: uc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const s = e, { reductionIndices: o } = s, r = t[0], i6 = t[1], a = Ct(o, r.shape), l = J0(n, i6, r, a);
    return {
      x: () => l.x()
    };
  }
};
var h$ = {
  kernelName: Vi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t;
    return { a: () => G(n, et(Do(e, s), "float32")), b: () => G(n, et(Fb(e, s), "float32")) };
  }
};
function p$(n, t, e, s, o, r, i6) {
  const a = T(n, "dy", "maxPool3dGrad"), l = T(t, "input", "maxPool3dGrad"), c = T(e, "output", "maxPool3dGrad");
  let u = a, d = l, h6 = c, p6 = false;
  l.rank === 4 && (p6 = true, u = W(a, [1, a.shape[0], a.shape[1], a.shape[2], a.shape[3]]), d = W(l, [
    1,
    l.shape[0],
    l.shape[1],
    l.shape[2],
    l.shape[3]
  ]), h6 = W(c, [
    1,
    c.shape[0],
    c.shape[1],
    c.shape[2],
    c.shape[3]
  ])), v2(u.rank === 5, () => `Error in maxPool3dGrad: dy must be rank 5 but got rank ${u.rank}.`), v2(d.rank === 5, () => `Error in maxPool3dGrad: input must be rank 5 but got rank ${d.rank}.`), v2(h6.rank === 5, () => `Error in maxPool3dGrad: output must be rank 5 but got rank ${h6.rank}.`), Be("maxPool3dGrad", r, i6);
  const f = { dy: u, input: d, output: h6 }, m = { filterSize: s, strides: o, pad: r, dimRoundingMode: i6 }, g6 = $.runKernel(mh, f, m);
  return p6 ? W(g6, [g6.shape[1], g6.shape[2], g6.shape[3], g6.shape[4]]) : g6;
}
var f$ = L({ maxPool3dGrad_: p$ });
var m$ = {
  kernelName: hc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = e;
    return {
      x: () => f$(n, s, o, r, i6, a, l)
    };
  }
};
function g$(n, t, e, s, o, r, i6) {
  const a = T(n, "dy", "maxPoolGrad"), l = T(t, "input", "maxPoolGrad"), c = T(e, "output", "maxPoolGrad");
  v2(l.rank === a.rank, () => `Rank of input (${l.rank}) does not match rank of dy (${a.rank})`), v2(a.rank === 4, () => `Error in maxPoolGrad: dy must be rank 4 but got rank ${a.rank}.`), v2(l.rank === 4, () => `Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`), Be("maxPoolGrad", r, i6);
  const u = { dy: a, input: l, output: c }, d = { filterSize: s, strides: o, pad: r, dimRoundingMode: i6 };
  return $.runKernel(fh, u, d);
}
var b$ = L({ maxPoolGrad_: g$ });
var x$ = {
  kernelName: dc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { filterSize: r, strides: i6, pad: a } = e;
    return {
      x: () => b$(n, s, o, r, i6, a)
    };
  }
};
var y$ = {
  kernelName: pc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { axis: o } = e, r = Ct(o, s.shape), a = ye(s.shape, r)[1], l = O(a);
    return { x: () => {
      const u = s.shape.slice();
      r.forEach((p6) => {
        u[p6] = 1;
      });
      const d = W(n, u);
      return ut(G(d, Us(s.shape, "float32")), l);
    } };
  }
};
var w$ = {
  kernelName: fc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const s = e, { axis: o } = s, [r, i6] = t, a = Ct(o, r.shape), l = J0(n, i6, r, a);
    return {
      x: () => l.x()
    };
  }
};
var I$ = {
  kernelName: zi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t;
    return { a: () => G(n, et(yr(e, s), "float32")), b: () => G(n, et(sn(e, s), "float32")) };
  }
};
var C$ = {
  kernelName: mc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const s = t[0], { paddings: o } = e, r = o.map((i6) => i6[0]);
    return { x: () => Dt(n, r, s.shape) };
  }
};
var v$ = {
  kernelName: Xi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = le(e.shape, o);
      return a.length > 0 ? W(at(n, a), e.shape) : n;
    }, b: () => {
      const a = G(n, jt(Ac(ut(e, s)))), l = le(s.shape, o);
      return l.length > 0 ? W(at(a, l), s.shape) : a;
    } };
  }
};
var S$ = {
  kernelName: Pi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = G(n, et(s, "float32")), l = le(e.shape, o);
      return l.length > 0 ? W(at(a, l), e.shape) : a;
    }, b: () => {
      const a = G(n, et(e, "float32")), l = le(s.shape, o);
      return l.length > 0 ? W(at(a, l), s.shape) : a;
    } };
  }
};
var k$ = {
  kernelName: gc,
  gradFunc: (n) => ({ x: () => jt(n) })
};
var T$ = {
  kernelName: yc,
  inputsToSave: ["indices"],
  gradFunc: (n, t) => {
    const e = t[0];
    return { indices: () => ge(e.shape, "float32") };
  }
};
var N$ = {
  kernelName: xc,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var R$ = {
  kernelName: wc,
  saveAllInputs: true,
  gradFunc: (n, t, e) => {
    const { axis: s } = e;
    return To(n, s).map((r) => () => r);
  }
};
var bm = {
  kernelName: Ic,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const s = t[0], { paddings: o } = e, r = o.map((i6) => i6[0]);
    return { x: () => Dt(n, r, s.shape) };
  }
};
var $$ = {
  kernelName: Ai,
  inputsToSave: ["a", "b"],
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e, s, o] = t, r = e, i6 = s, a = bt(r.shape, i6.shape);
    return { a: () => {
      const u = et(i6, "float32");
      let d = G(n, G(u, ir(r, lt(u, gt(1)))));
      const h6 = le(r.shape, a);
      return h6.length > 0 && (d = at(d, h6)), W(d, r.shape);
    }, b: () => {
      const u = sn(r, 0), d = Oe(u, Nn(r), Tt(r));
      let h6 = G(n, G(o, d));
      const p6 = le(i6.shape, a);
      return p6.length > 0 && (h6 = at(h6, p6)), W(h6, i6.shape);
    } };
  }
};
var G$ = {
  kernelName: Cc,
  inputsToSave: ["x", "alpha"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = sn(e, 0);
    return {
      x: () => Oe(o, n, G(n, s)),
      alpha: () => {
        let r = Oe(o, Tt(n), G(n, e));
        const i6 = le(s.shape, n.shape);
        return i6.length > 0 && (r = at(r, i6)), W(r, s.shape);
      }
    };
  }
};
function E$(n, t, e) {
  const s = n.shape.slice();
  s[e] = 1;
  const o = W(t, s), r = yd(n, e, true, false), i6 = yd(n, e, true, true), a = G(r, i6);
  return G(o, a);
}
function L$(n, t, e) {
  const s = n.shape.length, o = s - e.length, r = qt(e, s);
  let i6 = n;
  r != null && (i6 = kt(n, r));
  const a = i6.shape.slice(), c = a.splice(s - e.length, e.length).reduce((h6, p6) => h6 * p6, 1);
  a.push(c);
  const u = i6.reshape(a);
  let d = E$(u, t, o);
  if (d = d.reshape(i6.shape), r != null) {
    const h6 = Hs(r);
    d = kt(d, h6);
  }
  return d;
}
var M$ = {
  kernelName: vc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { axis: o } = e;
    let r = [];
    return o == null ? r = s.shape.map((i6, a) => a) : typeof o == "number" ? r = [o] : r = o, { x: () => L$(s, n, r) };
  }
};
var W$ = {
  kernelName: vi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = ut(n, et(s, "float32")), l = le(e.shape, o);
      return l.length > 0 ? W(at(a, l), e.shape) : a;
    }, b: () => {
      let a = G(n, et(e, "float32"));
      const l = le(s.shape, o);
      l.length > 0 && (a = W(at(a, l), s.shape));
      const c = At(s);
      return jt(ut(a, et(c, "float32")));
    } };
  }
};
var D$ = {
  kernelName: Oi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, jt(At(e))) };
  }
};
var F$ = {
  kernelName: Zi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t, s = G(yr(e, 6), pa(e));
    return { x: () => G(n, et(s, "float32")) };
  }
};
var V$ = {
  kernelName: Ki,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, et(pa(e), "float32")) };
  }
};
var z$ = {
  kernelName: Sc,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => W(n, e.shape) };
  }
};
var X$ = {
  kernelName: Tc,
  inputsToSave: ["images"],
  gradFunc: (n, t, e) => {
    const [s] = t, o = { dy: n, images: s };
    return { images: () => (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(Ch, o, e)
    ) };
  }
};
var P$ = {
  kernelName: kc,
  inputsToSave: ["images"],
  gradFunc: (n, t, e) => {
    const [s] = t, o = { dy: n, images: s };
    return { images: () => (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(Ih, o, e)
    ) };
  }
};
var A$ = {
  kernelName: Nc,
  gradFunc: (n, t, e) => {
    const { dims: s } = e, o = Ct(s, n.shape);
    return { x: () => ko(n, o) };
  }
};
var O$ = {
  kernelName: Bi,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var K$ = {
  kernelName: Hi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => jt(ut(n, G(ir(e, 1.5), 2))) };
  }
};
var Z$ = {
  kernelName: Rc,
  inputsToSave: ["condition"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      // TODO(julianoks): Return null for condition gradient
      // when backprop supports it.
      condition: () => et(Tt(e), "float32"),
      t: () => G(n, et(e, n.dtype)),
      e: () => G(n, et(np(e), n.dtype))
    };
  }
};
var B$ = {
  kernelName: _i,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      x: () => {
        const s = sn(e, gt(0)), o = gt(Yc), r = gt(Qc), i6 = G(n, r), a = G(G(n, o), Tn(et(e, "float32")));
        return Oe(s, i6, a);
      }
    };
  }
};
var H$ = {
  kernelName: Ji,
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, G(e, lt(gt(1), e))) };
  }
};
var _$ = {
  kernelName: Qi,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var U$ = {
  kernelName: Ui,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(Yh(et(e, "float32")), n) };
  }
};
var Y$ = {
  kernelName: Yi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(Eb(et(e, "float32")), n) };
  }
};
var Q$ = {
  kernelName: $c,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { begin: o, size: r } = e, i6 = s.shape, [a, l] = Hc(s, o, r), c = [];
    for (let u = 0; u < n.rank; u++)
      c.push([a[u], i6[u] - a[u] - l[u]]);
    return { x: () => rp(n, c) };
  }
};
var J$ = {
  kernelName: Mc,
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s] = t, { dim: o } = e, r = true, i6 = G(n, s);
    return {
      logits: () => lt(i6, G(at(i6, [o], r), s))
    };
  }
};
var j$ = {
  kernelName: ji,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, xr(e)) };
  }
};
var xm = {
  kernelName: Ec,
  gradFunc: (n, t, e) => {
    const { blockShape: s, paddings: o } = e;
    return { x: () => _h(n, s, o) };
  }
};
var ym = {
  kernelName: Lc,
  gradFunc: (n, t, e) => {
    const { axis: s } = e;
    return { x: () => Ge(n, s) };
  }
};
var q$ = {
  kernelName: qi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, G(De(et(e, "float32")), 2)) };
  }
};
var tG = {
  kernelName: Nh,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, G(et(e, "float32"), 2)) };
  }
};
var eG = {
  kernelName: ta,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = gt(2);
    return { a: () => G(n, G(o, lt(e, s))), b: () => G(n, G(o, lt(s, e))) };
  }
};
var nG = {
  kernelName: ra,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var sG = {
  kernelName: ea,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      let a = n;
      const l = le(e.shape, o);
      return l.length > 0 && (a = at(a, l)), W(a, e.shape);
    }, b: () => {
      let a = n;
      const l = le(s.shape, o);
      return l.length > 0 && (a = at(a, l)), W(jt(a), s.shape);
    } };
  }
};
var oG = {
  kernelName: Gc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, o = s.shape.slice(), { axis: r } = e;
    Ct(r, s.shape).forEach((c) => {
      o[c] = 1;
    });
    const a = W(n, o), l = G(a, Us(s.shape, "float32"));
    return { x: () => l };
  }
};
var rG = {
  kernelName: na,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, At(Yh(e))) };
  }
};
var iG = {
  kernelName: sa,
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(lt(gt(1), At(e)), n) };
  }
};
var aG = {
  kernelName: oa,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { reps: o } = e;
    return { x: () => {
      let i6 = Tt(s);
      if (s.rank === 1)
        for (let a = 0; a < o[0]; ++a)
          i6 = U(i6, Dt(n, [a * s.shape[0]], [s.shape[0]]));
      else if (s.rank === 2)
        for (let a = 0; a < o[0]; ++a)
          for (let l = 0; l < o[1]; ++l)
            i6 = U(i6, Dt(n, [a * s.shape[0], l * s.shape[1]], [
              s.shape[0],
              s.shape[1]
            ]));
      else if (s.rank === 3)
        for (let a = 0; a < o[0]; ++a)
          for (let l = 0; l < o[1]; ++l)
            for (let c = 0; c < o[2]; ++c)
              i6 = U(i6, Dt(n, [a * s.shape[0], l * s.shape[1], c * s.shape[2]], [s.shape[0], s.shape[1], s.shape[2]]));
      else if (s.rank === 4)
        for (let a = 0; a < o[0]; ++a)
          for (let l = 0; l < o[1]; ++l)
            for (let c = 0; c < o[2]; ++c)
              for (let u = 0; u < o[3]; ++u)
                i6 = U(i6, Dt(n, [
                  a * s.shape[0],
                  l * s.shape[1],
                  c * s.shape[2],
                  u * s.shape[3]
                ], [s.shape[0], s.shape[1], s.shape[2], s.shape[3]]));
      else
        throw new Error(`Gradient for tile operation is not implemented for rank-${s.rank} tensors yet.`);
      return i6;
    } };
  }
};
var lG = {
  kernelName: Jo,
  gradFunc: (n, t, e) => {
    const s = e, { perm: o } = s, r = Hs(o);
    return { x: () => kt(n, r) };
  }
};
var cG = {
  kernelName: Wc,
  gradFunc: (n, t, e) => {
    const s = e, { axis: o } = s;
    return { value: () => os(n, o) };
  }
};
var uG = {
  kernelName: Dc,
  inputsToSave: ["segmentIds"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => dG(n, e) };
  }
};
function dG(n, t) {
  const e = _s(t, Tt(t)), s = jh(n, e);
  let o = Do(t, gt(0, "int32"));
  const r = s.rank - o.rank;
  for (let a = 0; a < r; ++a)
    o = Ue(o, a + 1);
  o = ss(o, Us(s.shape, "bool"));
  const i6 = Tt(s);
  return Oe(o, s, i6);
}
var hG = {
  kernelName: Fc,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var pG = [
  Q0,
  uR,
  dR,
  hR,
  pR,
  fR,
  mR,
  gR,
  bR,
  xR,
  yR,
  wR,
  vR,
  TR,
  NR,
  RR,
  $R,
  GR,
  ER,
  LR,
  MR,
  WR,
  FR,
  DR,
  XR,
  PR,
  AR,
  OR,
  KR,
  ZR,
  W$,
  BR,
  HR,
  _R,
  UR,
  YR,
  JR,
  QR,
  jR,
  qR,
  t$,
  e$,
  n$,
  s$,
  o$,
  r$,
  i$,
  a$,
  l$,
  d$,
  gm,
  gm,
  h$,
  m$,
  x$,
  y$,
  w$,
  I$,
  C$,
  v$,
  S$,
  k$,
  T$,
  N$,
  R$,
  bm,
  bm,
  $$,
  G$,
  M$,
  D$,
  F$,
  V$,
  z$,
  X$,
  P$,
  A$,
  O$,
  K$,
  Z$,
  B$,
  H$,
  _$,
  U$,
  Y$,
  Q$,
  J$,
  j$,
  xm,
  xm,
  ym,
  ym,
  q$,
  eG,
  tG,
  nG,
  sG,
  oG,
  rG,
  iG,
  aG,
  lG,
  cG,
  uG,
  hG
];
for (const n of pG)
  UI(n);
K().prototype.abs = function() {
  return this.throwIfDisposed(), fe(this);
};
K().prototype.acos = function() {
  return this.throwIfDisposed(), o2(this);
};
K().prototype.acosh = function() {
  return this.throwIfDisposed(), i2(this);
};
K().prototype.add = function(n) {
  return this.throwIfDisposed(), U(this, n);
};
K().prototype.all = function(n, t) {
  return this.throwIfDisposed(), Nb(this, n, t);
};
K().prototype.any = function(n, t) {
  return this.throwIfDisposed(), bd(this, n, t);
};
K().prototype.argMax = function(n) {
  return this.throwIfDisposed(), Qr(this, n);
};
K().prototype.argMin = function(n) {
  return this.throwIfDisposed(), d2(this, n);
};
K().prototype.asScalar = function() {
  return this.throwIfDisposed(), v2(this.size === 1, () => "The array must have only 1 element."), W(this, []);
};
K().prototype.asType = function(n) {
  return this.throwIfDisposed(), et(this, n);
};
K().prototype.as1D = function() {
  return this.throwIfDisposed(), W(this, [this.size]);
};
K().prototype.as2D = function(n, t) {
  return this.throwIfDisposed(), W(this, [n, t]);
};
K().prototype.as3D = function(n, t, e) {
  return this.throwIfDisposed(), W(this, [n, t, e]);
};
K().prototype.as4D = function(n, t, e, s) {
  return this.throwIfDisposed(), W(this, [n, t, e, s]);
};
K().prototype.as5D = function(n, t, e, s, o) {
  return this.throwIfDisposed(), W(this, [n, t, e, s, o]);
};
K().prototype.asin = function() {
  return this.throwIfDisposed(), p2(this);
};
K().prototype.asinh = function() {
  return this.throwIfDisposed(), m2(this);
};
K().prototype.atan = function() {
  return this.throwIfDisposed(), b2(this);
};
K().prototype.atan2 = function(n) {
  return this.throwIfDisposed(), y2(this, n);
};
K().prototype.atanh = function() {
  return this.throwIfDisposed(), I2(this);
};
K().prototype.avgPool = function(n, t, e, s) {
  return this.throwIfDisposed(), Bh(this, n, t, e, s);
};
K().prototype.batchToSpaceND = function(n, t) {
  return this.throwIfDisposed(), _h(this, n, t);
};
K().prototype.batchNorm = function(n, t, e, s, o) {
  return this.throwIfDisposed(), zc(this, n, t, e, s, o);
};
K().prototype.broadcastTo = function(n) {
  return this.throwIfDisposed(), Br(this, n);
};
K().prototype.cast = function(n) {
  return this.throwIfDisposed(), et(this, n);
};
K().prototype.ceil = function() {
  return this.throwIfDisposed(), U2(this);
};
K().prototype.clipByValue = function(n, t) {
  return this.throwIfDisposed(), pn(this, n, t);
};
K().prototype.concat = function(n, t) {
  return this.throwIfDisposed(), n instanceof Lt && (n = [n]), Ge([this, ...n], t);
};
K().prototype.conv1d = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), Rb(this, n, t, e, s, o, r);
};
K().prototype.conv2dTranspose = function(n, t, e, s, o) {
  return this.throwIfDisposed(), $b(this, n, t, e, s, o);
};
K().prototype.conv2d = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), Co(this, n, t, e, s, o, r);
};
K().prototype.cos = function() {
  return this.throwIfDisposed(), Yh(this);
};
K().prototype.cosh = function() {
  return this.throwIfDisposed(), Eb(this);
};
K().prototype.cumprod = function(n, t, e) {
  return this.throwIfDisposed(), yd(this, n, t, e);
};
K().prototype.cumsum = function(n, t, e) {
  return this.throwIfDisposed(), Lb(this, n, t, e);
};
K().prototype.depthToSpace = function(n, t) {
  return this.throwIfDisposed(), yv(this, n, t);
};
K().prototype.depthwiseConv2d = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), Qh(this, n, t, e, s, o, r);
};
K().prototype.dilation2d = function(n, t, e, s, o) {
  return this.throwIfDisposed(), Cv(this, n, t, e, s, o);
};
K().prototype.divNoNan = function(n) {
  return this.throwIfDisposed(), Nv(this, n);
};
K().prototype.div = function(n) {
  return this.throwIfDisposed(), ut(this, n);
};
K().prototype.dot = function(n) {
  return this.throwIfDisposed(), $v(this, n);
};
K().prototype.elu = function() {
  return this.throwIfDisposed(), Xc(this);
};
K().prototype.equal = function(n) {
  return this.throwIfDisposed(), kn(this, n);
};
K().prototype.erf = function() {
  return this.throwIfDisposed(), Lv(this);
};
K().prototype.euclideanNorm = function(n, t) {
  return this.throwIfDisposed(), Av(this, n, t);
};
K().prototype.exp = function() {
  return this.throwIfDisposed(), Tn(this);
};
K().prototype.expandDims = function(n) {
  return this.throwIfDisposed(), Ue(this, n);
};
K().prototype.expm1 = function() {
  return this.throwIfDisposed(), Bv(this);
};
K().prototype.fft = function() {
  return this.throwIfDisposed(), xp(this);
};
K().prototype.flatten = function() {
  return this.throwIfDisposed(), W(this, [this.size]);
};
K().prototype.floor = function() {
  return this.throwIfDisposed(), Ac(this);
};
K().prototype.floorDiv = function(n) {
  return this.throwIfDisposed(), Tb(this, n);
};
K().prototype.gather = function(n, t) {
  return this.throwIfDisposed(), jh(this, n, t);
};
K().prototype.greaterEqual = function(n) {
  return this.throwIfDisposed(), Do(this, n);
};
K().prototype.greater = function(n) {
  return this.throwIfDisposed(), sn(this, n);
};
K().prototype.ifft = function() {
  return this.throwIfDisposed(), pl(this);
};
K().prototype.irfft = function() {
  return this.throwIfDisposed(), Qb(this);
};
K().prototype.isFinite = function() {
  return this.throwIfDisposed(), tS(this);
};
K().prototype.isInf = function() {
  return this.throwIfDisposed(), nS(this);
};
K().prototype.isNaN = function() {
  return this.throwIfDisposed(), oS(this);
};
K().prototype.leakyRelu = function(n) {
  return this.throwIfDisposed(), tp(this, n);
};
K().prototype.lessEqual = function(n) {
  return this.throwIfDisposed(), yr(this, n);
};
K().prototype.less = function(n) {
  return this.throwIfDisposed(), Fb(this, n);
};
K().prototype.localResponseNormalization = function(n, t, e, s) {
  return this.throwIfDisposed(), cS(this, n, t, e, s);
};
K().prototype.logSigmoid = function() {
  return this.throwIfDisposed(), gS(this);
};
K().prototype.logSoftmax = function(n) {
  return this.throwIfDisposed(), Vb(this, n);
};
K().prototype.logSumExp = function(n, t) {
  return this.throwIfDisposed(), zb(this, n, t);
};
K().prototype.log = function() {
  return this.throwIfDisposed(), Nn(this);
};
K().prototype.log1p = function() {
  return this.throwIfDisposed(), ep(this);
};
K().prototype.logicalAnd = function(n) {
  return this.throwIfDisposed(), ss(this, n);
};
K().prototype.logicalNot = function() {
  return this.throwIfDisposed(), np(this);
};
K().prototype.logicalOr = function(n) {
  return this.throwIfDisposed(), Xb(this, n);
};
K().prototype.logicalXor = function(n) {
  return this.throwIfDisposed(), SS(this, n);
};
K().prototype.matMul = function(n, t, e) {
  return this.throwIfDisposed(), Gt(this, n, t, e);
};
K().prototype.maxPool = function(n, t, e, s) {
  return this.throwIfDisposed(), sp(this, n, t, e, s);
};
K().prototype.max = function(n, t) {
  return this.throwIfDisposed(), Xn(this, n, t);
};
K().prototype.maximum = function(n) {
  return this.throwIfDisposed(), _s(this, n);
};
K().prototype.mean = function(n, t) {
  return this.throwIfDisposed(), se(this, n, t);
};
K().prototype.min = function(n, t) {
  return this.throwIfDisposed(), ul(this, n, t);
};
K().prototype.minimum = function(n) {
  return this.throwIfDisposed(), Kc(this, n);
};
K().prototype.mirrorPad = function(n, t) {
  return this.throwIfDisposed(), LS(this, n, t);
};
K().prototype.mod = function(n) {
  return this.throwIfDisposed(), WS(this, n);
};
K().prototype.mul = function(n) {
  return this.throwIfDisposed(), G(this, n);
};
K().prototype.neg = function() {
  return this.throwIfDisposed(), jt(this);
};
K().prototype.norm = function(n, t, e) {
  return this.throwIfDisposed(), Pc(this, n, t, e);
};
K().prototype.notEqual = function(n) {
  return this.throwIfDisposed(), qr(this, n);
};
K().prototype.oneHot = function(n, t = 1, e = 0) {
  return this.throwIfDisposed(), Pb(this, n, t, e);
};
K().prototype.onesLike = function() {
  return this.throwIfDisposed(), Rn(this);
};
K().prototype.pad = function(n, t) {
  return this.throwIfDisposed(), rp(this, n, t);
};
K().prototype.pool = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), ZS(this, n, t, e, s, o, r);
};
K().prototype.pow = function(n) {
  return this.throwIfDisposed(), ir(this, n);
};
K().prototype.prelu = function(n) {
  return this.throwIfDisposed(), ap(this, n);
};
K().prototype.prod = function(n, t) {
  return this.throwIfDisposed(), _S(this, n, t);
};
K().prototype.reciprocal = function() {
  return this.throwIfDisposed(), gk(this);
};
K().prototype.relu = function() {
  return this.throwIfDisposed(), ws(this);
};
K().prototype.relu6 = function() {
  return this.throwIfDisposed(), Ob(this);
};
K().prototype.reshapeAs = function(n) {
  return this.throwIfDisposed(), W(this, n.shape);
};
K().prototype.reshape = function(n) {
  return this.throwIfDisposed(), W(this, n);
};
K().prototype.resizeBilinear = function(n, t, e) {
  return this.throwIfDisposed(), r0(this, n, t, e);
};
K().prototype.resizeNearestNeighbor = function(n, t, e) {
  return this.throwIfDisposed(), i0(this, n, t, e);
};
K().prototype.reverse = function(n) {
  return this.throwIfDisposed(), ko(this, n);
};
K().prototype.rfft = function() {
  return this.throwIfDisposed(), yp(this);
};
K().prototype.round = function() {
  return this.throwIfDisposed(), Kb(this);
};
K().prototype.rsqrt = function() {
  return this.throwIfDisposed(), Zb(this);
};
K().prototype.selu = function() {
  return this.throwIfDisposed(), Bb(this);
};
K().prototype.separableConv2d = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), Hb(this, n, t, e, s, o, r);
};
K().prototype.sigmoid = function() {
  return this.throwIfDisposed(), xr(this);
};
K().prototype.sign = function() {
  return this.throwIfDisposed(), kk(this);
};
K().prototype.sin = function() {
  return this.throwIfDisposed(), _b(this);
};
K().prototype.sinh = function() {
  return this.throwIfDisposed(), Ub(this);
};
K().prototype.slice = function(n, t) {
  return this.throwIfDisposed(), Dt(this, n, t);
};
K().prototype.softmax = function(n) {
  return this.throwIfDisposed(), bp(this, n);
};
K().prototype.softplus = function() {
  return this.throwIfDisposed(), da(this);
};
K().prototype.spaceToBatchND = function(n, t) {
  return this.throwIfDisposed(), ip(this, n, t);
};
K().prototype.split = function(n, t) {
  return this.throwIfDisposed(), un(this, n, t);
};
K().prototype.sqrt = function() {
  return this.throwIfDisposed(), De(this);
};
K().prototype.square = function() {
  return this.throwIfDisposed(), At(this);
};
K().prototype.squaredDifference = function(n) {
  return this.throwIfDisposed(), Jb(this, n);
};
K().prototype.squeeze = function(n) {
  return this.throwIfDisposed(), ha(this, n);
};
K().prototype.stack = function(n, t) {
  this.throwIfDisposed();
  const e = n instanceof Lt ? [this, n] : [this, ...n];
  return os(e, t);
};
K().prototype.step = function(n) {
  return this.throwIfDisposed(), pa(this, n);
};
K().prototype.stridedSlice = function(n, t, e, s, o, r, i6, a) {
  return this.throwIfDisposed(), Kk(this, n, t, e, s, o, r, i6, a);
};
K().prototype.sub = function(n) {
  return this.throwIfDisposed(), lt(this, n);
};
K().prototype.sum = function(n, t) {
  return this.throwIfDisposed(), at(this, n, t);
};
K().prototype.tan = function() {
  return this.throwIfDisposed(), Bk(this);
};
K().prototype.tanh = function() {
  return this.throwIfDisposed(), Hh(this);
};
K().prototype.tile = function(n) {
  return this.throwIfDisposed(), Vn(this, n);
};
K().prototype.toBool = function() {
  return this.throwIfDisposed(), et(this, "bool");
};
K().prototype.toFloat = function() {
  return this.throwIfDisposed(), et(this, "float32");
};
K().prototype.toInt = function() {
  return this.throwIfDisposed(), et(this, "int32");
};
K().prototype.topk = function(n, t) {
  return this.throwIfDisposed(), Uk(this, n, t);
};
K().prototype.transpose = function(n) {
  return this.throwIfDisposed(), kt(this, n);
};
K().prototype.unique = function(n) {
  return this.throwIfDisposed(), Jk(this, n);
};
K().prototype.unsortedSegmentSum = function(n, t) {
  return this.throwIfDisposed(), qb(this, n, t);
};
K().prototype.unstack = function(n) {
  return this.throwIfDisposed(), To(this, n);
};
K().prototype.where = function(n, t) {
  return this.throwIfDisposed(), Oe(n, this, t);
};
K().prototype.zerosLike = function() {
  return this.throwIfDisposed(), Tt(this);
};
var Yn = class extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, Yn.prototype);
  }
};
var Cn = class extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, Cn.prototype);
  }
};
var E = class extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, E.prototype);
  }
};
var xt = class extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, xt.prototype);
  }
};
var nf = class extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, nf.prototype);
  }
};
var j0 = class {
  constructor(t) {
    this.maxEntries = t || 100, this.cache = /* @__PURE__ */ new Map();
  }
  /**
   * Get the entry for the key and mark it as used recently.
   */
  get(t) {
    let e;
    return this.cache.has(t) && (e = this.cache.get(t), this.cache.delete(t), this.cache.set(t, e)), e;
  }
  /**
   * Put the entry into the cache. If the key already existed, mark the key as
   * used recently.
   */
  put(t, e) {
    if (this.cache.has(t))
      this.cache.delete(t);
    else if (this.cache.size >= this.maxEntries) {
      const s = this.cache.keys().next().value;
      this.cache.delete(s);
    }
    this.cache.set(t, e);
  }
  /**
   * Get the MaxEntries of the cache.
   */
  getMaxEntries() {
    return this.maxEntries;
  }
  /**
   * Set the MaxEntries of the cache. If the maxEntries is decreased, reduce
   * entries in the cache.
   */
  setMaxEntries(t) {
    if (t < 0)
      throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${t}.`);
    if (this.maxEntries > t)
      for (let e = 0; e < this.maxEntries - t; e++) {
        const s = this.cache.keys().next().value;
        this.cache.delete(s);
      }
    this.maxEntries = t;
  }
};
function Ro(n, t) {
  if (Array.isArray(n)) {
    let e = [];
    for (let s = 0; s < t; s++)
      e = e.concat(n);
    return e;
  } else {
    const e = new Array(t);
    return e.fill(n), e;
  }
}
function Qn(n, t) {
  if (!n)
    throw new nf(t);
}
function wm(n, t) {
  let e = 0;
  for (const s of n)
    s === t && e++;
  return e;
}
function Pe(n) {
  return n.length === 1 ? n[0] : n;
}
function Zt(n) {
  return Array.isArray(n) ? n : [n];
}
function cs(n) {
  const e = n.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2").replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
  return e[0] !== "_" ? e : "private" + e;
}
function ro(n) {
  return n.length <= 1 || n.indexOf("_") === -1 ? n : n.replace(/[_]+(\w|$)/g, (t, e) => e.toUpperCase());
}
var mn = {};
function sf(n) {
  if (n == null)
    return null;
  const t = {};
  return t.className = n.getClassName(), t.config = n.getConfig(), t;
}
function Cd(n) {
  if (!(n == null || typeof n != "object"))
    if (Array.isArray(n))
      n.forEach((t) => Cd(t));
    else {
      const t = Object.keys(n);
      for (const e of t) {
        const s = n[e];
        s != null && typeof s == "object" && (!Array.isArray(s) && s.type === "ndarray" && typeof s.value == "number" ? n[e] = s.value : Cd(s));
      }
    }
}
function ba(n, t = {}, e = {}, s = "object", o = false) {
  if (typeof n == "string") {
    const r = n;
    let i6;
    if (r in e)
      i6 = e[r];
    else if (r in mn)
      i6 = mn[r];
    else if (i6 = t[r], i6 == null)
      throw new E(`Unknown ${s}: ${n}. This may be due to one of the following reasons:
1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
    return i6;
  } else {
    const r = n;
    if (r.className == null || r.config == null)
      throw new E(`${s}: Improper config format: ${JSON.stringify(r)}.
'className' and 'config' must set.`);
    const i6 = r.className;
    let a, l;
    if (i6 in e ? [a, l] = e[i6] : i6 in mn ? [a, l] = mn.className : i6 in t && ([a, l] = t[i6]), a == null)
      throw new E(`Unknown ${s}: ${i6}. This may be due to one of the following reasons:
1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
    if (l != null) {
      const c = {};
      for (const p6 of Object.keys(mn))
        c[p6] = mn[p6];
      for (const p6 of Object.keys(e))
        c[p6] = e[p6];
      const u = r.config;
      u.customObjects = c;
      const d = Object.assign({}, mn);
      for (const p6 of Object.keys(e))
        mn[p6] = e[p6];
      Cd(r.config);
      const h6 = l(a, r.config, e, o);
      return mn = Object.assign({}, d), h6;
    } else {
      const c = Object.assign({}, mn);
      for (const d of Object.keys(e))
        mn[d] = e[d];
      const u = new a(r.config);
      return mn = Object.assign({}, c), u;
    }
  }
}
function fG(n, t) {
  return n < t ? -1 : n > t ? 1 : 0;
}
function Da(n, t) {
  return -1 * fG(n, t);
}
function Ws(n) {
  if (n == null)
    return n;
  const t = [];
  for (const e of n)
    t.indexOf(e) === -1 && t.push(e);
  return t;
}
function mG(n) {
  if (n == null)
    throw new E(`Invalid value in obj: ${JSON.stringify(n)}`);
  for (const t in n)
    if (n.hasOwnProperty(t))
      return false;
  return true;
}
function zo(n, t, e) {
  if (e != null && n.indexOf(e) < 0)
    throw new E(`${e} is not a valid ${t}.  Valid values are ${n} or null/undefined.`);
}
function of(n, t, e = 0, s = 1 / 0) {
  return Qn(e >= 0), Qn(s >= e), Array.isArray(n) && n.length >= e && n.length <= s && n.every((o) => typeof o === t);
}
function be(n, t) {
  Array.isArray(n) ? (v2(n.length > 0, () => `${t} is unexpectedly an empty array.`), n.forEach((e, s) => be(e, `element ${s + 1} of ${t}`))) : v2(Number.isInteger(n) && n > 0, () => `Expected ${t} to be a positive integer, but got ${q0(n)}.`);
}
function q0(n) {
  return n === null ? "null" : Array.isArray(n) ? "[" + n.map((t) => q0(t)).join(",") + "]" : typeof n == "string" ? `"${n}"` : `${n}`;
}
function gG(n, t, e) {
  let s = e != null ? e() : Ce(), o;
  return (...i6) => {
    const a = e != null ? e() : Ce();
    return a - s < t || (s = a, o = n(...i6)), o;
  };
}
function tx(n) {
  return n === "relu" ? "relu" : n === "linear" ? "linear" : n === "elu" ? "elu" : null;
}
var bG = 0;
function ex() {
  return bG++;
}
var Fa = {};
function Jc(n = "") {
  return n in Fa || (Fa[n] = 0), Fa[n] += 1, n + Fa[n].toString();
}
var xG = ["channelsFirst", "channelsLast"];
var yG = ["nearest", "bilinear"];
var wG = ["valid", "same", "causal"];
var IG = ["max", "avg"];
var CG = ["sum", "mul", "concat", "ave"];
var Zo = /* @__PURE__ */ new Map();
function ae(n) {
  zo(xG, "DataFormat", n);
}
function vG(n) {
  zo(yG, "InterpolationFormat", n);
}
function fn(n) {
  zo(wG, "PaddingMode", n);
}
function nx(n) {
  zo(IG, "PoolMode", n);
}
var Hr = [];
var Im = "/";
function fo(n, t) {
  Hr.push(n);
  try {
    const e = t();
    return Hr.pop(), e;
  } catch (e) {
    throw Hr.pop(), e;
  }
}
function SG() {
  return Hr.length === 0 ? "" : Hr.join(Im) + Im;
}
function sx(n) {
  if (!rx(n))
    throw new Error("Not a valid tensor name: '" + n + "'");
  return SG() + n;
}
function ox(n) {
  if (!rx(n))
    throw new Error("Not a valid tensor name: '" + n + "'");
  Zo.has(n) || Zo.set(n, 0);
  const t = Zo.get(n);
  if (Zo.set(n, Zo.get(n) + 1), t > 0) {
    const e = `${n}_${t}`;
    return Zo.set(e, 1), e;
  } else
    return n;
}
var kG = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);
function rx(n) {
  return !!n.match(kG);
}
function TG(n) {
  return n === parseInt(n.toString(), 10);
}
function Ds(n, t, e) {
  t == null && (t = 0), e == null && (e = n.length);
  let s = 1;
  for (let o = t; o < e; ++o)
    s *= n[o];
  return s;
}
function ar(n) {
  if (n.length === 0)
    return Number.NaN;
  let t = Number.POSITIVE_INFINITY;
  for (let e = 0; e < n.length; e++) {
    const s = n[e];
    s < t && (t = s);
  }
  return t;
}
function Xs(n) {
  if (n.length === 0)
    return Number.NaN;
  let t = Number.NEGATIVE_INFINITY;
  for (let e = 0; e < n.length; e++) {
    const s = n[e];
    s > t && (t = s);
  }
  return t;
}
function On(n, t) {
  if (t < n)
    throw new E(`end (${t}) < begin (${n}) is forbidden.`);
  const e = [];
  for (let s = n; s < t; ++s)
    e.push(s);
  return e;
}
var Su;
function ue() {
  return Su == null && (Su = $s().epsilon()), Su;
}
function Kn() {
  return "channelsLast";
}
function es(n, t) {
  return et(n, t);
}
function xa(n, t = -1) {
  const e = n.shape.slice();
  return t < 0 && (t = e.length + t + 1), e.splice(t, 0, 1), W(n, e);
}
function NG(n, t) {
  return D(() => {
    if (n.shape.length !== 2)
      throw new E(`repeat() expects a rank-2 tensor, but received a rank-${n.shape.length} tensor.`);
    const e = xa(n, 1);
    return vd(e, [1, t, 1]);
  });
}
function RG(n) {
  const t = [Ds(n.shape)];
  return W(n, t);
}
function $G(n) {
  if (n.rank <= 1)
    throw new E(`batchFlatten requires a minimum rank of 2. Got rank: ${n.rank}.`);
  const t = [n.shape[0], Ds(n.shape, 1)];
  return W(n, t);
}
function mo(n, t, e) {
  return D(() => {
    switch (n.rank) {
      case 1:
        return mp(n, t, e);
      case 2:
        return Yb(n, [t, 0], [e, n.shape[1]]);
      case 3:
        return gp(n, [t, 0, 0], [e, n.shape[1], n.shape[2]]);
      case 4:
        return hl(n, [t, 0, 0, 0], [e, n.shape[1], n.shape[2], n.shape[3]]);
      case 5:
        return Dt(n, [t, 0, 0, 0, 0], [
          e,
          n.shape[1],
          n.shape[2],
          n.shape[3],
          n.shape[4]
        ]);
      case 6:
        return Dt(n, [t, 0, 0, 0, 0, 0], [
          e,
          n.shape[1],
          n.shape[2],
          n.shape[3],
          n.shape[4],
          n.shape[5]
        ]);
      default:
        throw new E(`sliceAlongFirstAxis() received an unsupported tensor rank: ${n.rank}`);
    }
  });
}
function ku(n, t, e) {
  return D(() => {
    switch (n.rank) {
      case 1:
        return mp(n, t, e);
      case 2:
        return Yb(n, [0, t], [n.shape[0], e]);
      case 3:
        return gp(n, [0, 0, t], [n.shape[0], n.shape[1], e]);
      case 4:
        return hl(n, [0, 0, 0, t], [n.shape[0], n.shape[1], n.shape[2], e]);
      default:
        throw new E(`sliceAlongLastAxis() received an unsupported tensor rank: ${n.rank}`);
    }
  });
}
function Va(n, t, e, s) {
  return D(() => {
    switch (n.rank) {
      case 1:
        return mp(n, t, e);
      case 2:
        switch (s) {
          case 1:
            return mo(n, t, e);
          case 2:
            return ku(n, t, e);
          default:
            throw new E(`The axis is not within the rank of the tensor ${s}`);
        }
      case 3:
        switch (s) {
          case 1:
            return mo(n, t, e);
          case 2:
            return gp(n, [0, t, 0], [n.shape[0], e, n.shape[2]]);
          case 3:
            return ku(n, t, e);
          default:
            throw new E(`The axis is not within the rank of the tensor ${s}`);
        }
      case 4:
        switch (s) {
          case 1:
            return mo(n, t, e);
          case 2:
            return hl(n, [0, t, 0, 0], [n.shape[0], e, n.shape[2], n.shape[3]]);
          case 3:
            return hl(n, [0, 0, t, 0], [n.shape[0], n.shape[1], e, n.shape[3]]);
          case 4:
            return ku(n, t, e);
          default:
            throw new E(`The axis is not within the rank of the tensor ${s}`);
        }
      default:
        throw new E(`sliceAlongLastAxis() received an unsupported tensor rank: ${n.rank}`);
    }
  });
}
function rf(n, t = -1) {
  let e;
  return t < 0 && (e = n[0].rank, e !== 0 ? t = e : t = 0), t === n[0].rank && (t = -1), Ge(n, t);
}
function Cm(n, t) {
  switch (n.rank) {
    case 1:
      return J2([n, t]);
    case 2:
      return q2([n, t], 0);
    case 3:
      return ev([n, t], 0);
    case 4:
      return sv([n, t], 0);
    default:
      throw new E(`concatAlongFirstAxis() received an unsupported tensor rank: ${n.rank}`);
  }
}
function vd(n, t) {
  if (Array.isArray(t) || (t = [t]), n.rank !== t.length)
    throw new E(`The length of input n (${t.length}) does not match the number of dimensions in input x (${n.rank})`);
  return Vn(n, t);
}
function jc(n, t = 0, e = 1, s, o) {
  return hk(n, t, e, s, o);
}
function ns(n, t, e, s) {
  if (n.rank < 2 || t.rank < 2)
    throw new xt(`dot requires both inputs to be rank >= 2 but got x shape = ${n.shape} and y shape = ${t.shape}`);
  if (t.rank >= 3) {
    const o = n.shape.slice(-1)[0], r = t.shape.slice(-2)[0];
    if (o !== r)
      throw new xt(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${n.shape} and  y shape = ${t.shape}`);
  }
  if (n.rank === 2 && t.rank === 2)
    return im({
      a: n,
      b: t,
      transposeA: false,
      transposeB: false,
      bias: s ? Sd(n.rank, s, Kn()) : null,
      activation: e
    });
  {
    const o = n.shape.slice(), r = o.pop();
    n = W(n, [-1, r]);
    const i6 = t.shape.slice(), a = i6.pop(), l = i6.pop(), c = [...i6, a], u = Array.from({ length: t.rank }, (f, m) => m === 0 ? t.rank - 2 : m <= t.rank - 2 ? m - 1 : m);
    t = W(kt(t, u), [l, -1]);
    const d = [...o, ...c];
    return W(im({
      a: n,
      b: t,
      transposeA: false,
      transposeB: false,
      bias: s ? Sd(n.rank, s, Kn()) : null,
      activation: e
    }), d);
  }
}
function ix(n, t, e) {
  return D(() => (Array.isArray(t) ? t = Je(t, "int32") : t = et(t, "int32"), jh(n, t, e)));
}
function ya(n) {
  return G(n, n);
}
function Sd(n, t, e) {
  const s = t.shape;
  if (t.rank !== 1 && t.rank !== n)
    throw new E(`Unexpected bias dimensions: ${t.rank}; expected it to be 1 or ${n}`);
  if (n === 5) {
    if (e === "channelsFirst")
      return s.length === 1 ? W(t, [1, s[0], 1, 1, 1]) : W(t, [1, s[3], s[0], s[1], s[2]]);
    if (e === "channelsLast")
      return s.length === 1 ? W(t, [1, 1, 1, 1, s[0]]) : W(t, [1].concat(s));
  } else if (n === 4) {
    if (e === "channelsFirst")
      return s.length === 1 ? W(t, [1, s[0], 1, 1]) : W(t, [1, s[2], s[0], s[1]]);
    if (e === "channelsLast")
      return s.length === 1 ? W(t, [1, 1, 1, s[0]]) : W(t, [1].concat(s));
  } else if (n === 3) {
    if (e === "channelsFirst")
      return s.length === 1 ? W(t, [1, s[0], 1]) : W(t, [1, s[1], s[0]]);
    if (e === "channelsLast")
      return s.length === 1 ? W(t, [1, 1, s[0]]) : W(t, [1].concat(s));
  } else if (n < 3)
    return t;
  throw new E(`Unsupported input rank by biasAdd: ${t.rank}`);
}
function Hn(n, t, e) {
  return D(() => (e == null && (e = Kn()), ae(e), U(n, Sd(n.rank, t, e))));
}
function GG(n, t = 1) {
  if (t !== 1)
    throw new xt(`Support for alpha values other than 1 (${t}) is not implemented yet.`);
  return Xc(n);
}
function EG(n) {
  return D(() => ut(n, U(fe(n), 1)));
}
function ax(n, t, e, s) {
  return D(() => oT(n, t, e, s));
}
function LG(n) {
  return D(() => {
    const t = U(0.5, G(0.2, n));
    return pn(t, 0, 1);
  });
}
function wa(n, t, e = false) {
  return e ? n() : t();
}
var MG = ["fanIn", "fanOut", "fanAvg"];
var WG = ["normal", "uniform", "truncatedNormal"];
function DG(n) {
  zo(MG, "FanMode", n);
}
function FG(n) {
  zo(WG, "Distribution", n);
}
var Gn = class extends Vo {
  fromConfigUsesCustomObjects() {
    return false;
  }
  getConfig() {
    return {};
  }
};
var lx = class extends Gn {
  apply(t, e) {
    return ge(t, e);
  }
};
lx.className = "Zeros";
_(lx);
var af = class extends Gn {
  apply(t, e) {
    return Us(t, e);
  }
};
af.className = "Ones";
_(af);
var cx = class extends Gn {
  constructor(t) {
    if (super(), typeof t != "object")
      throw new E(`Expected argument of type ConstantConfig but got ${t}`);
    if (t.value === void 0)
      throw new E(`config must have value set but got ${t}`);
    this.value = t.value;
  }
  apply(t, e) {
    return D(() => G(gt(this.value), Us(t, e)));
  }
  getConfig() {
    return {
      value: this.value
    };
  }
};
cx.className = "Constant";
_(cx);
var ux = class extends Gn {
  constructor(t) {
    super(), this.DEFAULT_MINVAL = -0.05, this.DEFAULT_MAXVAL = 0.05, this.minval = t.minval || this.DEFAULT_MINVAL, this.maxval = t.maxval || this.DEFAULT_MAXVAL, this.seed = t.seed;
  }
  apply(t, e) {
    return Zc(t, this.minval, this.maxval, e, this.seed);
  }
  getConfig() {
    return { minval: this.minval, maxval: this.maxval, seed: this.seed };
  }
};
ux.className = "RandomUniform";
_(ux);
var dx = class extends Gn {
  constructor(t) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = 0.05, this.mean = t.mean || this.DEFAULT_MEAN, this.stddev = t.stddev || this.DEFAULT_STDDEV, this.seed = t.seed;
  }
  apply(t, e) {
    if (e = e || "float32", e !== "float32" && e !== "int32")
      throw new xt(`randomNormal does not support dType ${e}.`);
    return jc(t, this.mean, this.stddev, e, this.seed);
  }
  getConfig() {
    return { mean: this.mean, stddev: this.stddev, seed: this.seed };
  }
};
dx.className = "RandomNormal";
_(dx);
var hx = class extends Gn {
  constructor(t) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = 0.05, this.mean = t.mean || this.DEFAULT_MEAN, this.stddev = t.stddev || this.DEFAULT_STDDEV, this.seed = t.seed;
  }
  apply(t, e) {
    if (e = e || "float32", e !== "float32" && e !== "int32")
      throw new xt(`truncatedNormal does not support dType ${e}.`);
    return jb(t, this.mean, this.stddev, e, this.seed);
  }
  getConfig() {
    return { mean: this.mean, stddev: this.stddev, seed: this.seed };
  }
};
hx.className = "TruncatedNormal";
_(hx);
var px = class extends Gn {
  constructor(t) {
    super(), this.gain = t.gain != null ? t.gain : 1;
  }
  apply(t, e) {
    return D(() => {
      if (t.length !== 2 || t[0] !== t[1])
        throw new E("Identity matrix initializer can only be used for 2D square matrices.");
      return G(this.gain, Db(t[0]));
    });
  }
  getConfig() {
    return { gain: this.gain };
  }
};
px.className = "Identity";
_(px);
function VG(n, t = "channelsLast") {
  let e, s;
  if (ae(t), n.length === 2)
    e = n[0], s = n[1];
  else if ([3, 4, 5].indexOf(n.length) !== -1) {
    if (t === "channelsFirst") {
      const o = Ds(n, 2);
      e = n[1] * o, s = n[0] * o;
    } else if (t === "channelsLast") {
      const o = Ds(n, 0, n.length - 2);
      e = n[n.length - 2] * o, s = n[n.length - 1] * o;
    }
  } else {
    const o = Ds(n);
    e = Math.sqrt(o), s = Math.sqrt(o);
  }
  return [e, s];
}
var qe = class extends Gn {
  /**
   * Constructor of VarianceScaling.
   * @throws ValueError for invalid value in scale.
   */
  constructor(t) {
    if (super(), t.scale < 0)
      throw new E(`scale must be a positive float. Got: ${t.scale}`);
    this.scale = t.scale == null ? 1 : t.scale, this.mode = t.mode == null ? "fanIn" : t.mode, DG(this.mode), this.distribution = t.distribution == null ? "normal" : t.distribution, FG(this.distribution), this.seed = t.seed;
  }
  apply(t, e) {
    const s = VG(t), o = s[0], r = s[1];
    let i6 = this.scale;
    if (this.mode === "fanIn" ? i6 /= Math.max(1, o) : this.mode === "fanOut" ? i6 /= Math.max(1, r) : i6 /= Math.max(1, (o + r) / 2), this.distribution === "normal") {
      const a = Math.sqrt(i6);
      if (e = e || "float32", e !== "float32" && e !== "int32")
        throw new xt(`${this.getClassName()} does not support dType ${e}.`);
      return jb(t, 0, a, e, this.seed);
    } else {
      const a = Math.sqrt(3 * i6);
      return Zc(t, -a, a, e, this.seed);
    }
  }
  getConfig() {
    return {
      scale: this.scale,
      mode: this.mode,
      distribution: this.distribution,
      seed: this.seed
    };
  }
};
qe.className = "VarianceScaling";
_(qe);
var lf = class extends qe {
  /**
   * Constructor of GlorotUniform
   * @param scale
   * @param mode
   * @param distribution
   * @param seed
   */
  constructor(t) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "uniform",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return qe.className;
  }
};
lf.className = "GlorotUniform";
_(lf);
var cf = class extends qe {
  /**
   * Constructor of GlorotNormal.
   * @param scale
   * @param mode
   * @param distribution
   * @param seed
   */
  constructor(t) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "normal",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return qe.className;
  }
};
cf.className = "GlorotNormal";
_(cf);
var uf = class extends qe {
  constructor(t) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "normal",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return qe.className;
  }
};
uf.className = "HeNormal";
_(uf);
var df = class extends qe {
  constructor(t) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "uniform",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return qe.className;
  }
};
df.className = "HeUniform";
_(df);
var hf = class extends qe {
  constructor(t) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "normal",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return qe.className;
  }
};
hf.className = "LeCunNormal";
_(hf);
var pf = class extends qe {
  constructor(t) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "uniform",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return qe.className;
  }
};
pf.className = "LeCunUniform";
_(pf);
var fx = class extends Gn {
  constructor(t) {
    if (super(), this.DEFAULT_GAIN = 1, this.gain = t.gain == null ? this.DEFAULT_GAIN : t.gain, this.seed = t.seed, this.seed != null)
      throw new xt("Random seed is not implemented for Orthogonal Initializer yet.");
  }
  apply(t, e) {
    return D(() => {
      if (t.length < 2)
        throw new xt("Shape must be at least 2D.");
      t[0] * t[1] > 2e3 && console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${t[0] * t[1]}) elements: Slowness may result.`);
      const s = t[0] > t[1] ? [t[1], t[0]] : t, o = jc(s, 0, 1, "float32");
      let r = zN.gramSchmidt(o);
      return t[0] > t[1] && (r = kt(r)), G(this.gain, r);
    });
  }
  getConfig() {
    return {
      gain: this.gain,
      seed: this.seed
    };
  }
};
fx.className = "Orthogonal";
_(fx);
var vm = {
  constant: "Constant",
  glorotNormal: "GlorotNormal",
  glorotUniform: "GlorotUniform",
  heNormal: "HeNormal",
  heUniform: "HeUniform",
  identity: "Identity",
  leCunNormal: "LeCunNormal",
  leCunUniform: "LeCunUniform",
  ones: "Ones",
  orthogonal: "Orthogonal",
  randomNormal: "RandomNormal",
  randomUniform: "RandomUniform",
  truncatedNormal: "TruncatedNormal",
  varianceScaling: "VarianceScaling",
  zeros: "Zeros"
};
function Sm(n, t = {}) {
  return ba(n, an.getMap().classNameMap, t, "initializer");
}
function Jt(n) {
  return sf(n);
}
function Ut(n) {
  if (typeof n == "string") {
    const t = n in vm ? vm[n] : n;
    if (t === "GlorotNormal")
      return new cf();
    if (t === "GlorotUniform")
      return new lf();
    if (t === "HeNormal")
      return new uf();
    if (t === "HeUniform")
      return new df();
    if (t === "LeCunNormal")
      return new hf();
    if (t === "LeCunUniform")
      return new pf();
    {
      const e = {};
      return e.className = t, e.config = {}, Sm(e);
    }
  } else
    return n instanceof Gn ? n : Sm(n);
}
function kd(n) {
  return Array.isArray(n) && Array.isArray(n[0]);
}
function fl(n) {
  return n.length === 0 ? [] : Array.isArray(n[0]) ? n : [n];
}
function mt(n) {
  let t;
  if (Array.isArray(n)) {
    if (n.length !== 1)
      throw new E(`Expected Tensor length to be 1; got ${n.length}`);
    t = n[0];
  } else
    t = n;
  return t;
}
function $t(n) {
  if (Array.isArray(n) && Array.isArray(n[0])) {
    if (n.length === 1)
      return n = n, n[0];
    throw new E(`Expected exactly 1 Shape; got ${n.length}`);
  } else
    return n;
}
function ml(n) {
  let t = 0;
  for (const e of n)
    e.shape.length === 0 ? t += 1 : t += e.shape.reduce((s, o) => s * o);
  return t;
}
var km = "Variable";
var zG = class {
  /**
   * Construct Variable from a `tf.Tensor`.
   *
   * If not explicitly named, the Variable will be given a name with the
   * prefix 'Variable'. Variable names are unique. In the case of name
   * collision, suffixies '_<num>' will be added to the name.
   *
   * @param val Initial value of the Variable.
   * @param name Name of the variable. If `null` or `undefined` is provided, it
   *   will default a name with the prefix 'Variable'.
   * @param constraint Optional, projection function to be applied to the
   * variable after optimize updates
   * @throws ValueError if `name` is `null` or `undefined`.
   */
  constructor(t, e = "float32", s = km, o = true, r = null) {
    this.dtype = e ?? "float32", this.shape = t.shape, this.id = ex(), s = s ?? km, this.originalName = sx(s), this.name = ox(this.originalName), this.trainable_ = o, this.constraint = r, this.val = tT(t, this.trainable_, this.name, this.dtype);
  }
  /**
   * Get a snapshot of the Variable's value.
   *
   * The returned value is a snapshot of the Variable's value at the time of
   * the invocation. Future mutations in the value of the tensor will only
   * be reflected by future calls to this method.
   */
  read() {
    return this.assertNotDisposed(), this.val;
  }
  /**
   * Update the value of the Variable.
   *
   * @param newVal: The new value to update to. Must be consistent with the
   *   dtype and shape of the Variable.
   * @return This Variable.
   */
  write(t) {
    return this.assertNotDisposed(), XG(this.val, t), this.val.id !== t.id && (this.val.assign(t), this.constraint != null && this.val.assign(this.constraint.apply(this.val))), this;
  }
  /**
   * Dispose this LayersVariable instance from memory.
   */
  dispose() {
    this.assertNotDisposed(), this.val.dispose();
  }
  assertNotDisposed() {
    if (this.val.isDisposed)
      throw new Error(`LayersVariable ${this.name} is already disposed.`);
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t) {
    this.trainable_ = t, this.val.trainable = t;
  }
};
function XG(n, t) {
  if (n.shape.toString() !== t.shape.toString())
    throw new Error("Shape mismatch: " + JSON.stringify(n.shape) + " vs. " + JSON.stringify(t.shape));
}
function Td(n) {
  return n.map((t) => t.read());
}
function ff(n) {
  n.forEach((t) => {
    t[0].write(t[1]);
  });
}
var de = class {
  constructor(t) {
    this.dtype = t.dtype, this.shape = t.shape, t.shape != null ? this.ndim = t.shape.length : this.ndim = t.ndim, this.maxNDim = t.maxNDim, this.minNDim = t.minNDim, this.axes = t.axes || {};
  }
};
var jn = class {
  /**
   *
   * @param dtype
   * @param shape
   * @param sourceLayer The Layer that produced this symbolic tensor.
   * @param inputs The inputs passed to sourceLayer's __call__() method.
   * @param nodeIndex
   * @param tensorIndex
   * @param callArgs The keyword arguments passed to the __call__() method.
   * @param name
   * @param outputTensorIndex The index of this tensor in the list of outputs
   *   returned by apply().
   */
  constructor(t, e, s, o, r, i6, a) {
    this.dtype = t, this.shape = e, this.sourceLayer = s, this.inputs = o, this.callArgs = r, this.outputTensorIndex = a, this.id = ex(), i6 != null && (this.originalName = sx(i6), this.name = ox(this.originalName)), this.rank = e.length;
  }
};
var PG = 0;
var qc = class {
  constructor(t, e) {
    this.callArgs = e, this.id = PG++, this.outboundLayer = t.outboundLayer, this.inboundLayers = t.inboundLayers, this.nodeIndices = t.nodeIndices, this.tensorIndices = t.tensorIndices, this.inputTensors = t.inputTensors, this.outputTensors = t.outputTensors, this.inputMasks = t.inputMasks, this.outputMasks = t.outputMasks, this.inputShapes = t.inputShapes, this.outputShapes = t.outputShapes;
    for (const s of t.inboundLayers)
      s != null && s.outboundNodes.push(this);
    t.outboundLayer.inboundNodes.push(this);
  }
  getConfig() {
    const t = [];
    for (const e of this.inboundLayers)
      e != null ? t.push(e.name) : t.push(null);
    return {
      outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,
      inboundLayers: t,
      nodeIndices: this.nodeIndices,
      tensorIndices: this.tensorIndices
    };
  }
};
var AG = 0;
var St = class extends Vo {
  constructor(t = {}) {
    super(), this._callHook = null, this._addedWeightNames = [], this._stateful = false, this.id = AG++, this.activityRegularizer = null, this.inputSpec = null, this.supportsMasking = false, this._trainableWeights = [], this._nonTrainableWeights = [], this._losses = [], this._updates = [], this._built = false, this.inboundNodes = [], this.outboundNodes = [];
    let e = t.name;
    if (!e) {
      const s = this.getClassName();
      e = cs(s) + "_" + Jc(s);
    }
    if (this.name = e, this.trainable_ = t.trainable == null ? true : t.trainable, t.inputShape != null || t.batchInputShape != null) {
      let s;
      if (t.batchInputShape != null)
        s = t.batchInputShape;
      else if (t.inputShape != null) {
        let r = null;
        t.batchSize != null && (r = t.batchSize), s = [r].concat(t.inputShape);
      }
      this.batchInputShape = s;
      let o = t.dtype;
      o == null && (o = t.inputDType), o == null && (o = "float32"), this.dtype = o;
    }
    t.weights != null ? this.initialWeights = t.weights : this.initialWeights = null, this._refCount = null, this.fastWeightInitDuringBuild = false;
  }
  /**
   * Converts a layer and its index to a unique (immutable type) name.
   * This function is used internally with `this.containerNodes`.
   * @param layer The layer.
   * @param nodeIndex The layer's position (e.g. via enumerate) in a list of
   *   nodes.
   *
   * @returns The unique name.
   */
  static nodeKey(t, e) {
    return t.name + "_ib-" + e.toString();
  }
  /**
   * Returns this.inboundNode at index nodeIndex.
   *
   * Porting note: This is a replacement for _get_node_attribute_at_index()
   * @param nodeIndex
   * @param attrName The name of the attribute related to request for this node.
   */
  getNodeAtIndex(t, e) {
    if (this.inboundNodes.length === 0)
      throw new Cn(`The layer has never been called and thus has no defined ${e}.`);
    if (this.inboundNodes.length <= t)
      throw new E(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);
    return this.inboundNodes[t];
  }
  /**
   * Retrieves the input tensor(s) of a layer at a given node.
   *
   * @param nodeIndex Integer, index of the node from which to retrieve the
   *   attribute. E.g. `nodeIndex=0` will correspond to the first time the layer
   *   was called.
   *
   * @return A tensor (or list of tensors if the layer has multiple inputs).
   */
  getInputAt(t) {
    return Pe(this.getNodeAtIndex(t, "input").inputTensors);
  }
  /**
   * Retrieves the output tensor(s) of a layer at a given node.
   *
   * @param nodeIndex Integer, index of the node from which to retrieve the
   *   attribute. E.g. `nodeIndex=0` will correspond to the first time the layer
   *   was called.
   *
   * @return A tensor (or list of tensors if the layer has multiple outputs).
   */
  getOutputAt(t) {
    return Pe(this.getNodeAtIndex(t, "output").outputTensors);
  }
  // Properties
  /**
   * Retrieves the input tensor(s) of a layer.
   *
   * Only applicable if the layer has exactly one inbound node,
   * i.e. if it is connected to one incoming layer.
   *
   * @return Input tensor or list of input tensors.
   *
   * @exception AttributeError if the layer is connected to more than one
   *   incoming layers.
   */
  get input() {
    if (this.inboundNodes.length > 1)
      throw new Yn(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);
    if (this.inboundNodes.length === 0)
      throw new Yn(`Layer ${this.name} is not connected, no input to return.`);
    return Pe(this.getNodeAtIndex(0, "input").inputTensors);
  }
  /**
   * Retrieves the output tensor(s) of a layer.
   *
   * Only applicable if the layer has exactly one inbound node,
   * i.e. if it is connected to one incoming layer.
   *
   * @return Output tensor or list of output tensors.
   *
   * @exception AttributeError if the layer is connected to more than one
   *   incoming layers.
   */
  get output() {
    if (this.inboundNodes.length === 0)
      throw new Yn(`Layer ${this.name} has no inbound nodes.`);
    if (this.inboundNodes.length > 1)
      throw new Yn(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);
    return Pe(this.getNodeAtIndex(0, "output").outputTensors);
  }
  get losses() {
    return this._losses;
  }
  /**
   * Retrieves the Layer's current loss values.
   *
   * Used for regularizers during training.
   */
  calculateLosses() {
    return this.losses.map((t) => t());
  }
  get updates() {
    return this._updates;
  }
  get built() {
    return this._built;
  }
  set built(t) {
    this._built = t;
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t) {
    this._trainableWeights.forEach((e) => e.trainable = t), this.trainable_ = t;
  }
  get trainableWeights() {
    return this.trainable_ ? this._trainableWeights.filter((t) => t.trainable) : [];
  }
  set trainableWeights(t) {
    this._trainableWeights = t;
  }
  get nonTrainableWeights() {
    return this.trainable ? this._trainableWeights.filter((t) => !t.trainable).concat(this._nonTrainableWeights) : this._trainableWeights.concat(this._nonTrainableWeights);
  }
  set nonTrainableWeights(t) {
    this._nonTrainableWeights = t;
  }
  /**
   * The concatenation of the lists trainableWeights and nonTrainableWeights
   * (in this order).
   */
  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }
  get stateful() {
    return this._stateful;
  }
  /**
   * Reset the states of the layer.
   *
   * This method of the base Layer class is essentially a no-op.
   * Subclasses that are stateful (e.g., stateful RNNs) should override this
   * method.
   */
  resetStates() {
    if (!this.stateful)
      throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.");
  }
  /**
   * Checks compatibility between the layer and provided inputs.
   *
   * This checks that the tensor(s) `input`
   * verify the input assumptions of the layer
   * (if any). If not, exceptions are raised.
   *
   * @param inputs Input tensor or list of input tensors.
   *
   * @exception ValueError in case of mismatch between
   *   the provided inputs and the expectations of the layer.
   */
  assertInputCompatibility(t) {
    if (t = Zt(t), this.inputSpec == null || this.inputSpec.length === 0)
      return;
    const e = Zt(this.inputSpec);
    if (t.length !== e.length)
      throw new E(`Layer ${this.name} expects ${e.length} inputs, but it received ${t.length} input tensors. Input received: ${t}`);
    for (let s = 0; s < t.length; s++) {
      const o = t[s], r = e[s];
      if (r == null)
        continue;
      const i6 = o.rank;
      if (r.ndim != null && i6 !== r.ndim)
        throw new E(`Input ${s} is incompatible with layer ${this.name}: expected ndim=${r.ndim}, found ndim=${i6}`);
      if (r.maxNDim != null && i6 > r.maxNDim)
        throw new E(`Input ${s} is incompatible with layer ${this.name}: expected max_ndim=${r.maxNDim}, found ndim=${i6}`);
      if (r.minNDim != null && i6 < r.minNDim)
        throw new E(`Input ${s} is incompatible with layer ${this.name}: expected min_ndim=${r.minNDim}, found ndim=${i6}.`);
      if (r.dtype != null && o.dtype !== r.dtype)
        throw new E(`Input ${s} is incompatible with layer ${this.name} : expected dtype=${r.dtype}, found dtype=${o.dtype}.`);
      if (r.axes) {
        const a = o.shape;
        for (const l in r.axes) {
          const c = Number(l), u = r.axes[l], d = c >= 0 ? a[c] : a[a.length + c];
          if (u != null && [u, null].indexOf(d) === -1)
            throw new E(`Input ${s} is incompatible with layer ${this.name}: expected axis ${c} of input shape to have value ${u} but got shape ${a}.`);
        }
      }
      if (r.shape != null)
        for (let a = 0; a < r.shape.length; ++a) {
          const l = r.shape[a], c = o.shape[a];
          if (l != null && c != null && l !== c)
            throw new E(`Input ${s} is incompatible with layer ${this.name}: expected shape=${r.shape}, found shape=${o.shape}.`);
        }
    }
  }
  /**
   * This is where the layer's logic lives.
   *
   * @param inputs Input tensor, or list/tuple of input tensors.
   * @param kwargs Additional keyword arguments.
   *
   * @return A tensor or list/tuple of tensors.
   */
  call(t, e) {
    return t;
  }
  invokeCallHook(t, e) {
    this._callHook != null && this._callHook(t, e);
  }
  /**
   * Set call hook.
   * This is currently used for testing only.
   * @param callHook
   */
  setCallHook(t) {
    this._callHook = t;
  }
  /**
   * Clear call hook.
   * This is currently used for testing only.
   */
  clearCallHook() {
    this._callHook = null;
  }
  /**
   * Builds or executes a `Layer`'s logic.
   *
   * When called with `tf.Tensor`(s), execute the `Layer`'s computation and
   * return Tensor(s). For example:
   *
   * ```js
   * const denseLayer = tf.layers.dense({
   *   units: 1,
   *   kernelInitializer: 'zeros',
   *   useBias: false
   * });
   *
   * // Invoke the layer's apply() method with a `tf.Tensor` (with concrete
   * // numeric values).
   * const input = tf.ones([2, 2]);
   * const output = denseLayer.apply(input);
   *
   * // The output's value is expected to be [[0], [0]], due to the fact that
   * // the dense layer has a kernel initialized to all-zeros and does not have
   * // a bias.
   * output.print();
   * ```
   *
   * When called with `tf.SymbolicTensor`(s), this will prepare the layer for
   * future execution.  This entails internal book-keeping on shapes of
   * expected Tensors, wiring layers together, and initializing weights.
   *
   * Calling `apply` with `tf.SymbolicTensor`s are typically used during the
   * building of non-`tf.Sequential` models. For example:
   *
   * ```js
   * const flattenLayer = tf.layers.flatten();
   * const denseLayer = tf.layers.dense({units: 1});
   *
   * // Use tf.layers.input() to obtain a SymbolicTensor as input to apply().
   * const input = tf.input({shape: [2, 2]});
   * const output1 = flattenLayer.apply(input);
   *
   * // output1.shape is [null, 4]. The first dimension is the undetermined
   * // batch size. The second dimension comes from flattening the [2, 2]
   * // shape.
   * console.log(JSON.stringify(output1.shape));
   *
   * // The output SymbolicTensor of the flatten layer can be used to call
   * // the apply() of the dense layer:
   * const output2 = denseLayer.apply(output1);
   *
   * // output2.shape is [null, 1]. The first dimension is the undetermined
   * // batch size. The second dimension matches the number of units of the
   * // dense layer.
   * console.log(JSON.stringify(output2.shape));
   *
   * // The input and output can be used to construct a model that consists
   * // of the flatten and dense layers.
   * const model = tf.model({inputs: input, outputs: output2});
   * ```
   *
   * @param inputs a `tf.Tensor` or `tf.SymbolicTensor` or an Array of them.
   * @param kwargs Additional keyword arguments to be passed to `call()`.
   *
   * @return Output of the layer's `call` method.
   *
   * @exception ValueError error in case the layer is missing shape information
   *   for its `build` call.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  // Porting Note: This is a replacement for __call__() in Python.
  apply(t, e) {
    e = e || {}, this.assertNotDisposed();
    const s = Zt(t);
    let o = true;
    for (const i6 of s)
      if (!(i6 instanceof jn)) {
        o = false;
        break;
      }
    let r = true;
    for (const i6 of s)
      if (i6 instanceof jn) {
        r = false;
        break;
      }
    if (o === r)
      throw new E("Arguments to apply() must be all SymbolicTensors or all Tensors");
    return fo(this.name, () => {
      if (!this.built) {
        this.assertInputCompatibility(t);
        const i6 = [];
        for (const a of Zt(t))
          i6.push(a.shape);
        this.build(Pe(i6)), this.built = true, this.initialWeights && this.setWeights(this.initialWeights), this._refCount === null && r && (this._refCount = 1);
      }
      if (this.assertInputCompatibility(t), r) {
        let i6 = this.call(t, e);
        const a = Zt(i6), l = [];
        for (let c of a)
          s.indexOf(c) !== -1 && (c = c.clone()), l.push(c);
        if (i6 = Pe(l), this.activityRegularizer != null)
          throw new xt("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return i6;
      } else {
        const i6 = OG(t), a = this.computeOutputShape(i6);
        let l;
        const c = KG(t);
        if (this.warnOnIncompatibleInputShape(Array.isArray(t) ? i6[0] : i6), a != null && a.length > 0 && Array.isArray(a[0]) ? l = a.map((u, d) => new jn(c, u, this, Zt(t), e, this.name, d)) : l = new jn(c, a, this, Zt(t), e, this.name), this.addInboundNode(t, l, null, null, i6, a, e), this._refCount++, this.activityRegularizer != null)
          throw new xt("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return l;
      }
    });
  }
  /**
   * Check compatibility between input shape and this layer's batchInputShape.
   *
   * Print warning if any incompatibility is found.
   *
   * @param inputShape Input shape to be checked.
   */
  warnOnIncompatibleInputShape(t) {
    if (this.batchInputShape != null)
      if (t.length !== this.batchInputShape.length)
        console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(t)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);
      else {
        let e = false;
        this.batchInputShape.forEach((s, o) => {
          s != null && t[o] != null && t[o] !== s && (e = true);
        }), e && console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`);
      }
  }
  /**
   * Retrieves the output shape(s) of a layer.
   *
   * Only applicable if the layer has only one inbound node, or if all inbound
   * nodes have the same output shape.
   *
   * @returns Output shape or shapes.
   * @throws AttributeError: if the layer is connected to more than one incoming
   *   nodes.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  get outputShape() {
    if (this.inboundNodes == null || this.inboundNodes.length === 0)
      throw new Yn(`The layer ${this.name} has never been called and thus has no defined output shape.`);
    const t = [];
    for (const e of this.inboundNodes) {
      const s = JSON.stringify(e.outputShapes);
      t.indexOf(s) === -1 && t.push(s);
    }
    if (t.length === 1) {
      const e = this.inboundNodes[0].outputShapes;
      return Array.isArray(e) && Array.isArray(e[0]) && e.length === 1 ? e[0] : e;
    } else
      throw new Yn(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`);
  }
  /**
   * Counts the total number of numbers (e.g., float32, int32) in the
   * weights.
   *
   * @returns An integer count.
   * @throws RuntimeError: If the layer is not built yet (in which case its
   *   weights are not defined yet.)
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  countParams() {
    if (!this.built)
      throw new Cn(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);
    return ml(this.weights);
  }
  /**
   * Creates the layer weights.
   *
   * Must be implemented on all layers that have weights.
   *
   * Called when apply() is called to construct the weights.
   *
   * @param inputShape A `Shape` or array of `Shape` (unused).
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  build(t) {
    this.built = true;
  }
  /**
   * Returns the current values of the weights of the layer.
   *
   * @param trainableOnly Whether to get the values of only trainable weights.
   * @returns Weight values as an `Array` of `tf.Tensor`s.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  getWeights(t = false) {
    return Td(t ? this.trainableWeights : this.weights);
  }
  /**
   * Sets the weights of the layer, from Tensors.
   *
   * @param weights a list of Tensors. The number of arrays and their shape
   *   must match number of the dimensions of the weights of the layer (i.e.
   *   it should match the output of `getWeights`).
   *
   * @exception ValueError If the provided weights list does not match the
   *   layer's specifications.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  setWeights(t) {
    D(() => {
      const e = this.weights;
      if (e.length !== t.length)
        throw new E(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);
      if (e.length === 0)
        return;
      const s = [], o = Td(e);
      for (let r = 0; r < o.length; ++r) {
        const i6 = o[r], a = e[r], l = t[r];
        if (!Rt(i6.shape, l.shape))
          throw new E(`Layer weight shape ${i6.shape} not compatible with provided weight shape ${l.shape}`);
        s.push([a, l]);
      }
      ff(s);
    });
  }
  /**
   * Adds a weight variable to the layer.
   *
   * @param name Name of the new weight variable.
   * @param shape The shape of the weight.
   * @param dtype The dtype of the weight.
   * @param initializer An initializer instance.
   * @param regularizer A regularizer instance.
   * @param trainable Whether the weight should be trained via backprop or not
   *   (assuming that the layer itself is also trainable).
   * @param constraint An optional trainable.
   * @return The created weight variable.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  addWeight(t, e, s, o, r, i6, a, l) {
    if (this._addedWeightNames.indexOf(t) !== -1)
      throw new E(`Duplicate weight name ${t} for layer ${this.name}`);
    this._addedWeightNames.push(t), s == null && (s = "float32"), this.fastWeightInitDuringBuild && (o = l != null ? l() : Ut("zeros"));
    const c = o.apply(e, s), u = new zG(c, s, t, i6, a);
    return c.dispose(), r != null && this.addLoss(() => r.apply(u.read())), i6 == null && (i6 = true), i6 ? this._trainableWeights.push(u) : this._nonTrainableWeights.push(u), u;
  }
  /**
   * Set the fast-weight-initialization flag.
   *
   * In cases where the initialized weight values will be immediately
   * overwritten by loaded weight values during model loading, setting
   * the flag to `true` saves unnecessary calls to potentially expensive
   * initializers and speeds up the loading process.
   *
   * @param value Target value of the flag.
   */
  setFastWeightInitDuringBuild(t) {
    this.fastWeightInitDuringBuild = t;
  }
  /**
   * Add losses to the layer.
   *
   * The loss may potentially be conditional on some inputs tensors,
   * for instance activity losses are conditional on the layer's inputs.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  addLoss(t) {
    t == null || Array.isArray(t) && t.length === 0 || (t = Zt(t), this._losses !== void 0 && this._losses !== null && this.losses.push(...t));
  }
  /**
   * Computes the output shape of the layer.
   *
   * Assumes that the layer will be built to match that input shape provided.
   *
   * @param inputShape A shape (tuple of integers) or a list of shape tuples
   *   (one per output tensor of the layer). Shape tuples can include null for
   *   free dimensions, instead of an integer.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  computeOutputShape(t) {
    return t;
  }
  /**
   * Computes an output mask tensor.
   *
   * @param inputs Tensor or list of tensors.
   * @param mask Tensor or list of tensors.
   *
   * @return null or a tensor (or list of tensors, one per output tensor of the
   * layer).
   */
  computeMask(t, e) {
    if (!this.supportsMasking) {
      if (e != null)
        if (Array.isArray(e))
          e.forEach((s) => {
            if (s != null)
              throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
          });
        else
          throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
      return null;
    }
    return e;
  }
  /**
   * Internal method to create an inbound node for the layer.
   *
   * @param inputTensors List of input tensors.
   * @param outputTensors List of output tensors.
   * @param inputMasks List of input masks (a mask can be a tensor, or null).
   * @param outputMasks List of output masks (a mask can be a tensor, or null).
   * @param inputShapes List of input shape tuples.
   * @param outputShapes List of output shape tuples.
   * @param kwargs Dictionary of keyword arguments that were passed to the
   *   `call` method of the layer at the call that created the node.
   */
  addInboundNode(t, e, s, o, r, i6, a = null) {
    const l = Zt(t);
    e = Zt(e), s = Zt(s), o = Zt(o), r = fl(r), i6 = fl(i6);
    const c = [], u = [], d = [];
    for (const h6 of l)
      c.push(h6.sourceLayer), u.push(h6.nodeIndex), d.push(h6.tensorIndex);
    new qc({
      outboundLayer: this,
      inboundLayers: c,
      nodeIndices: u,
      tensorIndices: d,
      inputTensors: l,
      outputTensors: e,
      inputMasks: s,
      outputMasks: o,
      inputShapes: r,
      outputShapes: i6
    }, a);
    for (let h6 = 0; h6 < e.length; h6++)
      e[h6].sourceLayer = this, e[h6].nodeIndex = this.inboundNodes.length - 1, e[h6].tensorIndex = h6;
  }
  /**
   * Returns the config of the layer.
   *
   * A layer config is a TS dictionary (serializable)
   * containing the configuration of a layer.
   * The same layer can be reinstantiated later
   * (without its trained weights) from this configuration.
   *
   * The config of a layer does not include connectivity
   * information, nor the layer class name.  These are handled
   * by 'Container' (one layer of abstraction above).
   *
   * Porting Note: The TS dictionary follows TS naming standards for
   * keys, and uses tfjs-layers type-safe Enums.  Serialization methods
   * should use a helper function to convert to the pythonic storage
   * standard. (see serialization_utils.convertTsToPythonic)
   *
   * @returns TS dictionary of configuration.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  getConfig() {
    const t = { name: this.name, trainable: this.trainable };
    return this.batchInputShape != null && (t.batchInputShape = this.batchInputShape), this.dtype != null && (t.dtype = this.dtype), t;
  }
  /**
   * Dispose the weight variables that this Layer instance holds.
   *
   * @returns {number} Number of disposed variables.
   */
  disposeWeights() {
    return this.weights.forEach((t) => t.dispose()), this.weights.length;
  }
  assertNotDisposed() {
    if (this._refCount === 0)
      throw new Error(`Layer '${this.name}' is already disposed.`);
  }
  /**
   * Attempt to dispose layer's weights.
   *
   * This method decreases the reference count of the Layer object by 1.
   *
   * A Layer is reference-counted. Its reference count is incremented by 1
   * the first item its `apply()` method is called and when it becomes a part
   * of a new `Node` (through calling the `apply()` method on a
   * `tf.SymbolicTensor`).
   *
   * If the reference count of a Layer becomes 0, all the weights will be
   * disposed and the underlying memory (e.g., the textures allocated in WebGL)
   * will be freed.
   *
   * Note: If the reference count is greater than 0 after the decrement, the
   * weights of the Layer will *not* be disposed.
   *
   * After a Layer is disposed, it cannot be used in calls such as `apply()`,
   * `getWeights()` or `setWeights()` anymore.
   *
   * @returns A DisposeResult Object with the following fields:
   *   - refCountAfterDispose: The reference count of the Container after this
   *     `dispose()` call.
   *   - numDisposedVariables: Number of `tf.Variable`s (i.e., weights) disposed
   *     during this `dispose()` call.
   * @throws {Error} If the layer is not built yet, or if the layer has already
   *   been disposed.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  dispose() {
    if (!this.built)
      throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);
    if (this._refCount === null)
      throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);
    this.assertNotDisposed();
    let t = 0;
    return --this._refCount === 0 && (t = this.disposeWeights()), { refCountAfterDispose: this._refCount, numDisposedVariables: t };
  }
};
function OG(n) {
  n = Zt(n);
  const t = [];
  for (const e of n)
    t.push(e.shape);
  return Pe(t);
}
function KG(n) {
  return "float32";
}
function mx(n, t, e) {
  if ((t == null || e != null && e > 0) && (t = n.sourceLayer, e = n.nodeIndex), t.inboundNodes.length === 0)
    return [n];
  {
    const s = t.inboundNodes[e];
    if (s.inboundLayers.length === 0)
      return s.inputTensors;
    {
      const o = [];
      for (let r = 0; r < s.inboundLayers.length; r++) {
        const i6 = s.inputTensors[r], a = s.inboundLayers[r], l = s.nodeIndices[r], c = mx(i6, a, l);
        for (const u of c)
          o.indexOf(u) === -1 && o.push(u);
      }
      return o;
    }
  }
}
var Ia = class extends St {
  constructor(t) {
    if (super({
      dtype: t.dtype,
      name: t.name != null ? t.name : Jc("input").toString()
    }), t.batchSize == null && (t.batchSize = null), t.sparse == null && (t.sparse = false), this.trainable = false, this.built = true, this.sparse = t.sparse, t.inputShape != null && t.batchInputShape != null)
      throw new E("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
    let e = t.batchInputShape;
    if (e == null) {
      if (t.inputShape == null)
        throw new E("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
      e = [t.batchSize].concat(t.inputShape);
    } else if (t.batchSize != null)
      throw new E("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");
    const s = t.dtype || "float32";
    this.batchInputShape = e, this.dtype = s, this.inputSpec = [{ shape: e }];
    const o = new jn(this.dtype, this.batchInputShape, this, [], {}, this.name);
    o.nodeIndex = 0, o.tensorIndex = 0, new qc({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: [o],
      outputTensors: [o],
      inputMasks: [null],
      outputMasks: [null],
      inputShapes: [e],
      outputShapes: [e]
    });
  }
  apply(t, e) {
    throw new E(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`);
  }
  dispose() {
    return { refCountAfterDispose: this._refCount, numDisposedVariables: 0 };
  }
  getConfig() {
    return {
      batchInputShape: this.batchInputShape,
      dtype: this.dtype,
      sparse: this.sparse,
      name: this.name
    };
  }
};
Ia.className = "InputLayer";
_(Ia);
function ZG(n) {
  if (n.batchShape == null && n.shape == null)
    throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
  if (n.batchShape != null && n.shape != null)
    throw new E("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
  let t = n.batchShape;
  n.shape != null && t == null && (t = [null].concat(n.shape));
  let e = n.dtype;
  return e == null && (e = "float32"), new Ia({
    batchInputShape: t,
    name: n.name,
    dtype: e,
    sparse: n.sparse
  }).inboundNodes[0].outputTensors[0];
}
function BG(n, t) {
  if (n.dtype == null || n.dtype === t.dtype)
    return t;
  try {
    return et(t, n.dtype);
  } catch {
    throw new E(`The dtype of the feed (${t.dtype}) can not be cast to the dtype of the key '${n.name}' (${n.dtype}).`);
  }
}
var Gs = class {
  /**
   * Constructor, optionally does copy-construction.
   * @param feeds An Array of `Feed`s, or another `FeedDict`, in which case
   *   copy-construction will be performed.
   */
  constructor(t) {
    if (this.id2Value = {}, this.id2Mask = {}, this.name2Id = {}, t instanceof Gs)
      for (const e in t.id2Value)
        this.id2Value[e] = t.id2Value[e], e in t.id2Mask && (this.id2Mask[e] = t.id2Mask[e]);
    else {
      if (t == null)
        return;
      for (const e of t)
        this.add(e.key, e.value);
    }
  }
  /**
   * Add a key-value pair to the FeedDict.
   *
   * @param key The key of the feed.
   * @param value The value of the tensor feed.
   * @param mask The value of the mask feed (optional).
   * @returns This `FeedDict`.
   * @throws ValueError: If the key `SymbolicTensor` already exists in the
   *   `FeedDict`.
   */
  add(t, e, s) {
    if (this.id2Value[t.id] == null)
      this.id2Value[t.id] = BG(t, e), this.name2Id[t.name] = t.id, s != null && (this.id2Mask[t.id] = s);
    else
      throw new E(`Duplicate key: name=${t.name}, id=${t.id}`);
    return this;
  }
  /**
   * Add a Feed to the FeedDict.
   * @param feed The new `Feed` to add.
   * @returns This `FeedDict`.
   */
  addFeed(t) {
    this.add(t.key, t.value);
  }
  /**
   * Probe whether a key already exists in the FeedDict.
   * @param key
   */
  hasKey(t) {
    return this.id2Value[t.id] != null;
  }
  /**
   * Get all the SymbolicTensor available in this FeedDict.
   */
  names() {
    return Object.keys(this.name2Id);
  }
  /**
   * Get the feed value for given key.
   * @param key The SymbolicTensor, or its name (as a string), of which the
   *     value is sought.
   * @returns If `key` exists, the corresponding feed value.
   * @throws ValueError: If `key` does not exist in this `FeedDict`.
   */
  getValue(t) {
    if (t instanceof jn) {
      if (this.id2Value[t.id] == null)
        throw new E(`Nonexistent key: ${t.name}`);
      return this.id2Value[t.id];
    } else {
      const e = this.name2Id[t];
      if (e == null)
        throw new E(`Feed dict has no SymbolicTensor name: ${t}`);
      return this.id2Value[e];
    }
  }
  /**
   * Get the feed mask for given key.
   * @param key The SymbolicTensor, or its name (as a string), of which the
   *     value is sought.
   * @returns If `key` exists, the corresponding feed mask.
   * @throws ValueError: If `key` does not exist in this `FeedDict`.
   */
  getMask(t) {
    if (t instanceof jn) {
      if (this.id2Value[t.id] == null)
        throw new E(`Nonexistent key: ${t.name}`);
      return this.id2Mask[t.id];
    } else {
      const e = this.name2Id[t];
      if (e == null)
        throw new E(`Feed dict has no SymbolicTensor name: ${t}`);
      return this.id2Mask[e];
    }
  }
  /** Dispose all mask Tensors held by this object. */
  disposeMasks() {
    this.id2Mask != null && yt(this.id2Mask);
  }
};
var gl = new j0();
var bl = new j0();
function HG(n) {
  gl != null && gl.setMaxEntries(n), bl != null && bl.setMaxEntries(n);
}
function Ar(n, t, e, s) {
  const o = e == null ? false : e.training, r = Array.isArray(n), i6 = r ? n : [n], a = i6.map((f) => f.name), l = [], c = t.names();
  for (const f of a)
    c.indexOf(f) !== -1 ? l.push(t.getValue(f)) : l.push(null);
  s != null && (s.maxNumTensors = -1 / 0, s.minNumTensors = 1 / 0);
  const u = a.join(",") + "|" + t.names().sort().join(",");
  let d = gl.get(u), h6;
  if (d == null) {
    const f = _G(i6, t);
    d = f.sorted, h6 = f.recipientCounts, gl.put(u, d), bl.put(u, h6);
  }
  h6 = {}, o || Object.assign(h6, bl.get(u));
  const p6 = new Gs(t);
  for (let f = 0; f < d.length; ++f) {
    if (s != null) {
      const N = cl().numTensors;
      N > s.maxNumTensors && (s.maxNumTensors = N), N < s.minNumTensors && (s.minNumTensors = N);
    }
    const m = d[f], g6 = m.sourceLayer;
    if (g6 instanceof Ia)
      continue;
    const b6 = [], x6 = [], w6 = [];
    let y6 = false;
    for (const N of m.inputs) {
      const R = p6.getValue(N), M6 = p6.getMask(N);
      b6.push(R), x6.push(M6), M6 != null && (y6 = true), o || (h6[N.name]--, h6[N.name] === 0 && !t.hasKey(N) && a.indexOf(N.name) === -1 && !R.isDisposed && N.sourceLayer.stateful !== true && w6.push(R));
    }
    y6 && (e = e || {}, e.mask = x6[0]);
    const I = Zt(g6.apply(b6, e));
    let C6 = null;
    g6.supportsMasking && (C6 = g6.computeMask(b6, x6));
    const k7 = YG(m), S = Array.isArray(k7) ? k7 : [k7];
    for (let N = 0; N < S.length; ++N) {
      p6.hasKey(S[N]) || p6.add(S[N], I[N], Array.isArray(C6) ? C6[0] : C6);
      const R = a.indexOf(S[N].name);
      R !== -1 && (l[R] = I[N]);
    }
    o || yt(w6);
  }
  return p6.disposeMasks(), r ? l : l[0];
}
function _G(n, t) {
  v2(n != null && n.length > 0, () => "Expected at least one fetch, got none");
  let e = [], s = {};
  if (n.length === 1) {
    const o = Tm(n[0], t);
    e = o.sorted, s = o.recipientMap;
  } else {
    const o = /* @__PURE__ */ new Set();
    for (const r of n) {
      const { sorted: i6, recipientMap: a } = Tm(r, t);
      for (const l of i6)
        o.has(l.name) || (e.push(l), o.add(l.name));
      for (const l in a)
        s[l] == null && (s[l] = /* @__PURE__ */ new Set()), a[l].forEach((c) => s[l].add(c));
    }
  }
  return {
    sorted: e,
    recipientCounts: UG(s)
  };
}
function UG(n) {
  const t = {};
  for (const e in n)
    t[e] = n[e].size;
  return t;
}
function Tm(n, t) {
  const e = /* @__PURE__ */ new Set(), s = [], o = {};
  for (const a of t.names())
    e.add(a);
  const r = [], i6 = [];
  for (r.push(n); r.length > 0; ) {
    const a = r[r.length - 1];
    if (e.has(a.name)) {
      r.pop();
      continue;
    }
    const l = i6[i6.length - 1] === r.length - 1;
    if (a.inputs.length === 0 || l)
      r.pop(), s.push(a), e.add(a.name), l && i6.pop();
    else {
      i6.push(r.length - 1);
      for (const c of a.inputs)
        o[c.name] == null && (o[c.name] = /* @__PURE__ */ new Set()), o[c.name].add(a.name), !e.has(c.name) && r.push(c);
    }
  }
  return { sorted: s, recipientMap: o };
}
function YG(n) {
  let t;
  if (n.sourceLayer.inboundNodes.length === 1)
    t = n.sourceLayer.output;
  else {
    let e = null;
    for (let s = 0; s < n.sourceLayer.inboundNodes.length; ++s)
      for (const o of n.sourceLayer.inboundNodes[s].outputTensors)
        if (o.id === n.id) {
          e = s;
          break;
        }
    t = n.sourceLayer.getOutputAt(e);
  }
  return t;
}
var QG = F();
QG.registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES", () => 100, HG);
function mf(n, t) {
  return D(() => De(at(G(n, n), t, true)));
}
var Ca = class extends Vo {
  getConfig() {
    return {};
  }
};
var gx = class extends Ca {
  constructor(t) {
    super(), this.defaultMaxValue = 2, this.defaultAxis = 0, this.maxValue = t.maxValue != null ? t.maxValue : this.defaultMaxValue, this.axis = t.axis != null ? t.axis : this.defaultAxis;
  }
  apply(t) {
    return D(() => {
      const e = mf(t, this.axis), s = pn(e, 0, this.maxValue);
      return G(t, ut(s, U(ue(), e)));
    });
  }
  getConfig() {
    return { maxValue: this.maxValue, axis: this.axis };
  }
};
gx.className = "MaxNorm";
_(gx);
var bx = class extends Ca {
  constructor(t) {
    super(), this.defaultAxis = 0, this.axis = t.axis != null ? t.axis : this.defaultAxis;
  }
  apply(t) {
    return D(() => ut(t, U(ue(), mf(t, this.axis))));
  }
  getConfig() {
    return { axis: this.axis };
  }
};
bx.className = "UnitNorm";
_(bx);
var xx = class extends Ca {
  apply(t) {
    return ws(t);
  }
};
xx.className = "NonNeg";
_(xx);
var yx = class extends Ca {
  constructor(t) {
    super(), this.defaultMinValue = 0, this.defaultMaxValue = 1, this.defaultRate = 1, this.defaultAxis = 0, this.minValue = t.minValue != null ? t.minValue : this.defaultMinValue, this.maxValue = t.maxValue != null ? t.maxValue : this.defaultMaxValue, this.rate = t.rate != null ? t.rate : this.defaultRate, this.axis = t.axis != null ? t.axis : this.defaultAxis;
  }
  apply(t) {
    return D(() => {
      const e = mf(t, this.axis), s = U(G(this.rate, pn(e, this.minValue, this.maxValue)), G(1 - this.rate, e));
      return G(t, ut(s, U(ue(), e)));
    });
  }
  getConfig() {
    return {
      minValue: this.minValue,
      maxValue: this.maxValue,
      rate: this.rate,
      axis: this.axis
    };
  }
};
yx.className = "MinMaxNorm";
_(yx);
var Nm = {
  maxNorm: "MaxNorm",
  minMaxNorm: "MinMaxNorm",
  nonNeg: "NonNeg",
  unitNorm: "UnitNorm"
};
function he(n) {
  return sf(n);
}
function Rm(n, t = {}) {
  return ba(n, an.getMap().classNameMap, t, "constraint");
}
function pe(n) {
  if (n == null)
    return null;
  if (typeof n == "string") {
    const e = { className: n in Nm ? Nm[n] : n, config: {} };
    return Rm(e);
  } else
    return n instanceof Ca ? n : Rm(n);
}
async function eo(n) {
  if (n == null)
    return;
  const t = [], e = [], s = [];
  for (const o in n) {
    const r = n[o];
    if (typeof r != "number") {
      const i6 = r;
      t.push(i6.data()), e.push(o), s.push(i6);
    }
  }
  if (t.length > 0) {
    const o = await Promise.all(t);
    for (let r = 0; r < o.length; ++r)
      n[e[r]] = o[r][0];
    yt(s);
  }
}
function wx(n) {
  if (n != null)
    for (const t in n) {
      const e = n[t];
      typeof e != "number" && e.dispose();
    }
}
var $m;
(function(n) {
  n[n.SILENT = 0] = "SILENT", n[n.VERBOSE = 1] = "VERBOSE";
})($m || ($m = {}));
var JG = 125;
var ei = class {
  constructor() {
    this.validationData = null;
  }
  setParams(t) {
    this.params = t;
  }
  async onEpochBegin(t, e) {
  }
  async onEpochEnd(t, e) {
  }
  async onBatchBegin(t, e) {
  }
  async onBatchEnd(t, e) {
  }
  async onTrainBegin(t) {
  }
  async onTrainEnd(t) {
  }
  // LayersModel needs to call Callback.setModel(), but cannot actually depend
  // on Callback because that creates a cyclic dependency.  Providing this no-op
  // method on BaseCallback breaks the cycle: this way LayersModel can depend on
  // BaseCallback but not on Callback.  The argument is typed as `Container`
  // (the superclass of LayersModel) to avoid recapitulating the cycle. Callback
  // overrides this method and enforces that the argument is really a
  // LayersModel.
  setModel(t) {
  }
};
var jG = class {
  // TODO(cais): When the need arises, uncomment the following lines and
  // implement the queue for time values.
  // private deltaTBatch: number;
  // private deltaTsBatchBegin: Array<number>;
  // private deltaTsBatchEnd: Array<number>;
  /**
   * Constructor of CallbackList.
   * @param callbacks Array of `Callback` instances.
   * @param queueLength Queue length for keeping running statistics over
   *   callback execution time.
   */
  constructor(t, e = 10) {
    t == null && (t = []), this.callbacks = t, this.queueLength = e;
  }
  append(t) {
    this.callbacks.push(t);
  }
  setParams(t) {
    for (const e of this.callbacks)
      e.setParams(t);
  }
  setModel(t) {
    for (const e of this.callbacks)
      e.setModel(t);
  }
  /**
   * Called at the start of an epoch.
   * @param epoch Index of epoch.
   * @param logs Dictionary of logs.
   */
  async onEpochBegin(t, e) {
    e == null && (e = {});
    for (const s of this.callbacks)
      await s.onEpochBegin(t, e);
  }
  /**
   * Called at the end of an epoch.
   * @param epoch Index of epoch.
   * @param logs Dictionary of logs.
   */
  async onEpochEnd(t, e) {
    e == null && (e = {});
    for (const s of this.callbacks)
      await s.onEpochEnd(t, e);
  }
  /**
   * Called  right before processing a batch.
   * @param batch Index of batch within the current epoch.
   * @param logs Dictionary of logs.
   */
  async onBatchBegin(t, e) {
    e == null && (e = {});
    for (const s of this.callbacks)
      await s.onBatchBegin(t, e);
  }
  /**
   * Called at the end of a batch.
   * @param batch Index of batch within the current epoch.
   * @param logs Dictionary of logs.
   */
  async onBatchEnd(t, e) {
    e == null && (e = {});
    for (const s of this.callbacks)
      await s.onBatchEnd(t, e);
  }
  /**
   * Called at the beginning of training.
   * @param logs Dictionary of logs.
   */
  async onTrainBegin(t) {
    t == null && (t = {});
    for (const e of this.callbacks)
      await e.onTrainBegin(t);
  }
  /**
   * Called at the end of training.
   * @param logs Dictionary of logs.
   */
  async onTrainEnd(t) {
    t == null && (t = {});
    for (const e of this.callbacks)
      await e.onTrainEnd(t);
  }
};
var qG = class extends ei {
  constructor() {
    super();
  }
  async onEpochBegin(t) {
    this.seen = 0, this.totals = {};
  }
  async onBatchEnd(t, e) {
    e == null && (e = {});
    const s = e.size == null ? 0 : e.size;
    this.seen += s;
    for (const o in e) {
      const r = e[o];
      if (typeof r == "number")
        this.totals.hasOwnProperty(o) || (this.totals[o] = 0), this.totals[o] = this.totals[o] + r * s;
      else {
        let i6;
        o in this.totals ? i6 = this.totals[o] : this.totals[o] = 0;
        const a = D(() => U(this.totals[o], G(r, s)));
        this.totals[o] = a, i6 != null && i6.dispose();
      }
    }
  }
  async onEpochEnd(t, e) {
    if (e != null)
      for (const s of this.params.metrics)
        this.totals[s] != null && (typeof this.totals[s] == "number" ? e[s] = this.totals[s] / this.seen : D(() => {
          const o = G(ut(1, this.seen), this.totals[s]);
          e[s] = o, this.totals[s].dispose(), cn(e[s]);
        }));
  }
};
var tE = class extends ei {
  async onTrainBegin(t) {
    this.epoch = [], this.history = {};
  }
  async onEpochEnd(t, e) {
    e == null && (e = {}), this.epoch.push(t);
    for (const s in e)
      this.history[s] == null && (this.history[s] = []), this.history[s].push(e[s]);
  }
  /**
   * Await the values of all losses and metrics.
   */
  async syncData() {
    const t = [], e = [], s = [];
    for (const r in this.history) {
      const i6 = this.history[r];
      for (let a = 0; a < i6.length; ++a)
        if (typeof i6[a] != "number") {
          const l = i6[a];
          t.push(l.data()), e.push(r), s.push(a);
        }
    }
    const o = await Promise.all(t);
    for (let r = 0; r < o.length; ++r)
      this.history[e[r]][s[r]].dispose(), this.history[e[r]][s[r]] = o[r][0];
  }
};
var eE = class extends ei {
  constructor(t, e) {
    if (super(), this.currentEpoch = 0, this.nowFunc = t.nowFunc, this.nextFrameFunc = t.nextFrameFunc || _c, this.yieldEvery = e || "auto", this.yieldEvery === "auto" && (this.yieldEvery = JG), this.yieldEvery === "never" && t.onYield != null)
      throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
    nl(this.yieldEvery) && (this.maybeWait = gG(this.maybeWait.bind(this), this.yieldEvery, this.nowFunc)), this.trainBegin = t.onTrainBegin, this.trainEnd = t.onTrainEnd, this.epochBegin = t.onEpochBegin, this.epochEnd = t.onEpochEnd, this.batchBegin = t.onBatchBegin, this.batchEnd = t.onBatchEnd, this.yield = t.onYield;
  }
  async maybeWait(t, e, s) {
    const o = [];
    this.yield != null && (await eo(s), o.push(this.yield(t, e, s))), o.push(this.nextFrameFunc()), await Promise.all(o);
  }
  async onEpochBegin(t, e) {
    this.currentEpoch = t, this.epochBegin != null && (await eo(e), await this.epochBegin(t, e));
  }
  async onEpochEnd(t, e) {
    const s = [];
    this.epochEnd != null && (await eo(e), s.push(this.epochEnd(t, e))), this.yieldEvery === "epoch" && s.push(this.nextFrameFunc()), await Promise.all(s);
  }
  async onBatchBegin(t, e) {
    this.batchBegin != null && (await eo(e), await this.batchBegin(t, e));
  }
  async onBatchEnd(t, e) {
    const s = [];
    this.batchEnd != null && (await eo(e), s.push(this.batchEnd(t, e))), this.yieldEvery === "batch" ? s.push(this.nextFrameFunc()) : nl(this.yieldEvery) && s.push(this.maybeWait(this.currentEpoch, t, e)), await Promise.all(s);
  }
  async onTrainBegin(t) {
    this.trainBegin != null && (await eo(t), await this.trainBegin(t));
  }
  async onTrainEnd(t) {
    this.trainEnd != null && (await eo(t), await this.trainEnd(t));
  }
};
function Ix(n, t) {
  return n == null && (n = {}), n instanceof ei ? [n] : Array.isArray(n) && n[0] instanceof ei ? n : Zt(n).map((s) => new eE(s, t));
}
var xn = class {
  /**
   * Blocks public access to constructor.
   */
  constructor() {
  }
  /**
   * Register a tf.LayersModel.fit() callback constructor.
   *
   * The registered callback constructor will be used to instantiate
   * callbacks for every tf.LayersModel.fit() call afterwards.
   *
   * @param verbosityLevel Level of verbosity at which the `callbackConstructor`
   *   is to be reigstered.
   * @param callbackConstructor A no-arg constructor for `tf.Callback`.
   * @throws Error, if the same callbackConstructor has been registered before,
   *   either at the same or a different `verbosityLevel`.
   */
  static registerCallbackConstructor(t, e) {
    v2(t >= 0 && Number.isInteger(t), () => `Verbosity level is expected to be an integer >= 0, but got ${t}`), xn.checkForDuplicate(e), xn.constructors[t] == null && (xn.constructors[t] = []), xn.constructors[t].push(e);
  }
  static checkForDuplicate(t) {
    for (const e in xn.constructors)
      xn.constructors[+e].forEach((o) => {
        if (o === t)
          throw new E("Duplicate callback constructor.");
      });
  }
  /**
   * Clear all registered callback constructors.
   */
  static clear() {
    xn.constructors = {};
  }
  /**
   * Create callbacks using the registered callback constructors.
   *
   * Given `verbosityLevel`, all constructors registered at that level or above
   * will be called and the instantiated callbacks will be used.
   *
   * @param verbosityLevel: Level of verbosity.
   */
  static createCallbacks(t) {
    const e = [];
    for (const s in xn.constructors) {
      const o = +s;
      t >= o && e.push(...xn.constructors[o]);
    }
    return e.map((s) => new s());
  }
};
xn.constructors = {};
function Cx(n, t, e, s, o, r, i6, a, l) {
  const c = new tE(), u = [
    new qG(),
    ...xn.createCallbacks(t)
  ];
  n != null && u.push(...n), u.push(c);
  const d = new jG(u);
  return d.setParams({
    epochs: e,
    initialEpoch: s,
    samples: o,
    steps: r,
    batchSize: i6,
    verbose: t,
    doValidation: a,
    metrics: l
  }), { callbackList: d, history: c };
}
function Pn(n, t = {}, e = false) {
  return ba(n, an.getMap().classNameMap, t, "layer", e);
}
function xl(n, t) {
  return D(() => {
    n.dtype !== "float32" && (n = et(n, "float32"));
    const e = at(ya(n), t, true), s = ua(e.shape, ue()), o = De(_s(e, s));
    return ut(n, o);
  });
}
function tu(n, t) {
  return D(() => se(ya(lt(t, n)), -1));
}
function gf(n, t) {
  return D(() => se(fe(lt(t, n)), -1));
}
function bf(n, t) {
  return D(() => {
    const e = lt(n, t), s = pn(fe(n), ue(), Number.MAX_VALUE), o = fe(ut(e, s));
    return G(100, se(o, -1));
  });
}
function nE(n, t) {
  return D(() => {
    const e = pn(t, ue(), Number.MAX_VALUE), s = Nn(U(1, e)), o = pn(n, ue(), Number.MAX_VALUE), r = Nn(U(1, o));
    return se(ya(lt(s, r)), -1);
  });
}
function sE(n, t) {
  return D(() => {
    const e = _s(0, lt(1, G(n, t)));
    return se(ya(e), -1);
  });
}
function oE(n, t) {
  return D(() => {
    const e = _s(0, lt(1, G(n, t)));
    return se(e, -1);
  });
}
function rE(n, t) {
  return D(() => {
    const e = at(G(n, t), -1), s = Xn(G(lt(1, n), t), -1);
    return _s(0, U(1, lt(s, e)));
  });
}
function iE(n, t) {
  return D(() => {
    const e = Math.log(2), s = lt(t, n), o = lt(U(s, da(G(-2, s))), e);
    return se(o, -1);
  });
}
function ni(n, t, e = false) {
  return D(() => {
    if (e)
      t = bp(t);
    else {
      const s = at(t, t.shape.length - 1, true);
      t = ut(t, s);
    }
    return t = pn(t, ue(), 1 - ue()), jt(at(G(et(n, "float32"), Nn(t)), t.shape.length - 1));
  });
}
function yl(n, t, e = false) {
  return D(() => {
    const s = et(Ac(RG(n)), "int32");
    t = pn(t, ue(), 1 - ue());
    const o = t.shape, r = W(Pb(s, o[o.length - 1]), o);
    return ni(r, t, e);
  });
}
function aE(n, t) {
  if (!Rt(n.shape, t.shape))
    throw new E(`logits and labels must have the same shape, but got shapes ${JSON.stringify(n.shape)} and ${JSON.stringify(t.shape)}`);
  return D(() => {
    const e = ws(t), s = jt(fe(t));
    return U(lt(e, G(t, n)), ep(Tn(s)));
  });
}
function eu(n, t) {
  return D(() => {
    let e;
    return e = pn(t, ue(), 1 - ue()), e = Nn(ut(e, lt(1, e))), se(aE(n, e), -1);
  });
}
function lE(n, t) {
  return D(() => {
    const e = pn(n, ue(), 1), s = pn(t, ue(), 1);
    return at(G(n, Nn(ut(e, s))), -1);
  });
}
function cE(n, t) {
  return D(() => {
    const e = Nn(U(ue(), t));
    return se(lt(t, G(n, e)), -1);
  });
}
function vx(n, t) {
  return D(() => {
    const e = xl(n, -1), s = xl(t, -1), o = G(e, s);
    return jt(at(o, -1));
  });
}
var wl = {
  meanSquaredError: tu,
  meanAbsoluteError: gf,
  meanAbsolutePercentageError: bf,
  meanSquaredLogarithmicError: nE,
  squaredHinge: sE,
  hinge: oE,
  categoricalHinge: rE,
  logcosh: iE,
  categoricalCrossentropy: ni,
  sparseCategoricalCrossentropy: yl,
  binaryCrossentropy: eu,
  kullbackLeiblerDivergence: lE,
  poisson: cE,
  cosineProximity: vx
};
function Tu(n) {
  if (typeof n == "string") {
    if (n in wl)
      return wl[n];
    let t = `Unknown loss ${n}`;
    throw n.toLowerCase().includes("softmaxcrossentropy") && (t = `Unknown loss ${n}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`), new E(t);
  } else
    return n;
}
function Sx(n, t) {
  return D(() => {
    const e = G(0.5, Rn(t)), s = es(sn(t, e), n.dtype);
    return se(kn(n, s), -1);
  });
}
function kx(n, t) {
  return D(() => es(kn(Qr(n, -1), Qr(t, -1)), "float32"));
}
function Tx(n, t) {
  return D(() => et(at(ss(kn(n, 1), kn(t, 1))), "float32"));
}
function uE(n, t) {
  return D(() => et(at(ss(kn(n, 1), kn(t, 0))), "float32"));
}
function dE(n, t) {
  return D(() => et(at(ss(kn(n, 0), kn(t, 1))), "float32"));
}
function hE(n, t) {
  return D(() => {
    const e = Tx(n, t), s = dE(n, t), o = U(e, s);
    return et(Oe(sn(o, 0), ut(e, o), 0), "float32");
  });
}
function IY(n, t) {
  return D(() => {
    const e = Tx(n, t), s = uE(n, t), o = U(e, s);
    return et(Oe(sn(o, 0), ut(e, o), 0), "float32");
  });
}
function pE(n, t) {
  return eu(n, t);
}
function fE(n, t) {
  return n.rank === t.rank && (n = ha(n, [n.rank - 1])), t = Qr(t, -1), t.dtype !== n.dtype && (t = et(t, n.dtype)), et(kn(n, t), "float32");
}
var mE = tu;
var gE = tu;
var bE = gf;
var xE = gf;
var yE = bf;
var wE = bf;
var Nx = ni;
var IE = vx;
var Rx = yl;
var Il = {
  binaryAccuracy: Sx,
  categoricalAccuracy: kx,
  precision: hE,
  categoricalCrossentropy: Nx,
  sparseCategoricalCrossentropy: Rx,
  mse: mE,
  MSE: gE,
  mae: bE,
  MAE: xE,
  mape: yE,
  MAPE: wE,
  cosine: IE
};
function CE(n) {
  if (typeof n == "string" && n in Il)
    return Il[n];
  if (typeof n != "string" && n != null)
    return n;
  throw new E(`Unknown metric ${n}`);
}
function za(n) {
  if (Qn(n !== null, `Unknown LossOrMetricFn ${n}`), typeof n == "string")
    return n;
  {
    let t;
    for (const e of Object.keys(wl))
      if (wl[e] === n) {
        t = e;
        break;
      }
    if (t !== void 0)
      return t;
    for (const e of Object.keys(Il))
      if (Il[e] === n) {
        t = e;
        break;
      }
    return t !== void 0 ? t : n.name;
  }
}
function vE(n) {
  const t = {
    Adagrad: () => Ko.adagrad(0.01),
    Adadelta: () => Ko.adadelta(1, 0.95, ue()),
    Adam: () => Ko.adam(1e-3, 0.9, 0.999, ue()),
    Adamax: () => Ko.adamax(2e-3, 0.9, 0.999, ue(), 0),
    RMSProp: () => Ko.rmsprop(1e-3, 0.9, 0, ue()),
    SGD: () => Ko.sgd(0.01)
  };
  if (t.adagrad = t.Adagrad, t.adadelta = t.Adadelta, t.adam = t.Adam, t.adamax = t.Adamax, t.rmsprop = t.RMSProp, t.sgd = t.SGD, n in t)
    return t[n]();
  throw new E(`Unknown Optimizer ${n}`);
}
var Gm = 1 * 1024 * 1024;
function Em(n, t, e = false) {
  if (n == null || typeof n != "object" || Object.getPrototypeOf(n) !== Object.prototype || !Nd(n))
    throw new Error("User-defined metadata is expected to be a JSON object, but is not.");
  if (e) {
    const s = JSON.stringify(n);
    s.length > Gm && console.warn(`User-defined metadata of model "${t}" is too large in size (length=${s.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${Gm}.`);
  }
}
function Nd(n) {
  if (n === null)
    return true;
  if (typeof n == "object")
    if (Object.getPrototypeOf(n) === Object.prototype) {
      const t = Object.keys(n);
      for (const e of t)
        if (typeof e != "string" || !Nd(n[e]))
          return false;
      return true;
    } else if (Array.isArray(n)) {
      for (const t of n)
        if (!Nd(t))
          return false;
      return true;
    } else
      return false;
  else {
    const t = typeof n;
    return t === "string" || t === "number" || t === "boolean";
  }
}
function SE(n, t, e, s = console.log) {
  const o = TE(n), r = ["Layer (type)", "Input Shape", "Output shape", "Param #"];
  o ? (t = t || 90, e = e || [0.32, 0.61, 0.89, 1]) : (t = t || 115, e = e || [0.24, 0.48, 0.7, 0.8, 1]), e[e.length - 1] <= 1 && (e = e.map((u) => Math.floor(t * u)));
  let i6;
  if (!o) {
    r.push("Receives inputs"), i6 = [];
    for (const u in n.nodesByDepth)
      i6.push(...n.nodesByDepth[u]);
  }
  s("_".repeat(t)), Cl(r, e, s), s("=".repeat(t));
  const a = n.layers;
  for (let u = 0; u < a.length; ++u)
    o ? NE(a[u], e, s) : RE(a[u], e, i6, s), s((u === a.length - 1 ? "=" : "_").repeat(t));
  n.checkTrainableWeightsConsistency();
  const l = kE(n), c = ml(n.nonTrainableWeights);
  s(`Total params: ${l + c}`), s(`Trainable params: ${l}`), s(`Non-trainable params: ${c}`), s("_".repeat(t));
}
function kE(n) {
  let t;
  return n.collectedTrainableWeights != null ? t = ml(n.collectedTrainableWeights) : t = ml(n.trainableWeights), t;
}
function TE(n) {
  let t = true;
  const e = [], s = [];
  for (const o in n.nodesByDepth)
    e.push(n.nodesByDepth[o]);
  for (const o of e) {
    if (o.length > 1 || o.length === 1 && o[0].inboundLayers.length > 1) {
      t = false;
      break;
    }
    s.push(...o);
  }
  if (t)
    for (const o of n.layers) {
      let r = false;
      for (const i6 of o.inboundNodes)
        if (s.indexOf(i6) !== -1)
          if (r) {
            t = false;
            break;
          } else
            r = true;
      if (!t)
        break;
    }
  return t;
}
function Cl(n, t, e = console.log) {
  let s = "";
  for (let o = 0; o < n.length; ++o)
    o > 0 && (s = s.slice(0, s.length - 1) + " "), s += n[o], s = s.slice(0, t[o]), s += " ".repeat(t[o] - s.length);
  e(s);
}
function NE(n, t, e) {
  let s, o;
  try {
    o = n.inboundNodes.map((l) => JSON.stringify(l.inputShapes)).join(",");
  } catch {
    o = "multiple";
  }
  try {
    s = JSON.stringify(n.outputShape);
  } catch {
    s = "multiple";
  }
  const r = n.name, i6 = n.getClassName(), a = [
    `${r} (${i6})`,
    o,
    s,
    n.countParams().toString()
  ];
  Cl(a, t, e);
}
function RE(n, t, e, s) {
  let o, r;
  try {
    r = n.inboundNodes.map((d) => JSON.stringify(d.inputShapes)).join(",");
  } catch {
    r = "multiple";
  }
  try {
    o = JSON.stringify(n.outputShape);
  } catch {
    o = "multiple";
  }
  const i6 = [];
  for (const d of n.inboundNodes)
    if (!(e != null && e.length > 0 && e.indexOf(d) === -1))
      for (let h6 = 0; h6 < d.inboundLayers.length; ++h6) {
        const p6 = d.inboundLayers[h6].name, f = d.nodeIndices[h6], m = d.tensorIndices[h6];
        i6.push(`${p6}[${f}][${m}]`);
      }
  const a = n.name, l = n.getClassName(), c = i6.length === 0 ? "" : i6[0], u = [
    `${a} (${l})`,
    r,
    o,
    n.countParams().toString(),
    c
  ];
  Cl(u, t, s);
  for (let d = 1; d < i6.length; ++d)
    Cl(["", "", "", "", i6[d]], t, s);
}
function $x(n, t, e) {
  return (n === "inboundNodes" || n === "outputLayers" || n === "inputLayers") && t === 0 && typeof e == "string";
}
function si(n, t) {
  if (n === null)
    return null;
  if (typeof n == "string")
    return ro(n);
  if (typeof n == "number" || typeof n == "boolean")
    return n;
  if (n instanceof Array) {
    const e = [], s = n.length;
    for (let o = 0; o < s; ++o) {
      const r = n[o];
      $x(t, o, r) ? e.push(r) : e.push(si(r, t));
    }
    return e;
  } else {
    const e = {};
    for (const s of Object.keys(n)) {
      const o = n[s];
      if (s === "name" && typeof o == "string")
        e[s] = o;
      else {
        const r = ro(s);
        e[r] = si(o, r);
      }
    }
    return e;
  }
}
function Rd(n, t) {
  if (n == null)
    return null;
  if (typeof n == "string")
    return cs(n);
  if (typeof n == "number" || typeof n == "boolean")
    return n;
  if (n instanceof Array) {
    const e = [], s = n.length;
    for (let o = 0; o < s; ++o) {
      const r = n[o];
      $x(t, o, r) ? e.push(r) : e.push(Rd(r, t));
    }
    return e;
  } else {
    const e = {};
    for (const s of Object.keys(n)) {
      const o = n[s], r = cs(s);
      (s === "name" || s === "className") && typeof o == "string" ? e[r] = o : e[r] = Rd(o, s);
    }
    return e;
  }
}
var Gx = "4.2.0";
var Wn = class extends St {
  constructor(t) {
    if (super({}), this.containerNodes = /* @__PURE__ */ new Set(), this.name = t.name, this.name == null) {
      const x6 = this.getClassName().toLowerCase();
      this.name = Jc(x6);
    }
    if (this.supportsMasking = false, this.trainable_ = true, Array.isArray(t.inputs) ? this.inputs = t.inputs.slice() : this.inputs = [t.inputs], Array.isArray(t.outputs) ? this.outputs = t.outputs.slice() : this.outputs = [t.outputs], Ws(this.inputs).length !== this.inputs.length)
      throw new E(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((x6) => x6.name)}`);
    Ws(this.outputs).length !== this.outputs.length && console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((x6) => x6.name)}`), this.inputLayers = [], this.inputLayersNodeIndices = [], this.inputLayersTensorIndices = [], this.outputLayers = [], this.outputLayersNodeIndices = [], this.outputLayersTensorIndices = [], this.layers = [], this.internalContainerRefs = [];
    for (const x6 of this.outputs) {
      const w6 = x6.sourceLayer, y6 = x6.nodeIndex, I = x6.tensorIndex;
      this.outputLayers.push(w6), this.outputLayersNodeIndices.push(y6), this.outputLayersTensorIndices.push(I);
    }
    for (const x6 of this.inputs) {
      const w6 = x6.sourceLayer, y6 = x6.nodeIndex, I = x6.tensorIndex;
      Qn(y6 === 0, "input layer has >1 nodes"), Qn(I === 0, "input layer has >1 tensors"), this.inputLayers.push(w6), this.inputLayersNodeIndices.push(y6), this.inputLayersTensorIndices.push(I);
    }
    this.inputNames = [], this.outputNames = [], this.feedInputShapes = [], this.feedInputNames = [], this.feedOutputNames = [];
    for (let x6 = 0; x6 < this.inputLayers.length; x6++) {
      const w6 = this.inputLayers[x6];
      if (!(w6 instanceof Ia))
        throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${x6} (0-based) originates from layer type ${w6.getClassName()}.`);
      this.inputNames.push(w6.name), this.feedInputShapes.push(w6.batchInputShape), this.feedInputNames.push(w6.name);
    }
    for (const x6 of this.outputLayers)
      this.outputNames.push(x6.name);
    this.internalInputShapes = this.inputs.map((x6) => x6.shape), this.internalOutputShapes = this.outputs.map((x6) => x6.shape);
    const e = {}, s = {}, o = {}, r = {}, i6 = {}, a = [], l = (x6, w6, y6, I, C6, k7) => {
      (I == null || C6 == null || k7 == null) && (I = x6.sourceLayer, C6 = x6.nodeIndex, k7 = x6.tensorIndex);
      const S = I.inboundNodes[C6];
      if (y6.indexOf(S) !== -1)
        throw new Cn(`The tensor ${x6.name} at layer "${I.name}" is part of a cycle.`);
      if (w6.indexOf(S) !== -1)
        return;
      this.containerNodes.add(Wn.nodeKey(I, C6)), I.id in i6 || (i6[I.id] = Object.keys(i6).length), y6.indexOf(S) === -1 && y6.push(S);
      const N = S.inboundLayers.length;
      for (let R = 0; R < N; R++) {
        const M6 = S.inputTensors[R], V = S.inboundLayers[R], z = S.nodeIndices[R], X = S.tensorIndices[R];
        l(M6, w6, y6, V, z, X);
      }
      for (w6.push(S); y6.indexOf(S) >= 0; )
        y6.splice(y6.indexOf(S), 1);
      a.push(S);
    }, c = [], u = [];
    for (const x6 of this.outputs)
      l(x6, c, u);
    const d = a.slice().reverse();
    for (const x6 of d) {
      s[x6.id] = x6, x6.id in e || (e[x6.id] = 0);
      let w6 = e[x6.id];
      const y6 = o[x6.outboundLayer.id] == null ? 0 : o[x6.outboundLayer.id];
      w6 = Math.max(w6, y6), o[x6.outboundLayer.id] = w6, r[x6.outboundLayer.id] = x6.outboundLayer, e[x6.id] = w6;
      for (let I = 0; I < x6.inboundLayers.length; I++) {
        const C6 = x6.inboundLayers[I], k7 = x6.nodeIndices[I], S = C6.inboundNodes[k7], N = e[S.id] == null ? 0 : e[S.id];
        e[S.id] = Math.max(w6 + 1, N), s[S.id] = S;
      }
    }
    const h6 = {};
    for (const x6 in e) {
      const w6 = e[x6];
      w6 in h6 || (h6[w6] = []), h6[w6].push(s[x6]);
    }
    const p6 = {};
    for (const x6 in o) {
      const w6 = o[x6];
      w6 in p6 || (p6[w6] = []), p6[w6].push(r[x6]);
    }
    let f = Object.keys(p6).map((x6) => parseInt(x6, 10)).sort(Da);
    this.layers = [];
    for (const x6 of f) {
      const w6 = p6[x6];
      w6.sort((y6, I) => {
        const C6 = i6[y6.id], k7 = i6[I.id];
        return C6 < k7 ? -1 : C6 > k7 ? 1 : 0;
      });
      for (const y6 of w6)
        y6 instanceof Wn && this.internalContainerRefs.push(y6), this.layers.push(y6);
    }
    this.layersByDepth = p6, f = Object.keys(h6).map((x6) => parseInt(x6, 10)).sort(Da);
    const m = this.inputs.slice(), g6 = [];
    for (const x6 of f)
      for (const w6 of h6[x6]) {
        const y6 = w6.outboundLayer;
        if (y6 != null) {
          for (const I of w6.inputTensors)
            if (m.indexOf(I) === -1)
              throw new Cn(`Graph disconnected: cannot obtain value for tensor ${I} at layer "${y6.name}". The following previous layers were accessed without issue: ${g6}`);
          for (const I of w6.outputTensors)
            m.push(I);
          g6.push(y6.name);
        }
      }
    this.nodesByDepth = h6;
    const b6 = this.layers.map((x6) => x6.name);
    for (const x6 of b6) {
      const w6 = b6.filter((y6) => y6 === x6).length;
      if (w6 !== 1)
        throw new Cn(`The name "${x6}" is used ${w6} times in the model. All layer names should be unique. Layer names: ` + JSON.stringify(b6));
    }
    this.outboundNodes = [], this.inboundNodes = [], new qc({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: this.inputs,
      outputTensors: this.outputs,
      inputMasks: this.inputs.map((x6) => null),
      outputMasks: this.outputs.map((x6) => null),
      inputShapes: this.inputs.map((x6) => x6.shape),
      outputShapes: this.outputs.map((x6) => x6.shape)
    }), this.built = true, this._refCount = 1;
  }
  assertNotDisposed() {
    if (this._refCount === 0)
      throw new Error(`Container '${this.name}' is already disposed.`);
  }
  /**
   * Attempt to dispose a LayersModel's weights.
   *
   * This method decrease the reference count of the LayersModel object by 1.
   *
   * A LayersModel is reference-counted. Its reference count is incremented by 1
   * when it is first constructed and when it is used as a Layer of another
   * LayersModel.
   *
   * If the reference count of a LayersModel becomes 0, the `dispose` method of
   * all its constituent `Layer`s will be called.
   *
   * Note: If the reference count is greater than 0 after the decrement, the
   * `dispose` method of its constituent `Layer`s will *not* be called.
   *
   * After a LayersModel is disposed, it cannot be used in calls such as
   * 'predict`, `evaluate` or `fit` anymore.
   *
   * @returns A DisposeResult Object with the following fields:
   *   - refCountAfterDispose: The reference count of the LayersModel after this
   *     `dispose()` call.
   *   - numDisposedVariables: Number of `tf.Variable`s (i.e., weights) disposed
   *     during this `dispose()` call.
   * @throws {Error} If the layer is not built yet, or if the LayersModel has
   *   already been disposed.
   */
  dispose() {
    this.assertNotDisposed();
    const t = { refCountAfterDispose: null, numDisposedVariables: 0 };
    if (--this._refCount === 0) {
      for (const e of this.layers)
        t.numDisposedVariables += e.dispose().numDisposedVariables;
      for (const e of this.internalContainerRefs)
        t.numDisposedVariables += e.dispose().numDisposedVariables;
    }
    return t.refCountAfterDispose = this._refCount, t;
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t) {
    this.layers.forEach((e) => {
      e._trainableWeights.forEach((s) => s.trainable = t);
    }), this.trainable_ = t;
  }
  get trainableWeights() {
    if (this._trainableWeights.length > 0)
      throw new E("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
    if (!this.trainable)
      return [];
    let t = [];
    for (const e of this.layers)
      t = t.concat(e.trainableWeights);
    return t;
  }
  get nonTrainableWeights() {
    const t = [];
    for (const e of this.layers)
      t.push(...e.nonTrainableWeights);
    if (!this.trainable) {
      const e = [];
      for (const s of this.layers)
        e.push(...s.trainableWeights);
      return e.concat(t);
    }
    return t;
  }
  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }
  /**
   * Loads all layer weights from a JSON object.
   *
   * Porting Note: HDF5 weight files cannot be directly loaded in JavaScript /
   *   TypeScript. The utility script at `scripts/pykeras.py` offers means
   *   to convert them into JSON strings compatible with this method.
   * Porting Note: TensorFlow.js Layers supports only loading by name currently.
   *
   * @param weights A JSON mapping weight names to weight values as nested
   *   arrays of numbers, or a `NamedTensorMap`, i.e., a JSON mapping weight
   *   names to `tf.Tensor` objects.
   * @param strict Require that the provided weights exactly match those
   *   required by the container.  Default: `true`.  Passing `false` means that
   *   extra weights and missing weights will be silently ignored.
   */
  loadWeights(t, e = true) {
    const s = {};
    let o = 0;
    for (const i6 of this.layers)
      for (const a of i6.weights) {
        if (s[a.originalName] != null)
          throw new E(`Duplicate weight name: ${a.originalName}`);
        s[a.originalName] = a, o++;
      }
    const r = [];
    for (const i6 in t) {
      let a = i6;
      if (s[i6] == null) {
        const l = i6.split("/");
        a = l.slice(0, -2).concat([l[l.length - 1]]).join("/");
      }
      if (s[a] != null)
        r.push([s[a], t[i6]]);
      else if (e)
        throw new E(`Provided weight data has no target variable: ${i6}`);
      delete s[a];
    }
    if (e) {
      const i6 = [];
      for (const a in s)
        i6.push(a);
      if (i6.length > 0)
        throw new E(`${i6.length} of ${o} weights are not set: ${i6}`);
    }
    ff(r);
  }
  /**
   * Util shared between different serialization methods.
   * @returns LayersModel config with Keras version information added.
   */
  updatedConfig() {
    const t = this.getConfig(), e = {};
    return e.className = this.getClassName(), e.config = t, e.kerasVersion = `tfjs-layers ${Gx}`, e.backend = "TensorFlow.js", e;
  }
  /**
   * Returns a JSON string containing the network configuration.
   *
   * To load a network from a JSON save file, use
   * models.modelFromJSON(jsonString);
   * @param extraJsonArgs Unused in tfjs-layers, maintained for PyKeras
   * @param returnString Whether the return value should be stringified
   *    (default: `true`).
   * @returns a JSON string if `returnString` (default), or a JSON object if
   *   `!returnString`.
   */
  // tslint:disable-next-line:no-any
  toJSON(t, e = true) {
    const s = Rd(this.updatedConfig());
    return e ? JSON.stringify(s) : s;
  }
  /**
   * Call the model on new inputs.
   *
   * In this case `call` just reapplies all ops in the graph to the new inputs
   * (e.g. build a new computational graph from the provided inputs).
   *
   * @param inputs A tensor or list of tensors.
   * @param mask A mask or list of masks. A mask can be either a tensor or null
   *   (no mask).
   *
   * @return A tensor if there is a single output, or a list of tensors if there
   *   are more than one outputs.
   */
  call(t, e) {
    return D(() => {
      t = Zt(t);
      const s = new Gs();
      for (let o = 0; o < this.inputs.length; ++o)
        s.add(this.inputs[o], t[o]);
      return Ar(this.outputs, s, e);
    });
  }
  /**
   * Computes an output mask tensor.
   *
   * @param inputs Tensor or list of tensors.
   * @param mask Tensor or list of tensors.
   *
   * @return null or a tensor (or list of tensors, one per output tensor of the
   * layer).
   */
  computeMask(t, e) {
    return D(() => {
      t = Zt(t);
      let s;
      return e == null ? s = Ro(null, t.length) : s = Zt(e), this.runInternalGraph(t, s)[1];
    });
  }
  /**
   * Computes the output shape of the layer.
   *
   * Assumes that the layer will be built to match that input shape provided.
   *
   * @param inputShape A shape (tuple of integers) or a list of shape tuples
   *   (one per output tensor of the layer). Shape tuples can include null for
   *   free dimensions, instead of an integer.
   */
  computeOutputShape(t) {
    const e = fl(t);
    if (e.length !== this.inputLayers.length)
      throw new E(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);
    const s = {};
    for (let a = 0; a < e.length; a++) {
      const l = this.inputLayers[a], c = e[a], u = l.name + "_0_0";
      s[u] = c;
    }
    const o = Object.keys(this.nodesByDepth).map((a) => parseInt(a, 10)).sort(Da);
    if (o.length > 1)
      for (const a of o) {
        const l = this.nodesByDepth[a];
        for (const c of l) {
          const u = c.outboundLayer;
          if (this.inputLayers.map((m) => m.id).indexOf(u.id) !== -1)
            continue;
          const d = [];
          for (let m = 0; m < c.inboundLayers.length; m++) {
            const g6 = c.inboundLayers[m], b6 = c.nodeIndices[m], x6 = c.tensorIndices[m], w6 = `${g6.name}_${b6}_${x6}`, y6 = s[w6];
            d.push(y6);
          }
          const h6 = u.computeOutputShape(Pe(d)), p6 = fl(h6), f = u.inboundNodes.indexOf(c);
          for (let m = 0; m < p6.length; m++) {
            const g6 = `${u.name}_${f}_${m}`;
            s[g6] = p6[m];
          }
        }
      }
    const r = [], i6 = [];
    for (let a = 0; a < this.outputLayers.length; a++) {
      const l = this.outputLayers[a], c = this.outputLayersNodeIndices[a], u = this.outputLayersTensorIndices[a], d = `${l.name}_${c}_${u}`;
      i6.push(d);
    }
    for (let a = 0; a < i6.length; a++) {
      const l = i6[a];
      Qn(l in s), r.push(s[l]);
    }
    return Pe(r);
  }
  /**
   * Computes output tensors for new inputs.
   *
   * Note:
   *   - Expects `inputs` to be a list (potentially with 1 element).
   *
   * @param inputs List of tensors
   * @param masks List of masks (tensors or null).
   * @return Three lists: outputTensors, outputMasks, outputShapes
   */
  runInternalGraph(t, e) {
    e == null && (e = Ro(null, t.length));
    const s = {};
    for (let l = 0; l < this.inputs.length; ++l) {
      const c = this.inputs[l], u = t[l], d = e[l];
      s[c.id] = [u, d];
    }
    const o = Object.keys(this.nodesByDepth).map((l) => parseInt(l, 10)).sort(Da);
    for (const l of o) {
      const c = this.nodesByDepth[l];
      for (const u of c) {
        const d = u.outboundLayer, h6 = u.inputTensors, p6 = u.outputTensors, f = new Array();
        for (const m of h6)
          m.id in s && f.push(s[m.id]);
        if (f.length === h6.length) {
          let m = {}, g6, b6, x6, w6;
          if (u.callArgs != null && (m = u.callArgs), f.length === 1) {
            const [y6, I] = f[0];
            m.mask == null && (m.mask = I), x6 = Zt(d.call(y6, m)), w6 = Zt(d.computeMask(y6, I)), g6 = [y6], b6 = [I];
          } else
            g6 = f.map((y6) => y6[0]), b6 = f.map((y6) => y6[1]), m.mask == null && (m.mask = b6), x6 = Zt(d.call(g6, m)), w6 = Zt(d.computeMask(g6, b6));
          if (d.activityRegularizer)
            throw new xt("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");
          for (let y6 = 0; y6 < p6.length; ++y6) {
            const I = p6[y6], C6 = x6[y6], k7 = w6[y6];
            s[I.id] = [C6, k7];
          }
        }
      }
    }
    const r = [], i6 = [], a = [];
    for (const l of this.outputs) {
      Qn(l.id in s, `Could not compute output ${l.name} : ${l.id}`);
      const [c, u] = s[l.id];
      a.push(c.shape), r.push(c), i6.push(u);
    }
    return [r, i6, a];
  }
  /**
   * Builds a map of internal node keys to node ordering.
   * Used in serializaion a node orderings may change as unused nodes are
   * dropped. Porting Note:  This helper method was pulled out of getConfig to
   * improve readability.
   * @param layers An array of Layers in the model.
   * @returns Map of Node Keys to index order within the layer.
   */
  buildNodeConversionMap(t) {
    const e = {};
    let s;
    for (const o of this.layers) {
      s = o instanceof Wn ? 1 : 0;
      for (let r = 0; r < o.inboundNodes.length; r++) {
        const i6 = Wn.nodeKey(o, r);
        this.containerNodes.has(i6) && (e[i6] = s, s += 1);
      }
    }
    return e;
  }
  /**
   * Retrieves a layer based on either its name (unique) or index.
   *
   * Indices are based on order of horizontal graph traversal (bottom-up).
   *
   * If both `name` and `index` are specified, `index` takes precedence.
   *
   * @param name Name of layer.
   * @param index Index of layer.
   * @returns A Layer instance.
   * @throws ValueError: In case of invalid layer name or index.
   *
   * @doc {
   *    heading: 'Layers',
   *    subheading: 'Classes',
   *    namespace: 'layers',
   *    subclasses: ['LayersModel']
   * }
   */
  getLayer(t, e) {
    if (e != null) {
      if (this.layers.length <= e)
        throw new E(`Was asked to retrieve layer at index ${e}, but model only has ${this.layers.length} layer(s).`);
      return this.layers[e];
    } else if (t == null)
      throw new E("Provide either a layer name or layer index");
    for (const s of this.layers)
      if (s.name === t)
        return s;
    throw new E(`No such layer: ${t}`);
  }
  /**
   * Retrieves the Container's current loss values.
   *
   * Used for regularizers during training.
   */
  calculateLosses() {
    return D(() => {
      const t = [];
      for (const e of this.layers)
        for (let s = 0; s < e.inboundNodes.length; ++s) {
          const o = Wn.nodeKey(e, s);
          this.containerNodes.has(o) && t.push(...e.calculateLosses());
        }
      return t;
    });
  }
  getConfig() {
    const t = { name: this.name }, e = this.buildNodeConversionMap(this.layers), s = [];
    for (const i6 of this.layers) {
      const a = i6.getClassName(), l = i6.getConfig(), c = [];
      for (let d = 0; d < i6.inboundNodes.length; d++) {
        const h6 = i6.inboundNodes[d], p6 = Wn.nodeKey(i6, d);
        let f = {};
        if (this.containerNodes.has(p6)) {
          if (h6.callArgs)
            try {
              JSON.stringify(h6.callArgs), f = h6.callArgs;
            } catch {
              console.warn(`Layer ${i6.name} was passed non-serializable keyword arguments: ${h6.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`), f = {};
            }
          if (h6.inboundLayers.length > 0) {
            const m = [];
            for (let g6 = 0; g6 < h6.inboundLayers.length; g6++) {
              const b6 = h6.inboundLayers[g6], x6 = h6.nodeIndices[g6], w6 = h6.tensorIndices[g6], y6 = Wn.nodeKey(b6, x6);
              let I = e[y6];
              I == null && (I = 0), m.push([b6.name, I, w6, f]);
            }
            c.push(m);
          }
        }
      }
      const u = {};
      u.name = i6.name, u.className = a, u.config = l, u.inboundNodes = c, s.push(u);
    }
    t.layers = s;
    const o = [];
    for (let i6 = 0; i6 < this.inputLayers.length; i6++) {
      const a = this.inputLayers[i6], l = this.inputLayersNodeIndices[i6], c = Wn.nodeKey(a, l);
      if (!this.containerNodes.has(c))
        continue;
      let u = e[c];
      u == null && (u = 0);
      const d = this.inputLayersTensorIndices[i6];
      o.push([a.name, u, d]);
    }
    t.inputLayers = o;
    const r = [];
    for (let i6 = 0; i6 < this.outputLayers.length; i6++) {
      const a = this.outputLayers[i6], l = this.outputLayersNodeIndices[i6], c = Wn.nodeKey(a, l);
      if (!this.containerNodes.has(c))
        continue;
      let u = e[c];
      u == null && (u = 0);
      const d = this.outputLayersTensorIndices[i6];
      r.push([a.name, u, d]);
    }
    return t.outputLayers = r, t;
  }
  /**
   * Instantiates a LayersModel from its config (output of `get_config()`).
   * @param cls the class to create
   * @param config LayersModel config dictionary.
   * @param customObjects An optional dictionary of custom objects.
   * @param fastWeightInit Optional flag to use fast weight initialization
   *   during deserialization. This is applicable to cases in which
   *   the initialization will be immediately overwritten by loaded weight
   *   values. Default: `false`.
   * @returns A LayersModel instance.
   * @throws ValueError: In case of improperly formatted config dict.
   */
  /** @nocollapse */
  static fromConfig(t, e, s = {}, o = false) {
    const r = {}, i6 = {};
    function a(g6, b6) {
      g6.name in i6 ? i6[g6.name].push(b6) : i6[g6.name] = [b6];
    }
    function l(g6, b6) {
      const x6 = [];
      let w6;
      for (const y6 of b6) {
        const I = y6[0], C6 = y6[1], k7 = y6[2];
        if (w6 = y6[3] == null ? {} : y6[3], !(I in r)) {
          a(g6, b6);
          return;
        }
        const S = r[I];
        if (S.inboundNodes.length <= C6) {
          a(g6, b6);
          return;
        }
        const N = S.inboundNodes[C6];
        x6.push(N.outputTensors[k7]);
      }
      x6.length > 0 && g6.apply(Pe(x6), w6);
    }
    function c(g6) {
      const b6 = g6.name, x6 = Pn(g6, e.customObjects != null ? e.customObjects : {});
      x6.setFastWeightInitDuringBuild(o), r[b6] = x6, g6.inboundNodes.forEach((y6) => {
        if (!(y6 instanceof Array))
          throw new E(`Corrupted configuration, expected array for nodeData: ${y6}`);
        a(x6, y6);
      });
    }
    const u = e.name, d = e.layers;
    for (const g6 of d)
      c(g6);
    for (; !mG(i6); )
      for (const g6 of d) {
        const b6 = r[g6.name];
        if (b6.name in i6) {
          const x6 = i6[b6.name];
          delete i6[b6.name];
          for (const w6 of x6)
            l(b6, w6);
        }
      }
    const h6 = [], p6 = [], f = e.inputLayers;
    for (const g6 of f) {
      const b6 = g6[0], x6 = g6[1], w6 = g6[2];
      Qn(b6 in r);
      const I = r[b6].inboundNodes[x6].outputTensors;
      h6.push(I[w6]);
    }
    const m = e.outputLayers;
    for (const g6 of m) {
      const b6 = g6[0], x6 = g6[1], w6 = g6[2];
      Qn(b6 in r);
      const I = r[b6].inboundNodes[x6].outputTensors;
      p6.push(I[w6]);
    }
    return new t({ inputs: h6, outputs: p6, name: u });
  }
  /**
   * Determine whether the container is stateful.
   *
   * Porting Note: this is the equivalent of the stateful @property of
   *   the Container class in PyKeras.
   */
  get stateful() {
    if (this._stateful)
      throw new E("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");
    for (const t of this.layers)
      if (t.stateful)
        return true;
    return false;
  }
  /**
   * Reset the state of all stateful constituent layers (if any).
   *
   * Examples of stateful layers include RNN layers whose `stateful` property
   * is set as `true`.
   */
  resetStates() {
    D(() => {
      this.layers.forEach((t) => {
        t.stateful && t.resetStates();
      });
    });
  }
};
function $E(n, t, e) {
  const s = t.length;
  if (n == null || Array.isArray(n) && n.length === 0)
    return t.map((o) => null);
  if (s === 1)
    return Array.isArray(n) && n.length === 1 ? n : typeof n == "object" && t[0] in n ? [n[t[0]]] : [n];
  if (Array.isArray(n)) {
    if (n.length !== s)
      throw new Error(`Provided ${e} is an array of ${n.length} element(s), but the model has ${s} outputs. Make sure a set of weights is provided for each model output.`);
    return n;
  } else if (typeof n == "object" && Object.keys(n).length > 0 && typeof n[Object.keys(n)[0]] == "object") {
    const o = [];
    return t.forEach((r) => {
      r in n ? o.push(n[r]) : o.push(null);
    }), o;
  } else
    throw new Error(`The model has multiple (${s}) outputs, so ${e} must be either an array with ${s} elements or an object with ${t} keys. Provided ${e} not understood: ${JSON.stringify(n)}`);
}
function Ex(n, t) {
  return $E(n, t, "classWeight");
}
async function Lx(n, t, e, s) {
  if (t != null || s != null)
    throw new Error("Support sampleWeight is not implemented yet");
  if (e != null) {
    const o = D(() => {
      if (n.shape.length === 1)
        return po(n);
      if (n.shape.length === 2) {
        if (n.shape[1] > 1)
          return Qr(n, 1);
        if (n.shape[1] === 1)
          return W(n, [n.shape[0]]);
        throw new Error(`Encountered unexpected last-dimension size (${n.shape[1]}) during handling of class weights. The size is expected to be >= 1.`);
      } else
        throw new Error(`Unexpected rank of target (y) tensor (${n.rank}) during handling of class weights. The rank is expected to be 1 or 2.`);
    }), r = Array.from(await o.data());
    yt(o);
    const i6 = [];
    return r.forEach((a) => {
      if (e[a] == null)
        throw new Error(`classWeight must contain all classes in the training data. The class ${a} exists in the data but not in classWeight`);
      i6.push(e[a]);
    }), Je(i6, "float32");
  } else
    return null;
}
function GE(n, t) {
  return G(n, t);
}
var EE = 32;
function Mx(n, t) {
  let e, s;
  const o = t;
  e = o.xs, s = o.ys, v2(e != null && s != null, () => `A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t}`);
  const r = Lm("input", n.inputNames, e), i6 = Lm("output", n.outputNames, s), a = r[0].shape[0];
  v2(r.length === n.inputs.length, () => `LayersModel has ${n.inputs.length} inputs, but the dataset provides ${r.length} inputs.  (Expected input keys: ${JSON.stringify(n.inputNames)})`), v2(i6.length === n.outputs.length, () => `LayersModel has ${n.outputs.length} outputs, but the dataset provides ${i6.length} outputs.  (Expected output keys: ${JSON.stringify(n.outputNames)})`);
  for (let l = 0; l < r.length; l++)
    v2(r[l].shape[0] === a, () => `Batch size mismatch: input ${n.inputNames[l]} has ${r[l].shape[0]}; expected  ${a} based on input ${n.inputNames[0]}.`);
  for (let l = 0; l < i6.length; l++)
    v2(i6[l].shape[0] === a, () => `Batch size mismatch: output ${n.outputNames[l]} has ${i6[l].shape[0]}; expected  ${a} based on input ${n.inputNames[0]}.`);
  return { xs: r, ys: i6 };
}
function Lm(n, t, e) {
  if (e instanceof Lt)
    return [e];
  if (Array.isArray(e))
    return v2(e.length === t.length, () => `Received an array of ${e.length} Tensors, but expected ${t.length} to match the ${n} keys ${t}.`), e;
  {
    const s = [];
    for (const o of t) {
      if (e[o] == null)
        throw new E(`The feature data generated by the dataset lacks the required ${n} key '${o}'.`);
      s.push(e[o]);
    }
    return s;
  }
}
function LE(n) {
  if (n.length === 3)
    throw new xt("Validation with sample weights is not implemented yet.");
  return { xs: n[0], ys: n[1] };
}
async function ME(n, t, e) {
  const s = e.batchesPerEpoch != null;
  if (v2(n.optimizer != null, () => "You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."), v2(e != null, () => "For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."), v2(e.epochs != null && e.epochs > 0 && Number.isInteger(e.epochs), () => `For fitDataset(), config.epochs is expected to be a positive integer, but got ${e.epochs}`), v2(!s || e.batchesPerEpoch > 0 && Number.isInteger(e.batchesPerEpoch), () => `For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${e.batchesPerEpoch}`), v2(
    // tslint:disable-next-line:no-any
    e.validationSplit == null,
    () => "`validationSplit` is not supported by `fitDataset()`. Use validationData instead."
  ), n.isTraining)
    throw new Error("Cannot start training because another fit() call is ongoing.");
  n.isTraining = true;
  try {
    const o = e.validationData != null;
    let r, i6;
    if (o)
      if (Mm(e.validationData))
        v2(e.validationBatches == null || e.validationBatches > 0 && Number.isInteger(e.validationBatches), () => `For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${e.validationBatches}`);
      else {
        const g6 = LE(e.validationData);
        r = g6.xs, i6 = g6.ys;
      }
    const a = n.makeTrainFunction(), l = n.getDedupedMetricsNames();
    let c;
    o ? c = l.slice().concat(l.map((g6) => "val_" + g6)) : c = l.slice();
    const u = Ix(e.callbacks, e.yieldEvery), d = e.verbose == null ? 1 : e.verbose, { callbackList: h6, history: p6 } = Cx(
      u,
      d,
      e.epochs,
      null,
      null,
      WE(t, e),
      null,
      // Batch size determined by the dataset itself.
      o,
      c
    );
    h6.setModel(n), n.history = p6, await h6.onTrainBegin(), n.stopTraining_ = false;
    let f = e.initialEpoch == null ? 0 : e.initialEpoch, m = await t.iterator();
    for (; f < e.epochs; ) {
      const g6 = {};
      await h6.onEpochBegin(f);
      let b6 = 0, x6 = 0;
      for (s || (m = await t.iterator()); !s || b6 < e.batchesPerEpoch; ) {
        const w6 = await m.next();
        if (s && w6.done) {
          console.warn(`You provided \`batchesPerEpoch\` as ${e.batchesPerEpoch}, but your dataset iterator ran out of data after ${b6} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ${e.batchesPerEpoch * e.epochs} batches). You may need to use the repeat() function when building your dataset.`);
          break;
        }
        if (w6.value != null) {
          const { xs: y6, ys: I } = Mx(n, w6.value), C6 = {};
          C6.batch = x6, C6.size = y6[0].shape[0], await h6.onBatchBegin(x6, C6);
          const k7 = [];
          if (e.classWeight != null) {
            const R = Ex(e.classWeight, n.outputNames);
            for (let M6 = 0; M6 < R.length; ++M6)
              k7.push(await Lx(I[M6], null, R[M6]));
          }
          const S = y6.concat(I).concat(k7), N = a(S);
          yt(S);
          for (let R = 0; R < l.length; ++R) {
            const M6 = l[R], V = N[R];
            C6[M6] = V, cn(V);
          }
          await h6.onBatchEnd(x6, C6), wx(C6), x6++, b6++;
        }
        if (s ? b6 >= e.batchesPerEpoch : w6.done) {
          if (o) {
            let y6;
            Mm(e.validationData) ? y6 = Zt(await n.evaluateDataset(e.validationData, { batches: e.validationBatches })) : y6 = Zt(n.evaluate(r, i6, {
              batchSize: e.validationBatchSize == null ? EE : e.validationBatchSize,
              verbose: 0
            }));
            for (let I = 0; I < n.metricsNames.length; ++I)
              g6[`val_${n.metricsNames[I]}`] = y6[I];
          }
          break;
        }
        if (n.stopTraining_)
          break;
      }
      if (await h6.onEpochEnd(f, g6), f++, n.stopTraining_)
        break;
    }
    return await h6.onTrainEnd(), await n.history.syncData(), n.history;
  } finally {
    n.isTraining = false;
  }
}
function WE(n, t) {
  let e = null;
  return t.batchesPerEpoch != null ? e = t.batchesPerEpoch : Number.isFinite(n.size) && (e = n.size), e;
}
function Mm(n) {
  return typeof n.iterator == "function";
}
function DE(n) {
  return typeof n.next == "function";
}
async function FE(n, t, e) {
  e = e || {};
  const s = e.batches != null, o = n.testFunction;
  let r = [];
  if (e.verbose > 0)
    throw new xt("Verbose mode is not implemented yet.");
  v2(!s || e.batches > 0 && Number.isInteger(e.batches), () => `Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(e.batches)}`);
  const i6 = DE(t) ? t : await t.iterator();
  let a = 0, l = 0;
  for (; !s || l < e.batches; ) {
    const c = await i6.next();
    if (r = D(() => {
      if (c.value) {
        const { xs: u, ys: d } = Mx(n, c.value), h6 = u.concat(d), p6 = D(() => o(h6));
        if (yt(h6), l === 0)
          for (let m = 0; m < p6.length; ++m)
            r.push(gt(0));
        const f = h6[0].shape[0];
        for (let m = 0; m < p6.length; ++m) {
          const g6 = p6[m], b6 = r[m];
          r[m] = D(() => U(r[m], G(f, g6))), l > 0 && yt(b6);
        }
        yt(p6), a += f, ++l;
      }
      return r;
    }), c.done) {
      s && console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${e.batches} batches). You may need to use the repeat() function when building your dataset.`);
      break;
    }
  }
  for (let c = 0; c < r.length; ++c) {
    const u = r[c];
    r[c] = ut(r[c], a), yt(u);
  }
  return Pe(r);
}
function Nu(n) {
  v2(n > 0 && Number.isInteger(n), () => `batchSize is required to be a positive integer, but got ${n}`);
}
function Wr(n, t, e) {
  return n == null ? [null] : Array.isArray(n) ? n.map((s) => mo(s, t, e - t)) : mo(n, t, e - t);
}
function $d(n, t) {
  return D(() => n == null ? null : Array.isArray(n) ? n.map((e) => $d(e, t)) : ix(n, t.dtype === "int32" ? t : et(t, "int32")));
}
function Ru(n, t) {
  const e = [];
  let s = 0, o = null;
  for (; s < n; )
    o = s + t, o >= n && (o = n), e.push([s, o]), s = o;
  return e;
}
function Wx(n) {
  const t = [];
  n instanceof Lt && (n = [n]);
  for (let e = 0; e < n.length; ++e) {
    const s = n[e];
    if (s.rank === 1)
      t.push(xa(s, 1));
    else {
      if (s.rank === 0)
        throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
      t.push(s);
    }
  }
  return t;
}
function Mn(n, t) {
  if (n == null)
    return;
  const e = [];
  if (t instanceof Lt)
    e.push(t.id);
  else if (Array.isArray(t))
    t.forEach((o) => e.push(o.id));
  else if (t != null)
    for (const o in t) {
      const r = t[o];
      e.push(r.id);
    }
  const s = [];
  if (n instanceof Lt)
    e.indexOf(n.id) === -1 && s.push(n);
  else if (Array.isArray(n))
    n.forEach((o) => {
      e.indexOf(o.id) === -1 && s.push(o);
    });
  else if (n != null)
    for (const o in n) {
      const r = n[o];
      e.indexOf(r.id) === -1 && s.push(r);
    }
  s.forEach((o) => {
    o.isDisposed || o.dispose();
  });
}
function VE(n) {
  return n instanceof Lt;
}
function Gd(n) {
  return Array.isArray(n);
}
function Wm(n) {
  return !VE(n) && !Gd(n);
}
function Dm(n, t, e, s = true, o = "") {
  if (t == null || t.length === 0) {
    if (n != null) {
      let i6 = false;
      if (Gd(n) && n.length > 0)
        i6 = true;
      else if (Wm(n)) {
        for (const a in n)
          if (n.hasOwnProperty(a)) {
            i6 = true;
            break;
          }
      } else
        i6 = true;
      if (i6)
        throw new E(`Error when checking model ${o} expected no data, but got ${n}`);
    }
    return [];
  }
  if (n == null)
    return t.map((i6) => null);
  let r;
  if (Wm(n)) {
    n = n, r = [];
    for (const i6 of t) {
      if (n[i6] == null)
        throw new E(`No data provided for "${i6}". Need data for each key in: ${t}`);
      r.push(n[i6]);
    }
  } else if (Gd(n)) {
    if (n = n, n.length !== t.length)
      throw new E(`Error when checking model ${o}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t.length} Tensor(s), but instead got the following list of Tensor(s): ${n}`);
    r = n;
  } else {
    if (n = n, t.length > 1)
      throw new E(`The model ${o} expects ${t.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${n.shape}`);
    r = [n];
  }
  if (r = Wx(r), e != null)
    for (let i6 = 0; i6 < t.length; ++i6) {
      if (e[i6] == null)
        continue;
      const a = r[i6];
      if (a.shape.length !== e[i6].length)
        throw new E(`Error when checking ${o}: expected ${t[i6]} to have ${e[i6].length} dimension(s). but got array with shape ${a.shape}`);
      for (let l = 0; l < e[i6].length; ++l) {
        if (l === 0 && !s)
          continue;
        const c = a.shape[l], u = e[i6][l];
        if (u != null && u >= 0 && c !== u)
          throw new E(`${o} expected a batch of elements where each example has shape [${e[i6].slice(1, e[i6].length)}] (i.e.,tensor shape [*,${e[i6].slice(1, e[i6].length)}]) but the ${o} received an input with ${a.shape[0]} examples, each with shape [${a.shape.slice(1, a.shape.length)}] (tensor shape [${a.shape}])`);
      }
    }
  return r;
}
function zE(n, t, e) {
  const s = Ws(n.map((r) => r.shape[0]));
  s.sort();
  const o = Ws(t.map((r) => r.shape[0]));
  if (o.sort(), s.length > 1)
    throw new E(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(n.map((r) => r.shape))}`);
  if (o.length > 1)
    throw new E(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map((r) => r.shape))}`);
  if (s.length > 0 && o.length > 0 && !Rt(s, o))
    throw new E(`Input Tensors should have the same number of samples as target Tensors. Found ${s[0]} input sample(s) and ${o[0]} target sample(s).`);
}
function XE(n, t, e) {
  const s = [
    tu,
    eu,
    ni
  ];
  for (let o = 0; o < n.length; ++o) {
    const r = n[o], i6 = t[o], a = e[o];
    if (i6 != null) {
      if (i6 === ni && r.shape[r.shape.length - 1] === 1)
        throw new E(`You are passing a target array of shape ${r.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);
      if (s.indexOf(i6) !== -1) {
        const l = r.shape.slice(1), c = a.slice(1);
        for (let u = 0; u < l.length; ++u) {
          const d = l[u], h6 = c[u];
          if (h6 != null && d !== h6)
            throw new E(`A target Tensor with shape ${r.shape} was passed for an output of shape ${a}, while using a loss function that expects targets to have the same shape as the output.`);
        }
      }
    }
  }
}
function Fm(n, t, e, s = true, o = "") {
  let r;
  if (Array.isArray(n)) {
    if (n.length !== t.length)
      throw new E(`Error when checking model ${o}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t.length} Tensor(s), but instead got ${n.length} Tensors(s).`);
    r = n;
  } else {
    if (t.length > 1)
      throw new E(`The model expects ${t.length} ${o} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(n.shape)}.`);
    r = [n];
  }
  if (e != null)
    for (let i6 = 0; i6 < t.length; ++i6) {
      if (e[i6] == null)
        continue;
      const a = r[i6];
      if (a.shape.length !== e[i6].length)
        throw new E(`Error when checking ${o}: expected ${t[i6]} to have ${e[i6].length} dimension(s), but got array with shape ${JSON.stringify(a.shape)}`);
      for (let l = 0; l < e[i6].length; ++l) {
        if (l === 0 && !s)
          continue;
        const c = a.shape[l], u = e[i6][l];
        if (u != null && u !== c)
          throw new E(`Error when checking ${o}: expected ${t[i6]} to have shape ${JSON.stringify(e[i6])} but got array with shape ${JSON.stringify(a.shape)}.`);
      }
    }
}
function PE(n, t) {
  if (n == null || Array.isArray(n) && n.length === 0)
    return t.map((s) => []);
  let e;
  if (typeof n == "string" || typeof n == "function")
    e = [n];
  else if (Array.isArray(n) || typeof n == "object")
    e = n;
  else
    throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${n}`);
  if (Array.isArray(e))
    return t.map((s) => e);
  {
    const s = [];
    for (const o of t) {
      let r = e.hasOwnProperty(o) ? e[o] : [];
      Array.isArray(r) || (r = [r]), s.push(r);
    }
    return s;
  }
}
var AE = "layers-model";
var tr = class extends Wn {
  constructor(t) {
    super(t), this.isTraining = false;
  }
  /**
   * Print a text summary of the model's layers.
   *
   * The summary includes
   * - Name and type of all layers that comprise the model.
   * - Output shape(s) of the layers
   * - Number of weight parameters of each layer
   * - If the model has non-sequential-like topology, the inputs each layer
   *   receives
   * - The total number of trainable and non-trainable parameters of the model.
   *
   * ```js
   * const input1 = tf.input({shape: [10]});
   * const input2 = tf.input({shape: [20]});
   * const dense1 = tf.layers.dense({units: 4}).apply(input1);
   * const dense2 = tf.layers.dense({units: 8}).apply(input2);
   * const concat = tf.layers.concatenate().apply([dense1, dense2]);
   * const output =
   *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);
   *
   * const model = tf.model({inputs: [input1, input2], outputs: output});
   * model.summary();
   * ```
   *
   * @param lineLength Custom line length, in number of characters.
   * @param positions Custom widths of each of the columns, as either
   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number
   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to
   *   right-most (i.e., ending) position of a column.
   * @param printFn Custom print function. Can be used to replace the default
   *   `console.log`. For example, you can use `x => {}` to mute the printed
   *   messages in the console.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  summary(t, e, s = console.log) {
    if (!this.built)
      throw new E("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");
    SE(this, t, e, s);
  }
  /**
   * Configures and prepares the model for training and evaluation.  Compiling
   * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`
   * or `evaluate` on an un-compiled model will throw an error.
   *
   * @param args a `ModelCompileArgs` specifying the loss, optimizer, and
   * metrics to be used for fitting and evaluating this model.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  compile(t) {
    if (t.loss == null && (t.loss = []), this.loss = t.loss, typeof t.optimizer == "string")
      this.optimizer_ = vE(t.optimizer), this.isOptimizerOwned = true;
    else {
      if (!(t.optimizer instanceof Ys))
        throw new E("User-defined optimizer must be an instance of tf.Optimizer.");
      this.optimizer_ = t.optimizer, this.isOptimizerOwned = false;
    }
    let e = [];
    if (!Array.isArray(t.loss) && typeof t.loss != "string" && typeof t.loss != "function") {
      t.loss = t.loss;
      for (const i6 in t.loss)
        if (this.outputNames.indexOf(i6) === -1)
          throw new E(`Unknown entry in loss dictionary: "${i6}". Only expected the following keys: ${this.outputNames}`);
      for (const i6 of this.outputNames)
        t.loss[i6] == null && console.warn(`Output "${i6}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${i6} during training`), e.push(Tu(t.loss[i6]));
    } else if (Array.isArray(t.loss)) {
      if (t.loss.length !== this.outputs.length)
        throw new E(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t.loss}.`);
      e = t.loss.map((a) => Tu(a));
    } else {
      const i6 = Tu(t.loss);
      this.outputs.forEach((a) => {
        e.push(i6);
      });
    }
    this.lossFunctions = e, this.feedOutputNames = [], this.feedOutputShapes = [], this.feedLossFns = [];
    for (let i6 = 0; i6 < this.outputs.length; ++i6) {
      const a = this.internalOutputShapes[i6], l = this.outputNames[i6];
      this.feedOutputNames.push(l), this.feedOutputShapes.push(a), this.feedLossFns.push(this.lossFunctions[i6]);
    }
    const s = [];
    this.metrics = t.metrics, this.metricsNames = ["loss"], this.metricsTensors = [], fo("loss", () => {
      for (let i6 = 0; i6 < this.outputs.length; ++i6) {
        if (s.indexOf(i6) !== -1)
          continue;
        const a = this.lossFunctions[i6];
        this.outputs.length > 1 && (this.metricsTensors.push([a, i6]), this.metricsNames.push(this.outputNames[i6] + "_loss"));
      }
    });
    const o = PE(t.metrics, this.outputNames), r = (i6, a, l) => {
      this.outputNames.length > 1 && (a = this.outputNames[i6] + "_" + a), this.metricsNames.push(a), this.metricsTensors.push([l, i6]);
    };
    fo("metric", () => {
      for (let i6 = 0; i6 < this.outputs.length; ++i6) {
        if (s.indexOf(i6) !== -1)
          continue;
        const a = o[i6];
        ((c) => {
          const u = "";
          let d, h6, p6;
          for (const f of c) {
            if (typeof f == "string" && ["accuracy", "acc", "crossentropy", "ce"].indexOf(f) !== -1) {
              const g6 = this.internalOutputShapes[i6];
              g6[g6.length - 1] === 1 || this.lossFunctions[i6] === eu ? ["accuracy", "acc"].indexOf(f) !== -1 ? h6 = Sx : ["crossentropy", "ce"].indexOf(f) !== -1 && (h6 = pE) : this.lossFunctions[i6] === yl ? ["accuracy", "acc"].indexOf(f) !== -1 ? h6 = fE : ["crossentropy", "ce"].indexOf(f) !== -1 && (h6 = Rx) : ["accuracy", "acc"].indexOf(f) !== -1 ? h6 = kx : ["crossentropy", "ce"].indexOf(f) !== -1 && (h6 = Nx);
              let b6;
              ["accuracy", "acc"].indexOf(f) !== -1 ? b6 = "acc" : ["crossentropy", "ce"].indexOf(f) !== -1 && (b6 = "ce"), p6 = h6, d = u + b6;
            } else
              p6 = CE(f), d = u + za(f);
            let m;
            fo(d, () => {
              m = p6;
            }), r(i6, d, m);
          }
        })(a);
      }
    }), this.collectedTrainableWeights = this.trainableWeights;
  }
  /**
   * Check trainable weights count consistency.
   *
   * This will raise a warning if `this.trainableWeights` and
   * `this.collectedTrainableWeights` are inconsistent (i.e., have different
   * numbers of parameters).
   * Inconsistency will typically arise when one modifies `model.trainable`
   * without calling `model.compile()` again.
   */
  checkTrainableWeightsConsistency() {
    this.collectedTrainableWeights != null && this.trainableWeights.length !== this.collectedTrainableWeights.length && console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?");
  }
  /**
   * Returns the loss value & metrics values for the model in test mode.
   *
   * Loss and metrics are specified during `compile()`, which needs to happen
   * before calls to `evaluate()`.
   *
   * Computation is done in batches.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * const result = model.evaluate(
   *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});
   * result.print();
   * ```
   *
   * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the
   * model has multiple inputs.
   * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the
   * model has multiple outputs.
   * @param args A `ModelEvaluateArgs`, containing optional fields.
   *
   * @return `Scalar` test loss (if the model has a single output and no
   *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs
   *   and/or metrics). The attribute `model.metricsNames`
   *   will give you the display labels for the scalar outputs.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  evaluate(t, e, s = {}) {
    const o = s.batchSize == null ? 32 : s.batchSize;
    Nu(o);
    const r = true, i6 = this.standardizeUserDataXY(t, e, r, o);
    try {
      const a = i6[0].concat(i6[1]);
      this.makeTestFunction();
      const l = this.testFunction, c = this.testLoop(l, a, o, s.verbose, s.steps);
      return Pe(c);
    } finally {
      Mn(i6[0], t), Mn(i6[1], e);
    }
  }
  // TODO(cais): Add code snippet below once real dataset objects are
  //   available.
  /**
   * Evaluate model using a dataset object.
   *
   * Note: Unlike `evaluate()`, this method is asynchronous (`async`).
   *
   * @param dataset A dataset object. Its `iterator()` method is expected
   *   to generate a dataset iterator object, the `next()` method of which
   *   is expected to produce data batches for evaluation. The return value
   *   of the `next()` call ought to contain a boolean `done` field and a
   *   `value` field. The `value` field is expected to be an array of two
   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
   *   case is for models with exactly one input and one output (e.g.
   *   a sequential model). The latter case is for models with multiple
   *   inputs and/or multiple outputs. Of the two items in the array, the
   *   first is the input feature(s) and the second is the output target(s).
   * @param args A configuration object for the dataset-based evaluation.
   * @returns Loss and metric values as an Array of `Scalar` objects.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async evaluateDataset(t, e) {
    return this.makeTestFunction(), FE(this, t, e);
  }
  /**
   * Get number of samples provided for training, evaluation or prediction.
   *
   * @param ins Input `tf.Tensor`.
   * @param batchSize Integer batch size, optional.
   * @param steps Total number of steps (batches of samples) before
   * declaring loop finished. Optional.
   * @param stepsName The public API's parameter name for `steps`.
   * @returns Number of samples provided.
   */
  checkNumSamples(t, e, s, o = "steps") {
    let r;
    if (s != null) {
      if (r = null, e != null)
        throw new E(`If ${o} is set, batchSize must be null or undefined.Got batchSize = ${e}`);
    } else if (t != null)
      Array.isArray(t) ? r = t[0].shape[0] : r = t.shape[0];
    else
      throw new E(`Either the input data should have a defined shape, or ${o} shoud be specified.`);
    return r;
  }
  /**
   * Execute internal tensors of the model with input data feed.
   * @param inputs Input data feed. Must match the inputs of the model.
   * @param outputs Names of the output tensors to be fetched. Must match
   *   names of the SymbolicTensors that belong to the graph.
   * @returns Fetched values for `outputs`.
   */
  execute(t, e) {
    if (Array.isArray(e) && e.length === 0)
      throw new E("`outputs` is an empty Array, which is not allowed.");
    const s = Array.isArray(e), o = s ? e : [e], r = this.retrieveSymbolicTensors(o), i6 = new Gs();
    if (t instanceof Lt && (t = [t]), Array.isArray(t)) {
      if (t.length !== this.inputs.length)
        throw new E(`The number of inputs provided (${t.length}) does not match the number of inputs of this model (${this.inputs.length}).`);
      for (let l = 0; l < this.inputs.length; ++l)
        i6.add(this.inputs[l], t[l]);
    } else
      for (const l of this.inputs) {
        const c = t[l.name];
        if (c == null)
          throw new E(`No value is provided for the model's input ${l.name}`);
        i6.add(l, c);
      }
    const a = Ar(r, i6);
    return s ? a : a[0];
  }
  /**
   * Retrieve the model's internal symbolic tensors from symbolic-tensor names.
   */
  retrieveSymbolicTensors(t) {
    const e = Ro(null, t.length);
    let s = t.length;
    for (const o of this.layers) {
      const r = Array.isArray(o.output) ? o.output : [o.output], i6 = r.map((a) => a.name);
      for (let a = 0; a < t.length; ++a) {
        const l = i6.indexOf(t[a]);
        if (l !== -1 && (e[a] = r[l], s--), s === 0)
          break;
      }
      if (s === 0)
        break;
    }
    if (s > 0) {
      const o = [];
      throw e.forEach((r, i6) => {
        r == null && o.push(t[i6]);
      }), new E(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(o)}`);
    }
    return e;
  }
  /**
   * Helper method to loop over some data in batches.
   *
   * Porting Note: Not using the functional approach in the Python equivalent
   *   due to the imperative backend.
   * Porting Note: Does not support step mode currently.
   *
   * @param ins: input data
   * @param batchSize: integer batch size.
   * @param verbose: verbosity model
   * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of
   *   `tf.Tensor` (if multipe outputs).
   */
  predictLoop(t, e = 32, s = false) {
    return D(() => {
      const o = this.checkNumSamples(t);
      if (s)
        throw new xt("Verbose predictLoop() is not implemented yet.");
      const r = Ru(o, e), i6 = this.outputs.map((a) => []);
      for (let a = 0; a < r.length; ++a)
        D(() => {
          const c = r[a][0], u = r[a][1], d = Wr(t, c, u), h6 = [];
          if (Array.isArray(d))
            for (let f = 0; f < d.length; ++f)
              h6.push({ key: this.inputs[f], value: d[f] });
          else
            h6.push({ key: this.inputs[0], value: d });
          const p6 = new Gs(h6);
          return Ar(this.outputs, p6);
        }).forEach((c, u) => i6[u].push(c));
      return Pe(i6.map((a) => Ge(a, 0)));
    });
  }
  /**
   * Generates output predictions for the input samples.
   *
   * Computation is done in batches.
   *
   * Note: the "step" mode of predict() is currently not supported.
   *   This is because the TensorFlow.js core backend is imperative only.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();
   * ```
   *
   * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if
   *   the model has multiple inputs.
   * @param args A `ModelPredictArgs` object containing optional fields.
   *
   * @return Prediction results as a `tf.Tensor`(s).
   *
   * @exception ValueError In case of mismatch between the provided input data
   *   and the model's expectations, or in case a stateful model receives a
   *   number of samples that is not a multiple of the batch size.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predict(t, e = {}) {
    const s = Wx(t);
    Fm(s, this.inputNames, this.feedInputShapes, false);
    try {
      const o = e.batchSize == null ? 32 : e.batchSize;
      return Nu(o), this.predictLoop(s, o);
    } finally {
      Mn(s, t);
    }
  }
  /**
   * Returns predictions for a single batch of samples.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.predictOnBatch(tf.ones([8, 10])).print();
   * ```
   * @param x: Input samples, as a Tensor (for models with exactly one
   *   input) or an array of Tensors (for models with more than one input).
   * @return Tensor(s) of predictions
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predictOnBatch(t) {
    Fm(t, this.inputNames, this.feedInputShapes, true);
    const e = (Array.isArray(t) ? t[0] : t).shape[0];
    return this.predictLoop(t, e);
  }
  standardizeUserDataXY(t, e, s = true, o) {
    if (this.optimizer_ == null)
      throw new Cn("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
    const r = [];
    for (let i6 = 0; i6 < this.feedOutputShapes.length; ++i6) {
      const a = this.feedOutputShapes[i6];
      this.feedLossFns[i6] === yl ? r.push(a.slice(0, a.length - 1).concat([1])) : r.push(a);
    }
    if (t = Dm(t, this.feedInputNames, this.feedInputShapes, false, "input"), e = Dm(e, this.feedOutputNames, r, false, "target"), zE(t, e), XE(e, this.feedLossFns, this.feedOutputShapes), this.stateful && o != null && o > 0 && t[0].shape[0] % o !== 0)
      throw new E(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${o}. Found: ${t[0].shape[0]} sample(s).`);
    return [t, e];
  }
  async standardizeUserData(t, e, s, o, r = true, i6) {
    const [a, l] = this.standardizeUserDataXY(t, e, r, i6);
    if (s != null)
      throw new Error("sample weight is not supported yet.");
    let c = null;
    if (o != null) {
      const u = Ex(o, this.outputNames);
      c = [];
      for (let d = 0; d < u.length; ++d)
        c.push(await Lx(l[d], null, u[d]));
    }
    return [a, l, c];
  }
  /**
   * Loop over some test data in batches.
   * @param f A Function returning a list of tensors.
   * @param ins Array of tensors to be fed to `f`.
   * @param batchSize Integer batch size or `null` / `undefined`.
   * @param verbose verbosity mode.
   * @param steps Total number of steps (batches of samples) before
   * declaring test finished. Ignored with the default value of `null` /
   * `undefined`.
   * @returns Array of Scalars.
   */
  testLoop(t, e, s, o = 0, r) {
    return D(() => {
      const i6 = this.checkNumSamples(e, s, r, "steps"), a = [];
      if (o > 0)
        throw new xt("Verbose mode is not implemented yet.");
      if (r != null)
        throw new xt("steps mode in testLoop() is not implemented yet");
      {
        const l = Ru(i6, s), c = Je(On(0, i6));
        for (let u = 0; u < l.length; ++u) {
          const d = l[u][0], h6 = l[u][1], p6 = mo(c, d, h6 - d), f = $d(e, p6), m = t(f);
          if (u === 0)
            for (let g6 = 0; g6 < m.length; ++g6)
              a.push(gt(0));
          for (let g6 = 0; g6 < m.length; ++g6) {
            const b6 = m[g6];
            a[g6] = U(a[g6], G(h6 - d, b6));
          }
        }
        for (let u = 0; u < a.length; ++u)
          a[u] = ut(a[u], i6);
      }
      return a;
    });
  }
  getDedupedMetricsNames() {
    const t = this.metricsNames, e = [];
    for (let s = 0; s < t.length; ++s) {
      const o = t[s];
      let r = o;
      if (wm(t, o) > 1) {
        const i6 = wm(t.slice(0, s), o);
        r += `_${i6}`;
      }
      e.push(r);
    }
    return e;
  }
  /**
   * Creates a function that performs the following actions:
   *
   * 1. computes the losses
   * 2. sums them to get the total loss
   * 3. call the optimizer computes the gradients of the LayersModel's
   *    trainable weights w.r.t. the total loss and update the variables
   * 4. calculates the metrics
   * 5. returns the values of the losses and metrics.
   */
  makeTrainFunction() {
    return (t) => {
      const e = [], s = t.slice(0, this.inputs.length), o = t.slice(this.inputs.length, this.inputs.length + this.outputs.length), r = t.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2), i6 = [], a = () => {
        const d = [];
        for (let m = 0; m < this.inputs.length; ++m)
          d.push({ key: this.inputs[m], value: s[m] });
        const h6 = new Gs(d), p6 = Ar(this.outputs, h6, { training: true });
        let f;
        for (let m = 0; m < this.lossFunctions.length; ++m) {
          const g6 = this.lossFunctions[m];
          let b6 = g6(o[m], p6[m]);
          r[m] != null && (b6 = GE(b6, r[m]));
          const x6 = se(b6);
          e.push(x6), m === 0 ? f = b6 : f = U(f, b6);
        }
        for (let m = 0; m < this.metricsTensors.length; ++m) {
          let g6;
          if (this.outputs.length > 1 && m < this.outputs.length)
            g6 = e[m];
          else {
            const b6 = this.metricsTensors[m][0], x6 = this.metricsTensors[m][1];
            g6 = se(b6(o[x6], p6[x6]));
          }
          cn(g6), i6.push(g6);
        }
        return f = se(f), this.calculateLosses().forEach((m) => {
          f = U(f, m);
        }), f;
      }, l = this.collectedTrainableWeights.map((d) => d.read()), c = true;
      return [this.optimizer_.minimize(a, c, l)].concat(i6);
    };
  }
  /**
   * Create a function which, when invoked with an array of `tf.Tensor`s as a
   * batch of inputs, returns the prespecified loss and metrics of the model
   * under the batch of input data.
   */
  makeTestFunction() {
    this.testFunction = (t) => D(() => {
      const e = [];
      let s;
      const o = t.slice(0, this.inputs.length), r = t.slice(this.inputs.length, this.inputs.length + this.outputs.length), i6 = [];
      for (let c = 0; c < this.inputs.length; ++c)
        i6.push({ key: this.inputs[c], value: o[c] });
      const a = new Gs(i6), l = Ar(this.outputs, a);
      for (let c = 0; c < this.lossFunctions.length; ++c) {
        const u = this.lossFunctions[c], d = se(u(r[c], l[c]));
        c === 0 ? s = d : s = U(s, d), e.push(s);
      }
      for (let c = 0; c < this.metricsTensors.length; ++c) {
        const u = this.metricsTensors[c][0], d = this.metricsTensors[c][1], h6 = se(u(r[d], l[d]));
        e.push(h6);
      }
      return e;
    });
  }
  /**
   * Trains the model for a fixed number of epochs (iterations on a
   * dataset).
   *
   * ```js
   * const model = tf.sequential({
   *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * for (let i = 1; i < 5 ; ++i) {
   *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {
   *       batchSize: 4,
   *       epochs: 3
   *   });
   *   console.log("Loss after Epoch " + i + " : " + h.history.loss[0]);
   * }
   * ```
   *
   * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the
   * model has multiple inputs. If all inputs in the model are named, you
   * can also pass a dictionary mapping input names to `tf.Tensor`s.
   * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if
   * the model has multiple outputs. If all outputs in the model are named,
   * you can also pass a dictionary mapping output names to `tf.Tensor`s.
   * @param args A `ModelFitArgs`, containing optional fields.
   *
   * @return A `History` instance. Its `history` attribute contains all
   *   information collected during training.
   *
   * @exception ValueError In case of mismatch between the provided input
   * data and what the model expects.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async fit(t, e, s = {}) {
    if (this.isTraining)
      throw new Error("Cannot start training because another fit() call is ongoing.");
    this.isTraining = true;
    let o, r, i6, a, l, c, u, d, h6;
    try {
      const p6 = s.batchSize == null ? 32 : s.batchSize;
      Nu(p6);
      const f = false, m = await this.standardizeUserData(t, e, s.sampleWeight, s.classWeight, f, p6);
      o = m[0], r = m[1], h6 = m[2];
      let g6 = false, b6;
      if (s.validationData != null && s.validationData.length > 0) {
        if (g6 = true, s.validationData.length === 2)
          l = s.validationData[0], c = s.validationData[1];
        else
          throw s.validationData.length === 3 ? new xt("validationData including sample weights is not supported yet.") : new E(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${s.validationData} is invalid.`);
        const N = true, R = await this.standardizeUserData(
          l,
          c,
          null,
          /** Unused sample weights. */
          null,
          /** Unused class weights. */
          N,
          p6
        );
        u = R[0], d = R[1], b6 = u.concat(d);
      } else if (s.validationSplit != null && s.validationSplit > 0 && s.validationSplit < 1) {
        g6 = true;
        const N = Math.floor(o[0].shape[0] * (1 - s.validationSplit)), R = o[0].shape[0];
        u = Wr(o, N, R), i6 = o, o = Wr(o, 0, N), d = Wr(r, N, R), a = r, r = Wr(r, 0, N), b6 = u.concat(d);
      } else
        s.validationSteps != null && (g6 = true);
      const x6 = o.concat(r).concat(h6);
      this.checkTrainableWeightsConsistency();
      const w6 = this.makeTrainFunction(), y6 = this.getDedupedMetricsNames();
      let I, C6;
      g6 ? (this.makeTestFunction(), I = this.testFunction, C6 = y6.slice().concat(y6.map((N) => "val_" + N))) : (I = null, b6 = [], C6 = y6.slice());
      const k7 = Ix(s.callbacks, s.yieldEvery);
      return await this.fitLoop(w6, x6, y6, p6, s.epochs, s.verbose, k7, I, b6, s.shuffle, C6, s.initialEpoch, null, null);
    } finally {
      this.isTraining = false, Mn(o, t), Mn(r, e), Mn(i6, t), Mn(a, e), Mn(u, l), Mn(d, c), h6 != null && yt(h6);
    }
  }
  /**
   * Abstract fit function for `f(ins)`.
   * @param f A Function returning a list of tensors. For training, this
   *   function is expected to perform the updates to the variables.
   * @param ins List of tensors to be fed to `f`.
   * @param outLabels List of strings, display names of the outputs of `f`.
   * @param batchSize Integer batch size or `== null` if unknown. Default : 32.
   * @param epochs Number of times to iterate over the data. Default : 1.
   * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.
   * @param callbacks List of callbacks to be called during training.
   * @param valF Function to call for validation.
   * @param valIns List of tensors to be fed to `valF`.
   * @param shuffle Whether to shuffle the data at the beginning of every
   * epoch. Default : true.
   * @param callbackMetrics List of strings, the display names of the metrics
   *   passed to the callbacks. They should be the concatenation of the
   *   display names of the outputs of `f` and the list of display names
   *   of the outputs of `valF`.
   * @param initialEpoch Epoch at which to start training (useful for
   *   resuming a previous training run). Default : 0.
   * @param stepsPerEpoch Total number of steps (batches on samples) before
   *   declaring one epoch finished and starting the next epoch. Ignored with
   *   the default value of `undefined` or `null`.
   * @param validationSteps Number of steps to run validation for (only if
   *   doing validation from data tensors). Not applicable for tfjs-layers.
   * @returns A `History` object.
   */
  async fitLoop(t, e, s, o, r, i6, a, l, c, u, d, h6, p6, f) {
    o == null && (o = 32), r == null && (r = 1), u == null && (u = true), h6 == null && (h6 = 0);
    let m = false;
    if (l != null && c != null && (m = true), f != null && (m = true, p6 == null))
      throw new E("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
    const g6 = this.checkNumSamples(e, o, p6, "steps_per_epoch");
    let b6;
    g6 != null && (b6 = On(0, g6)), i6 == null && (i6 = 1);
    const { callbackList: x6, history: w6 } = Cx(a, i6, r, h6, g6, p6, o, m, d);
    x6.setModel(this), this.history = w6, await x6.onTrainBegin(), this.stopTraining_ = false;
    for (let y6 = h6; y6 < r; ++y6) {
      await x6.onEpochBegin(y6);
      const I = {};
      if (p6 != null)
        throw new xt("stepsPerEpoch mode is not implemented yet.");
      {
        if (u === "batch")
          throw new xt("batch shuffling is not implemneted yet");
        u && Pd(b6);
        const C6 = Je(b6), k7 = Ru(g6, o);
        for (let S = 0; S < k7.length; ++S) {
          const N = {};
          if (await x6.onBatchBegin(S, N), D(() => {
            const R = k7[S][0], M6 = k7[S][1], V = mo(C6, R, M6 - R);
            N.batch = S, N.size = M6 - R;
            const z = $d(e, V), X = t(z);
            for (let P6 = 0; P6 < s.length; ++P6) {
              const A6 = s[P6], B6 = X[P6];
              N[A6] = B6, cn(B6);
            }
            if (S === k7.length - 1 && m) {
              const P6 = this.testLoop(l, c, o);
              for (let A6 = 0; A6 < s.length; ++A6) {
                const B6 = s[A6], Z = P6[A6];
                cn(Z), I["val_" + B6] = Z;
              }
            }
          }), await x6.onBatchEnd(S, N), wx(N), this.stopTraining_)
            break;
        }
        C6.dispose();
      }
      if (await x6.onEpochEnd(y6, I), this.stopTraining_)
        break;
    }
    return await x6.onTrainEnd(), await this.history.syncData(), this.history;
  }
  // TODO(cais): Add code snippet below when it's possible to instantiate
  //   actual dataset objects.
  /**
   * Trains the model using a dataset object.
   *
   * @param dataset A dataset object. Its `iterator()` method is expected
   *   to generate a dataset iterator object, the `next()` method of which
   *   is expected to produce data batches for training. The return value
   *   of the `next()` call ought to contain a boolean `done` field and a
   *   `value` field. The `value` field is expected to be an array of two
   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
   *   case is for models with exactly one input and one output (e.g.
   *   a sequential model). The latter case is for models with multiple
   *   inputs and/or multiple outputs.
   *   Of the two items in the array, the first is the input feature(s) and
   *   the second is the output target(s).
   * @param args A `ModelFitDatasetArgs`, containing optional fields.
   *
   * @return A `History` instance. Its `history` attribute contains all
   *   information collected during training.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async fitDataset(t, e) {
    return ME(this, t, e);
  }
  /**
   * Runs a single gradient update on a single batch of data.
   *
   * This method differs from `fit()` and `fitDataset()` in the following
   * regards:
   *   - It operates on exactly one batch of data.
   *   - It returns only the loss and metric values, instead of
   *     returning the batch-by-batch loss and metric values.
   *   - It doesn't support fine-grained options such as verbosity and
   *     callbacks.
   *
   * @param x Input data. It could be one of the following:
   *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has
   *     multiple inputs).
   *   - An Object mapping input names to corresponding `tf.Tensor` (if the
   *     model has named inputs).
   * @param y Target data. It could be either a `tf.Tensor` or multiple
   *   `tf.Tensor`s. It should be consistent with `x`.
   * @returns Training loss or losses (in case the model has
   *   multiple outputs), along with metrics (if any), as numbers.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async trainOnBatch(t, e) {
    const s = await this.standardizeUserData(t, e), o = s[0], r = s[1], a = this.makeTrainFunction()(o.concat(r)), l = [];
    for (const c of a) {
      const u = await c.data();
      l.push(u[0]);
    }
    return yt(a), Mn(s[0], t), Mn(s[1], e), Pe(l);
  }
  /**
   * Extract weight values of the model.
   *
   * @param config: An instance of `io.SaveConfig`, which specifies
   * model-saving options such as whether only trainable weights are to be
   * saved.
   * @returns A `NamedTensorMap` mapping original weight names (i.e.,
   *   non-uniqueified weight names) to their values.
   */
  getNamedWeights(t) {
    const e = [], s = t != null && t.trainableOnly, o = s ? this.trainableWeights : this.weights, r = this.getWeights(s);
    for (let i6 = 0; i6 < o.length; ++i6)
      s && !o[i6].trainable || e.push({ name: o[i6].originalName, tensor: r[i6] });
    return e;
  }
  /**
   * Setter used for force stopping of LayersModel.fit() (i.e., training).
   *
   * Example:
   *
   * ```js
   * const input = tf.input({shape: [10]});
   * const output = tf.layers.dense({units: 1}).apply(input);
   * const model = tf.model({inputs: [input], outputs: [output]});
   * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});
   * const xs = tf.ones([8, 10]);
   * const ys = tf.zeros([8, 1]);
   *
   * const history = await model.fit(xs, ys, {
   *   epochs: 10,
   *   callbacks: {
   *     onEpochEnd: async (epoch, logs) => {
   *       if (epoch === 2) {
   *         model.stopTraining = true;
   *       }
   *     }
   *   }
   * });
   *
   * // There should be only 3 values in the loss array, instead of 10
   * values,
   * // due to the stopping after 3 epochs.
   * console.log(history.history.loss);
   * ```
   */
  set stopTraining(t) {
    this.stopTraining_ = t;
  }
  get stopTraining() {
    return this.stopTraining_;
  }
  get optimizer() {
    return this.optimizer_;
  }
  set optimizer(t) {
    this.optimizer_ !== t && (this.optimizer_ = t, this.isOptimizerOwned = false);
  }
  dispose() {
    const t = super.dispose();
    if (t.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {
      const e = cl().numTensors;
      this.optimizer_.dispose(), t.numDisposedVariables += e - cl().numTensors;
    }
    return t;
  }
  getLossIdentifiers() {
    let t;
    if (typeof this.loss == "string")
      t = cs(this.loss);
    else if (Array.isArray(this.loss)) {
      for (const e of this.loss)
        if (typeof e != "string")
          throw new Error("Serialization of non-string loss is not supported.");
      t = this.loss.map((e) => cs(e));
    } else {
      const e = Object.keys(this.loss);
      t = {};
      const s = this.loss;
      for (const o of e)
        if (typeof s[o] == "string")
          t[o] = cs(s[o]);
        else
          throw new Error("Serialization of non-string loss is not supported.");
    }
    return t;
  }
  getMetricIdentifiers() {
    if (typeof this.metrics == "string" || typeof this.metrics == "function")
      return [cs(za(this.metrics))];
    if (Array.isArray(this.metrics))
      return this.metrics.map((t) => cs(za(t)));
    {
      const t = {};
      for (const e in this.metrics)
        t[e] = cs(za(this.metrics[e]));
      return t;
    }
  }
  getTrainingConfig() {
    return {
      loss: this.getLossIdentifiers(),
      metrics: this.getMetricIdentifiers(),
      optimizer_config: {
        class_name: this.optimizer.getClassName(),
        config: this.optimizer.getConfig()
      }
    };
  }
  loadTrainingConfig(t) {
    if (t.weighted_metrics != null)
      throw new Error("Loading weight_metrics is not supported yet.");
    if (t.loss_weights != null)
      throw new Error("Loading loss_weights is not supported yet.");
    if (t.sample_weight_mode != null)
      throw new Error("Loading sample_weight_mode is not supported yet.");
    const e = si(t.optimizer_config), s = Pn(e);
    let o;
    if (typeof t.loss == "string")
      o = ro(t.loss);
    else if (Array.isArray(t.loss))
      o = t.loss.map((i6) => ro(i6));
    else if (t.loss != null) {
      o = {};
      for (const i6 in t.loss)
        o[i6] = ro(t.loss[i6]);
    }
    let r;
    if (Array.isArray(t.metrics))
      r = t.metrics.map((i6) => ro(i6));
    else if (t.metrics != null) {
      r = {};
      for (const i6 in t.metrics)
        r[i6] = ro(t.metrics[i6]);
    }
    this.compile({ loss: o, metrics: r, optimizer: s });
  }
  /**
   * Save the configuration and/or weights of the LayersModel.
   *
   * An `IOHandler` is an object that has a `save` method of the proper
   * signature defined. The `save` method manages the storing or
   * transmission of serialized data ("artifacts") that represent the
   * model's topology and weights onto or via a specific medium, such as
   * file downloads, local storage, IndexedDB in the web browser and HTTP
   * requests to a server. TensorFlow.js provides `IOHandler`
   * implementations for a number of frequently used saving mediums, such as
   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`
   * for more details.
   *
   * This method also allows you to refer to certain types of `IOHandler`s
   * as URL-like string shortcuts, such as 'localstorage://' and
   * 'indexeddb://'.
   *
   * Example 1: Save `model`'s topology and weights to browser [local
   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);
   * then load it back.
   *
   * ```js
   * const model = tf.sequential(
   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
   * console.log('Prediction from original model:');
   * model.predict(tf.ones([1, 3])).print();
   *
   * const saveResults = await model.save('localstorage://my-model-1');
   *
   * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');
   * console.log('Prediction from loaded model:');
   * loadedModel.predict(tf.ones([1, 3])).print();
   * ```
   *
   * Example 2. Saving `model`'s topology and weights to browser
   * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);
   * then load it back.
   *
   * ```js
   * const model = tf.sequential(
   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
   * console.log('Prediction from original model:');
   * model.predict(tf.ones([1, 3])).print();
   *
   * const saveResults = await model.save('indexeddb://my-model-1');
   *
   * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');
   * console.log('Prediction from loaded model:');
   * loadedModel.predict(tf.ones([1, 3])).print();
   * ```
   *
   * Example 3. Saving `model`'s topology and weights as two files
   * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from
   * browser.
   *
   * ```js
   * const model = tf.sequential(
   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
   * const saveResults = await model.save('downloads://my-model-1');
   * ```
   *
   * Example 4. Send  `model`'s topology and weights to an HTTP server.
   * See the documentation of `tf.io.http` for more details
   * including specifying request parameters and implementation of the
   * server.
   *
   * ```js
   * const model = tf.sequential(
   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
   * const saveResults = await model.save('http://my-server/model/upload');
   * ```
   *
   * @param handlerOrURL An instance of `IOHandler` or a URL-like,
   * scheme-based string shortcut for `IOHandler`.
   * @param config Options for saving the model.
   * @returns A `Promise` of `SaveResult`, which summarizes the result of
   * the saving, such as byte sizes of the saved artifacts for the model's
   *   topology and weight values.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  async save(t, e) {
    if (typeof t == "string") {
      const c = LC(t);
      if (c.length === 0)
        throw new E(`Cannot find any save handlers for URL '${t}'`);
      if (c.length > 1)
        throw new E(`Found more than one (${c.length}) save handlers for URL '${t}'`);
      t = c[0];
    }
    if (t.save == null)
      throw new E("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    const s = await sm(this.getNamedWeights(e)), o = false, r = null, a = {
      modelTopology: this.toJSON(r, o),
      format: AE,
      generatedBy: `TensorFlow.js tfjs-layers v${Gx}`,
      convertedBy: null
    };
    if ((e == null ? false : e.includeOptimizer) && this.optimizer != null) {
      a.trainingConfig = this.getTrainingConfig();
      const c = "optimizer", { data: u, specs: d } = await sm(await this.optimizer.getWeights(), c);
      s.specs.push(...d), s.data = bb([s.data, u]);
    }
    return this.userDefinedMetadata != null && (Em(this.userDefinedMetadata, this.name, true), a.userDefinedMetadata = this.userDefinedMetadata), a.weightData = s.data, a.weightSpecs = s.specs, t.save(a);
  }
  /**
   * Set user-defined metadata.
   *
   * The set metadata will be serialized together with the topology
   * and weights of the model during `save()` calls.
   *
   * @param setUserDefinedMetadata
   */
  setUserDefinedMetadata(t) {
    Em(t, this.name), this.userDefinedMetadata = t;
  }
  /**
   * Get user-defined metadata.
   *
   * The metadata is supplied via one of the two routes:
   *   1. By calling `setUserDefinedMetadata()`.
   *   2. Loaded during model loading (if the model is constructed
   *      via `tf.loadLayersModel()`.)
   *
   * If no user-defined metadata is available from either of the
   * two routes, this function will return `undefined`.
   */
  getUserDefinedMetadata() {
    return this.userDefinedMetadata;
  }
};
tr.className = "Model";
_(tr);
var Dx = class extends tr {
};
Dx.className = "Functional";
_(Dx);
async function CY(n, t) {
  "modelTopology" in n || (n = { modelTopology: n }), n = n;
  let e = n.modelTopology;
  e.model_config != null && (e = e.model_config);
  const s = si(e), o = Pn(s, t);
  if (n.weightsManifest != null) {
    const r = await AN(n.weightsManifest, n.pathPrefix, o.weights.map((a) => a.originalName)), i6 = {};
    for (const a of o.weights)
      i6[a.originalName] = r[a.originalName];
    o.loadWeights(i6), yt(r);
  }
  return o;
}
async function vY(n, t) {
  if (t == null && (t = {}), typeof n == "string") {
    const e = MC(n, t);
    if (e.length === 0)
      e.push(HN(n, t));
    else if (e.length > 1)
      throw new E(`Found more than one (${e.length}) load handlers for URL '${n}'`);
    n = e[0];
  }
  return OE(n, void 0, t);
}
async function OE(n, t, e) {
  if (e == null && (e = {}), n.load == null)
    throw new E("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
  const s = await n.load();
  let o = s.modelTopology;
  o.model_config != null && (o = o.model_config);
  const r = e.strict == null ? true : e.strict, i6 = s.weightData != null && s.weightSpecs != null && r, a = Pn(si(o), t, i6), l = s.trainingConfig;
  if (l != null && a.loadTrainingConfig(l), s.userDefinedMetadata != null && a.setUserDefinedMetadata(s.userDefinedMetadata), s.weightData != null) {
    if (s.weightSpecs == null)
      throw new E("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");
    const { modelWeights: c, optimizerWeights: u } = KE(s.weightData, s.weightSpecs);
    a.loadWeights(c, r), a.optimizer != null && u.length > 0 && await a.optimizer.setWeights(u), yt(c), yt(u.map((d) => d.tensor));
  }
  return a;
}
function KE(n, t) {
  const e = gb(n, t), s = {}, o = [];
  return t.forEach((r) => {
    r.group === "optimizer" ? o.push({ name: r.name, tensor: e[r.name] }) : s[r.name] = e[r.name];
  }), { modelWeights: s, optimizerWeights: o };
}
var oi = class extends tr {
  constructor(t) {
    if (super({ inputs: [], outputs: [] }), t = t || {}, this.trainable = true, this.built = false, this.name = t.name != null ? t.name : Jc("sequential_"), t.layers != null)
      for (const e of t.layers)
        this.add(e);
  }
  // Helper function to Sequential.add  Throws if the new output shape will be
  // invalid.
  checkShape(t) {
    if (t.inboundNodes[0].outputTensors[0].shape.some((s) => s < 0))
      throw new E(`Negative dimension size caused by adding layer ${t.name} with input shape [${t.inboundNodes[0].inputTensors[0].shape}]`);
  }
  /**
   * Adds a layer instance on top of the layer stack.
   *
   * ```js
   *  const model = tf.sequential();
   *  model.add(tf.layers.dense({units: 8, inputShape: [1]}));
   *  model.add(tf.layers.dense({units: 4, activation: 'relu6'}));
   *  model.add(tf.layers.dense({units: 1, activation: 'relu6'}));
   *  // Note that the untrained model is random at this point.
   *  model.predict(tf.randomNormal([10, 1])).print();
   * ```
   * @param layer Layer instance.
   *
   * @exception ValueError In case the `layer` argument does not know its
   * input shape.
   * @exception ValueError In case the `layer` argument has multiple output
   *   tensors, or is already connected somewhere else (forbidden in
   *   `Sequential` models).
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  add(t) {
    const e = t instanceof oi || t instanceof tr;
    let s;
    if (e) {
      if (s = t, s.outputs.length !== 1)
        throw new E("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      if (s.inputs.length !== 1)
        throw new E("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.");
    }
    if (this.outputs.length === 0) {
      if (t.inboundNodes.length === 0) {
        if (t.batchInputShape == null)
          throw new E("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");
        const o = ZG({
          batchShape: t.batchInputShape,
          dtype: t.dtype,
          name: t.name + "_input"
        });
        t.apply(o);
      }
      if (e)
        this.outputs = s.outputs, this.inputs = s.inputs;
      else {
        if (t.inboundNodes.length !== 1)
          throw new E(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t.name} which has ${t.inboundNodes.length} pre-existing inbound connections.`);
        if (t.inboundNodes[0].outputTensors.length !== 1)
          throw new E("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
        this.checkShape(t), this.outputs = [t.inboundNodes[0].outputTensors[0]], this.inputs = mx(this.outputs[0]);
      }
      this.inboundNodes = [], new qc({
        outboundLayer: this,
        inboundLayers: [],
        nodeIndices: [],
        tensorIndices: [],
        inputTensors: this.inputs,
        outputTensors: this.outputs,
        // no model-level masking for now
        inputMasks: Ro(null, this.inputs.length),
        outputMasks: [null],
        inputShapes: this.inputs.map((o) => o.shape),
        outputShapes: this.outputs[0].shape
      });
    } else {
      const o = t.apply(this.outputs[0]);
      if (Array.isArray(o))
        throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      this.checkShape(t), this.outputs = [o], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
    this.layers.push(t), this.built = false;
  }
  /**
   * Removes the last layer in the model.
   *
   * @exception TypeError if there are no layers in the model.
   */
  pop() {
    if (this.layers.length === 0)
      throw new TypeError("There are no layers in the model.");
    if (this.layers.pop(), this.layers.length === 0)
      this.outputs = [], this.inboundNodes = [], this.outboundNodes = [];
    else {
      const t = this.layers.length - 1;
      this.layers[t].outboundNodes = [], this.outputs = [this.layers[t].output], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
  }
  call(t, e) {
    return this.model == null && this.build(), this.model.call(t, e);
  }
  build(t) {
    if ($t(t), this.inputs.length === 0 || this.outputs.length === 0)
      throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
    this.model = new tr({
      inputs: this.inputs,
      outputs: this.outputs[0],
      name: this.name + "_model"
    }), this.model.trainable = this.trainable, this.supportsMasking = this.model.supportsMasking, this.inputLayers = this.model.inputLayers, this.inputLayersNodeIndices = this.model.inputLayersNodeIndices, this.inputLayersTensorIndices = this.model.inputLayersTensorIndices, this.outputLayers = this.model.outputLayers, this.outputLayersNodeIndices = this.model.outputLayersNodeIndices, this.outputLayersTensorIndices = this.model.outputLayersTensorIndices, this.nodesByDepth = this.model.nodesByDepth, this.containerNodes = this.model.containerNodes, this.outputNames = this.model.outputNames, this.inputNames = this.model.inputNames, this.built = true;
  }
  countParams() {
    return this.built || this.build(), super.countParams();
  }
  /**
   * Print a text summary of the Sequential model's layers.
   *
   * The summary includes
   * - Name and type of all layers that comprise the model.
   * - Output shape(s) of the layers
   * - Number of weight parameters of each layer
   * - The total number of trainable and non-trainable parameters of the
   * model.
   *
   * ```js
   * const model = tf.sequential();
   * model.add(
   *     tf.layers.dense({units: 100, inputShape: [10], activation: 'relu'}));
   * model.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));
   *
   * model.summary();
   * ```
   *
   * @param lineLength Custom line length, in number of characters.
   * @param positions Custom widths of each of the columns, as either
   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number
   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to
   *   right-most (i.e., ending) position of a column.
   * @param printFn Custom print function. Can be used to replace the default
   *   `console.log`. For example, you can use `x => {}` to mute the printed
   *   messages in the console.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  summary(t, e, s = console.log) {
    this.built || this.build(), super.summary(t, e, s);
  }
  /**
   * Sets the weights of the model.
   *
   * @param weights Should be a list of Tensors with shapes and types matching
   *   the output of `model.getWeights()`.
   */
  setWeights(t) {
    this.model == null && this.build(), this.model.setWeights(t);
  }
  /**
   * Returns the loss value & metrics values for the model in test mode.
   *
   * Loss and metrics are specified during `compile()`, which needs to happen
   * before calls to `evaluate()`.
   *
   * Computation is done in batches.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * const result = model.evaluate(tf.ones([8, 10]), tf.ones([8, 1]), {
   *   batchSize: 4,
   * });
   * result.print();
   * ```
   *
   * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the
   * model has multiple inputs.
   * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the
   * model has multiple outputs.
   * @param args A `ModelEvaluateConfig`, containing optional fields.
   *
   * @return `Scalar` test loss (if the model has a single output and no
   *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs
   *   and/or metrics). The attribute `model.metricsNames`
   *   will give you the display labels for the scalar outputs.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  evaluate(t, e, s = {}) {
    if (!this.built)
      throw new Cn("The model needs to be compiled before being used.");
    return this.model.evaluate(t, e, s);
  }
  // TODO(cais): Add code snippet below once real dataset objects are
  //   available.
  /**
   * Evaluate model using a dataset object.
   *
   * Note: Unlike `evaluate()`, this method is asynchronous (`async`).
   *
   * @param dataset A dataset object. Its `iterator()` method is expected
   *   to generate a dataset iterator object, the `next()` method of which
   *   is expected to produce data batches for evaluation. The return value
   *   of the `next()` call ought to contain a boolean `done` field and a
   *   `value` field. The `value` field is expected to be an array of two
   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
   *   case is for models with exactly one input and one output (e.g.
   *   a sequential model). The latter case is for models with multiple
   *   inputs and/or multiple outputs. Of the two items in the array, the
   *   first is the input feature(s) and the second is the output target(s).
   * @param args A configuration object for the dataset-based evaluation.
   * @returns Loss and metric values as an Array of `Scalar` objects.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async evaluateDataset(t, e) {
    if (!this.built)
      throw new Cn("The model needs to be compiled before being used.");
    return this.model.evaluateDataset(t, e);
  }
  /**
   * Generates output predictions for the input samples.
   *
   * Computation is done in batches.
   *
   * Note: the "step" mode of predict() is currently not supported.
   *   This is because the TensorFlow.js core backend is imperative only.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.predict(tf.ones([2, 10])).print();
   * ```
   *
   * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if
   *   the model has multiple inputs.
   * @param conifg A `ModelPredictConfig` object containing optional fields.
   *
   * @return `tf.Tensor`(s) of predictions.
   *
   * @exception ValueError In case of mismatch between the provided input data
   *   and the model's expectations, or in case a stateful model receives a
   *   number of samples that is not a multiple of the batch size.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predict(t, e = {}) {
    return this.model == null && this.build(), this.model.predict(t, e);
  }
  /**
   * Returns predictions for a single batch of samples.
   *
   * @param x: Input samples, as a Tensor, or list of Tensors (if the model
   *   has multiple inputs).
   * @return Tensor(s) of predictions
   */
  predictOnBatch(t) {
    return this.model == null && this.build(), this.model.predictOnBatch(t);
  }
  /**
   * See `LayersModel.compile`.
   *
   * @param args
   */
  compile(t) {
    this.build(), this.model.compile(t), this.optimizer_ = this.model.optimizer, this.isOptimizerOwned = this.model.isOptimizerOwned, this.loss = this.model.loss, this.metrics = this.model.metrics, this.metricsTensors = this.model.metricsTensors, this.metricsNames = this.model.metricsNames;
  }
  get optimizer() {
    return this.model == null ? void 0 : this.model.optimizer;
  }
  set optimizer(t) {
    this.model.optimizer = t;
  }
  /**
   * Trains the model for a fixed number of epochs (iterations on a dataset).
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * const history = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {
   *   batchSize: 4,
   *   epochs: 3
   * });
   * console.log(history.history.loss[0]);
   * ```
   *
   * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the
   * model has multiple inputs. If all inputs in the model are named, you can
   * also pass a dictionary mapping input names to `tf.Tensor`s.
   * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if
   * the model has multiple outputs. If all outputs in the model are named, you
   *  can also pass a dictionary mapping output names to `tf.Tensor`s.
   * @param args  A `ModelFitConfig`, containing optional fields.
   *
   * @return A `History` instance. Its `history` attribute contains all
   *   information collected during training.
   *
   * @exception ValueError In case of mismatch between the provided input data
   *   and what the model expects.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async fit(t, e, s = {}) {
    if (!this.built)
      throw new Cn("The model needs to be compiled before being used.");
    return this.model.fit(t, e, s);
  }
  /**
   * Trains the model using a dataset object.
   *
   * ```js
   * const xArray = [
   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
   * ];
   * const yArray = [1, 1, 1, 1];
   * // Create a dataset from the JavaScript array.
   * const xDataset = tf.data.array(xArray);
   * const yDataset = tf.data.array(yArray);
   * // Zip combines the `x` and `y` Datasets into a single Dataset, the
   * // iterator of which will return an object containing of two tensors,
   * // corresponding to `x` and `y`.  The call to `batch(4)` will bundle
   * // four such samples into a single object, with the same keys now pointing
   * // to tensors that hold 4 examples, organized along the batch dimension.
   * // The call to `shuffle(4)` causes each iteration through the dataset to
   * // happen in a different order.  The size of the shuffle window is 4.
   * const xyDataset = tf.data.zip({xs: xDataset, ys: yDataset})
   *     .batch(4)
   *     .shuffle(4);
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [9]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * const history = await model.fitDataset(xyDataset, {
   *   epochs: 4,
   *   callbacks: {onEpochEnd: (epoch, logs) => console.log(logs.loss)}
   * });
   * ```
   *
   * @param dataset A dataset object. Its `iterator()` method is expected to
   *   generate a dataset iterator object, the `next()` method of which is
   *   expected to produce data batches for evaluation. The return value of the
   *   `next()` call ought to contain a boolean `done` field and a `value`
   *   field.
   *
   *   The `value` field is expected to be an object of with fields
   *   `xs` and `ys`, which point to the feature tensor and the target tensor,
   *   respectively. This case is for models with exactly one input and one
   *   output (e.g. a sequential model). For example:
   *   ```js
   *   {value: {xs: xsTensor, ys: ysTensor}, done: false}
   *   ```
   *
   *   If the model has multiple inputs, the `xs` field of `value` should
   *   be an object mapping input names to their respective feature tensors.
   *   For example:
   *   ```js
   *   {
   *     value: {
   *       xs: {
   *         input_1: xsTensor1,
   *         input_2: xsTensor2
   *       },
   *       ys: ysTensor
   *     },
   *     done: false
   *   }
   *   ```
   *   If the model has multiple outputs, the `ys` field of `value` should
   *   be an object mapping output names to their respective target tensors.
   *   For example:
   *   ```js
   *   {
   *     value: {
   *       xs: xsTensor,
   *       ys: {
   *         output_1: ysTensor1,
   *         output_2: ysTensor2
   *       },
   *     },
   *     done: false
   *   }
   *   ```
   * @param args A `ModelFitDatasetArgs`, containing optional fields.
   *
   * @return A `History` instance. Its `history` attribute contains all
   *   information collected during training.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  async fitDataset(t, e) {
    if (!this.built)
      throw new Cn("The model needs to be compiled before being used.");
    return this.model.fitDataset(t, e);
  }
  /**
   * Runs a single gradient update on a single batch of data.
   *
   * This method differs from `fit()` and `fitDataset()` in the following
   * regards:
   *   - It operates on exactly one batch of data.
   *   - It returns only the loss and metric values, instead of
   *     returning the batch-by-batch loss and metric values.
   *   - It doesn't support fine-grained options such as verbosity and
   *     callbacks.
   *
   * @param x Input data. It could be one of the following:
   *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has
   *     multiple inputs).
   *   - An Object mapping input names to corresponding `tf.Tensor` (if the
   *     model has named inputs).
   * @param y Target data. It could be either a `tf.Tensor` or multiple
   *   `tf.Tensor`s. It should be consistent with `x`.
   * @returns Training loss or losses (in case the model has
   *   multiple outputs), along with metrics (if any), as numbers.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async trainOnBatch(t, e) {
    return this.model.trainOnBatch(t, e);
  }
  /* See parent class for JsDoc */
  /** @nocollapse */
  static fromConfig(t, e, s = {}, o = false) {
    let r, i6 = {};
    if (e instanceof Array) {
      if (e[0].className == null || e[0].className === "Merge")
        throw new E("Legacy serialization format not supported yet.");
      r = e;
    } else
      v2(e.layers != null, () => "When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."), r = e.layers, delete e.layers, i6 = e;
    const a = new t(i6);
    if (!(a instanceof oi))
      throw new xt(`Sequential.fromConfig called on non-Sequential input: ${a}`);
    for (const l of r) {
      const u = Pn(l, void 0, o);
      o && u.setFastWeightInitDuringBuild(true), a.add(u);
    }
    return a;
  }
  /**
   * Setter used for force stopping of LayersModel.fit() (i.e., training).
   *
   * Example:
   *
   * ```js
   * const model = tf.sequential();
   * model.add(tf.layers.dense({units: 1, inputShape: [10]}));
   * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});
   * const xs = tf.ones([8, 10]);
   * const ys = tf.zeros([8, 1]);
   *
   * const history = await model.fit(xs, ys, {
   *   epochs: 10,
   *   callbacks: {
   *     onEpochEnd: async (epoch, logs) => {
   *       if (epoch === 2) {
   *         model.stopTraining = true;
   *       }
   *     }
   *   }
   * });
   *
   * // There should be only 3 values in the loss array, instead of 10 values,
   * // due to the stopping after 3 epochs.
   * console.log(history.history.loss);
   * ```
   */
  set stopTraining(t) {
    if (this.model == null)
      throw new E("Cannot set the stopTraining property of a sequential model before it is compiled.");
    this.model.stopTraining = t;
  }
  get stopTraining() {
    if (this.model == null)
      throw new E("Cannot get the stopTraining property of a sequential model before it is compiled.");
    return this.model.stopTraining;
  }
  // TODO(cais): Override get trainableWeights() here
  // tslint:disable-next-line:no-any
  getConfig() {
    const t = [];
    for (const e of this.layers) {
      const s = {};
      s.className = e.getClassName(), s.config = e.getConfig(), t.push(s);
    }
    return { name: this.name, layers: t };
  }
};
oi.className = "Sequential";
_(oi);
var He = class extends Vo {
  getConfig() {
    return {};
  }
};
var Fx = class extends He {
  /**
   * Calculate the activation function.
   *
   * @param x: Input.
   * @param alpha: Scaling factor the negative section.
   * @return Output of the ELU activation.
   */
  apply(t, e = 1) {
    return GG(t, e);
  }
};
Fx.className = "elu";
_(Fx);
var Vx = class extends He {
  apply(t) {
    return Bb(t);
  }
};
Vx.className = "selu";
_(Vx);
var zx = class extends He {
  apply(t) {
    return ws(t);
  }
};
zx.className = "relu";
_(zx);
var Xx = class extends He {
  apply(t) {
    return D(() => Kc(6, ws(t)));
  }
};
Xx.className = "relu6";
_(Xx);
var Px = class extends He {
  apply(t) {
    return t;
  }
};
Px.className = "linear";
_(Px);
var Ax = class extends He {
  apply(t) {
    return xr(t);
  }
};
Ax.className = "sigmoid";
_(Ax);
var Ox = class extends He {
  apply(t) {
    return LG(t);
  }
};
Ox.className = "hardSigmoid";
_(Ox);
var Kx = class extends He {
  apply(t) {
    return da(t);
  }
};
Kx.className = "softplus";
_(Kx);
var Zx = class extends He {
  apply(t) {
    return EG(t);
  }
};
Zx.className = "softsign";
_(Zx);
var Bx = class extends He {
  apply(t) {
    return Hh(t);
  }
};
Bx.className = "tanh";
_(Bx);
var xf = class extends He {
  /**
   * Calculate the activation function.
   *
   * @param x Tensor.
   * @param axis Integer, axis along which the softmax normalization is applied.
   * Invalid if < 2, as softmax across 1 (the batch dimension) is assumed to be
   * an error.
   *
   * @returns a Tensor of the same shape as x
   *
   * @throws ValueError: In case `dim(x) < 2`.
   */
  apply(t, e = -1) {
    return bp(t, e);
  }
};
xf.className = "softmax";
_(xf);
var Hx = class extends He {
  /**
   * Calculate the activation function of log softmax:
   * log( exp(x_i) / sum(exp(x)) )
   *
   * @param x Tensor.
   * @param axis Integer, axis along which the softmax normalization is applied.
   * Invalid if < 2, as softmax across 1 (the batch dimension) is assumed to be
   * an error.
   *
   * @returns a Tensor of the same shape as x
   *
   * @throws ValueError: In case `dim(x) < 2`.
   */
  apply(t, e = -1) {
    return Vb(t, e);
  }
};
Hx.className = "logSoftmax";
_(Hx);
var _x = class extends He {
  /**
   * Calculate the activation function.
   *
   * @param x Tensor.
   * @param alpha Scaling factor for the sigmoid function.
   * @returns a Tensor of the same shape as x
   */
  apply(t, e = 1) {
    return D(() => G(xr(G(t, e)), t));
  }
};
_x.className = "swish";
_(_x);
var Ux = class extends He {
  /**
   * Calculate the activation function.
   *
   * @param x Tensor.
   * @returns a Tensor of the same shape as x
   */
  apply(t) {
    return D(() => G(t, Hh(da(t))));
  }
};
Ux.className = "mish";
_(Ux);
function Ps(n) {
  return n.getClassName();
}
function $u(n, t = {}) {
  return ba(n, an.getMap().classNameMap, t, "activation");
}
function As(n) {
  if (n == null) {
    const t = {};
    return t.className = "linear", t.config = {}, $u(t);
  }
  if (typeof n == "string") {
    const t = {};
    return t.className = n, t.config = {}, $u(t);
  } else
    return n instanceof He ? n : $u(n);
}
function yf(n) {
  if (n != null && typeof n != "object")
    throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${n}`);
}
var Yx = class extends Vo {
};
var nu = class extends Yx {
  constructor(t) {
    super(), yf(t), this.l1 = t == null || t.l1 == null ? 0.01 : t.l1, this.l2 = t == null || t.l2 == null ? 0.01 : t.l2, this.hasL1 = this.l1 !== 0, this.hasL2 = this.l2 !== 0;
  }
  /**
   * Porting note: Renamed from __call__.
   * @param x Variable of which to calculate the regularization score.
   */
  apply(t) {
    return D(() => {
      let e = ge([1]);
      return this.hasL1 && (e = U(e, at(G(this.l1, fe(t))))), this.hasL2 && (e = U(e, at(G(this.l2, ya(t))))), W(e, []);
    });
  }
  getConfig() {
    return { l1: this.l1, l2: this.l2 };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t({ l1: e.l1, l2: e.l2 });
  }
};
nu.className = "L1L2";
_(nu);
function TY(n) {
  return yf(n), new nu({ l1: n != null ? n.l1 : null, l2: 0 });
}
function NY(n) {
  return yf(n), new nu({ l2: n != null ? n.l2 : null, l1: 0 });
}
var Vm = {
  l1l2: "L1L2"
};
function Ft(n) {
  return sf(n);
}
function zm(n, t = {}) {
  return ba(n, an.getMap().classNameMap, t, "regularizer");
}
function Yt(n) {
  if (n == null)
    return null;
  if (typeof n == "string") {
    const e = { className: n in Vm ? Vm[n] : n, config: {} };
    return zm(e);
  } else
    return n instanceof Yx ? n : zm(n);
}
var Qx = class extends St {
  constructor(t) {
    super(t ?? {}), this.supportsMasking = true, t != null && (this.maxValue = t.maxValue);
  }
  call(t, e) {
    t = mt(t);
    let s = ws(t);
    return this.maxValue != null && (s = pn(s, 0, this.maxValue)), s;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { maxValue: this.maxValue }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Qx.className = "ReLU";
_(Qx);
var Jx = class extends St {
  constructor(t) {
    super(t ?? {}), this.DEFAULT_ALPHA = 0.3, t == null && (t = {}), this.alpha = t.alpha == null ? this.DEFAULT_ALPHA : t.alpha;
  }
  call(t, e) {
    const s = mt(t);
    return tp(s, this.alpha);
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { alpha: this.alpha }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Jx.className = "LeakyReLU";
_(Jx);
var jx = class extends St {
  constructor(t) {
    if (super(t ?? {}), this.DEFAULT_ALPHA_INITIALIZER = "zeros", t == null && (t = {}), this.supportsMasking = true, this.alphaInitializer = Ut(t.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER), this.alphaRegularizer = Yt(t.alphaRegularizer), this.alphaConstraint = pe(t.alphaConstraint), t.sharedAxes == null)
      this.sharedAxes = null;
    else if (Array.isArray(t.sharedAxes))
      this.sharedAxes = t.sharedAxes;
    else if (typeof t.sharedAxes == "number")
      this.sharedAxes = [t.sharedAxes];
    else
      throw new E(`Expected sharedAxes to be a number or an array of numbers, but got ${t.sharedAxes}`);
  }
  build(t) {
    t = $t(t);
    const e = t.slice(1);
    if (this.sharedAxes != null)
      for (const o of this.sharedAxes)
        e[o - 1] = 1;
    this.alpha = this.addWeight("alpha", e, "float32", this.alphaInitializer, this.alphaRegularizer, true, this.alphaConstraint);
    const s = {};
    if (this.sharedAxes != null)
      for (let o = 1; o < t.length; ++o)
        s[o] = t[o];
    this.inputSpec = [new de({
      ndim: t.length,
      axes: s
    })], this.built = true;
  }
  call(t, e) {
    return t = mt(t), ap(t, this.alpha.read());
  }
  getConfig() {
    const t = {
      alphaInitializer: Jt(this.alphaInitializer),
      alphaRegularizer: Ft(this.alphaRegularizer),
      alphaConstraint: he(this.alphaConstraint),
      sharedAxes: this.sharedAxes
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
jx.className = "PReLU";
_(jx);
var qx = class extends St {
  constructor(t) {
    if (super(t ?? {}), this.DEFAULT_ALPHA = 1, t == null && (t = {}), t.alpha != null && t.alpha !== this.DEFAULT_ALPHA)
      throw new xt(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);
    this.alpha = t.alpha == null ? this.DEFAULT_ALPHA : t.alpha;
  }
  call(t, e) {
    const s = mt(t);
    return Xc(s);
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { alpha: this.alpha }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
qx.className = "ELU";
_(qx);
var ty = class extends St {
  constructor(t) {
    super(t ?? {}), this.DEFAULT_THETA = 1, t == null && (t = {}), this.theta = t.theta == null ? this.DEFAULT_THETA : t.theta;
  }
  call(t, e) {
    const s = mt(t);
    return G(s, et(sn(s, this.theta), "float32"));
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { theta: this.theta }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
ty.className = "ThresholdedReLU";
_(ty);
var ey = class extends St {
  constructor(t) {
    super(t ?? {}), this.DEFAULT_AXIS = 1, t == null && (t = {}), this.softmax = new xf().apply, this.axis = t.axis == null ? this.DEFAULT_AXIS : t.axis;
  }
  call(t, e) {
    const s = mt(t);
    return this.softmax(s, this.axis);
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { axis: this.axis }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
ey.className = "Softmax";
_(ey);
function er(n, t, e) {
  if (typeof n == "number")
    return Ro(n, t);
  if (n.length !== t)
    throw new E(`The ${e} argument must be an integer or tuple of ${t} integers. Received: ${n.length} elements.`);
  for (let s = 0; s < t; ++s) {
    const o = n[s];
    if (!TG(o))
      throw new E(`The ${e} argument must be an integer or tuple of ${t} integers. Received: ${JSON.stringify(n)} including a non-integer number ${o}`);
  }
  return n;
}
function An(n, t, e, s, o = 1) {
  if (n == null)
    return n;
  const r = t + (t - 1) * (o - 1);
  let i6;
  return e === "same" ? i6 = n : i6 = n - r + 1, Math.floor((i6 + s - 1) / s);
}
function Jn(n, t, e, s) {
  if (n == null)
    return null;
  if (s === "valid")
    n = n * t + Xs([e - t, 0]);
  else if (s === "same")
    n = n * t;
  else
    throw new E(`Unsupport padding mode: ${s}.`);
  return n;
}
function wf(n, t) {
  return D(() => (ae(t), t === "channelsFirst" ? kt(n, [0, 2, 3, 1]) : n));
}
function ny(n, t) {
  return D(() => (ae(t), t === "channelsFirst" ? kt(n, [0, 2, 3, 4, 1]) : n));
}
function ZE(n, t, e, s = 1, o = "valid", r, i6 = 1) {
  return D(() => {
    if (r == null && (r = Kn()), ae(r), n.shape.length !== 3)
      throw new E(`The input of a conv1dWithBias operation should be 3, but is ${n.shape.length} instead.`);
    if (t.shape.length !== 3)
      throw new E(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);
    if (e != null && e.shape.length !== 1)
      throw new E(`The bias for a conv1dWithBias operation should be 1, but is ${t.shape.length} instead`);
    if (r === "channelsFirst" && (n = kt(n, [0, 2, 1])), o === "causal")
      throw new xt("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    let a = Rb(n, t, s, o === "same" ? "same" : "valid", "NWC", i6);
    return e != null && (a = Hn(a, e)), a;
  });
}
function Xm(n, t, e, s = [1, 1], o = "valid", r, i6, a = null) {
  return D(() => {
    if (r == null && (r = Kn()), ae(r), n.rank !== 3 && n.rank !== 4)
      throw new E(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${n.rank}.`);
    if (t.rank !== 3 && t.rank !== 4)
      throw new E(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${n.rank}.`);
    let l = wf(n, r);
    if (o === "causal")
      throw new xt("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    return l = lT({
      x: l,
      filter: t,
      strides: s,
      pad: o === "same" ? "same" : "valid",
      dilations: i6,
      dataFormat: "NHWC",
      bias: e,
      activation: a
    }), r === "channelsFirst" && (l = kt(l, [0, 3, 1, 2])), l;
  });
}
function BE(n, t, e, s = [1, 1, 1], o = "valid", r, i6) {
  return D(() => {
    if (r == null && (r = Kn()), ae(r), n.rank !== 4 && n.rank !== 5)
      throw new E(`conv3dWithBias expects input to be of rank 4 or 5, but received ${n.rank}.`);
    if (t.rank !== 4 && t.rank !== 5)
      throw new E(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${n.rank}.`);
    let a = ny(n, r);
    if (o === "causal")
      throw new xt("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
    return a = cv(a, t, s, o === "same" ? "same" : "valid", "NDHWC", i6), e != null && (a = Hn(a, e)), r === "channelsFirst" && (a = kt(a, [0, 4, 1, 2, 3])), a;
  });
}
var su = class extends St {
  constructor(t, e) {
    if (super(e), this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", su.verifyArgs(e), this.rank = t, be(this.rank, "rank"), this.rank !== 1 && this.rank !== 2 && this.rank !== 3)
      throw new xt(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);
    if (this.kernelSize = er(e.kernelSize, t, "kernelSize"), this.strides = er(e.strides == null ? 1 : e.strides, t, "strides"), this.padding = e.padding == null ? "valid" : e.padding, fn(this.padding), this.dataFormat = e.dataFormat == null ? "channelsLast" : e.dataFormat, ae(this.dataFormat), this.activation = As(e.activation), this.useBias = e.useBias == null ? true : e.useBias, this.biasInitializer = Ut(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.biasConstraint = pe(e.biasConstraint), this.biasRegularizer = Yt(e.biasRegularizer), this.activityRegularizer = Yt(e.activityRegularizer), this.dilationRate = er(e.dilationRate == null ? 1 : e.dilationRate, t, "dilationRate"), this.rank === 1 && Array.isArray(this.dilationRate) && this.dilationRate.length !== 1)
      throw new E(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    if (this.rank === 2) {
      if (typeof this.dilationRate == "number")
        this.dilationRate = [this.dilationRate, this.dilationRate];
      else if (this.dilationRate.length !== 2)
        throw new E(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    } else if (this.rank === 3) {
      if (typeof this.dilationRate == "number")
        this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];
      else if (this.dilationRate.length !== 3)
        throw new E(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    }
  }
  static verifyArgs(t) {
    if (Qn("kernelSize" in t, "required key 'kernelSize' not in config"), typeof t.kernelSize != "number" && !of(t.kernelSize, "number", 1, 3))
      throw new E(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`);
  }
  getConfig() {
    const t = {
      kernelSize: this.kernelSize,
      strides: this.strides,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      activation: Ps(this.activation),
      useBias: this.useBias,
      biasInitializer: Jt(this.biasInitializer),
      biasRegularizer: Ft(this.biasRegularizer),
      activityRegularizer: Ft(this.activityRegularizer),
      biasConstraint: he(this.biasConstraint)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var vr = class extends su {
  constructor(t, e) {
    super(t, e), this.kernel = null, vr.verifyArgs(e), this.filters = e.filters, be(this.filters, "filters"), this.kernelInitializer = Ut(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.kernelConstraint = pe(e.kernelConstraint), this.kernelRegularizer = Yt(e.kernelRegularizer);
  }
  build(t) {
    t = $t(t);
    const e = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[e] == null)
      throw new E(`The channel dimension of the input should be defined. Found ${t[e]}`);
    const s = t[e], o = this.kernelSize.concat([s, this.filters]);
    this.kernel = this.addWeight("kernel", o, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [{ ndim: this.rank + 2, axes: { [e]: s } }], this.built = true;
  }
  call(t, e) {
    return D(() => {
      t = mt(t);
      let s;
      const o = this.bias == null ? null : this.bias.read(), r = tx(this.activation.getClassName());
      if (r != null && this.rank === 2)
        s = Xm(t, this.kernel.read(), o, this.strides, this.padding, this.dataFormat, this.dilationRate, r);
      else {
        if (this.rank === 1)
          s = ZE(t, this.kernel.read(), o, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);
        else if (this.rank === 2)
          s = Xm(t, this.kernel.read(), o, this.strides, this.padding, this.dataFormat, this.dilationRate);
        else if (this.rank === 3)
          s = BE(t, this.kernel.read(), o, this.strides, this.padding, this.dataFormat, this.dilationRate);
        else
          throw new xt("convolutions greater than 3D are not implemented yet.");
        this.activation != null && (s = this.activation.apply(s));
      }
      return s;
    });
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = [], s = this.dataFormat === "channelsLast" ? t.slice(1, t.length - 1) : t.slice(2);
    for (let r = 0; r < s.length; ++r) {
      const i6 = An(s[r], this.kernelSize[r], this.padding, this.strides[r], typeof this.dilationRate == "number" ? this.dilationRate : this.dilationRate[r]);
      e.push(i6);
    }
    let o = [t[0]];
    return this.dataFormat === "channelsLast" ? (o = o.concat(e), o.push(this.filters)) : (o.push(this.filters), o = o.concat(e)), o;
  }
  getConfig() {
    const t = {
      filters: this.filters,
      kernelInitializer: Jt(this.kernelInitializer),
      kernelRegularizer: Ft(this.kernelRegularizer),
      kernelConstraint: he(this.kernelConstraint)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  static verifyArgs(t) {
    if (!("filters" in t) || typeof t.filters != "number" || t.filters < 1)
      throw new E(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(t.filters)}`);
  }
};
var va = class extends vr {
  constructor(t) {
    super(2, t), va.verifyArgs(t);
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.rank, t;
  }
  static verifyArgs(t) {
    if (typeof t.kernelSize != "number" && !of(t.kernelSize, "number", 1, 2))
      throw new E(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`);
  }
};
va.className = "Conv2D";
_(va);
var Sa = class extends vr {
  constructor(t) {
    super(3, t), Sa.verifyArgs(t);
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.rank, t;
  }
  static verifyArgs(t) {
    if (typeof t.kernelSize != "number" && !(Array.isArray(t.kernelSize) && (t.kernelSize.length === 1 || t.kernelSize.length === 3)))
      throw new E(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`);
  }
};
Sa.className = "Conv3D";
_(Sa);
var sy = class extends va {
  constructor(t) {
    if (super(t), this.inputSpec = [new de({ ndim: 4 })], this.padding !== "same" && this.padding !== "valid")
      throw new E(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
  }
  build(t) {
    if (t = $t(t), t.length !== 4)
      throw new E("Input should have rank 4; Received input shape: " + JSON.stringify(t));
    const e = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[e] == null)
      throw new E("The channel dimension of the inputs should be defined. Found `None`.");
    const s = t[e], o = this.kernelSize.concat([this.filters, s]);
    this.kernel = this.addWeight("kernel", o, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [new de({ ndim: 4, axes: { [e]: s } })], this.built = true;
  }
  call(t, e) {
    return D(() => {
      let s = mt(t);
      if (s.shape.length !== 4)
        throw new E(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);
      const o = s.shape, r = o[0];
      let i6, a;
      this.dataFormat === "channelsFirst" ? (i6 = 2, a = 3) : (i6 = 1, a = 2);
      const l = o[i6], c = o[a], u = this.kernelSize[0], d = this.kernelSize[1], h6 = this.strides[0], p6 = this.strides[1], f = Jn(l, h6, u, this.padding), m = Jn(c, p6, d, this.padding), g6 = [r, f, m, this.filters];
      this.dataFormat !== "channelsLast" && (s = kt(s, [0, 2, 3, 1]));
      let b6 = $b(s, this.kernel.read(), g6, this.strides, this.padding);
      return this.dataFormat !== "channelsLast" && (b6 = kt(b6, [0, 3, 1, 2])), this.bias != null && (b6 = Hn(b6, this.bias.read(), this.dataFormat)), this.activation != null && (b6 = this.activation.apply(b6)), b6;
    });
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = t.slice();
    let s, o, r;
    this.dataFormat === "channelsFirst" ? (s = 1, o = 2, r = 3) : (s = 3, o = 1, r = 2);
    const i6 = this.kernelSize[0], a = this.kernelSize[1], l = this.strides[0], c = this.strides[1];
    return e[s] = this.filters, e[o] = Jn(e[o], l, i6, this.padding), e[r] = Jn(e[r], c, a, this.padding), e;
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.dilationRate, t;
  }
};
sy.className = "Conv2DTranspose";
_(sy);
var oy = class extends Sa {
  constructor(t) {
    if (super(t), this.inputSpec = [new de({ ndim: 5 })], this.padding !== "same" && this.padding !== "valid")
      throw new E(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
  }
  build(t) {
    if (t = $t(t), t.length !== 5)
      throw new E("Input should have rank 5; Received input shape: " + JSON.stringify(t));
    const e = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[e] == null)
      throw new E("The channel dimension of the inputs should be defined. Found `None`.");
    const s = t[e], o = this.kernelSize.concat([this.filters, s]);
    this.kernel = this.addWeight("kernel", o, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [new de({ ndim: 5, axes: { [e]: s } })], this.built = true;
  }
  call(t, e) {
    return D(() => {
      let s = mt(t);
      if (s.shape.length !== 5)
        throw new E(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);
      const o = s.shape, r = o[0];
      let i6, a, l;
      this.dataFormat === "channelsFirst" ? (l = 2, i6 = 3, a = 4) : (l = 1, i6 = 2, a = 3);
      const c = o[l], u = o[i6], d = o[a], h6 = this.kernelSize[0], p6 = this.kernelSize[1], f = this.kernelSize[2], m = this.strides[0], g6 = this.strides[1], b6 = this.strides[2], x6 = Jn(c, m, h6, this.padding), w6 = Jn(u, g6, p6, this.padding), y6 = Jn(d, b6, f, this.padding), I = [r, x6, w6, y6, this.filters];
      this.dataFormat !== "channelsLast" && (s = kt(s, [0, 2, 3, 4, 1]));
      let C6 = hv(s, this.kernel.read(), I, this.strides, this.padding);
      return this.dataFormat !== "channelsLast" && (C6 = kt(C6, [0, 4, 1, 2, 3])), this.bias !== null && (C6 = Hn(C6, this.bias.read(), this.dataFormat)), this.activation !== null && (C6 = this.activation.apply(C6)), C6;
    });
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = t.slice();
    let s, o, r, i6;
    this.dataFormat === "channelsFirst" ? (s = 1, o = 2, r = 3, i6 = 4) : (s = 4, o = 1, r = 2, i6 = 3);
    const a = this.kernelSize[0], l = this.kernelSize[1], c = this.kernelSize[2], u = this.strides[0], d = this.strides[1], h6 = this.strides[2];
    return e[s] = this.filters, e[o] = Jn(e[o], u, a, this.padding), e[r] = Jn(e[r], d, l, this.padding), e[i6] = Jn(e[i6], h6, c, this.padding), e;
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.dilationRate, t;
  }
};
oy.className = "Conv3DTranspose";
_(oy);
var ry = class extends vr {
  constructor(t, e) {
    if (super(t, e), this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform", this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform", this.depthwiseKernel = null, this.pointwiseKernel = null, e.filters == null)
      throw new E("The `filters` configuration field is required by SeparableConv, but is unspecified.");
    if (e.kernelInitializer != null || e.kernelRegularizer != null || e.kernelConstraint != null)
      throw new E("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
    if (e.padding != null && e.padding !== "same" && e.padding !== "valid")
      throw new E(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e.padding)}`);
    this.depthMultiplier = e.depthMultiplier == null ? 1 : e.depthMultiplier, this.depthwiseInitializer = Ut(e.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER), this.depthwiseRegularizer = Yt(e.depthwiseRegularizer), this.depthwiseConstraint = pe(e.depthwiseConstraint), this.pointwiseInitializer = Ut(e.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER), this.pointwiseRegularizer = Yt(e.pointwiseRegularizer), this.pointwiseConstraint = pe(e.pointwiseConstraint);
  }
  build(t) {
    if (t = $t(t), t.length < this.rank + 2)
      throw new E(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank + 2}, but received input shape: ${JSON.stringify(t)}`);
    const e = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[e] == null || t[e] < 0)
      throw new E(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t[e])}`);
    const s = t[e], o = this.kernelSize.concat([s, this.depthMultiplier]), r = [];
    for (let a = 0; a < this.rank; ++a)
      r.push(1);
    r.push(s * this.depthMultiplier, this.filters);
    const i6 = true;
    this.depthwiseKernel = this.addWeight("depthwise_kernel", o, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, i6, this.depthwiseConstraint), this.pointwiseKernel = this.addWeight("pointwise_kernel", r, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, i6, this.pointwiseConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, i6, this.biasConstraint) : this.bias = null, this.inputSpec = [new de({ ndim: this.rank + 2, axes: { [e]: s } })], this.built = true;
  }
  call(t, e) {
    return D(() => {
      t = mt(t);
      let s;
      if (this.rank === 1)
        throw new xt("1D separable convolution is not implemented yet.");
      return this.rank === 2 && (this.dataFormat === "channelsFirst" && (t = kt(t, [0, 2, 3, 1])), s = Hb(t, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC")), this.useBias && (s = Hn(s, this.bias.read(), this.dataFormat)), this.activation != null && (s = this.activation.apply(s)), this.dataFormat === "channelsFirst" && (s = kt(s, [0, 3, 1, 2])), s;
    });
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.rank, delete t.kernelInitializer, delete t.kernelRegularizer, delete t.kernelConstraint, t.depthwiseInitializer = Jt(this.depthwiseInitializer), t.pointwiseInitializer = Jt(this.pointwiseInitializer), t.depthwiseRegularizer = Ft(this.depthwiseRegularizer), t.pointwiseRegularizer = Ft(this.pointwiseRegularizer), t.depthwiseConstraint = he(this.depthwiseConstraint), t.pointwiseConstraint = he(this.pointwiseConstraint), t;
  }
};
ry.className = "SeparableConv";
var iy = class extends ry {
  constructor(t) {
    super(2, t);
  }
};
iy.className = "SeparableConv2D";
_(iy);
var ou = class extends vr {
  constructor(t) {
    super(1, t), ou.verifyArgs(t), this.inputSpec = [{ ndim: 3 }];
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.rank, delete t.dataFormat, t;
  }
  static verifyArgs(t) {
    if (typeof t.kernelSize != "number" && !of(t.kernelSize, "number", 1, 1))
      throw new E(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`);
  }
};
ou.className = "Conv1D";
_(ou);
var ay = class extends St {
  constructor(t) {
    super(t), typeof t.cropping == "number" ? this.cropping = [[t.cropping, t.cropping], [t.cropping, t.cropping]] : typeof t.cropping[0] == "number" ? this.cropping = [
      [t.cropping[0], t.cropping[0]],
      [t.cropping[1], t.cropping[1]]
    ] : this.cropping = t.cropping, this.dataFormat = t.dataFormat === void 0 ? "channelsLast" : t.dataFormat, this.inputSpec = [{ ndim: 4 }];
  }
  computeOutputShape(t) {
    return this.dataFormat === "channelsFirst" ? [
      t[0],
      t[1],
      t[2] - this.cropping[0][0] - this.cropping[0][1],
      t[3] - this.cropping[1][0] - this.cropping[1][1]
    ] : [
      t[0],
      t[1] - this.cropping[0][0] - this.cropping[0][1],
      t[2] - this.cropping[1][0] - this.cropping[1][1],
      t[3]
    ];
  }
  call(t, e) {
    return D(() => {
      if (t = mt(t), this.dataFormat === "channelsLast") {
        const s = Va(t, this.cropping[0][0], t.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);
        return Va(s, this.cropping[1][0], t.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);
      } else {
        const s = Va(t, this.cropping[0][0], t.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);
        return Va(s, this.cropping[1][0], t.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);
      }
    });
  }
  getConfig() {
    const t = { cropping: this.cropping, dataFormat: this.dataFormat }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
ay.className = "Cropping2D";
_(ay);
var ly = class extends St {
  constructor(t) {
    super(t), this.DEFAULT_SIZE = [2, 2], this.inputSpec = [{ ndim: 4 }], this.size = t.size == null ? this.DEFAULT_SIZE : t.size, this.dataFormat = t.dataFormat == null ? "channelsLast" : t.dataFormat, ae(this.dataFormat), this.interpolation = t.interpolation == null ? "nearest" : t.interpolation, vG(this.interpolation);
  }
  computeOutputShape(t) {
    if (this.dataFormat === "channelsFirst") {
      const e = t[2] == null ? null : this.size[0] * t[2], s = t[3] == null ? null : this.size[1] * t[3];
      return [t[0], t[1], e, s];
    } else {
      const e = t[1] == null ? null : this.size[0] * t[1], s = t[2] == null ? null : this.size[1] * t[2];
      return [t[0], e, s, t[3]];
    }
  }
  call(t, e) {
    return D(() => {
      let s = mt(t);
      const o = s.shape;
      if (this.dataFormat === "channelsFirst") {
        s = kt(s, [0, 2, 3, 1]);
        const r = this.size[0] * o[2], i6 = this.size[1] * o[3], a = this.interpolation === "nearest" ? uo.resizeNearestNeighbor(s, [r, i6]) : uo.resizeBilinear(s, [r, i6]);
        return kt(a, [0, 3, 1, 2]);
      } else {
        const r = this.size[0] * o[1], i6 = this.size[1] * o[2];
        return this.interpolation === "nearest" ? uo.resizeNearestNeighbor(s, [r, i6]) : uo.resizeBilinear(s, [r, i6]);
      }
    });
  }
  getConfig() {
    const t = {
      size: this.size,
      dataFormat: this.dataFormat,
      interpolation: this.interpolation
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
ly.className = "UpSampling2D";
_(ly);
function HE(n, t, e = [1, 1], s = "valid", o, r) {
  return D(() => {
    o == null && (o = Kn()), ae(o);
    let i6 = wf(n, o);
    if (n.rank !== 4)
      throw new E(`Input for depthwiseConv2d is required to be 4-D, but is instead ${n.rank}-D`);
    if (t.rank !== 4)
      throw new E(`depthwiseKernel is required to be 4-D, but is instead ${t.rank}-D`);
    return i6 = Qh(i6, t, e, s === "same" ? "same" : "valid", "NHWC", r), o === "channelsFirst" && (i6 = kt(i6, [0, 3, 1, 2])), i6;
  });
}
var cy = class extends su {
  constructor(t) {
    super(2, t), this.depthwiseKernel = null, this.depthMultiplier = t.depthMultiplier == null ? 1 : t.depthMultiplier, this.depthwiseInitializer = Ut(t.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.depthwiseConstraint = pe(t.depthwiseConstraint), this.depthwiseRegularizer = Yt(t.depthwiseRegularizer);
  }
  build(t) {
    if (t = $t(t), t.length < 4)
      throw new E(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);
    const e = this.dataFormat === "channelsFirst" ? 1 : 3;
    if (t[e] == null || t[e] < 0)
      throw new E(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);
    const s = t[e], o = [
      this.kernelSize[0],
      this.kernelSize[1],
      s,
      this.depthMultiplier
    ];
    this.depthwiseKernel = this.addWeight("depthwise_kernel", o, null, this.depthwiseInitializer, this.depthwiseRegularizer, true, this.depthwiseConstraint), this.useBias ? this.bias = this.addWeight("bias", [s * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  call(t, e) {
    return D(() => {
      t = mt(t);
      let s = HE(t, this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
      return this.useBias && (s = Hn(s, this.bias.read(), this.dataFormat)), this.activation != null && (s = this.activation.apply(s)), s;
    });
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = this.dataFormat === "channelsFirst" ? t[2] : t[1], s = this.dataFormat === "channelsFirst" ? t[3] : t[2], o = this.dataFormat === "channelsFirst" ? t[1] * this.depthMultiplier : t[3] * this.depthMultiplier, r = An(e, this.kernelSize[0], this.padding, this.strides[0]), i6 = An(s, this.kernelSize[1], this.padding, this.strides[1]);
    return this.dataFormat === "channelsFirst" ? [t[0], o, r, i6] : [t[0], r, i6, o];
  }
  getConfig() {
    const t = super.getConfig();
    return t.depthMultiplier = this.depthMultiplier, t.depthwiseInitializer = Jt(this.depthwiseInitializer), t.depthwiseRegularizer = Ft(this.depthwiseRegularizer), t.depthwiseConstraint = he(this.depthwiseRegularizer), t;
  }
};
cy.className = "DepthwiseConv2D";
_(cy);
function uy(n, t, e, s) {
  if (Array.isArray(n)) {
    if (t != null || e != null)
      throw new E("When inputs is an array, neither initialState or constants should be provided");
    s != null && (e = n.slice(n.length - s, n.length), n = n.slice(0, n.length - s)), n.length > 1 && (t = n.slice(1, n.length)), n = n[0];
  }
  function o(r) {
    return r == null || Array.isArray(r) ? r : [r];
  }
  return t = o(t), e = o(e), { inputs: n, initialState: t, constants: e };
}
function dy(n, t, e, s = false, o, r, i6 = false, a = false) {
  return D(() => {
    const l = t.shape.length;
    if (l < 3)
      throw new E(`Input should be at least 3D, but is ${l}D.`);
    const c = [1, 0].concat(On(2, l));
    if (t = kt(t, c), r != null)
      throw new xt("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
    i6 && console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."), o != null && (o = et(et(o, "bool"), "float32"), o.rank === l - 1 && (o = Ue(o, -1)), o = kt(o, c)), s && (t = ko(t, 0), o != null && (o = ko(o, 0)));
    const u = [];
    let d, h6 = e;
    const p6 = t.shape[0], f = To(t);
    let m;
    o != null && (m = To(o));
    for (let b6 = 0; b6 < p6; ++b6) {
      const x6 = f[b6], w6 = D(() => n(x6, h6));
      if (o == null)
        d = w6[0], h6 = w6[1];
      else {
        const y6 = D(() => {
          const I = m[b6], C6 = lt(Rn(I), I), k7 = U(G(w6[0], I), G(h6[0], C6)), S = h6.map((N, R) => U(G(w6[1][R], I), G(N, C6)));
          return { output: k7, newStates: S };
        });
        d = y6.output, h6 = y6.newStates;
      }
      a && u.push(d);
    }
    let g6;
    return a && (g6 = os(u, 1)), [d, g6, h6];
  });
}
var Qs = class extends St {
  constructor(t) {
    super(t);
    let e;
    if (t.cell == null)
      throw new E("cell property is missing for the constructor of RNN.");
    if (Array.isArray(t.cell) ? e = new vf({ cells: t.cell }) : e = t.cell, e.stateSize == null)
      throw new E("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
    this.cell = e, this.returnSequences = t.returnSequences == null ? false : t.returnSequences, this.returnState = t.returnState == null ? false : t.returnState, this.goBackwards = t.goBackwards == null ? false : t.goBackwards, this._stateful = t.stateful == null ? false : t.stateful, this.unroll = t.unroll == null ? false : t.unroll, this.supportsMasking = true, this.inputSpec = [new de({ ndim: 3 })], this.stateSpec = null, this.states_ = null, this.numConstants = null, this.keptStates = [];
  }
  // Porting Note: This is the equivalent of `RNN.states` property getter in
  //   PyKeras.
  getStates() {
    if (this.states_ == null) {
      const t = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      return On(0, t).map((e) => null);
    } else
      return this.states_;
  }
  // Porting Note: This is the equivalent of the `RNN.states` property setter in
  //   PyKeras.
  setStates(t) {
    this.states_ = t;
  }
  computeOutputShape(t) {
    kd(t) && (t = t[0]), t = t;
    let e = this.cell.stateSize;
    Array.isArray(e) || (e = [e]);
    const s = e[0];
    let o;
    if (this.returnSequences ? o = [t[0], t[1], s] : o = [t[0], s], this.returnState) {
      const r = [];
      for (const i6 of e)
        r.push([t[0], i6]);
      return [o].concat(r);
    } else
      return o;
  }
  computeMask(t, e) {
    return D(() => {
      Array.isArray(e) && (e = e[0]);
      const s = this.returnSequences ? e : null;
      if (this.returnState) {
        const o = this.states.map((r) => null);
        return [s].concat(o);
      } else
        return s;
    });
  }
  /**
   * Get the current state tensors of the RNN.
   *
   * If the state hasn't been set, return an array of `null`s of the correct
   * length.
   */
  get states() {
    if (this.states_ == null) {
      const t = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1, e = [];
      for (let s = 0; s < t; ++s)
        e.push(null);
      return e;
    } else
      return this.states_;
  }
  set states(t) {
    this.states_ = t;
  }
  build(t) {
    if (this.numConstants != null)
      throw new xt("Constants support is not implemented in RNN yet.");
    kd(t) && (t = t[0]), t = t;
    const e = this.stateful ? t[0] : null, s = t.slice(2);
    this.inputSpec[0] = new de({ shape: [e, null, ...s] });
    const o = [t[0]].concat(t.slice(2));
    this.cell.build(o);
    let r;
    if (Array.isArray(this.cell.stateSize) ? r = this.cell.stateSize : r = [this.cell.stateSize], this.stateSpec != null) {
      if (!Rt(this.stateSpec.map((i6) => i6.shape[i6.shape.length - 1]), r))
        throw new E(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`);
    } else
      this.stateSpec = r.map((i6) => new de({ shape: [null, i6] }));
    this.stateful && this.resetStates();
  }
  /**
   * Reset the state tensors of the RNN.
   *
   * If the `states` argument is `undefined` or `null`, will set the
   * state tensor(s) of the RNN to all-zero tensors of the appropriate
   * shape(s).
   *
   * If `states` is provided, will set the state tensors of the RNN to its
   * value.
   *
   * @param states Optional externally-provided initial states.
   * @param training Whether this call is done during training. For stateful
   *   RNNs, this affects whether the old states are kept or discarded. In
   *   particular, if `training` is `true`, the old states will be kept so
   *   that subsequent backpropgataion through time (BPTT) may work properly.
   *   Else, the old states will be discarded.
   */
  resetStates(t, e = false) {
    D(() => {
      if (!this.stateful)
        throw new Yn("Cannot call resetStates() on an RNN Layer that is not stateful.");
      const s = this.inputSpec[0].shape[0];
      if (s == null)
        throw new E("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (this.states_ == null)
        Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((o) => ge([s, o])) : this.states_ = [ge([s, this.cell.stateSize])];
      else if (t == null)
        yt(this.states_), this.keptStates != null && (yt(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((o) => ge([s, o])) : this.states_[0] = ge([s, this.cell.stateSize]);
      else {
        if (Array.isArray(t) || (t = [t]), t.length !== this.states_.length)
          throw new E(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);
        e === true ? this.keptStates.push(this.states_.slice()) : yt(this.states_);
        for (let o = 0; o < this.states_.length; ++o) {
          const r = t[o], i6 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[o] : this.cell.stateSize, a = [s, i6];
          if (!Rt(r.shape, a))
            throw new E(`State ${o} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${r.shape}`);
          this.states_[o] = r;
        }
      }
      this.states_ = this.states_.map((o) => cn(o.clone()));
    });
  }
  apply(t, e) {
    let s = e == null ? null : e.initialState, o = e == null ? null : e.constants;
    e == null && (e = {});
    const r = uy(t, s, o, this.numConstants);
    t = r.inputs, s = r.initialState, o = r.constants;
    let i6 = [], a = [];
    if (s != null) {
      e.initialState = s, i6 = i6.concat(s), this.stateSpec = [];
      for (const c of s)
        this.stateSpec.push(new de({ shape: c.shape }));
      a = a.concat(this.stateSpec);
    }
    if (o != null && (e.constants = o, i6 = i6.concat(o), this.numConstants = o.length), i6[0] instanceof jn) {
      const c = [t].concat(i6), u = this.inputSpec.concat(a), d = this.inputSpec;
      this.inputSpec = u;
      const h6 = super.apply(c, e);
      return this.inputSpec = d, h6;
    } else
      return super.apply(t, e);
  }
  // tslint:disable-next-line:no-any
  call(t, e) {
    return D(() => {
      const s = e == null ? null : e.mask, o = e == null ? null : e.training;
      let r = e == null ? null : e.initialState;
      t = mt(t), r == null && (this.stateful ? r = this.states_ : r = this.getInitialState(t));
      const i6 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      if (r.length !== i6)
        throw new E(`RNN Layer has ${i6} state(s) but was passed ${r.length} initial state(s).`);
      this.unroll && console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
      const a = { training: o }, c = dy((f, m) => {
        const g6 = this.cell.call([f].concat(m), a);
        return [g6[0], g6.slice(1)];
      }, t, r, this.goBackwards, s, null, this.unroll, this.returnSequences), u = c[0], d = c[1], h6 = c[2];
      this.stateful && this.resetStates(h6, o);
      const p6 = this.returnSequences ? d : u;
      return this.returnState ? [p6].concat(h6) : p6;
    });
  }
  getInitialState(t) {
    return D(() => {
      let e = ge(t.shape);
      return e = at(e, [1, 2]), e = xa(e), Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map((s) => s > 1 ? vd(e, [1, s]) : e) : this.cell.stateSize > 1 ? [vd(e, [1, this.cell.stateSize])] : [e];
    });
  }
  get trainableWeights() {
    return this.trainable ? this.cell.trainableWeights : [];
  }
  get nonTrainableWeights() {
    return this.trainable ? this.cell.nonTrainableWeights : this.cell.weights;
  }
  setFastWeightInitDuringBuild(t) {
    super.setFastWeightInitDuringBuild(t), this.cell != null && this.cell.setFastWeightInitDuringBuild(t);
  }
  getConfig() {
    const t = super.getConfig(), e = {
      returnSequences: this.returnSequences,
      returnState: this.returnState,
      goBackwards: this.goBackwards,
      stateful: this.stateful,
      unroll: this.unroll
    };
    this.numConstants != null && (e.numConstants = this.numConstants);
    const s = this.cell.getConfig();
    return this.getClassName() === Qs.className && (e.cell = {
      className: this.cell.getClassName(),
      config: s
    }), Object.assign(Object.assign(Object.assign({}, s), t), e);
  }
  /** @nocollapse */
  static fromConfig(t, e, s = {}) {
    const o = e.cell, r = Pn(o, s);
    return new t(Object.assign(e, { cell: r }));
  }
};
Qs.className = "RNN";
_(Qs);
var ru = class extends St {
};
var If = class extends ru {
  constructor(t) {
    super(t), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = t.units, be(this.units, "units"), this.activation = As(t.activation == null ? this.DEFAULT_ACTIVATION : t.activation), this.useBias = t.useBias == null ? true : t.useBias, this.kernelInitializer = Ut(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Ut(t.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Ut(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = Yt(t.kernelRegularizer), this.recurrentRegularizer = Yt(t.recurrentRegularizer), this.biasRegularizer = Yt(t.biasRegularizer), this.kernelConstraint = pe(t.kernelConstraint), this.recurrentConstraint = pe(t.recurrentConstraint), this.biasConstraint = pe(t.biasConstraint), this.dropout = ar([1, Xs([0, t.dropout == null ? 0 : t.dropout])]), this.recurrentDropout = ar([
      1,
      Xs([0, t.recurrentDropout == null ? 0 : t.recurrentDropout])
    ]), this.dropoutFunc = t.dropoutFunc, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t) {
    t = $t(t), this.kernel = this.addWeight("kernel", [t[t.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  // Porting Note: PyKeras' equivalent of this method takes two tensor inputs:
  //   `inputs` and `states`. Here, the two tensors are combined into an
  //   `Tensor[]` Array as the first input argument.
  //   Similarly, PyKeras' equivalent of this method returns two values:
  //    `output` and `[output]`. Here the two are combined into one length-2
  //    `Tensor[]`, consisting of `output` repeated.
  call(t, e) {
    return D(() => {
      if (t = t, t.length !== 2)
        throw new E(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);
      let s = t[1];
      t = t[0];
      const o = e.training == null ? false : e.training;
      0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = Os({
        ones: () => Rn(t),
        rate: this.dropout,
        training: o,
        dropoutFunc: this.dropoutFunc
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = Os({
        ones: () => Rn(s),
        rate: this.recurrentDropout,
        training: o,
        dropoutFunc: this.dropoutFunc
      }));
      let r;
      const i6 = this.dropoutMask, a = this.recurrentDropoutMask;
      i6 != null ? r = ns(G(t, i6), this.kernel.read()) : r = ns(t, this.kernel.read()), this.bias != null && (r = Hn(r, this.bias.read())), a != null && (s = G(s, a));
      let l = U(r, ns(s, this.recurrentKernel.read()));
      return this.activation != null && (l = this.activation.apply(l)), [l, l];
    });
  }
  getConfig() {
    const t = super.getConfig(), e = {
      units: this.units,
      activation: Ps(this.activation),
      useBias: this.useBias,
      kernelInitializer: Jt(this.kernelInitializer),
      recurrentInitializer: Jt(this.recurrentInitializer),
      biasInitializer: Jt(this.biasInitializer),
      kernelRegularizer: Ft(this.kernelRegularizer),
      recurrentRegularizer: Ft(this.recurrentRegularizer),
      biasRegularizer: Ft(this.biasRegularizer),
      activityRegularizer: Ft(this.activityRegularizer),
      kernelConstraint: he(this.kernelConstraint),
      recurrentConstraint: he(this.recurrentConstraint),
      biasConstraint: he(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout
    };
    return Object.assign(Object.assign({}, t), e);
  }
};
If.className = "SimpleRNNCell";
_(If);
var hy = class extends Qs {
  constructor(t) {
    t.cell = new If(t), super(t);
  }
  call(t, e) {
    return D(() => {
      this.cell.dropoutMask != null && (yt(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (yt(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      const s = e == null ? null : e.mask, o = e == null ? null : e.training, r = e == null ? null : e.initialState;
      return super.call(t, { mask: s, training: o, initialState: r });
    });
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e);
  }
};
hy.className = "SimpleRNN";
_(hy);
var Cf = class extends ru {
  constructor(t) {
    if (super(t), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", t.resetAfter)
      throw new E("GRUCell does not support reset_after parameter set to true.");
    this.units = t.units, be(this.units, "units"), this.activation = As(t.activation === void 0 ? this.DEFAULT_ACTIVATION : t.activation), this.recurrentActivation = As(t.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : t.recurrentActivation), this.useBias = t.useBias == null ? true : t.useBias, this.kernelInitializer = Ut(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Ut(t.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Ut(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = Yt(t.kernelRegularizer), this.recurrentRegularizer = Yt(t.recurrentRegularizer), this.biasRegularizer = Yt(t.biasRegularizer), this.kernelConstraint = pe(t.kernelConstraint), this.recurrentConstraint = pe(t.recurrentConstraint), this.biasConstraint = pe(t.biasConstraint), this.dropout = ar([1, Xs([0, t.dropout == null ? 0 : t.dropout])]), this.recurrentDropout = ar([
      1,
      Xs([0, t.recurrentDropout == null ? 0 : t.recurrentDropout])
    ]), this.dropoutFunc = t.dropoutFunc, this.implementation = t.implementation, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t) {
    t = $t(t);
    const e = t[t.length - 1];
    this.kernel = this.addWeight("kernel", [e, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  call(t, e) {
    return D(() => {
      if (t = t, t.length !== 2)
        throw new E(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t.length}.`);
      const s = e.training == null ? false : e.training;
      let o = t[1];
      t = t[0], 0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = Os({
        ones: () => Rn(t),
        rate: this.dropout,
        training: s,
        count: 3,
        dropoutFunc: this.dropoutFunc
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = Os({
        ones: () => Rn(o),
        rate: this.recurrentDropout,
        training: s,
        count: 3,
        dropoutFunc: this.dropoutFunc
      }));
      const r = this.dropoutMask, i6 = this.recurrentDropoutMask;
      let a, l, c;
      0 < this.dropout && this.dropout < 1 && (t = G(t, r[0]));
      let u = ns(t, this.kernel.read());
      this.useBias && (u = Hn(u, this.bias.read())), 0 < this.recurrentDropout && this.recurrentDropout < 1 && (o = G(o, i6[0]));
      const d = this.recurrentKernel.read(), [h6, p6] = un(d, [2 * this.units, this.units], d.rank - 1), f = ns(o, h6), [m, g6, b6] = un(u, 3, u.rank - 1), [x6, w6] = un(f, 2, f.rank - 1);
      a = this.recurrentActivation.apply(U(m, x6)), l = this.recurrentActivation.apply(U(g6, w6));
      const y6 = ns(G(l, o), p6);
      c = this.activation.apply(U(b6, y6));
      const I = U(G(a, o), G(U(1, jt(a)), c));
      return [I, I];
    });
  }
  getConfig() {
    const t = super.getConfig(), e = {
      units: this.units,
      activation: Ps(this.activation),
      recurrentActivation: Ps(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: Jt(this.kernelInitializer),
      recurrentInitializer: Jt(this.recurrentInitializer),
      biasInitializer: Jt(this.biasInitializer),
      kernelRegularizer: Ft(this.kernelRegularizer),
      recurrentRegularizer: Ft(this.recurrentRegularizer),
      biasRegularizer: Ft(this.biasRegularizer),
      activityRegularizer: Ft(this.activityRegularizer),
      kernelConstraint: he(this.kernelConstraint),
      recurrentConstraint: he(this.recurrentConstraint),
      biasConstraint: he(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation,
      resetAfter: false
    };
    return Object.assign(Object.assign({}, t), e);
  }
};
Cf.className = "GRUCell";
_(Cf);
var py = class extends Qs {
  constructor(t) {
    t.implementation === 0 && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), t.cell = new Cf(t), super(t);
  }
  call(t, e) {
    return D(() => {
      this.cell.dropoutMask != null && (yt(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (yt(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      const s = e == null ? null : e.mask, o = e == null ? null : e.training, r = e == null ? null : e.initialState;
      return super.call(t, { mask: s, training: o, initialState: r });
    });
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return e.implmentation === 0 && (e.implementation = 1), new t(e);
  }
};
py.className = "GRU";
_(py);
var iu = class extends ru {
  constructor(t) {
    super(t), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = t.units, be(this.units, "units"), this.activation = As(t.activation === void 0 ? this.DEFAULT_ACTIVATION : t.activation), this.recurrentActivation = As(t.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : t.recurrentActivation), this.useBias = t.useBias == null ? true : t.useBias, this.kernelInitializer = Ut(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Ut(t.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Ut(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.unitForgetBias = t.unitForgetBias, this.kernelRegularizer = Yt(t.kernelRegularizer), this.recurrentRegularizer = Yt(t.recurrentRegularizer), this.biasRegularizer = Yt(t.biasRegularizer), this.kernelConstraint = pe(t.kernelConstraint), this.recurrentConstraint = pe(t.recurrentConstraint), this.biasConstraint = pe(t.biasConstraint), this.dropout = ar([1, Xs([0, t.dropout == null ? 0 : t.dropout])]), this.recurrentDropout = ar([
      1,
      Xs([0, t.recurrentDropout == null ? 0 : t.recurrentDropout])
    ]), this.dropoutFunc = t.dropoutFunc, this.implementation = t.implementation, this.stateSize = [this.units, this.units], this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t) {
    var e;
    t = $t(t);
    const s = t[t.length - 1];
    this.kernel = this.addWeight("kernel", [s, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
    let o;
    if (this.useBias) {
      if (this.unitForgetBias) {
        const r = this.biasInitializer, i6 = this.units;
        o = new (e = class extends Gn {
          apply(l, c) {
            const u = r.apply([i6]), d = new af().apply([i6]), h6 = r.apply([i6 * 2]);
            return Cm(Cm(u, d), h6);
          }
        }, /** @nocollapse */
        e.className = "CustomInit", e)();
      } else
        o = this.biasInitializer;
      this.bias = this.addWeight("bias", [this.units * 4], null, o, this.biasRegularizer, true, this.biasConstraint);
    } else
      this.bias = null;
    this.built = true;
  }
  call(t, e) {
    return D(() => {
      const s = e.training == null ? false : e.training;
      if (t = t, t.length !== 3)
        throw new E(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);
      let o = t[1];
      const r = t[2];
      t = t[0], 0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = Os({
        ones: () => Rn(t),
        rate: this.dropout,
        training: s,
        count: 4,
        dropoutFunc: this.dropoutFunc
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = Os({
        ones: () => Rn(o),
        rate: this.recurrentDropout,
        training: s,
        count: 4,
        dropoutFunc: this.dropoutFunc
      }));
      const i6 = this.dropoutMask, a = this.recurrentDropoutMask;
      let l, c, u, d;
      0 < this.dropout && this.dropout < 1 && (t = G(t, i6[0]));
      let h6 = ns(t, this.kernel.read());
      0 < this.recurrentDropout && this.recurrentDropout < 1 && (o = G(o, a[0])), h6 = U(h6, ns(o, this.recurrentKernel.read())), this.useBias && (h6 = Hn(h6, this.bias.read()));
      const [p6, f, m, g6] = un(h6, 4, h6.rank - 1);
      l = this.recurrentActivation.apply(p6), c = this.recurrentActivation.apply(f), u = U(G(c, r), G(l, this.activation.apply(m))), d = this.recurrentActivation.apply(g6);
      const b6 = G(d, this.activation.apply(u));
      return [b6, b6, u];
    });
  }
  getConfig() {
    const t = super.getConfig(), e = {
      units: this.units,
      activation: Ps(this.activation),
      recurrentActivation: Ps(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: Jt(this.kernelInitializer),
      recurrentInitializer: Jt(this.recurrentInitializer),
      biasInitializer: Jt(this.biasInitializer),
      unitForgetBias: this.unitForgetBias,
      kernelRegularizer: Ft(this.kernelRegularizer),
      recurrentRegularizer: Ft(this.recurrentRegularizer),
      biasRegularizer: Ft(this.biasRegularizer),
      activityRegularizer: Ft(this.activityRegularizer),
      kernelConstraint: he(this.kernelConstraint),
      recurrentConstraint: he(this.recurrentConstraint),
      biasConstraint: he(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation
    };
    return Object.assign(Object.assign({}, t), e);
  }
};
iu.className = "LSTMCell";
_(iu);
var fy = class extends Qs {
  constructor(t) {
    t.implementation === 0 && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), t.cell = new iu(t), super(t);
  }
  call(t, e) {
    return D(() => {
      this.cell.dropoutMask != null && (yt(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (yt(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      const s = e == null ? null : e.mask, o = e == null ? null : e.training, r = e == null ? null : e.initialState;
      return super.call(t, { mask: s, training: o, initialState: r });
    });
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return e.implmentation === 0 && (e.implementation = 1), new t(e);
  }
};
fy.className = "LSTM";
_(fy);
var vf = class extends ru {
  constructor(t) {
    super(t), this.cells = t.cells;
  }
  get stateSize() {
    const t = [];
    for (const e of this.cells.slice().reverse())
      Array.isArray(e.stateSize) ? t.push(...e.stateSize) : t.push(e.stateSize);
    return t;
  }
  call(t, e) {
    return D(() => {
      t = t;
      let s = t.slice(1);
      const o = [];
      for (const a of this.cells.slice().reverse())
        Array.isArray(a.stateSize) ? o.push(s.splice(0, a.stateSize.length)) : o.push(s.splice(0, 1));
      o.reverse();
      const r = [];
      let i6;
      for (let a = 0; a < this.cells.length; ++a) {
        const l = this.cells[a];
        s = o[a], a === 0 ? i6 = [t[0]].concat(s) : i6 = [i6[0]].concat(s), i6 = l.call(i6, e), r.push(i6.slice(1));
      }
      s = [];
      for (const a of r.slice().reverse())
        s.push(...a);
      return [i6[0]].concat(s);
    });
  }
  build(t) {
    kd(t) && (t = t[0]), t = t;
    let e;
    this.cells.forEach((s, o) => {
      fo(`RNNCell_${o}`, () => {
        s.build(t), Array.isArray(s.stateSize) ? e = s.stateSize[0] : e = s.stateSize, t = [t[0], e];
      });
    }), this.built = true;
  }
  getConfig() {
    const t = super.getConfig(), e = (r) => ({
      className: r.getClassName(),
      config: r.getConfig()
    }), o = { cells: this.cells.map(e) };
    return Object.assign(Object.assign({}, t), o);
  }
  /** @nocollapse */
  static fromConfig(t, e, s = {}) {
    const o = [];
    for (const r of e.cells)
      o.push(Pn(r, s));
    return new t({ cells: o });
  }
  get trainableWeights() {
    if (!this.trainable)
      return [];
    const t = [];
    for (const e of this.cells)
      t.push(...e.trainableWeights);
    return t;
  }
  get nonTrainableWeights() {
    const t = [];
    for (const e of this.cells)
      t.push(...e.nonTrainableWeights);
    if (!this.trainable) {
      const e = [];
      for (const s of this.cells)
        e.push(...s.trainableWeights);
      return e.concat(t);
    }
    return t;
  }
  /**
   * Retrieve the weights of a the model.
   *
   * @returns A flat `Array` of `tf.Tensor`s.
   */
  getWeights() {
    const t = [];
    for (const e of this.cells)
      t.push(...e.weights);
    return Td(t);
  }
  /**
   * Set the weights of the model.
   *
   * @param weights An `Array` of `tf.Tensor`s with shapes and types matching
   *     the output of `getWeights()`.
   */
  setWeights(t) {
    const e = [];
    for (const s of this.cells) {
      const o = s.weights.length, r = t.splice(o);
      for (let i6 = 0; i6 < s.weights.length; ++i6)
        e.push([s.weights[i6], r[i6]]);
    }
    ff(e);
  }
};
vf.className = "StackedRNNCells";
_(vf);
function Os(n) {
  const { ones: t, rate: e, training: s = false, count: o = 1, dropoutFunc: r } = n, i6 = () => r != null ? r(t(), e) : ax(t(), e), a = () => wa(i6, t, s);
  return !o || o <= 1 ? cn(a().clone()) : Array(o).fill(void 0).map(a).map((c) => cn(c.clone()));
}
var _E = globalThis && globalThis.__rest || function(n, t) {
  var e = {};
  for (var s in n)
    Object.prototype.hasOwnProperty.call(n, s) && t.indexOf(s) < 0 && (e[s] = n[s]);
  if (n != null && typeof Object.getOwnPropertySymbols == "function")
    for (var o = 0, s = Object.getOwnPropertySymbols(n); o < s.length; o++)
      t.indexOf(s[o]) < 0 && Object.prototype.propertyIsEnumerable.call(n, s[o]) && (e[s[o]] = n[s[o]]);
  return e;
};
var my = class extends Qs {
  constructor(t) {
    if (t.unroll)
      throw new xt("Unrolling is not possible with convolutional RNNs.");
    if (Array.isArray(t.cell))
      throw new xt("It is not possible at the moment to stack convolutional cells.");
    super(t), this.inputSpec = [new de({ ndim: 5 })];
  }
  call(t, e) {
    return D(() => {
      if (this.cell.dropoutMask != null && (yt(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (yt(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), e && e.constants)
        throw new E("ConvRNN2D cell does not support constants");
      const s = e == null ? null : e.mask, o = e == null ? null : e.training, r = e == null ? null : e.initialState;
      return super.call(t, { mask: s, training: o, initialState: r });
    });
  }
  computeOutputShape(t) {
    let e = this.computeSingleOutputShape(t);
    return this.returnSequences || (e = [e[0], ...e.slice(2)]), this.returnState && (e = [e, ...Array(2).fill([t[0], ...e.slice(-3)])]), e;
  }
  getInitialState(t) {
    return D(() => {
      const { stateSize: e } = this.cell, s = t.shape, o = this.computeSingleOutputShape(s), r = [o[0], ...o.slice(2)], i6 = ge(r);
      return Array.isArray(e) ? Array(e.length).fill(i6) : [i6];
    });
  }
  resetStates(t, e = false) {
    D(() => {
      if (!this.stateful)
        throw new Yn("Cannot call resetStates() on an RNN Layer that is not stateful.");
      const s = this.inputSpec[0].shape, o = this.computeSingleOutputShape(s), r = [o[0], ...o.slice(2)];
      if (s[0] == null)
        throw new E("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (this.getStates() == null)
        Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => ge(r)) : this.states_ = [ge(r)];
      else if (t == null)
        yt(this.states_), this.keptStates != null && (yt(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => ge(r)) : this.states_[0] = ge(r);
      else {
        if (Array.isArray(t) || (t = [t]), t.length !== this.states_.length)
          throw new E(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);
        e ? this.keptStates.push(this.states_.slice()) : yt(this.states_);
        for (let a = 0; a < this.states_.length; ++a) {
          const l = t[a], c = r;
          if (!Rt(l.shape, c))
            throw new E(`State ${a} is incompatible with layer ${this.name}: expected shape=${c}, received shape=${l.shape}`);
          this.states_[a] = l;
        }
      }
      this.states_ = this.states_.map((a) => cn(a.clone()));
    });
  }
  computeSingleOutputShape(t) {
    const { dataFormat: e, filters: s, kernelSize: o, padding: r, strides: i6, dilationRate: a } = this.cell, l = e === "channelsFirst", c = t[l ? 3 : 2], u = t[l ? 4 : 3], d = An(c, o[0], r, i6[0], a[0]), h6 = An(u, o[1], r, i6[1], a[1]);
    return [
      ...t.slice(0, 2),
      ...l ? [s, d, h6] : [d, h6, s]
    ];
  }
};
my.className = "ConvRNN2D";
var Sf = class extends iu {
  constructor(t) {
    const { filters: e, kernelSize: s, strides: o, padding: r, dataFormat: i6, dilationRate: a } = t;
    super(Object.assign(Object.assign({}, t), { units: e })), this.filters = e, be(this.filters, "filters"), this.kernelSize = er(s, 2, "kernelSize"), this.kernelSize.forEach((l) => be(l, "kernelSize")), this.strides = er(o || 1, 2, "strides"), this.strides.forEach((l) => be(l, "strides")), this.padding = r || "valid", fn(this.padding), this.dataFormat = i6 || "channelsLast", ae(this.dataFormat), this.dilationRate = er(a || 1, 2, "dilationRate"), this.dilationRate.forEach((l) => be(l, "dilationRate"));
  }
  build(t) {
    var e;
    t = $t(t);
    const s = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[s] == null)
      throw new E(`The channel dimension of the input should be defined. Found ${t[s]}`);
    const o = t[s], r = 4, i6 = this.kernelSize.concat([o, this.filters * r]);
    this.kernel = this.addWeight("kernel", i6, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    const a = this.kernelSize.concat([this.filters, this.filters * r]);
    if (this.recurrentKernel = this.addWeight("recurrent_kernel", a, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias) {
      let l;
      if (this.unitForgetBias) {
        const c = this.biasInitializer, u = this.filters;
        l = new (e = class extends Gn {
          apply(h6, p6) {
            const f = c.apply([u]), m = Us([u]), g6 = c.apply([u * 2]);
            return rf([f, m, g6]);
          }
        }, /** @nocollapse */
        e.className = "CustomInit", e)();
      } else
        l = this.biasInitializer;
      this.bias = this.addWeight("bias", [this.filters * r], null, l, this.biasRegularizer, true, this.biasConstraint);
    }
    this.built = true;
  }
  call(t, e) {
    return D(() => {
      if (t.length !== 3)
        throw new E(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);
      const s = e.training || false, o = t[0], r = t[1], i6 = t[2], a = 4;
      0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = Os({
        ones: () => Rn(o),
        rate: this.dropout,
        training: s,
        count: a,
        dropoutFunc: this.dropoutFunc
      }));
      const l = this.dropoutMask, c = (Y, Q, j) => !Q || !Q[j] ? Y : G(Q[j], Y);
      let u = c(o, l, 0), d = c(o, l, 1), h6 = c(o, l, 2), p6 = c(o, l, 3);
      0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = Os({
        ones: () => Rn(r),
        rate: this.recurrentDropout,
        training: s,
        count: a,
        dropoutFunc: this.dropoutFunc
      }));
      const f = this.recurrentDropoutMask;
      let m = c(r, f, 0), g6 = c(r, f, 1), b6 = c(r, f, 2), x6 = c(r, f, 3);
      const w6 = 3, [y6, I, C6, k7] = un(this.kernel.read(), a, w6), [S, N, R, M6] = this.useBias ? un(this.bias.read(), a) : [null, null, null, null];
      u = this.inputConv(u, y6, S, this.padding), d = this.inputConv(d, I, N, this.padding), h6 = this.inputConv(h6, C6, R, this.padding), p6 = this.inputConv(p6, k7, M6, this.padding);
      const [V, z, X, P6] = un(this.recurrentKernel.read(), a, w6);
      m = this.recurrentConv(m, V), g6 = this.recurrentConv(g6, z), b6 = this.recurrentConv(b6, X), x6 = this.recurrentConv(x6, P6);
      const A6 = this.recurrentActivation.apply(U(u, m)), B6 = this.recurrentActivation.apply(U(d, g6)), Z = U(G(B6, i6), G(A6, this.activation.apply(U(h6, b6)))), H6 = G(this.recurrentActivation.apply(U(p6, x6)), this.activation.apply(Z));
      return [H6, H6, Z];
    });
  }
  getConfig() {
    const t = super.getConfig(), e = _E(t, ["units"]), s = {
      filters: this.filters,
      kernelSize: this.kernelSize,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      strides: this.strides
    };
    return Object.assign(Object.assign({}, e), s);
  }
  inputConv(t, e, s, o) {
    const r = Co(t, e, this.strides, o || "valid", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC", this.dilationRate);
    return s ? Hn(r, s, this.dataFormat) : r;
  }
  recurrentConv(t, e) {
    return Co(t, e, 1, "same", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC");
  }
};
Sf.className = "ConvLSTM2DCell";
_(Sf);
var gy = class extends my {
  constructor(t) {
    const e = new Sf(t);
    super(Object.assign(Object.assign({}, t), { cell: e }));
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e);
  }
};
gy.className = "ConvLSTM2D";
_(gy);
var kf = class extends St {
  constructor(t) {
    super(t), this.rate = Math.max(Math.min(t.rate, 1), 0), this.noiseShape = t.noiseShape, this.seed = t.seed, this.supportsMasking = true;
  }
  getNoiseShape(t) {
    if (this.noiseShape == null)
      return this.noiseShape;
    const e = t.shape, s = [];
    for (let o = 0; o < this.noiseShape.length; ++o)
      s.push(this.noiseShape[o] == null ? e[o] : this.noiseShape[o]);
    return s;
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t);
      if (0 < this.rate && this.rate < 1) {
        const o = e.training == null ? false : e.training, r = this.getNoiseShape(s);
        return wa(() => ax(s, this.rate, r, this.seed), () => s, o);
      }
      return t;
    });
  }
  getConfig() {
    const t = {
      rate: this.rate,
      noiseShape: this.noiseShape,
      seed: this.seed
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  dispose() {
    return super.dispose();
  }
};
kf.className = "Dropout";
_(kf);
var by = class extends kf {
  constructor(t) {
    super(t), this.inputSpec = [{ ndim: 3 }];
  }
  getNoiseShape(t) {
    const e = t.shape;
    return [e[0], 1, e[2]];
  }
};
by.className = "SpatialDropout1D";
_(by);
var xy = class extends St {
  constructor(t) {
    if (super(t), this.activation = null, this.useBias = true, this.kernel = null, this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", t.batchInputShape == null && t.inputShape == null && t.inputDim != null) {
      let e = null;
      t.batchSize != null && (e = t.batchSize), this.batchInputShape = [e, t.inputDim];
    }
    this.units = t.units, be(this.units, "units"), this.activation = As(t.activation), t.useBias != null && (this.useBias = t.useBias), this.kernelInitializer = Ut(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.biasInitializer = Ut(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelConstraint = pe(t.kernelConstraint), this.biasConstraint = pe(t.biasConstraint), this.kernelRegularizer = Yt(t.kernelRegularizer), this.biasRegularizer = Yt(t.biasRegularizer), this.activityRegularizer = Yt(t.activityRegularizer), this.supportsMasking = true, this.inputSpec = [{ minNDim: 2 }];
  }
  build(t) {
    t = $t(t);
    const e = t[t.length - 1];
    this.kernel == null && (this.kernel = this.addWeight("kernel", [e, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint))), this.inputSpec = [{ minNDim: 2, axes: { [-1]: e } }], this.built = true;
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = t.slice();
    return e[e.length - 1] = this.units, e;
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t), o = tx(this.activation.getClassName());
      let r;
      return o != null ? r = ns(s, this.kernel.read(), o, this.bias ? this.bias.read() : null) : (r = ns(s, this.kernel.read()), this.bias != null && (r = Hn(r, this.bias.read())), this.activation != null && (r = this.activation.apply(r))), r;
    });
  }
  getConfig() {
    const t = {
      units: this.units,
      activation: Ps(this.activation),
      useBias: this.useBias,
      kernelInitializer: Jt(this.kernelInitializer),
      biasInitializer: Jt(this.biasInitializer),
      kernelRegularizer: Ft(this.kernelRegularizer),
      biasRegularizer: Ft(this.biasRegularizer),
      activityRegularizer: Ft(this.activityRegularizer),
      kernelConstraint: he(this.kernelConstraint),
      biasConstraint: he(this.biasConstraint)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
xy.className = "Dense";
_(xy);
var yy = class extends St {
  constructor(t) {
    t = t || {}, super(t), this.inputSpec = [{ minNDim: 3 }], this.dataFormat = t.dataFormat;
  }
  computeOutputShape(t) {
    t = $t(t);
    for (const e of t.slice(1))
      if (e == null)
        throw new E(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);
    return [t[0], Ds(t, 1)];
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      let s = mt(t);
      if (this.dataFormat === "channelsFirst" && s.rank > 1) {
        const o = [0];
        for (let r = 2; r < s.rank; ++r)
          o.push(r);
        o.push(1), s = kt(s, o);
      }
      return $G(s);
    });
  }
  getConfig() {
    const t = {};
    this.dataFormat != null && (t.dataFormat = this.dataFormat);
    const e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
yy.className = "Flatten";
_(yy);
var wy = class extends St {
  constructor(t) {
    super(t), this.supportsMasking = true, this.activation = As(t.activation);
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t);
      return this.activation.apply(s);
    });
  }
  getConfig() {
    const t = { activation: Ps(this.activation) }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
wy.className = "Activation";
_(wy);
var Iy = class extends St {
  constructor(t) {
    super(t), this.n = t.n, this.inputSpec = [{ ndim: 2 }];
  }
  computeOutputShape(t) {
    return [t[0], this.n, t[1]];
  }
  call(t, e) {
    return D(() => (t = mt(t), NG(t, this.n)));
  }
  getConfig() {
    const t = {
      n: this.n
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Iy.className = "RepeatVector";
_(Iy);
var Cy = class extends St {
  constructor(t) {
    super(t), this.targetShape = t.targetShape;
    for (let e = 0; e < this.targetShape.length; ++e)
      this.isUnknown(this.targetShape[e]) && (this.targetShape[e] = null);
  }
  isUnknown(t) {
    return t < 0 || t == null;
  }
  /**
   * Finds and replaces a missing dimension in output shape.
   *
   * This is a near direct port of the internal Numpy function
   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.
   *
   * @param inputShape: Original shape of array begin reshape.
   * @param outputShape: Target shape of the array, with at most a single
   * `null` or negative number, which indicates an underdetermined dimension
   * that should be derived from `inputShape` and the known dimensions of
   *   `outputShape`.
   * @returns: The output shape with `null` replaced with its computed value.
   * @throws: ValueError: If `inputShape` and `outputShape` do not match.
   */
  fixUnknownDimension(t, e) {
    const s = "Total size of new array must be unchanged.", o = e.slice();
    let r = 1, i6 = null;
    for (let l = 0; l < o.length; ++l) {
      const c = o[l];
      if (this.isUnknown(c))
        if (i6 === null)
          i6 = l;
        else
          throw new E("Can only specifiy one unknown dimension.");
      else
        r *= c;
    }
    const a = Ds(t);
    if (i6 !== null) {
      if (r === 0 || a % r !== 0)
        throw new E(s);
      o[i6] = a / r;
    } else if (a !== r)
      throw new E(s);
    return o;
  }
  computeOutputShape(t) {
    let e = false;
    for (let s = 0; s < t.length; ++s)
      if (this.isUnknown(t[s])) {
        e = true;
        break;
      }
    return e ? t.slice(0, 1).concat(this.targetShape) : t.slice(0, 1).concat(this.fixUnknownDimension(t.slice(1), this.targetShape));
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t), o = s.shape, r = o.slice(0, 1).concat(this.fixUnknownDimension(o.slice(1), this.targetShape));
      return W(s, r);
    });
  }
  getConfig() {
    const t = {
      targetShape: this.targetShape
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Cy.className = "Reshape";
_(Cy);
var vy = class extends St {
  constructor(t) {
    if (super(t), t.dims == null)
      throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
    if (!Array.isArray(t.dims))
      throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t.dims} instead.`);
    const e = On(1, t.dims.length + 1);
    if (!Rt(t.dims.slice().sort(), e))
      throw new Error("Invalid permutation `dims`: " + JSON.stringify(t.dims) + " `dims` must contain consecutive integers starting from 1.");
    this.dims = t.dims, this.dimsIncludingBatch = [0].concat(this.dims), this.inputSpec = [new de({ ndim: this.dims.length + 1 })];
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = t.slice();
    return this.dims.forEach((s, o) => {
      e[o + 1] = t[s];
    }), e;
  }
  call(t, e) {
    return kt(mt(t), this.dimsIncludingBatch);
  }
  getConfig() {
    const t = {
      dims: this.dims
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
vy.className = "Permute";
_(vy);
var Sy = class extends St {
  constructor(t) {
    super(t ?? {}), this.supportsMasking = true, t != null ? this.maskValue = t.maskValue == null ? 0 : t.maskValue : this.maskValue = 0;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = super.getConfig(), e = { maskValue: this.maskValue };
    return Object.assign(e, t), e;
  }
  computeMask(t, e) {
    const s = mt(t), o = -1;
    return bd(qr(s, this.maskValue), o);
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t), o = -1, r = true, i6 = bd(qr(s, this.maskValue), o, r);
      return G(s, et(i6, s.dtype));
    });
  }
};
Sy.className = "Masking";
_(Sy);
var ky = class extends St {
  constructor(t) {
    if (super(t), this.embeddings = null, this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform", t.batchInputShape == null && t.inputShape == null) {
      let e = null;
      t.batchSize != null && (e = t.batchSize), t.inputLength == null ? this.batchInputShape = [e, null] : this.batchInputShape = [e].concat(Zt(t.inputLength));
    }
    this.inputDim = t.inputDim, be(this.inputDim, "inputDim"), this.outputDim = t.outputDim, be(this.outputDim, "outputDim"), this.embeddingsInitializer = Ut(t.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER), this.embeddingsRegularizer = Yt(t.embeddingsRegularizer), this.activityRegularizer = Yt(t.activityRegularizer), this.embeddingsConstraint = pe(t.embeddingsConstraint), this.maskZero = t.maskZero, this.supportsMasking = t.maskZero, this.inputLength = t.inputLength;
  }
  build(t) {
    this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint), this.built = true;
  }
  // Override warnOnIncompatibleInputShape because an embedding layer allows
  // the input to have varying ranks.
  warnOnIncompatibleInputShape(t) {
  }
  computeMask(t, e) {
    return D(() => this.maskZero ? (t = mt(t), qr(t, Tt(t))) : null);
  }
  computeOutputShape(t) {
    if (t = $t(t), this.inputLength == null)
      return [...t, this.outputDim];
    const e = Zt(this.inputLength);
    if (e.length !== t.length - 1)
      throw new E(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);
    {
      let s = 0;
      for (let o = 0; o < e.length; ++o) {
        const r = e[o], i6 = t[o + 1];
        if (r != null && i6 != null && r !== i6)
          throw new E(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);
        r == null && (e[s] = i6), s++;
      }
    }
    return [t[0], ...e, this.outputDim];
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      let s = mt(t);
      s.dtype !== "int32" && (s = es(s, "int32"));
      const o = ix(this.embeddings.read(), W(s, [s.size]));
      return W(o, $t(this.computeOutputShape(s.shape)));
    });
  }
  getConfig() {
    const t = {
      inputDim: this.inputDim,
      outputDim: this.outputDim,
      embeddingsInitializer: Jt(this.embeddingsInitializer),
      embeddingsRegularizer: Ft(this.embeddingsRegularizer),
      activityRegularizer: Ft(this.activityRegularizer),
      embeddingsConstraint: he(this.embeddingsConstraint),
      maskZero: this.maskZero,
      inputLength: this.inputLength
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
ky.className = "Embedding";
_(ky);
var Xo = class extends St {
  constructor(t) {
    super(t || {}), this.supportsMasking = true;
  }
  /**
   * Logic for merging multiple tensors, to be overridden by subclasses.
   * @param inputs
   */
  mergeFunction(t) {
    throw new xt();
  }
  /**
   * Computes the shape of the result of an elementwise operation.
   *
   * @param shape1: Shape of the first tensor.
   * @param shape2: Shape of the second tensor.
   * @returns Expected output shape when an elementwise operation is carried
   *   out on 2 tensors with shapes `shape1` and `shape2`.
   * @throws ValueError: If `shape1` and `shape2` are not compatible for
   *   element-wise operations.
   */
  computeElementwiseOpOutputShape(t, e) {
    if (t == null || e == null)
      return null;
    if (t.length < e.length)
      return this.computeElementwiseOpOutputShape(e, t);
    if (e.length === 0)
      return t;
    const s = t.slice(0, t.length - e.length);
    for (let o = 0; o < e.length; ++o) {
      const r = t[t.length - e.length + o], i6 = e[o];
      if (r == null || i6 == null || r < 0 || i6 < 0)
        s.push(null);
      else if (r === 1)
        s.push(i6);
      else if (i6 === 1)
        s.push(r);
      else {
        if (r !== i6)
          throw new E("Operands could not be broadcast together with shapes " + JSON.stringify(t) + " " + JSON.stringify(e));
        s.push(r);
      }
    }
    return s;
  }
  build(t) {
    if (Array.isArray(t) && !Array.isArray(t[0]) && (t = [$t(t)]), t = t, t.length < 2)
      throw new E(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);
    let e = [];
    for (const r of t)
      r != null && r[0] !== null && e.push(r[0]);
    if (e = Ws(e), e.length > 1)
      throw new E(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);
    let s = t[0] == null ? null : t[0].slice(1);
    for (let r = 1; r < t.length; ++r) {
      const i6 = t[r] == null ? null : t[r].slice(1);
      s = this.computeElementwiseOpOutputShape(s, i6);
    }
    const o = t.map((r) => r.length);
    t.indexOf(null) === -1 && Ws(o).length === 1 ? this.reshapeRequired = false : this.reshapeRequired = true;
  }
  call(t, e) {
    return D(() => {
      if (t = t, this.reshapeRequired) {
        const s = [], o = t.map((r) => r.rank);
        if (o.indexOf(null) === -1) {
          const r = Xs(o);
          for (let i6 of t) {
            const a = i6.rank;
            for (let l = 0; l < r - a; ++l)
              i6 = xa(i6, 1);
            s.push(i6);
          }
          return this.mergeFunction(s);
        } else {
          let r = false;
          for (const l of t) {
            const c = l.rank;
            if (c == null) {
              const u = l.shape, d = u[0], h6 = u.slice(1).concat([d]);
              let p6 = W(l, [d].concat(Ds(u.slice(1))));
              p6 = kt(p6, [1, 0]), p6 = W(p6, h6), s.push(p6), r = true;
            } else if (c > 1) {
              const u = On(1, c).concat([0]);
              s.push(kt(l, u)), r = true;
            } else
              s.push(l);
          }
          let i6 = this.mergeFunction(s);
          const a = i6.rank;
          if (r) {
            if (a == null) {
              const l = i6.shape, c = l.length, u = l[c - 1], d = [u].concat(l.slice(0, l.length - 1));
              i6 = W(kt(W(i6, [-1, u]), [1, 0]), d);
            } else if (a > 1) {
              const l = [a - 1].concat(On(0, a - 1));
              i6 = kt(i6, l);
            }
          }
          return i6;
        }
      } else
        return this.mergeFunction(t);
    });
  }
  computeOutputShape(t) {
    t = t;
    let e;
    t[0] == null ? e = null : e = t[0].slice(1);
    for (let o = 1; o < t.length; ++o) {
      const r = t[o] == null ? null : t[o].slice(1);
      e = this.computeElementwiseOpOutputShape(e, r);
    }
    let s = [];
    for (const o of t)
      o != null && o[0] !== null && s.push(o[0]);
    return s = Ws(s), s.length === 1 ? e = s.concat(e) : e = [null].concat(e), e;
  }
  computeMask(t, e) {
    return D(() => {
      if (e == null)
        return null;
      if (!Array.isArray(e))
        throw new E("`mask` should be an Array");
      if (!Array.isArray(t))
        throw new E("`inputs` should be an Array");
      if (e.length !== t.length)
        throw new E(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);
      if (e.every((o) => o == null))
        return null;
      e = e.map((o) => o == null ? o : Ue(o, 0));
      let s = e[0];
      for (let o = 1; o < e.length - 1; ++o)
        s = ss(s, e[o]);
      return s;
    });
  }
};
var Ty = class extends Xo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0].clone();
      for (let s = 1; s < t.length; ++s)
        e = U(e, t[s]);
      return e;
    });
  }
};
Ty.className = "Add";
_(Ty);
var Ny = class extends Xo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0].clone();
      for (let s = 1; s < t.length; ++s)
        e = G(e, t[s]);
      return e;
    });
  }
};
Ny.className = "Multiply";
_(Ny);
var Ry = class extends Xo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0].clone();
      for (let s = 1; s < t.length; ++s)
        e = U(e, t[s]);
      return G(1 / t.length, e);
    });
  }
};
Ry.className = "Average";
_(Ry);
var $y = class extends Xo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0];
      for (let s = 1; s < t.length; ++s)
        e = _s(e, t[s]);
      return e;
    });
  }
};
$y.className = "Maximum";
_($y);
var Gy = class extends Xo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0];
      for (let s = 1; s < t.length; ++s)
        e = Kc(e, t[s]);
      return e;
    });
  }
};
Gy.className = "Minimum";
_(Gy);
var Ey = class extends Xo {
  constructor(t) {
    super(t), this.DEFAULT_AXIS = -1, t == null && (t = {}), this.axis = t.axis == null ? this.DEFAULT_AXIS : t.axis, this.supportsMasking = true, this.reshapeRequired = false;
  }
  build(t) {
    if (!(Array.isArray(t) && Array.isArray(t[0])) || t.length === 1)
      throw new E("A `Concatenate` layer should be called on a list of at least 2 inputs");
    t = t;
    let e = true;
    for (const o of t)
      if (o != null) {
        e = false;
        break;
      }
    if (e)
      return;
    const s = [];
    for (let o = 0; o < t.length; ++o) {
      const r = t[o].slice();
      r.splice(this.axis, 1);
      let i6 = false;
      for (const a of s)
        if (Rt(a, r)) {
          i6 = true;
          break;
        }
      i6 || s.push(r);
    }
    if (s.length > 1)
      throw new E("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(t));
  }
  mergeFunction(t) {
    return D(() => rf(t, this.axis));
  }
  computeOutputShape(t) {
    if (!(Array.isArray(t) && Array.isArray(t[0])))
      throw new E("A `Concatenate` layer should be called on a list of inputs.");
    const e = t, s = e[0].slice(), o = this.axis < 0 ? s.length + this.axis : this.axis;
    for (const r of e.slice(1)) {
      if (s[o] == null || r[o] == null) {
        s[o] = null;
        break;
      }
      s[o] += r[o];
    }
    return s;
  }
  computeMask(t, e) {
    if (e == null)
      return null;
    if (!Array.isArray(e))
      throw new E("`mask` should be an array for Concatenate");
    if (!Array.isArray(t))
      throw new E("`inputs` should be an array for Concatenate");
    if (e.length !== t.length)
      throw new E(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);
    return D(() => {
      let s = true;
      if (e.forEach((i6) => {
        if (i6 != null) {
          s = false;
          return;
        }
      }), s)
        return null;
      const o = [];
      for (let i6 = 0; i6 < t.length; ++i6)
        e[i6] == null ? o.push(et(Rn(t[i6]), "bool")) : e[i6].rank < t[i6].rank ? o.push(Ue(e[i6], -1)) : o.push(e[i6]);
      const r = Ge(o, this.axis);
      return Nb(r, -1, false);
    });
  }
  getConfig() {
    const t = {
      axis: this.axis
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Ey.className = "Concatenate";
_(Ey);
function Dr(n, t) {
  for (; n < 0; )
    n += t;
  return n;
}
function UE(n, t, e) {
  if (n.shape.length > 3 || t.shape.length > 3)
    throw new xt("batchDot is not implemented for tensors of 4D or higher rank yet");
  if (v2(n.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, but got ${n.shape.length}`), v2(n.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, but got ${t.shape.length}`), typeof e == "number" && (e = [e, e]), n.dtype === "complex64" || t.dtype === "complex64")
    throw new xt("batchDot is not implemented for complex64-type Tensors yet.");
  const s = n.shape.length, o = t.shape.length;
  e == null && (e = [s - 1, o - 2]);
  const r = e;
  return D(() => {
    let i6;
    if (s > o) {
      i6 = s - o;
      const l = [];
      for (let c = 0; c < i6; ++c)
        l.push(1);
      t = W(t, t.shape.concat(l));
    } else if (o > s) {
      i6 = o - s;
      const l = [];
      for (let c = 0; c < i6; ++c)
        l.push(1);
      n = W(n, n.shape.concat(l));
    } else
      i6 = 0;
    let a;
    if (n.shape.length === 2 && t.shape.length === 2)
      r[0] === r[1] ? a = at(G(n, t), r[0]) : a = at(G(kt(n, [1, 0]), t), r[1]);
    else {
      const l = r[0] !== n.shape.length - 1, c = r[1] === t.shape.length - 1;
      a = Gt(n, t, l, c);
    }
    if (i6 > 0) {
      let l;
      s > o ? l = s + o - 3 : l = s - 1;
      const c = [];
      for (let u = l; u < l + i6; ++u)
        c.push(u);
      a = ha(a, c);
    }
    return a.shape.length === 1 && (a = Ue(a, 1)), a;
  });
}
var Ly = class extends Xo {
  constructor(t) {
    super(t), this.axes = t.axes, this.normalize = t.normalize == null ? false : t.normalize, this.supportsMasking = true, this.reshapeRequired = false;
  }
  build(t) {
    v2(Array.isArray(t) && t.length === 2 && Array.isArray(t[0]) && Array.isArray(t[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    const e = t[0], s = t[1];
    if (e.length > 3 || s.length > 3)
      throw new xt("Dot layer does not support tensors of 4D or higher rank yet.");
    const o = this.interpretAxes(e, s);
    if (e[o[0]] !== s[o[1]])
      throw new E(`Dimension incompatibility: ${e[o[0]]} !== ${s[o[1]]}`);
  }
  mergeFunction(t) {
    if (t.length !== 2)
      throw new E(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);
    let e = t[0], s = t[1], o;
    return Array.isArray(this.axes) ? o = this.axes.map((r, i6) => Dr(r, t[i6].shape.length)) : o = [
      Dr(this.axes, e.shape.length),
      Dr(this.axes, s.shape.length)
    ], this.normalize && (e = xl(e, o[0]), s = xl(s, o[1])), UE(e, s, o);
  }
  interpretAxes(t, e) {
    let s;
    return Array.isArray(this.axes) ? s = this.axes : s = [
      Dr(this.axes, t.length),
      Dr(this.axes, e.length)
    ], s;
  }
  computeOutputShape(t) {
    v2(Array.isArray(t) && t.length === 2 && Array.isArray(t[0]) && Array.isArray(t[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    const e = t[0].slice(), s = t[1].slice();
    if (e.length > 3 || s.length > 3)
      throw new xt("Dot layer does not support tensors of 4D or higher rank yet.");
    const o = this.interpretAxes(e, s);
    e.splice(o[0], 1), s.splice(o[1], 1), s.splice(0, 1);
    const r = e.concat(s);
    return r.length === 1 && r.push(1), r;
  }
  computeMask(t, e) {
    return null;
  }
  getConfig() {
    const t = {
      axes: this.axes,
      normalize: this.normalize
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Ly.className = "Dot";
_(Ly);
var My = class extends St {
  constructor(t) {
    super(t), this.supportsMasking = true, this.stddev = t.stddev;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = super.getConfig(), e = { stddev: this.stddev };
    return Object.assign(e, t), e;
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t);
      return wa(() => U(jc(s.shape, 0, this.stddev), s), () => s, e.training || false);
    });
  }
};
My.className = "GaussianNoise";
_(My);
var Wy = class extends St {
  constructor(t) {
    super(t), this.supportsMasking = true, this.rate = t.rate;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = super.getConfig(), e = { rate: this.rate };
    return Object.assign(e, t), e;
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t);
      return this.rate > 0 && this.rate < 1 ? wa(() => {
        const r = Math.sqrt(this.rate / (1 - this.rate));
        return G(s, jc(s.shape, 1, r));
      }, () => s, e.training || false) : s;
    });
  }
};
Wy.className = "GaussianDropout";
_(Wy);
var Dy = class extends St {
  constructor(t) {
    super(t), this.supportsMasking = true, this.rate = t.rate, this.noiseShape = t.noiseShape;
  }
  _getNoiseShape(t) {
    return this.noiseShape || mt(t).shape;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = super.getConfig(), e = { rate: this.rate };
    return Object.assign(e, t), e;
  }
  call(t, e) {
    return D(() => {
      if (this.rate < 1 && this.rate > 0) {
        const s = this._getNoiseShape(t);
        return wa(() => {
          const r = mt(t), i6 = 1.6732632423543772, a = 1.0507009873554805, l = -i6 * a;
          let c = Do(Zc(s), this.rate);
          c = es(c, "float32");
          const u = ((1 - this.rate) * (1 + this.rate * l ** 2)) ** -0.5, d = -u * l * this.rate, h6 = U(G(r, c), G(U(c, -1), l));
          return U(G(h6, u), d);
        }, () => mt(t), e.training || false);
      }
      return t;
    });
  }
};
Dy.className = "AlphaDropout";
_(Dy);
function ri(n, t, e, s, o, r = 1e-3) {
  let i6;
  if (n.rank === 2)
    i6 = X2(n, t, e, s, o, r);
  else if (n.rank === 3)
    i6 = A2(n, t, e, s, o, r);
  else if (n.rank === 4)
    i6 = K2(n, t, e, s, o, r);
  else
    throw new xt(`batchNormalization is not implemented for array of rank ${n.rank} yet`);
  return i6;
}
function YE(n, t, e, s, o = 1e-3) {
  return D(() => {
    const r = op(n, s), i6 = r.mean, a = r.variance;
    return [ri(n, i6, a, e, t, o), i6, a];
  });
}
function QE(n, t, e, s, o = 1e-3) {
  return D(() => {
    const r = op(n, s), i6 = r.mean, a = r.variance, l = [];
    for (const f of On(0, n.rank))
      s.indexOf(f) !== -1 ? l.push(1) : l.push(n.shape[f]);
    const c = W(i6, l), u = W(a, l), d = t == null ? null : W(t, l), h6 = e == null ? null : W(e, l);
    return [ri(n, c, u, h6, d, o), i6, a];
  });
}
function JE(n, t, e, s, o = 1e-3) {
  return Rt(s.slice().sort(), On(0, n.rank - 1)) ? YE(n, t, e, s, o) : QE(n, t, e, s, o);
}
var Fy = class extends St {
  constructor(t) {
    t == null && (t = {}), super(t), this.supportsMasking = true, this.axis = t.axis == null ? -1 : t.axis, this.momentum = t.momentum == null ? 0.99 : t.momentum, this.epsilon = t.epsilon == null ? 1e-3 : t.epsilon, this.center = t.center == null ? true : t.center, this.scale = t.scale == null ? true : t.scale, this.betaInitializer = Ut(t.betaInitializer || "zeros"), this.gammaInitializer = Ut(t.gammaInitializer || "ones"), this.movingMeanInitializer = Ut(t.movingMeanInitializer || "zeros"), this.movingVarianceInitializer = Ut(t.movingVarianceInitializer || "ones"), this.betaConstraint = pe(t.betaConstraint), this.gammaConstraint = pe(t.gammaConstraint), this.betaRegularizer = Yt(t.betaRegularizer), this.gammaRegularizer = Yt(t.gammaRegularizer);
  }
  build(t) {
    t = $t(t);
    const e = this.axis >= 0 ? this.axis : this.axis + t.length, s = t[e];
    if (s == null)
      throw new E(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t)}.`);
    this.inputSpec = [new de({ ndim: t.length, axes: { [e]: s } })];
    const o = [s];
    this.scale && (this.gamma = this.addWeight("gamma", o, null, this.gammaInitializer, this.gammaRegularizer, true, this.gammaConstraint)), this.center && (this.beta = this.addWeight("beta", o, null, this.betaInitializer, this.betaRegularizer, true, this.betaConstraint)), this.movingMean = this.addWeight("moving_mean", o, null, this.movingMeanInitializer, null, false), this.movingVariance = this.addWeight("moving_variance", o, null, this.movingVarianceInitializer, null, false), this.built = true;
  }
  call(t, e) {
    return D(() => {
      const s = e.training == null ? false : e.training, o = mt(t), r = o.shape, i6 = r.length, a = On(0, i6), l = this.axis >= 0 ? this.axis : this.axis + i6;
      a.splice(l, 1);
      const c = Ro(1, i6);
      c[l] = r[l];
      const u = a.slice();
      u.sort();
      const d = !Rt(u, On(0, i6).slice(0, i6 - 1)), h6 = () => {
        if (d) {
          const x6 = W(this.movingMean.read(), c), w6 = W(this.movingVariance.read(), c), y6 = this.center ? W(this.beta.read(), c) : null, I = this.scale ? W(this.gamma.read(), c) : null;
          return ri(o, x6, w6, y6, I, this.epsilon);
        } else
          return ri(o, this.movingMean.read(), this.movingVariance.read(), this.beta == null ? null : this.beta.read(), this.gamma == null ? null : this.gamma.read(), this.epsilon);
      };
      if (!s)
        return h6();
      const [p6, f, m] = JE(o, this.gamma.read(), this.beta.read(), a, this.epsilon), g6 = (x6, w6, y6) => {
        D(() => {
          const I = 1 - y6, C6 = x6.read(), k7 = G(lt(C6, w6), I);
          x6.write(lt(C6, k7));
        });
      };
      return (() => {
        g6(this.movingMean, f, this.momentum), g6(this.movingVariance, m, this.momentum);
      })(), p6;
    });
  }
  getConfig() {
    const t = {
      axis: this.axis,
      momentum: this.momentum,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: Jt(this.betaInitializer),
      gammaInitializer: Jt(this.gammaInitializer),
      movingMeanInitializer: Jt(this.movingMeanInitializer),
      movingVarianceInitializer: Jt(this.movingVarianceInitializer),
      betaRegularizer: Ft(this.betaRegularizer),
      gammaRegularizer: Ft(this.gammaRegularizer),
      betaConstraint: he(this.betaConstraint),
      gammaConstraint: he(this.gammaConstraint)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Fy.className = "BatchNormalization";
_(Fy);
var Vy = class extends St {
  constructor(t) {
    if (t == null && (t = {}), super(t), this.axis = t.axis == null ? -1 : t.axis, typeof this.axis == "number") {
      if (!Number.isInteger(this.axis))
        throw new Error(`Expected axis to be an integer, but received ${this.axis}`);
    } else if (Array.isArray(this.axis)) {
      for (const e of this.axis)
        if (!Number.isInteger(e))
          throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`);
    } else
      throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);
    this.epsilon = t.epsilon == null ? 1e-3 : t.epsilon, this.center = t.center == null ? true : t.center, this.scale = t.scale == null ? true : t.scale, this.betaInitializer = Ut(t.betaInitializer || "zeros"), this.gammaInitializer = Ut(t.gammaInitializer || "ones"), this.betaRegularizer = Yt(t.betaRegularizer), this.gammaRegularizer = Yt(t.gammaRegularizer), this.supportsMasking = true;
  }
  build(t) {
    t = $t(t);
    const e = t.length;
    typeof this.axis == "number" && (this.axis = [this.axis]);
    for (let r = 0; r < this.axis.length; ++r)
      this.axis[r] < 0 && (this.axis[r] += e);
    for (const r of this.axis)
      if (r < 0 || r >= e)
        throw new Error(`Invalid axis: ${r}`);
    if (this.axis.length !== Ws(this.axis).length)
      throw new Error(`Found duplicate axes in: ${this.axis}`);
    const s = this.axis.map((r) => t[r]), o = true;
    this.scale ? this.gamma = this.addWeight("gamma", s, "float32", this.gammaInitializer, this.gammaRegularizer, o) : this.gamma = null, this.center ? this.beta = this.addWeight("beta", s, "float32", this.betaInitializer, this.betaRegularizer, o) : this.beta = null, this.built = true;
  }
  call(t, e) {
    const s = mt(t), o = s.shape, r = o.length;
    return D(() => {
      let { mean: a, variance: l } = op(s, this.axis, true);
      const c = Ro(1, r);
      for (const m of this.axis)
        c[m] = o[m];
      const u = (m) => m != null && m.shape.length !== r ? W(m, c) : m;
      let d = this.scale ? u(this.gamma.read()) : null, h6 = this.center ? u(this.beta.read()) : null;
      const p6 = [], f = [];
      for (let m = 0; m < r; ++m)
        this.axis.indexOf(m) !== -1 ? (p6.push(o[m]), f.push(1)) : (p6.push(1), f.push(o[m]));
      return a = Vn(a, p6), l = Vn(l, p6), d != null && (d = Vn(d, f)), h6 != null && (h6 = Vn(h6, f)), ri(s, a, l, h6, d, this.epsilon);
    });
  }
  getConfig() {
    const t = {
      axis: this.axis,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: Jt(this.betaInitializer),
      gammaInitializer: Jt(this.gammaInitializer),
      betaRegularizer: Ft(this.betaRegularizer),
      gammaRegularizer: Ft(this.gammaRegularizer)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Vy.className = "LayerNormalization";
_(Vy);
function jE(n, t, e) {
  return D(() => {
    if (n.rank !== 4)
      throw new E(`temporalPadding expects input tensor to be 4-D, but received a ${n.rank}-D tensor.`);
    if (t == null && (t = [[1, 1], [1, 1]]), t.length !== 2 || t[0].length !== 2 || t[1].length !== 2)
      throw new E("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
    if (e == null && (e = Kn()), e !== "channelsLast" && e !== "channelsFirst")
      throw new E(`Unknown data format: ${e}. Supported data formats are 'channelsLast' and 'channelsFirst.`);
    let s;
    return e === "channelsFirst" ? s = [[0, 0], [0, 0], t[0], t[1]] : s = [[0, 0], t[0], t[1], [0, 0]], rp(n, s);
  });
}
var zy = class extends St {
  constructor(t) {
    if (t == null && (t = {}), super(t), this.dataFormat = t.dataFormat == null ? Kn() : t.dataFormat, t.padding == null)
      this.padding = [[1, 1], [1, 1]];
    else if (typeof t.padding == "number")
      this.padding = [[t.padding, t.padding], [t.padding, t.padding]];
    else {
      if (t.padding = t.padding, t.padding.length !== 2)
        throw new E(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);
      let e, s;
      if (typeof t.padding[0] == "number")
        e = [t.padding[0], t.padding[0]], s = [t.padding[1], t.padding[1]];
      else {
        if (t.padding = t.padding, t.padding[0].length !== 2)
          throw new E(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);
        if (e = t.padding[0], t.padding[1].length !== 2)
          throw new E(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);
        s = t.padding[1];
      }
      this.padding = [e, s];
    }
    this.inputSpec = [new de({ ndim: 4 })];
  }
  computeOutputShape(t) {
    t = $t(t);
    let e, s;
    return this.dataFormat === "channelsFirst" ? (t[2] != null && t[2] >= 0 ? e = t[2] + this.padding[0][0] + this.padding[0][1] : e = null, t[3] != null && t[3] >= 0 ? s = t[3] + this.padding[1][0] + this.padding[1][1] : s = null, [t[0], t[1], e, s]) : (t[1] != null && t[1] >= 0 ? e = t[1] + this.padding[0][0] + this.padding[0][1] : e = null, t[2] != null && t[2] >= 0 ? s = t[2] + this.padding[1][0] + this.padding[1][1] : s = null, [t[0], e, s, t[3]]);
  }
  call(t, e) {
    return D(() => jE(mt(t), this.padding, this.dataFormat));
  }
  getConfig() {
    const t = {
      padding: this.padding,
      dataFormat: this.dataFormat
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
zy.className = "ZeroPadding2D";
_(zy);
function au(n, t, e, s, o, r) {
  return D(() => {
    ae(o), nx(r), fn(s), e == null && (e = [1, 1]), s == null && (s = "valid"), o == null && (o = Kn()), r == null && (r = "max"), n = wf(n, o);
    let i6;
    const a = s === "same" ? "same" : "valid";
    return r === "max" ? i6 = sp(n, t, e, a) : i6 = Bh(
      // TODO(cais): Rank check?
      n,
      t,
      e,
      a
    ), o === "channelsFirst" && (i6 = kt(i6, [0, 3, 1, 2])), i6;
  });
}
function Xy(n, t, e, s, o, r) {
  return D(() => {
    ae(o), nx(r), fn(s), e == null && (e = [1, 1, 1]), s == null && (s = "valid"), o == null && (o = Kn()), r == null && (r = "max"), n = ny(n, o);
    let i6;
    const a = s === "same" ? "same" : "valid";
    return r === "max" ? i6 = NS(n, t, e, a) : i6 = $2(n, t, e, a), o === "channelsFirst" && (i6 = kt(i6, [0, 4, 1, 2, 3])), i6;
  });
}
var Py = class extends St {
  /**
   *
   * @param args Parameters for the Pooling layer.
   *
   * config.poolSize defaults to 2.
   */
  constructor(t) {
    if (t.poolSize == null && (t.poolSize = 2), super(t), typeof t.poolSize == "number")
      this.poolSize = [t.poolSize];
    else if (Array.isArray(t.poolSize) && t.poolSize.length === 1 && typeof t.poolSize[0] == "number")
      this.poolSize = t.poolSize;
    else
      throw new E(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.poolSize)}`);
    if (be(this.poolSize, "poolSize"), t.strides == null)
      this.strides = this.poolSize;
    else if (typeof t.strides == "number")
      this.strides = [t.strides];
    else if (Array.isArray(t.strides) && t.strides.length === 1 && typeof t.strides[0] == "number")
      this.strides = t.strides;
    else
      throw new E(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.strides)}`);
    be(this.strides, "strides"), this.padding = t.padding == null ? "valid" : t.padding, fn(this.padding), this.inputSpec = [new de({ ndim: 3 })];
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = An(t[1], this.poolSize[0], this.padding, this.strides[0]);
    return [t[0], e, t[2]];
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e), t = xa(mt(t), 2);
      const s = this.poolingFunction(mt(t), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
      return ha(s, [2]);
    });
  }
  getConfig() {
    const t = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var Ay = class extends Py {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), fn(o), au(t, e, s, o, r, "max");
  }
};
Ay.className = "MaxPooling1D";
_(Ay);
var Oy = class extends Py {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), fn(o), au(t, e, s, o, r, "avg");
  }
};
Oy.className = "AveragePooling1D";
_(Oy);
var Ky = class extends St {
  constructor(t) {
    if (t.poolSize == null && (t.poolSize = [2, 2]), super(t), this.poolSize = Array.isArray(t.poolSize) ? t.poolSize : [t.poolSize, t.poolSize], t.strides == null)
      this.strides = this.poolSize;
    else if (Array.isArray(t.strides)) {
      if (t.strides.length !== 2)
        throw new E(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${t.strides.length}.`);
      this.strides = t.strides;
    } else
      this.strides = [t.strides, t.strides];
    be(this.poolSize, "poolSize"), be(this.strides, "strides"), this.padding = t.padding == null ? "valid" : t.padding, this.dataFormat = t.dataFormat == null ? "channelsLast" : t.dataFormat, ae(this.dataFormat), fn(this.padding), this.inputSpec = [new de({ ndim: 4 })];
  }
  computeOutputShape(t) {
    t = $t(t);
    let e = this.dataFormat === "channelsFirst" ? t[2] : t[1], s = this.dataFormat === "channelsFirst" ? t[3] : t[2];
    return e = An(e, this.poolSize[0], this.padding, this.strides[0]), s = An(s, this.poolSize[1], this.padding, this.strides[1]), this.dataFormat === "channelsFirst" ? [t[0], t[1], e, s] : [t[0], e, s, t[3]];
  }
  call(t, e) {
    return D(() => (this.invokeCallHook(t, e), this.poolingFunction(mt(t), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }
  getConfig() {
    const t = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var Zy = class extends Ky {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), fn(o), au(t, e, s, o, r, "max");
  }
};
Zy.className = "MaxPooling2D";
_(Zy);
var By = class extends Ky {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), fn(o), au(t, e, s, o, r, "avg");
  }
};
By.className = "AveragePooling2D";
_(By);
var Hy = class extends St {
  constructor(t) {
    if (t.poolSize == null && (t.poolSize = [2, 2, 2]), super(t), this.poolSize = Array.isArray(t.poolSize) ? t.poolSize : [t.poolSize, t.poolSize, t.poolSize], t.strides == null)
      this.strides = this.poolSize;
    else if (Array.isArray(t.strides)) {
      if (t.strides.length !== 3)
        throw new E(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${t.strides.length}.`);
      this.strides = t.strides;
    } else
      this.strides = [t.strides, t.strides, t.strides];
    be(this.poolSize, "poolSize"), be(this.strides, "strides"), this.padding = t.padding == null ? "valid" : t.padding, this.dataFormat = t.dataFormat == null ? "channelsLast" : t.dataFormat, ae(this.dataFormat), fn(this.padding), this.inputSpec = [new de({ ndim: 5 })];
  }
  computeOutputShape(t) {
    t = $t(t);
    let e = this.dataFormat === "channelsFirst" ? t[2] : t[1], s = this.dataFormat === "channelsFirst" ? t[3] : t[2], o = this.dataFormat === "channelsFirst" ? t[4] : t[3];
    return e = An(e, this.poolSize[0], this.padding, this.strides[0]), s = An(s, this.poolSize[1], this.padding, this.strides[1]), o = An(o, this.poolSize[2], this.padding, this.strides[2]), this.dataFormat === "channelsFirst" ? [t[0], t[1], e, s, o] : [t[0], e, s, o, t[4]];
  }
  call(t, e) {
    return D(() => (this.invokeCallHook(t, e), this.poolingFunction(mt(t), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }
  getConfig() {
    const t = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var _y = class extends Hy {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), fn(o), Xy(t, e, s, o, r, "max");
  }
};
_y.className = "MaxPooling3D";
_(_y);
var Uy = class extends Hy {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), fn(o), Xy(t, e, s, o, r, "avg");
  }
};
Uy.className = "AveragePooling3D";
_(Uy);
var Yy = class extends St {
  constructor(t) {
    super(t), this.inputSpec = [new de({ ndim: 3 })];
  }
  computeOutputShape(t) {
    return [t[0], t[2]];
  }
  call(t, e) {
    throw new xt();
  }
};
var Qy = class extends Yy {
  constructor(t) {
    super(t || {});
  }
  call(t, e) {
    return D(() => {
      const s = mt(t);
      return se(s, 1);
    });
  }
};
Qy.className = "GlobalAveragePooling1D";
_(Qy);
var Jy = class extends Yy {
  constructor(t) {
    super(t || {});
  }
  call(t, e) {
    return D(() => {
      const s = mt(t);
      return Xn(s, 1);
    });
  }
};
Jy.className = "GlobalMaxPooling1D";
_(Jy);
var jy = class extends St {
  constructor(t) {
    super(t), this.dataFormat = t.dataFormat == null ? "channelsLast" : t.dataFormat, ae(this.dataFormat), this.inputSpec = [new de({ ndim: 4 })];
  }
  computeOutputShape(t) {
    return t = t, this.dataFormat === "channelsLast" ? [t[0], t[3]] : [t[0], t[1]];
  }
  call(t, e) {
    throw new xt();
  }
  getConfig() {
    const t = { dataFormat: this.dataFormat }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var qy = class extends jy {
  call(t, e) {
    return D(() => {
      const s = mt(t);
      return this.dataFormat === "channelsLast" ? se(s, [1, 2]) : se(s, [2, 3]);
    });
  }
};
qy.className = "GlobalAveragePooling2D";
_(qy);
var t1 = class extends jy {
  call(t, e) {
    return D(() => {
      const s = mt(t);
      return this.dataFormat === "channelsLast" ? Xn(s, [1, 2]) : Xn(s, [2, 3]);
    });
  }
};
t1.className = "GlobalMaxPooling2D";
_(t1);
var e1 = class extends St {
  constructor(t) {
    super(t), this.layer = t.layer;
  }
  build(t) {
    this.built = true;
  }
  // TODO(cais): Implement activityRegularizer getter.
  get trainable() {
    return this.layer != null ? this.layer.trainable : false;
  }
  set trainable(t) {
    this.layer != null && (this.layer.trainable = t);
  }
  get trainableWeights() {
    return this.layer.trainableWeights;
  }
  // TODO(cais): Implement setter for trainableWeights.
  get nonTrainableWeights() {
    return this.layer.nonTrainableWeights;
  }
  // TODO(cais): Implement setter for nonTrainableWeights.
  get updates() {
    return this.layer._updates;
  }
  // TODO(cais): Implement getUpdatesFor().
  get losses() {
    return this.layer.losses;
  }
  // TODO(cais): Implement getLossesFor().
  getWeights() {
    return this.layer.getWeights();
  }
  setWeights(t) {
    this.layer.setWeights(t);
  }
  getConfig() {
    const t = {
      layer: {
        className: this.layer.getClassName(),
        config: this.layer.getConfig()
      }
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  setFastWeightInitDuringBuild(t) {
    super.setFastWeightInitDuringBuild(t), this.layer != null && this.layer.setFastWeightInitDuringBuild(t);
  }
  /** @nocollapse */
  static fromConfig(t, e, s = {}) {
    const o = e.layer, r = Pn(o, s);
    delete e.layer;
    const i6 = { layer: r };
    return Object.assign(i6, e), new t(i6);
  }
};
var n1 = class extends e1 {
  constructor(t) {
    super(t), this.supportsMasking = true;
  }
  build(t) {
    if (t = $t(t), t.length < 3)
      throw new E(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(t)}`);
    this.inputSpec = [{ shape: t }];
    const e = [t[0]].concat(t.slice(2));
    this.layer.built || (this.layer.build(e), this.layer.built = true), super.build(t);
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = [t[0]].concat(t.slice(2)), s = this.layer.computeOutputShape(e), o = t[1];
    return [s[0], o].concat(s.slice(1));
  }
  call(t, e) {
    return D(() => (t = mt(t), dy(
      (i6, a) => [mt(this.layer.call(i6, e)), []],
      t,
      [],
      false,
      null,
      null,
      false,
      true
      /* needPerStepOutputs */
    )[1]));
  }
};
n1.className = "TimeDistributed";
_(n1);
function qE(n) {
  zo(CG, "BidirectionalMergeMode", n);
}
var tL = "concat";
var s1 = class extends e1 {
  constructor(t) {
    super(t);
    const e = t.layer.getConfig(), s = {};
    s.className = t.layer.getClassName(), s.config = e, this.forwardLayer = Pn(s), e.goBackwards = e.goBackwards !== true;
    const o = {};
    if (o.className = t.layer.getClassName(), o.config = e, this.backwardLayer = Pn(o), this.forwardLayer.name = "forward_" + this.forwardLayer.name, this.backwardLayer.name = "backward_" + this.backwardLayer.name, this.mergeMode = t.mergeMode === void 0 ? tL : t.mergeMode, qE(this.mergeMode), t.weights)
      throw new xt("weights support is not implemented for Bidirectional layer yet.");
    this._stateful = t.layer.stateful, this.returnSequences = t.layer.returnSequences, this.returnState = t.layer.returnState, this.supportsMasking = true, this._trainable = true, this.inputSpec = t.layer.inputSpec, this.numConstants = null;
  }
  get trainable() {
    return this._trainable;
  }
  set trainable(t) {
    this._trainable = t, this.forwardLayer != null && (this.forwardLayer.trainable = t), this.backwardLayer != null && (this.backwardLayer.trainable = t);
  }
  getWeights() {
    return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());
  }
  setWeights(t) {
    const e = t.length, s = Math.floor(e / 2);
    this.forwardLayer.setWeights(t.slice(0, s)), this.backwardLayer.setWeights(t.slice(s));
  }
  computeOutputShape(t) {
    let e = this.forwardLayer.computeOutputShape(t);
    Array.isArray(e) && Array.isArray(e[0]) || (e = [e]), e = e;
    let s, o, r;
    return this.returnState && (r = e.slice(1)), s = e[0], s = s, this.mergeMode === "concat" ? (s[s.length - 1] *= 2, o = [s]) : this.mergeMode == null ? o = [s, s.slice()] : o = [s], this.returnState ? this.mergeMode == null ? o.concat(r).concat(r.slice()) : [s].concat(r).concat(r.slice()) : Pe(o);
  }
  apply(t, e) {
    let s = e == null ? null : e.initialState, o = e == null ? null : e.constants;
    e == null && (e = {});
    const r = uy(t, s, o, this.numConstants);
    if (t = r.inputs, s = r.initialState, o = r.constants, Array.isArray(t) && (s = t.slice(1), t = t[0]), (s == null || s.length === 0) && o == null)
      return super.apply(t, e);
    const i6 = [], a = [];
    if (s != null) {
      const c = s.length;
      if (c % 2 > 0)
        throw new E("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
      e.initialState = s, i6.push(...s);
      const u = s.map((d) => new de({ shape: d.shape }));
      this.forwardLayer.stateSpec = u.slice(0, c / 2), this.backwardLayer.stateSpec = u.slice(c / 2), a.push(...u);
    }
    if (o != null)
      throw new xt("Support for constants in Bidirectional layers is not implemented yet.");
    const l = i6[0] instanceof jn;
    for (const c of i6)
      if (c instanceof jn !== l)
        throw new E("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
    if (l) {
      const c = [t].concat(i6), u = this.inputSpec.concat(a), d = this.inputSpec;
      this.inputSpec = u;
      const h6 = super.apply(c, e);
      return this.inputSpec = d, h6;
    } else
      return super.apply(t, e);
  }
  call(t, e) {
    return D(() => {
      const s = e.initialState;
      let o, r;
      if (s == null)
        o = this.forwardLayer.call(t, e), r = this.backwardLayer.call(t, e);
      else {
        const l = s.slice(0, s.length / 2), c = s.slice(s.length / 2);
        o = this.forwardLayer.call(t, Object.assign(e, { initialState: l })), r = this.backwardLayer.call(t, Object.assign(e, { initialState: c }));
      }
      let i6;
      this.returnState && (Array.isArray(o) && (i6 = o.slice(1).concat(r.slice(1))), o = o[0], r = r[0]), this.returnSequences && (r = ko(r, 1));
      let a;
      return this.mergeMode === "concat" ? a = rf([o, r]) : this.mergeMode === "sum" ? a = U(o, r) : this.mergeMode === "ave" ? a = G(0.5, U(o, r)) : this.mergeMode === "mul" ? a = G(o, r) : this.mergeMode == null && (a = [o, r]), this.returnState ? this.mergeMode == null ? a.concat(i6) : [a].concat(i6) : a;
    });
  }
  resetStates(t) {
    this.forwardLayer.resetStates(), this.backwardLayer.resetStates();
  }
  build(t) {
    fo(this.forwardLayer.name, () => {
      this.forwardLayer.build(t);
    }), fo(this.backwardLayer.name, () => {
      this.backwardLayer.build(t);
    }), this.built = true;
  }
  computeMask(t, e) {
    Array.isArray(e) && (e = e[0]);
    let s;
    if (this.returnSequences ? this.mergeMode == null ? s = [e, e] : s = e : this.mergeMode == null ? s = [null, null] : s = null, this.returnState) {
      const r = this.forwardLayer.states.map((i6) => null);
      return Array.isArray(s) ? s.concat(r).concat(r) : [s].concat(r).concat(r);
    } else
      return s;
  }
  get trainableWeights() {
    return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);
  }
  get nonTrainableWeights() {
    return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);
  }
  // TODO(cais): Implement constraints().
  setFastWeightInitDuringBuild(t) {
    super.setFastWeightInitDuringBuild(t), this.forwardLayer != null && this.forwardLayer.setFastWeightInitDuringBuild(t), this.backwardLayer != null && this.backwardLayer.setFastWeightInitDuringBuild(t);
  }
  getConfig() {
    const t = {
      mergeMode: this.mergeMode
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    const s = Pn(e.layer);
    if (delete e.layer, e.numConstants != null)
      throw new xt("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");
    const o = e;
    return o.layer = s, new t(o);
  }
};
s1.className = "Bidirectional";
_(s1);
var o1 = class extends St {
  constructor(t) {
    super(t), this.scale = t.scale, t.offset ? this.offset = t.offset : this.offset = 0;
  }
  getConfig() {
    const t = {
      scale: this.scale,
      offset: this.offset
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  call(t, e) {
    return D(() => (t = mt(t), t.dtype !== "float32" && (t = es(t, "float32")), U(G(t, this.scale), this.offset)));
  }
};
o1.className = "Rescaling";
_(o1);
var { resizeBilinear: eL, cropAndResize: nL } = uo;
var r1 = class extends St {
  constructor(t) {
    super(t), this.height = t.height, this.width = t.width;
  }
  centerCrop(t, e, s, o, r, i6, a, l) {
    return D(() => {
      let c, u = false;
      const d = e / i6, h6 = s / a, p6 = (o + e) / i6, f = (r + s) / a, m = [d, h6, p6, f], g6 = [];
      t.rank === 3 ? (u = true, c = os([t])) : c = t;
      for (let I = 0; I < c.shape[0]; I++)
        g6.push(m);
      const b6 = Re(g6, [g6.length, 4]), x6 = ti(0, g6.length, 1, "int32"), y6 = nL(c, b6, x6, [o, r], "nearest");
      return es(u ? mt(To(y6)) : y6, l);
    });
  }
  upsize(t, e, s, o) {
    return D(() => {
      const r = eL(t, [e, s]);
      return es(r, o);
    });
  }
  call(t, e) {
    return D(() => {
      const s = mt(t), o = s.dtype, r = s.shape, i6 = r[r.length - 3], a = r[r.length - 2];
      let l = 0;
      i6 !== this.height && (l = Math.floor((i6 - this.height) / 2));
      let c = 0;
      return a !== this.width && (c = Math.floor((a - this.width) / 2), c === 0 && (c = 1)), l >= 0 && c >= 0 ? this.centerCrop(s, l, c, this.height, this.width, i6, a, o) : this.upsize(t, this.height, this.width, o);
    });
  }
  getConfig() {
    const t = {
      height: this.height,
      width: this.width
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = t.length - 3, s = t.length - 2;
    return t[e] = this.height, t[s] = this.width, t;
  }
};
r1.className = "CenterCrop";
_(r1);
function sL(n, t, e, s) {
  let o = mt(n);
  if (o.dtype !== "int32" && (o = es(o, "int32")), t === "int")
    return o;
  const r = o.shape;
  if (o.rank === 0 && (o = Ue(o, -1)), t === "oneHot" && o.shape[o.shape.length - 1] !== 1 && (o = Ue(o, -1)), o.rank > 2)
    throw new E(`When outputMode is not int, maximum output rank is 2 Received outputMode ${t} and input shape ${r} which would result in output rank ${o.rank}.`);
  const i6 = ["multiHot", "oneHot"].includes(t), a = o;
  let l;
  if (typeof s < "u" && t === "count" ? l = rm(a, s, e, i6) : l = rm(a, [], e, i6), t !== "tfIdf")
    return l;
  if (s)
    return G(l, s);
  throw new E("When outputMode is 'tfIdf', weights must be provided.");
}
var i1 = class extends St {
  constructor(t) {
    super(t), this.numTokens = t.numTokens, t.outputMode ? this.outputMode = t.outputMode : this.outputMode = "multiHot";
  }
  getConfig() {
    const t = {
      numTokens: this.numTokens,
      outputMode: this.outputMode
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  computeOutputShape(t) {
    return t = $t(t), t == null ? [this.numTokens] : this.outputMode === "oneHot" && t[t.length - 1] !== 1 ? (t.push(this.numTokens), t) : (t[t.length - 1] = this.numTokens, t);
  }
  call(t, e) {
    return D(() => {
      t = mt(t), t.dtype !== "int32" && (t = es(t, "int32"));
      let s;
      if (typeof e.countWeights < "u") {
        if (this.outputMode !== "count")
          throw new E(`countWeights is not used when outputMode !== count.
              Received countWeights=${e.countWeights}`);
        s = mt(e.countWeights);
      }
      const o = Xn(t), r = ul(t), i6 = sn(this.numTokens, o).bufferSync().get(0), a = Do(r, 0).bufferSync().get(0);
      if (!(i6 && a))
        throw new E(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);
      return sL(t, this.outputMode, this.numTokens, s);
    });
  }
};
i1.className = "CategoryEncoding";
_(i1);
var oL = ["bilinear", "nearest"];
var Pm = new Set(oL);
var a1 = class extends St {
  constructor(t) {
    if (super(t), this.height = t.height, this.width = t.width, t.interpolation)
      if (Pm.has(t.interpolation))
        this.interpolation = t.interpolation;
      else
        throw new E(`Invalid interpolation parameter: ${t.interpolation} is not implemented`);
    else
      this.interpolation = "bilinear";
    this.cropToAspectRatio = !!t.cropToAspectRatio;
  }
  computeOutputShape(t) {
    t = $t(t);
    const e = t[2];
    return [this.height, this.width, e];
  }
  getConfig() {
    const t = {
      height: this.height,
      width: this.width,
      interpolation: this.interpolation,
      cropToAspectRatio: this.cropToAspectRatio
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  call(t, e) {
    return D(() => {
      const s = [this.height, this.width];
      if (this.interpolation === "bilinear")
        return uo.resizeBilinear(t, s, !this.cropToAspectRatio);
      if (this.interpolation === "nearest")
        return uo.resizeNearestNeighbor(t, s, !this.cropToAspectRatio);
      throw new Error(`Interpolation is ${this.interpolation} but only ${[...Pm]} are supported`);
    });
  }
};
a1.className = "Resizing";
_(a1);
var rL = F();
rL.registerFlag("KEEP_INTERMEDIATE_TENSORS", () => false, (n) => {
  n && console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.");
});
var Am;
(function(n) {
  n[n.DT_INVALID = 0] = "DT_INVALID", n[n.DT_FLOAT = 1] = "DT_FLOAT", n[n.DT_DOUBLE = 2] = "DT_DOUBLE", n[n.DT_INT32 = 3] = "DT_INT32", n[n.DT_UINT8 = 4] = "DT_UINT8", n[n.DT_INT16 = 5] = "DT_INT16", n[n.DT_INT8 = 6] = "DT_INT8", n[n.DT_STRING = 7] = "DT_STRING", n[n.DT_COMPLEX64 = 8] = "DT_COMPLEX64", n[n.DT_INT64 = 9] = "DT_INT64", n[n.DT_BOOL = 10] = "DT_BOOL", n[n.DT_QINT8 = 11] = "DT_QINT8", n[n.DT_QUINT8 = 12] = "DT_QUINT8", n[n.DT_QINT32 = 13] = "DT_QINT32", n[n.DT_BFLOAT16 = 14] = "DT_BFLOAT16", n[n.DT_QINT16 = 15] = "DT_QINT16", n[n.DT_QUINT16 = 16] = "DT_QUINT16", n[n.DT_UINT16 = 17] = "DT_UINT16", n[n.DT_COMPLEX128 = 18] = "DT_COMPLEX128", n[n.DT_HALF = 19] = "DT_HALF", n[n.DT_RESOURCE = 20] = "DT_RESOURCE", n[n.DT_VARIANT = 21] = "DT_VARIANT", n[n.DT_UINT32 = 22] = "DT_UINT32", n[n.DT_UINT64 = 23] = "DT_UINT64", n[n.DT_FLOAT_REF = 101] = "DT_FLOAT_REF", n[n.DT_DOUBLE_REF = 102] = "DT_DOUBLE_REF", n[n.DT_INT32_REF = 103] = "DT_INT32_REF", n[n.DT_UINT8_REF = 104] = "DT_UINT8_REF", n[n.DT_INT16_REF = 105] = "DT_INT16_REF", n[n.DT_INT8_REF = 106] = "DT_INT8_REF", n[n.DT_STRING_REF = 107] = "DT_STRING_REF", n[n.DT_COMPLEX64_REF = 108] = "DT_COMPLEX64_REF", n[n.DT_INT64_REF = 109] = "DT_INT64_REF", n[n.DT_BOOL_REF = 110] = "DT_BOOL_REF", n[n.DT_QINT8_REF = 111] = "DT_QINT8_REF", n[n.DT_QUINT8_REF = 112] = "DT_QUINT8_REF", n[n.DT_QINT32_REF = 113] = "DT_QINT32_REF", n[n.DT_BFLOAT16_REF = 114] = "DT_BFLOAT16_REF", n[n.DT_QINT16_REF = 115] = "DT_QINT16_REF", n[n.DT_QUINT16_REF = 116] = "DT_QUINT16_REF", n[n.DT_UINT16_REF = 117] = "DT_UINT16_REF", n[n.DT_COMPLEX128_REF = 118] = "DT_COMPLEX128_REF", n[n.DT_HALF_REF = 119] = "DT_HALF_REF", n[n.DT_RESOURCE_REF = 120] = "DT_RESOURCE_REF", n[n.DT_VARIANT_REF = 121] = "DT_VARIANT_REF", n[n.DT_UINT32_REF = 122] = "DT_UINT32_REF", n[n.DT_UINT64_REF = 123] = "DT_UINT64_REF";
})(Am || (Am = {}));
var Om;
(function(n) {
  (function(t) {
    t[t.LEGACY = 0] = "LEGACY", t[t.V1 = 1] = "V1", t[t.V2 = 2] = "V2";
  })(n.CheckpointFormatVersion || (n.CheckpointFormatVersion = {}));
})(Om || (Om = {}));
function iL(n, t) {
  return vl(n, t);
}
function vl(n, t, e = /* @__PURE__ */ new Map(), s = /* @__PURE__ */ new Set()) {
  if (n == null)
    return null;
  if (typeof Blob == "function" && n instanceof Blob)
    return n.slice();
  if (s.has(n))
    throw new Error("Circular references are not supported.");
  if (e.has(n))
    return e.get(n);
  const o = t(n);
  if (o.recurse && o.value !== null)
    throw new Error("A deep map function may not return both a value and recurse=true.");
  if (o.recurse)
    if (lr(n)) {
      const r = Array.isArray(n) ? [] : {};
      s.add(n);
      for (const i6 in n) {
        const a = n[i6], l = vl(a, t, e, s);
        r[i6] = l;
      }
      return s.delete(n), n.__proto__ && (r.__proto__ = n.__proto__), r;
    } else
      throw new Error(`Can't recurse into non-iterable type: ${n}`);
  else
    return e.set(n, o.value), o.value;
}
function aL(n, t = c1) {
  return l1(n, t);
}
function l1(n, t, e = /* @__PURE__ */ new Set()) {
  const s = n[0];
  if (e.has(s))
    throw new Error("Circular references are not supported.");
  const o = t(n);
  if (o.recurse && o.value !== null)
    throw new Error("A deep zip function may not return both a value and recurse=true.");
  if (o.recurse)
    if (lr(s)) {
      const r = Array.isArray(s) ? [] : {};
      e.add(s);
      for (const i6 in s) {
        const a = n.map((c) => c[i6]), l = l1(a, t, e);
        r[i6] = l;
      }
      return e.delete(s), r;
    } else
      throw new Error(`Can't recurse into non-iterable type: ${s}`);
  else
    return o.value;
}
function c1(n) {
  return n === null ? null : lr(n[0]) ? { value: null, recurse: true } : { value: n, recurse: false };
}
async function u1(n, t) {
  const e = /* @__PURE__ */ new Map();
  vl(n, t, e);
  for (const o of Array.from(e.keys())) {
    const r = e.get(o);
    if (ui(r)) {
      const i6 = await r;
      e.set(o, i6);
    }
  }
  return vl(n, t, e);
}
function lr(n) {
  let t = false;
  if (F().get("IS_BROWSER"))
    t = n instanceof TextDecoder;
  else {
    const { StringDecoder: e } = require_string_decoder();
    t = n instanceof e;
  }
  return n != null && !ArrayBuffer.isView(n) && (Array.isArray(n) || typeof n == "object" && !(n instanceof Lt) && !(n instanceof Promise) && !t);
}
function lL(n) {
  return n == null || cL(n) || Array.isArray(n) || typeof n == "object" && n instanceof Lt || dn(n);
}
function cL(n) {
  return n === null || typeof n != "object" && typeof n != "function";
}
function uL(n) {
  return iL(n, dL);
}
function dL(n) {
  return n instanceof Lt ? { value: n.clone(), recurse: false } : lr(n) ? { value: null, recurse: true } : { value: n, recurse: false };
}
var d1 = class {
  /**
   * Constructs a `RingBuffer`.
   * @param capacity The number of items that the buffer can accomodate.
   */
  constructor(t) {
    if (this.capacity = t, this.begin = 0, this.end = 0, t == null)
      throw new RangeError("Can't create a ring buffer of unknown capacity.");
    if (t < 1)
      throw new RangeError("Can't create ring buffer of capacity < 1.");
    this.data = new Array(t), this.doubledCapacity = 2 * t;
  }
  /**
   * Map any index into the range 0 <= index < 2*capacity.
   */
  wrap(t) {
    for (; t < 0; )
      t += this.doubledCapacity;
    return t % this.doubledCapacity;
  }
  get(t) {
    if (t < 0)
      throw new RangeError("Can't get item at a negative index.");
    return this.data[t % this.capacity];
  }
  set(t, e) {
    if (t < 0)
      throw new RangeError("Can't set item at a negative index.");
    this.data[t % this.capacity] = e;
  }
  /**
   * Returns the current number of items in the buffer.
   */
  length() {
    let t = this.end - this.begin;
    return t < 0 && (t = this.doubledCapacity + t), t;
  }
  /**
   * Reports whether the buffer is full.
   * @returns true if the number of items in the buffer equals its capacity, and
   *   false otherwise.
   */
  isFull() {
    return this.length() === this.capacity;
  }
  /**
   * Reports whether the buffer is empty.
   * @returns true if the number of items in the buffer equals zero, and
   *   false otherwise.
   */
  isEmpty() {
    return this.length() === 0;
  }
  /**
   * Adds an item to the end of the buffer.
   */
  push(t) {
    if (this.isFull())
      throw new RangeError("Ring buffer is full.");
    this.set(this.end, t), this.end = this.wrap(this.end + 1);
  }
  /**
   * Adds many items to the end of the buffer, in order.
   */
  pushAll(t) {
    for (const e of t)
      this.push(e);
  }
  /**
   * Removes and returns the last item in the buffer.
   */
  pop() {
    if (this.isEmpty())
      throw new RangeError("Ring buffer is empty.");
    this.end = this.wrap(this.end - 1);
    const t = this.get(this.end);
    return this.set(this.end, void 0), t;
  }
  /**
   * Adds an item to the beginning of the buffer.
   */
  unshift(t) {
    if (this.isFull())
      throw new RangeError("Ring buffer is full.");
    this.begin = this.wrap(this.begin - 1), this.set(this.begin, t);
  }
  /**
   * Removes and returns the first item in the buffer.
   */
  shift() {
    if (this.isEmpty())
      throw new RangeError("Ring buffer is empty.");
    const t = this.get(this.begin);
    return this.set(this.begin, void 0), this.begin = this.wrap(this.begin + 1), t;
  }
  /**
   * Removes and returns a specific item in the buffer, and moves the last item
   * to the vacated slot.  This is useful for implementing a shuffling stream.
   * Note that this operation necessarily scrambles the original order.
   *
   * @param relativeIndex: the index of the item to remove, relative to the
   *   first item in the buffer (e.g., hiding the ring nature of the underlying
   *   storage).
   */
  shuffleExcise(t) {
    if (this.isEmpty())
      throw new RangeError("Ring buffer is empty.");
    const e = this.wrap(this.begin + t), s = this.get(e);
    return this.set(e, this.pop()), s;
  }
};
var lu = class extends d1 {
  /**
   * Constructs a `GrowingRingBuffer`.
   */
  constructor() {
    super(lu.INITIAL_CAPACITY);
  }
  isFull() {
    return false;
  }
  push(t) {
    super.isFull() && this.expand(), super.push(t);
  }
  unshift(t) {
    super.isFull() && this.expand(), super.unshift(t);
  }
  /**
   * Doubles the capacity of the buffer.
   */
  expand() {
    const t = this.capacity * 2, e = new Array(t), s = this.length();
    for (let o = 0; o < s; o++)
      e[o] = this.get(this.wrap(this.begin + o));
    this.data = e, this.capacity = t, this.doubledCapacity = 2 * this.capacity, this.begin = 0, this.end = s;
  }
};
lu.INITIAL_CAPACITY = 32;
function h1(n) {
  return new mL(n);
}
function hL(n) {
  return new gL(n);
}
function pL(n, t) {
  return new p1(n, t);
}
function fL(n, t = Es.FAIL) {
  return new TL(n, t);
}
var Ke = class {
  /**
   * Collect all remaining elements of a bounded stream into an array.
   * Obviously this will succeed only for small streams that fit in memory.
   * Useful for testing.
   *
   * @returns A Promise for an array of stream elements, which will resolve
   *   when the stream is exhausted.
   */
  async toArray() {
    const t = [];
    let e = await this.next();
    for (; !e.done; )
      t.push(e.value), e = await this.next();
    return t;
  }
  /**
   * Collect all elements of this dataset into an array with prefetching 100
   * elements. This is useful for testing, because the prefetch changes the
   * order in which the Promises are resolved along the processing pipeline.
   * This may help expose bugs where results are dependent on the order of
   * Promise resolution rather than on the logical order of the stream (i.e.,
   * due to hidden mutable state).
   *
   * @returns A Promise for an array of stream elements, which will resolve
   *   when the stream is exhausted.
   */
  async toArrayForTest() {
    const t = this.prefetch(100), e = [];
    let s = await t.next();
    for (; !s.done; )
      e.push(s.value), s = await t.next();
    return e;
  }
  /**
   * Draw items from the stream until it is exhausted.
   *
   * This can be useful when the stream has side effects but no output.  In
   * that case, calling this function guarantees that the stream will be
   * fully processed.
   */
  async resolveFully() {
    let t = await this.next();
    for (; !t.done; )
      t = await this.next();
  }
  /**
   * Draw items from the stream until it is exhausted, or a predicate fails.
   *
   * This can be useful when the stream has side effects but no output.  In
   * that case, calling this function guarantees that the stream will be
   * fully processed.
   */
  async resolveWhile(t) {
    let e = await this.next(), s = t(e.value);
    for (; !e.done && s; )
      e = await this.next(), s = t(e.value);
  }
  /**
   * Handles errors thrown on this stream using a provided handler function.
   *
   * @param handler A function that handles any `Error` thrown during a `next()`
   *   call and returns true if the stream should continue (dropping the failed
   *   call) or false if the stream should quietly terminate.  If the handler
   *   itself throws (or rethrows) an `Error`, that will be propagated.
   *
   * @returns A `LazyIterator` of elements passed through from upstream,
   *   possibly filtering or terminating on upstream `next()` calls that
   *   throw an `Error`.
   */
  handleErrors(t) {
    return new vL(this, t);
  }
  // TODO(soergel): Implement reduce() etc.
  /**
   * Filters this stream according to `predicate`.
   *
   * @param predicate A function mapping a stream element to a boolean or a
   * `Promise` for one.
   *
   * @returns A `LazyIterator` of elements for which the predicate was true.
   */
  filter(t) {
    return new IL(this, t);
  }
  /**
   * Maps this stream through a 1-to-1 transform.
   *
   * @param transform A function mapping a stream element to a transformed
   *   element.
   *
   * @returns A `LazyIterator` of transformed elements.
   */
  map(t) {
    return new CL(this, t);
  }
  /**
   * Maps this stream through an async 1-to-1 transform.
   *
   * @param transform A function mapping a stream element to a `Promise` for a
   *   transformed stream element.
   *
   * @returns A `LazyIterator` of transformed elements.
   */
  mapAsync(t) {
    return new Km(this, t);
  }
  /**
   * Maps this stream through a 1-to-1 transform, forcing serial execution.
   *
   * @param transform A function mapping a stream element to a transformed
   *   element.
   *
   * @returns A `LazyIterator` of transformed elements.
   */
  serialMapAsync(t) {
    return new Km(this, t).serial();
  }
  /**
   * Maps this stream through a 1-to-many transform.
   *
   * @param transform A function mapping a stream element to an array of
   *   transformed elements.
   *
   * @returns A `DataStream` of transformed elements.
   */
  flatmap(t) {
    return new kL(this, t);
  }
  /**
   * Apply a function to every element of the stream.
   *
   * @param f A function to apply to each stream element.
   */
  async forEachAsync(t) {
    return this.map(t).resolveFully();
  }
  /**
   * Apply a function to every element of the stream, forcing serial execution.
   *
   * @param f A function to apply to each stream element.  Should return 'true'
   *   to indicate that the stream should continue, or 'false' to cause it to
   *   terminate.
   */
  async serialForEach(t) {
    return this.serialMapAsync(t).resolveWhile((e) => e === true);
  }
  /**
   * Groups elements into batches, represented as arrays of elements.
   *
   * We can think of the elements of this iterator as 'rows' (even if they are
   * nested structures).  By the same token, consecutive values for a given
   * key within the elements form a 'column'.  This matches the usual sense of
   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).
   *
   * Thus, "Row-major" means that the resulting batch is simply a collection of
   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major
   * form, which is needed for vectorized computation.
   *
   * @param batchSize The number of elements desired per batch.
   * @param smallLastBatch Whether to emit the final batch when it has fewer
   *   than batchSize elements. Default true.
   * @returns A `LazyIterator` of batches of elements, represented as arrays
   *   of the original element type.
   */
  rowMajorBatch(t, e = true) {
    return new wL(this, t, e);
  }
  /**
   * Groups elements into batches, represented in column-major form.
   *
   * We can think of the elements of this iterator as 'rows' (even if they are
   * nested structures).  By the same token, consecutive values for a given
   * key within the elements form a 'column'.  This matches the usual sense of
   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).
   *
   * Thus, "column-major" means that the resulting batch is a (potentially
   * nested) structure representing the columns.  Each column entry, then,
   * contains a collection of the values found in that column for a range of
   * input elements.  This representation allows for vectorized computation, in
   * contrast to the row-major form.
   *
   * The inputs should all have the same nested structure (i.e., of arrays and
   * dicts).  The result is a single object with the same nested structure,
   * where the leaves are arrays collecting the values of the inputs at that
   * location (or, optionally, the result of a custom function applied to those
   * arrays).
   *
   * @param batchSize The number of elements desired per batch.
   * @param smallLastBatch Whether to emit the final batch when it has fewer
   *   than batchSize elements. Default true.
   * @param zipFn: (optional) A function that expects an array of elements at a
   *   single node of the object tree, and returns a `DeepMapResult`.  The
   *   `DeepMapResult` either provides a result value for that node (i.e.,
   *   representing the subtree), or indicates that the node should be processed
   *   recursively.  The default zipFn recurses as far as possible and places
   *   arrays at the leaves.
   * @returns A `LazyIterator` of batches of elements, represented as an object
   *   with collections at the leaves.
   */
  columnMajorBatch(t, e = true, s = c1) {
    return this.rowMajorBatch(t, e).map((r) => aL(r, s));
  }
  /**
   * Concatenate this `LazyIterator` with another.
   *
   * @param iterator A `LazyIterator` to be concatenated onto this one.
   * @param baseErrorHandler An optional function that can intercept `Error`s
   *   raised during a `next()` call on the base stream.  This function can
   *   decide whether the error should be propagated, whether the error should
   *   be ignored, or whether the base stream should be terminated.
   * @returns A `LazyIterator`.
   */
  concatenate(t, e) {
    return new p1(h1([this, t]), e);
  }
  /**
   * Limits this stream to return at most `count` items.
   *
   * @param count The maximum number of items to provide from the stream. If
   * a negative or undefined value is given, the entire stream is returned
   *   unaltered.
   */
  take(t) {
    return t < 0 || t == null ? this : new yL(this, t);
  }
  /**
   * Skips the first `count` items in this stream.
   *
   * @param count The number of items to skip.  If a negative or undefined
   * value is given, the entire stream is returned unaltered.
   */
  skip(t) {
    return t < 0 || t == null ? this : new xL(this, t);
  }
  /**
   * Prefetch the first `bufferSize` items in this stream.
   *
   * Note this prefetches Promises, but makes no guarantees about when those
   * Promises resolve.
   *
   * @param bufferSize: An integer specifying the number of elements to be
   *   prefetched.
   */
  prefetch(t) {
    return new f1(this, t);
  }
  // TODO(soergel): deep sharded shuffle, where supported
  /**
   * Randomly shuffles the elements of this stream.
   *
   * @param bufferSize: An integer specifying the number of elements from
   * this stream from which the new stream will sample.
   * @param seed: (Optional.) An integer specifying the random seed that
   * will be used to create the distribution.
   */
  shuffle(t, e) {
    return new NL(this, t, e);
  }
  /**
   * Force an iterator to execute serially: each next() call will await the
   * prior one, so that they cannot execute concurrently.
   */
  serial() {
    return new bL(this);
  }
};
var mL = class extends Ke {
  constructor(t) {
    super(), this.items = t, this.trav = 0;
  }
  summary() {
    return `Array of ${this.items.length} items`;
  }
  async next() {
    if (this.trav >= this.items.length)
      return { value: null, done: true };
    const t = this.items[this.trav];
    return this.trav++, { value: uL(t), done: false };
  }
};
var gL = class extends Ke {
  constructor(t) {
    super(), this.nextFn = t;
  }
  summary() {
    return "Function call";
  }
  async next() {
    try {
      return this.nextFn();
    } catch (t) {
      throw t.message = `Error thrown while iterating through a dataset: ${t.message}`, t;
    }
  }
};
var bL = class extends Ke {
  constructor(t) {
    super(), this.upstream = t, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Serial`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    return this.upstream.next();
  }
};
var xL = class extends Ke {
  constructor(t, e) {
    super(), this.upstream = t, this.maxCount = e, this.count = 0, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Skip`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; this.count++ < this.maxCount; ) {
      const t = await this.upstream.next();
      if (t.done)
        return t;
      yt(t.value);
    }
    return this.upstream.next();
  }
};
var yL = class extends Ke {
  constructor(t, e) {
    super(), this.upstream = t, this.maxCount = e, this.count = 0;
  }
  summary() {
    return `${this.upstream.summary()} -> Take`;
  }
  async next() {
    return this.count++ >= this.maxCount ? { value: null, done: true } : this.upstream.next();
  }
};
var wL = class extends Ke {
  constructor(t, e, s = true) {
    super(), this.upstream = t, this.batchSize = e, this.enableSmallLastBatch = s, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> RowMajorBatch`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    const t = [];
    for (; t.length < this.batchSize; ) {
      const e = await this.upstream.next();
      if (e.done)
        return this.enableSmallLastBatch && t.length > 0 ? { value: t, done: false } : { value: null, done: true };
      t.push(e.value);
    }
    return { value: t, done: false };
  }
};
var IL = class extends Ke {
  constructor(t, e) {
    super(), this.upstream = t, this.predicate = e, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Filter`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; ; ) {
      const t = await this.upstream.next();
      if (t.done || this.predicate(t.value))
        return t;
      yt(t.value);
    }
  }
};
var CL = class extends Ke {
  constructor(t, e) {
    super(), this.upstream = t, this.transform = e;
  }
  summary() {
    return `${this.upstream.summary()} -> Map`;
  }
  async next() {
    const t = await this.upstream.next();
    if (t.done)
      return { value: null, done: true };
    const e = fs(t.value), s = this.transform(t.value), o = fs(s);
    for (const r of e)
      Vc(r, o) || r.dispose();
    return { value: s, done: false };
  }
};
var vL = class extends Ke {
  constructor(t, e) {
    super(), this.upstream = t, this.handler = e, this.count = 0, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> handleErrors`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; ; )
      try {
        return await this.upstream.next();
      } catch (t) {
        if (!this.handler(t))
          return { value: null, done: true };
      }
  }
};
var Km = class extends Ke {
  constructor(t, e) {
    super(), this.upstream = t, this.transform = e;
  }
  summary() {
    return `${this.upstream.summary()} -> AsyncMap`;
  }
  async next() {
    const t = await this.upstream.next();
    if (t.done)
      return { value: null, done: true };
    const e = fs(t.value), s = await this.transform(t.value), o = fs(s);
    for (const r of e)
      Vc(r, o) || r.dispose();
    return { value: s, done: false };
  }
};
var SL = class extends Ke {
  constructor() {
    super(), this.outputQueue = new lu(), this.lastRead = Promise.resolve({ value: null, done: false });
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; this.outputQueue.length() === 0; )
      if (!await this.pump())
        return { value: null, done: true };
    return { value: this.outputQueue.shift(), done: false };
  }
};
var kL = class extends SL {
  constructor(t, e) {
    super(), this.upstream = t, this.transform = e;
  }
  summary() {
    return `${this.upstream.summary()} -> Flatmap`;
  }
  async pump() {
    const t = await this.upstream.next();
    if (t.done)
      return false;
    const e = fs(t.value), s = this.transform(t.value), o = fs(s);
    this.outputQueue.pushAll(s);
    for (const r of e)
      Vc(r, o) || r.dispose();
    return true;
  }
};
var p1 = class extends Ke {
  constructor(t, e) {
    super(), this.baseErrorHandler = e, this.lastRead = null, this.iterator = null, this.moreIterators = t;
  }
  summary() {
    return "TODO: fill in upstream of chained summaries -> Chained";
  }
  async next() {
    return this.lastRead = this.readFromChain(this.lastRead), this.lastRead;
  }
  async readFromChain(t) {
    if (await t, this.iterator == null) {
      const s = await this.moreIterators.next();
      if (s.done)
        return { value: null, done: true };
      this.iterator = s.value, this.baseErrorHandler != null && (this.iterator = this.iterator.handleErrors(this.baseErrorHandler));
    }
    const e = await this.iterator.next();
    return e.done ? (this.iterator = null, this.readFromChain(t)) : e;
  }
};
var Es;
(function(n) {
  n[n.FAIL = 0] = "FAIL", n[n.SHORTEST = 1] = "SHORTEST", n[n.LONGEST = 2] = "LONGEST";
})(Es || (Es = {}));
var TL = class extends Ke {
  constructor(t, e = Es.FAIL) {
    super(), this.iterators = t, this.mismatchMode = e, this.count = 0, this.currentPromise = null;
  }
  summary() {
    return "{TODO: fill in upstream of zip summaries} -> Zip";
  }
  async nextState(t) {
    await t;
    let e = 0, s = 0;
    function o(i6) {
      return i6 instanceof Ke ? {
        value: i6.next().then((l) => (e++, l.done && s++, l.value)),
        recurse: false
      } : { value: null, recurse: true };
    }
    const r = await u1(this.iterators, o);
    if (e === s)
      return { value: null, done: true };
    if (s > 0)
      switch (this.mismatchMode) {
        case Es.FAIL:
          throw new Error(`Zipped streams should have the same length. Mismatched at element ${this.count}.`);
        case Es.SHORTEST:
          return { value: null, done: true };
        case Es.LONGEST:
      }
    return this.count++, { value: r, done: false };
  }
  async next() {
    return this.currentPromise = this.nextState(this.currentPromise), this.currentPromise;
  }
};
var f1 = class extends Ke {
  constructor(t, e) {
    super(), this.upstream = t, this.bufferSize = e, this.buffer = new d1(e);
  }
  summary() {
    return `${this.upstream.summary()} -> Prefetch`;
  }
  /**
   * Refill the prefetch buffer.  Returns only after the buffer is full, or
   * the upstream source is exhausted.
   */
  refill() {
    for (; !this.buffer.isFull(); ) {
      const t = this.upstream.next();
      this.buffer.push(t);
    }
  }
  next() {
    return this.refill(), this.buffer.shift();
  }
};
var NL = class extends f1 {
  constructor(t, e, s) {
    super(t, e), this.upstream = t, this.windowSize = e, this.upstreamExhausted = false, this.random = wr.alea(s || Ce().toString()), this.lastRead = Promise.resolve({ value: null, done: false });
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  randomInt(t) {
    return Math.floor(this.random() * t);
  }
  chooseIndex() {
    return this.randomInt(this.buffer.length());
  }
  async serialNext() {
    for (this.upstreamExhausted || this.refill(); !this.buffer.isEmpty(); ) {
      const t = this.chooseIndex(), e = await this.buffer.shuffleExcise(t);
      if (e.done)
        this.upstreamExhausted = true;
      else
        return this.refill(), e;
    }
    return { value: null, done: true };
  }
};
var Tf = class {
  constructor() {
    this.size = null;
  }
  // TODO(soergel): Make Datasets report whether repeated iterator() calls
  // produce the same result (e.g., reading from a file) or different results
  // (e.g., from the webcam).  Currently we don't make this distinction but it
  // could be important for the user to know.
  // abstract isDeterministic(): boolean;
  /**
   * Groups elements into batches.
   *
   * It is assumed that each of the incoming dataset elements has the same
   * structure -- i.e. the same set of keys at each location in an object
   * hierarchy.  For each key, the resulting `Dataset` provides a batched
   * element collecting all of the incoming values for that key.
   *
   *  * Incoming primitives are grouped into a 1-D Tensor.
   *  * Incoming Tensors are grouped into a new Tensor where the 0th axis is
   *    the batch dimension.
   *  * Incoming arrays are converted to Tensor and then batched.
   *  * A nested array is interpreted as an n-D Tensor, so the batched result
   *    has n+1 dimensions.
   *  * An array that cannot be converted to Tensor produces an error.
   *
   * If an array should not be batched as a unit, it should first be converted
   * to an object with integer keys.
   *
   * Here are a few examples:
   *
   * Batch a dataset of numbers:
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8]).batch(4);
   * await a.forEachAsync(e => e.print());
   * ```
   *
   * Batch a dataset of arrays:
   * ```js
   * const b = tf.data.array([[1], [2], [3], [4], [5], [6], [7], [8]]).batch(4);
   * await b.forEachAsync(e => e.print());
   * ```
   *
   * Batch a dataset of objects:
   * ```js
   * const c = tf.data.array([{a: 1, b: 11}, {a: 2, b: 12}, {a: 3, b: 13},
   *   {a: 4, b: 14}, {a: 5, b: 15}, {a: 6, b: 16}, {a: 7, b: 17},
   *   {a: 8, b: 18}]).batch(4);
   * await c.forEachAsync(e => {
   *   console.log('{');
   *   for(var key in e) {
   *     console.log(key+':');
   *     e[key].print();
   *   }
   *   console.log('}');
   * })
   * ```
   *
   * @param batchSize The number of elements desired per batch.
   * @param smallLastBatch Whether to emit the final batch when it has fewer
   *   than batchSize elements. Default true.
   * @returns A `Dataset`, from which a stream of batches can be obtained.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  batch(t, e = true) {
    const s = this;
    v2(t > 0, () => `batchSize needs to be positive, but it is
      ${t}`);
    let o;
    return this.size === 1 / 0 || this.size == null ? o = this.size : e ? o = Math.ceil(this.size / t) : o = Math.floor(this.size / t), bn(async () => (await s.iterator()).columnMajorBatch(t, e, RL), o);
  }
  /**
   * Concatenates this `Dataset` with another.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3]);
   * const b = tf.data.array([4, 5, 6]);
   * const c = a.concatenate(b);
   * await c.forEachAsync(e => console.log(e));
   * ```
   *
   * @param dataset A `Dataset` to be concatenated onto this one.
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  concatenate(t) {
    const e = this;
    let s;
    return this.size === 1 / 0 || t.size === 1 / 0 ? s = 1 / 0 : this.size != null && t.size != null ? s = this.size + t.size : s = null, bn(async () => (await e.iterator()).concatenate(await t.iterator()), s);
  }
  /**
   * Filters this dataset according to `predicate`.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
   *   .filter(x => x%2 === 0);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param predicate A function mapping a dataset element to a boolean or a
   * `Promise` for one.
   *
   * @returns A `Dataset` of elements for which the predicate was true.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  filter(t) {
    const e = this;
    let s;
    return this.size === 1 / 0 ? s = 1 / 0 : s = null, bn(async () => (await e.iterator()).filter((o) => D(() => t(o))), s);
  }
  /**
   * Apply a function to every element of the dataset.
   *
   * After the function is applied to a dataset element, any Tensors contained
   * within that element are disposed.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3]);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param f A function to apply to each dataset element.
   * @returns A `Promise` that resolves after all elements have been processed.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  async forEachAsync(t) {
    return (await this.iterator()).forEachAsync(t);
  }
  /**
   * Maps this dataset through a 1-to-1 transform.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3]).map(x => x*x);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param transform A function mapping a dataset element to a transformed
   *   dataset element.
   *
   * @returns A `Dataset` of transformed elements.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  map(t) {
    const e = this;
    return bn(async () => (await e.iterator()).map((s) => D(() => t(s))), this.size);
  }
  /**
   * Maps this dataset through an async 1-to-1 transform.
   *
   * ```js
   * const a =
   *  tf.data.array([1, 2, 3]).mapAsync(x => new Promise(function(resolve){
   *    setTimeout(() => {
   *      resolve(x * x);
   *    }, Math.random()*1000 + 500);
   *  }));
   * console.log(await a.toArray());
   * ```
   *
   * @param transform A function mapping a dataset element to a `Promise` for a
   *   transformed dataset element.  This transform is responsible for disposing
   *   any intermediate `Tensor`s, i.e. by wrapping its computation in
   *   `tf.tidy()`; that cannot be automated here (as it is in the synchronous
   *   `map()` case).
   *
   * @returns A `Dataset` of transformed elements.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  mapAsync(t) {
    const e = this;
    return bn(async () => (await e.iterator()).mapAsync(t), this.size);
  }
  /**
   *  Creates a `Dataset` that prefetches elements from this dataset.
   *
   * @param bufferSize: An integer specifying the number of elements to be
   *   prefetched.
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  prefetch(t) {
    if (t == null)
      throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");
    const e = this;
    return bn(async () => (await e.iterator()).prefetch(t), this.size);
  }
  /**
   * Repeats this dataset `count` times.
   *
   * NOTE: If this dataset is a function of global state (e.g. a random number
   * generator), then different repetitions may produce different elements.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3]).repeat(3);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param count: (Optional) An integer, representing the number of times
   *   the dataset should be repeated. The default behavior (if `count` is
   *   `undefined` or negative) is for the dataset be repeated indefinitely.
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  repeat(t) {
    const e = this;
    let s;
    return this.size != null && t > 0 ? s = this.size * t : t === 0 ? s = 0 : this.size != null && (t === void 0 || t < 0) ? s = 1 / 0 : s = null, bn(async () => {
      const o = hL(async () => ({ value: await e.iterator(), done: false }));
      return pL(o.take(t));
    }, s);
  }
  /**
   * Creates a `Dataset` that skips `count` initial elements from this dataset.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).skip(3);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param count: The number of elements of this dataset that should be skipped
   *   to form the new dataset.  If `count` is greater than the size of this
   *   dataset, the new dataset will contain no elements.  If `count`
   *   is `undefined` or negative, skips the entire dataset.
   *
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  skip(t) {
    const e = this;
    let s;
    return this.size != null && t >= 0 && this.size >= t ? s = this.size - t : this.size != null && (this.size < t || t === void 0 || t < 0) ? s = 0 : s = null, bn(async () => (await e.iterator()).skip(t), s);
  }
  /**
   * Pseudorandomly shuffles the elements of this dataset. This is done in a
   * streaming manner, by sampling from a given number of prefetched elements.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).shuffle(3);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param bufferSize: An integer specifying the number of elements from this
   *   dataset from which the new dataset will sample.
   * @param seed: (Optional) An integer specifying the random seed that will
   *   be used to create the distribution.
   * @param reshuffleEachIteration: (Optional) A boolean, which if true
   *   indicates that the dataset should be pseudorandomly reshuffled each time
   *   it is iterated over. If false, elements will be returned in the same
   *   shuffled order on each iteration. (Defaults to `true`.)
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  shuffle(t, e, s = true) {
    if (t == null || t < 0)
      throw this.size == null ? new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.") : new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);
    const o = this, r = wr.alea(e || Ce().toString());
    return bn(async () => {
      let i6 = r.int32();
      return s && (i6 += r.int32()), (await o.iterator()).shuffle(t, i6.toString());
    }, this.size);
  }
  /**
   * Creates a `Dataset` with at most `count` initial elements from this
   * dataset.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).take(3);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param count: The number of elements of this dataset that should be taken
   *   to form the new dataset.  If `count` is `undefined` or negative, or if
   *   `count` is greater than the size of this dataset, the new dataset will
   *   contain all elements of this dataset.
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  take(t) {
    const e = this;
    let s;
    return this.size != null && this.size > t ? s = t : this.size != null && this.size <= t ? s = this.size : s = null, bn(async () => (await e.iterator()).take(t), s);
  }
  /**
   * Collect all elements of this dataset into an array.
   *
   * Obviously this will succeed only for small datasets that fit in memory.
   * Useful for testing and generally should be avoided if possible.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6]);
   * console.log(await a.toArray());
   * ```
   *
   * @returns A Promise for an array of elements, which will resolve
   *   when a new stream has been obtained and fully consumed.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  async toArray() {
    if (this.size === 1 / 0)
      throw new Error("Can not convert infinite data stream to array.");
    return (await this.iterator()).toArray();
  }
  /**
   * Collect all elements of this dataset into an array with prefetching 100
   * elements. This is useful for testing, because the prefetch changes the
   * order in which the Promises are resolved along the processing pipeline.
   * This may help expose bugs where results are dependent on the order of
   * Promise resolution rather than on the logical order of the stream (i.e.,
   * due to hidden mutable state).
   *
   * @returns A Promise for an array of elements, which will resolve
   *   when a new stream has been obtained and fully consumed.
   */
  async toArrayForTest() {
    if (this.size === 1 / 0)
      throw new Error("Can not convert infinite data stream to array.");
    return (await this.iterator()).toArrayForTest();
  }
};
Tf.MAX_BUFFER_SIZE = 1e4;
function bn(n, t = null) {
  return new class extends Tf {
    constructor() {
      super(...arguments), this.size = t;
    }
    /*
     * Provide a new stream of elements.  Note this will also start new streams
     * from any underlying `Dataset`s.
     */
    async iterator() {
      return n();
    }
  }();
}
function EY(n) {
  return bn(async () => h1(n), n.length);
}
function LY(n) {
  if (!lr(n))
    throw new Error("The argument to zip() must be an object or array.");
  let t;
  if (Array.isArray(n))
    for (let e = 0; e < n.length; e++)
      t = t == null ? n[e].size : Math.min(t, n[e].size);
  else if (n instanceof Object)
    for (const e in n)
      t = t == null ? n[e].size : Math.min(t, n[e].size);
  return bn(async () => {
    const e = await u1(n, (s) => {
      if (s instanceof Tf)
        return { value: s.iterator(), recurse: false };
      if (lr(s))
        return { value: null, recurse: true };
      throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.");
    });
    return fL(e, Es.SHORTEST);
  }, t);
}
function RL(n) {
  if (n === null)
    return null;
  const t = n[0];
  return lL(t) ? { value: $L(n), recurse: false } : { value: null, recurse: true };
}
function $L(n) {
  if (n.length === 0)
    throw new Error("Can't make a batch of zero elements.");
  return n[0] instanceof Lt ? os(n) : Re(n);
}
function it(n, t) {
  Array.isArray(n) || (n = [n]), n.forEach((e) => {
    e != null && v2(e.dtype !== "complex64", () => `${t} does not support complex64 tensors in the CPU backend.`);
  });
}
var GL = t0;
var cu = class extends Xd {
  constructor() {
    super(), this.blockSize = 48, this.firstUse = true, this.data = new Mg(this, Xt());
  }
  nextDataId() {
    return cu.nextDataId++;
  }
  write(t, e, s) {
    this.firstUse && (this.firstUse = false, F().get("IS_NODE") && rn(`
============================
Hi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. 
============================`));
    const o = { id: this.nextDataId() };
    return this.data.set(o, { values: t, dtype: s, refCount: 1 }), o;
  }
  /**
   * Create a data bucket in cpu backend.
   * @param shape Shape of the `TensorInfo`.
   * @param dtype DType of the `TensorInfo`.
   * @param values The value of the `TensorInfo` stored as a flattened array.
   */
  makeTensorInfo(t, e, s) {
    let o;
    if (e === "string" && s != null && s.length > 0 && mr(s[0])) {
      const r = s.map((i6) => hs(i6));
      o = this.write(r, t, e);
    } else
      o = this.write(s, t, e);
    return { dataId: o, shape: t, dtype: e };
  }
  /** Return refCount of a `TensorData`. */
  refCount(t) {
    return this.data.has(t) ? this.data.get(t).refCount : 0;
  }
  /** Increase refCount of a `TensorData`. */
  incRef(t) {
    const e = this.data.get(t);
    e.refCount++;
  }
  /** Decrease refCount of a `TensorData`. */
  decRef(t) {
    if (this.data.has(t)) {
      const e = this.data.get(t);
      e.refCount--;
    }
  }
  move(t, e, s, o, r) {
    this.data.set(t, { values: e, dtype: o, refCount: r });
  }
  numDataIds() {
    return this.data.numDataIds();
  }
  async read(t) {
    return this.readSync(t);
  }
  readSync(t) {
    const { dtype: e, complexTensorInfos: s } = this.data.get(t);
    if (e === "complex64") {
      const o = this.readSync(s.real.dataId), r = this.readSync(s.imag.dataId);
      return ms(o, r);
    }
    return Pg(this.data.get(t).values, e);
  }
  bufferSync(t) {
    const e = this.readSync(t.dataId);
    if (t.dtype === "string")
      try {
        const s = e.map((o) => ps(o));
        return vt(t.shape, t.dtype, s);
      } catch {
        throw new Error("Failed to decode encoded string bytes into utf-8");
      }
    return vt(t.shape, t.dtype, e);
  }
  makeOutput(t, e, s) {
    return Xt().makeTensorFromTensorInfo(this.makeTensorInfo(e, s, t), this);
  }
  /**
   * Dispose the memory if the dataId has 0 refCount. Return true if the memory
   * is released or memory is not managed in this backend, false if memory is
   * not cleared.
   * @param dataId
   * @oaram force Optional, remove the data regardless of refCount
   */
  disposeData(t, e = false) {
    if (this.data.has(t)) {
      if (this.data.get(t).refCount--, !e && this.data.get(t).refCount > 0)
        return false;
      const { complexTensorInfos: s } = this.data.get(t);
      s != null && (this.disposeData(s.real.dataId, true), this.disposeData(s.imag.dataId, true)), this.data.delete(t);
    }
    return true;
  }
  disposeIntermediateTensorInfo(t) {
    this.disposeData(t.dataId);
  }
  async time(t) {
    const e = Ce();
    return t(), { kernelMs: Ce() - e };
  }
  memory() {
    return {
      // Unreliable due to automatic gc. The numbers above are cumulative.
      unreliable: true,
      reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
    };
  }
  where(t) {
    it([t], "where");
    const e = this.readSync(t.dataId);
    return GL(t.shape, e);
  }
  dispose() {
  }
  floatPrecision() {
    return 32;
  }
  /** Returns the smallest representable number.  */
  epsilon() {
    return super.epsilon();
  }
};
cu.nextDataId = 0;
function m1(n) {
  const t = new Float32Array(n.length);
  for (let e = 0; e < n.length; ++e)
    t[e] = Math.abs(n[e]);
  return t;
}
var EL = (n) => {
  const { x: t } = n.inputs, e = n.backend;
  it(t, "abs");
  let s = new Float32Array(O(t.shape));
  const o = e.data.get(t.dataId).values;
  return s = m1(o), e.makeOutput(s, t.shape, t.dtype);
};
var LL = {
  kernelName: Vl,
  backendName: "cpu",
  kernelFunc: EL
};
function ce(n) {
  return (t, e, s, o, r) => {
    const i6 = bt(t, e), a = i6.length, l = dt(i6), c = O(i6), u = xe(r, c), d = t.length, h6 = e.length, p6 = dt(t), f = dt(e), m = vo(t, i6), g6 = vo(e, i6);
    if (m.length + g6.length === 0)
      for (let b6 = 0; b6 < u.length; ++b6)
        u[b6] = n(s[b6 % s.length], o[b6 % o.length]);
    else
      for (let b6 = 0; b6 < u.length; ++b6) {
        const x6 = Mo(b6, a, l), w6 = x6.slice(-d);
        m.forEach((k7) => w6[k7] = 0);
        const y6 = zn(w6, d, p6), I = x6.slice(-h6);
        g6.forEach((k7) => I[k7] = 0);
        const C6 = zn(I, h6, f);
        u[b6] = n(s[y6], o[C6]);
      }
    return [u, i6];
  };
}
function Ye(n) {
  const { inputs: t, backend: e } = n, { real: s, imag: o } = t, r = e.data.get(s.dataId).values, i6 = e.data.get(o.dataId).values, a = e.makeTensorInfo(s.shape, "complex64"), l = e.data.get(a.dataId);
  return l.complexTensorInfos = {
    real: e.makeTensorInfo(s.shape, "float32", r),
    imag: e.makeTensorInfo(o.shape, "float32", i6)
  }, a;
}
var ML = {
  kernelName: Jd,
  backendName: "cpu",
  kernelFunc: Ye
};
function Sl(n, t, e = "float32") {
  if (e === "complex64") {
    const o = Sl(n, t, "float32"), r = Sl(n, t, "float32");
    return Ye({ inputs: { real: o, imag: r }, backend: n });
  }
  const s = Se(O(t), e);
  return n.makeTensorInfo(t, e, s);
}
function rs(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  return e.incRef(s.dataId), { dataId: s.dataId, shape: s.shape, dtype: s.dtype };
}
var WL = {
  kernelName: Ei,
  backendName: "cpu",
  kernelFunc: rs
};
function $o(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = e.data.get(s.dataId).complexTensorInfos.real, r = e.data.get(o.dataId).values;
  return e.makeTensorInfo(o.shape, o.dtype, r);
}
var DL = {
  kernelName: wh,
  backendName: "cpu",
  kernelFunc: $o
};
function g1(n, t, e, s) {
  if (s === "int32") {
    const o = Int32Array.from(n);
    return [t, "int32", o];
  }
  if (s === "bool") {
    const o = Zs([0], e), [r, i6] = ce((a, l) => a !== l ? 1 : 0)(t, [], n, o, "bool");
    return [i6, "bool", r];
  }
  throw new Error(`Error in Cast: failed to cast ${e} to ${s}`);
}
function Ks(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { dtype: r } = s;
  if (r === "complex64") {
    if (o.dtype === "complex64")
      return rs({ inputs: { x: o }, backend: e });
    const u = Sl(e, o.shape, o.dtype), d = Ks({ inputs: { x: o }, backend: e, attrs: { dtype: "float32" } }), h6 = Ye({ inputs: { real: d, imag: u }, backend: e });
    return e.disposeIntermediateTensorInfo(u), e.disposeIntermediateTensorInfo(d), h6;
  }
  if (o.dtype === "complex64") {
    const u = $o({ inputs: { input: o }, backend: e }), d = Ks({ inputs: { x: u }, backend: e, attrs: { dtype: r } });
    return e.disposeIntermediateTensorInfo(u), d;
  }
  if (!Od(o.dtype, r)) {
    const u = rs({ inputs: { x: o }, backend: e });
    return { dataId: u.dataId, shape: u.shape, dtype: r };
  }
  const i6 = e.data.get(o.dataId).values, [a, l, c] = g1(i6, o.shape, o.dtype, r);
  return e.makeTensorInfo(a, l, c);
}
var FL = {
  kernelName: xi,
  backendName: "cpu",
  kernelFunc: Ks
};
function we(n, t, e, s) {
  return e == null ? ({ inputs: o, backend: r }) => {
    const { a: i6, b: a } = o, l = r;
    it([i6, a], n);
    const c = l.data.get(i6.dataId).values, u = l.data.get(a.dataId).values, d = i6.dtype === "string" ? (
      // tslint:disable-next-line: no-any
      No(c)
    ) : c, h6 = i6.dtype === "string" ? (
      // tslint:disable-next-line: no-any
      No(u)
    ) : u, p6 = s || i6.dtype, [f, m] = t(i6.shape, a.shape, d, h6, p6);
    return l.makeTensorInfo(m, p6, f);
  } : ({ inputs: o, backend: r }) => {
    const { a: i6, b: a } = o, l = r;
    if (i6.dtype === "complex64" || a.dtype === "complex64") {
      const c = Ks({ inputs: { x: i6 }, backend: l, attrs: { dtype: "complex64" } }), u = l.data.get(c.dataId), d = u.complexTensorInfos.real, h6 = u.complexTensorInfos.imag, p6 = l.data.get(d.dataId).values, f = l.data.get(h6.dataId).values, m = Ks({ inputs: { x: a }, backend: l, attrs: { dtype: "complex64" } }), g6 = l.data.get(m.dataId), b6 = g6.complexTensorInfos.real, x6 = g6.complexTensorInfos.imag, w6 = l.data.get(b6.dataId).values, y6 = l.data.get(x6.dataId).values, [I, C6, k7] = e(i6.shape, a.shape, p6, f, w6, y6), S = l.makeTensorInfo(k7, "float32", I), N = l.makeTensorInfo(k7, "float32", C6), R = Ye({ inputs: { real: S, imag: N }, backend: l });
      return l.disposeIntermediateTensorInfo(c), l.disposeIntermediateTensorInfo(m), l.disposeIntermediateTensorInfo(S), l.disposeIntermediateTensorInfo(N), R;
    } else {
      const c = l.data.get(i6.dataId).values, u = l.data.get(a.dataId).values, d = s || i6.dtype, [h6, p6] = t(i6.shape, a.shape, c, u, d);
      return l.makeTensorInfo(p6, d, h6);
    }
  };
}
function Nf(n) {
  return (t, e, s, o, r, i6) => {
    const a = bt(t, e), l = O(a), c = a.length, u = dt(a), d = xe("float32", l), h6 = xe("float32", l), p6 = vo(t, a), f = vo(e, a), m = ms(s, o), g6 = ms(r, i6), b6 = t.length, x6 = dt(t), w6 = e.length, y6 = dt(e);
    if (p6.length + f.length === 0)
      for (let I = 0; I < d.length; I++) {
        const C6 = I % m.length, k7 = I % g6.length, S = n(m[C6 * 2], m[C6 * 2 + 1], g6[k7 * 2], g6[k7 * 2 + 1]);
        d[I] = S.real, h6[I] = S.imag;
      }
    else
      for (let I = 0; I < d.length; I++) {
        const C6 = Mo(I, c, u), k7 = C6.slice(-b6);
        p6.forEach((V) => k7[V] = 0);
        const S = zn(k7, b6, x6), N = C6.slice(-w6);
        f.forEach((V) => N[V] = 0);
        const R = zn(N, w6, y6), M6 = n(m[S * 2], m[S * 2 + 1], g6[R * 2], g6[R * 2 + 1]);
        d[I] = M6.real, h6[I] = M6.imag;
      }
    return [d, h6, a];
  };
}
var b1 = ce((n, t) => n + t);
var VL = Nf((n, t, e, s) => ({ real: n + e, imag: t + s }));
var cr = we(br, b1, VL);
var zL = {
  kernelName: br,
  backendName: "cpu",
  kernelFunc: cr
};
function Rf(n, t, e, s, o) {
  const r = O(s), i6 = Se(o, e);
  for (let a = 0; a < n.length; a++) {
    const l = n[a];
    if (l < 0)
      throw new Error("Input x must be non-negative!");
    l >= o || (r > 0 ? i6[l] += t[a] : i6[l] += 1);
  }
  return i6;
}
function x1(n, t, e, s = false) {
  const o = n.shape[0], r = n.shape[1], i6 = vt([o, e], t.dtype);
  for (let a = 0; a < o; a++)
    for (let l = 0; l < r; l++) {
      const c = n.get(a, l);
      if (c < 0)
        throw new Error("Input x must be non-negative!");
      c >= e || (s ? i6.set(1, a, c) : t.size > 0 ? i6.set(i6.get(a, c) + t.get(a, l), a, c) : i6.set(i6.get(a, c) + 1, a, c));
    }
  return i6;
}
function Js(n) {
  return (t, e, s) => {
    const o = xe(e, t.length);
    for (let r = 0; r < t.length; ++r)
      o[r] = n(t[r], s);
    return o;
  };
}
function Mt(n, t, e) {
  return ({ inputs: s, attrs: o, backend: r }) => {
    const { x: i6 } = s;
    if (it(i6, n), i6.dtype === "string" || e === "string")
      throw new Error("unaryKernelFunc does not support string input/output");
    const a = r, l = a.data.get(i6.dataId).values, c = O(i6.shape), u = e || i6.dtype, d = oe(u, c);
    for (let h6 = 0; h6 < c; ++h6)
      d[h6] = t(l[h6], o);
    return a.makeTensorInfo(i6.shape, u, d);
  };
}
function Sr(n, t, e) {
  return ({ inputs: s, attrs: o, backend: r }) => {
    const { x: i6 } = s;
    if (it(i6, n), i6.dtype === "string" || e === "string")
      throw new Error("unaryKernelFunc does not support string input/output");
    const a = r, l = a.data.get(i6.dataId).values, c = e || i6.dtype, u = t(l, c, o);
    return a.makeTensorInfo(i6.shape, c, u);
  };
}
var y1 = Js((n) => Math.ceil(n));
var XL = Sr(yi, y1);
var PL = {
  kernelName: yi,
  backendName: "cpu",
  kernelFunc: XL
};
function w1(n, t, e, s) {
  const o = oe(e, O(t));
  if (s && e !== "string") {
    let r = 0;
    n.forEach((i6) => {
      const a = O(i6.shape);
      o.set(i6.vals, r), r += a;
    });
  } else {
    let r = 0;
    n.forEach((i6) => {
      const a = e === "string" ? No(i6.vals) : i6.vals;
      let l = 0;
      for (let c = 0; c < i6.shape[0]; ++c) {
        const u = c * t[1] + r;
        for (let d = 0; d < i6.shape[1]; ++d)
          o[u + d] = a[l++];
      }
      r += i6.shape[1];
    });
  }
  return o;
}
var I1 = ce((n, t) => n === t ? 1 : 0);
var C1 = we(jl, I1, null, "bool");
var AL = {
  kernelName: jl,
  backendName: "cpu",
  kernelFunc: C1
};
var v1 = Js((n) => Math.exp(n));
var S1 = Sr(Ti, v1, "float32");
var OL = {
  kernelName: Ti,
  backendName: "cpu",
  kernelFunc: S1
};
var k1 = Js((n) => Math.expm1(n));
var KL = Sr(Ni, k1);
var ZL = {
  kernelName: Ni,
  backendName: "cpu",
  kernelFunc: KL
};
var T1 = Js((n) => Math.floor(n));
var BL = Sr(Ri, T1);
var HL = {
  kernelName: Ri,
  backendName: "cpu",
  kernelFunc: BL
};
function N1(n, t, e, s, o, r, i6, a, l) {
  const c = vt([s, r], e);
  for (let u = 0; u < s; u++) {
    const d = [];
    let h6 = 0;
    for (let p6 = 0; p6 < o; p6++) {
      const f = n[u * o + p6];
      h6 += f * i6[p6], d.push(f);
    }
    if (h6 < 0 || h6 >= l / r)
      throw new Error(`Invalid indices: ${d} does not index into ${a}`);
    for (let p6 = 0; p6 < r; p6++)
      c.values[u * r + p6] = t.get(...t.indexToLoc(h6 * r + p6));
  }
  return c;
}
function R1(n, t, e) {
  const s = vt(e, n.dtype);
  for (let o = 0; o < s.size; ++o) {
    const i6 = s.indexToLoc(o).slice(), a = i6[0], l = i6[2], c = t.locToIndex([a, l]);
    i6[2] = t.values[c];
    const u = n.locToIndex(i6);
    0 <= u && u < n.values.length && (s.values[o] = n.values[u]);
  }
  return s;
}
var $1 = ce((n, t) => n > t ? 1 : 0);
var _L = we(nc, $1, null, "bool");
var UL = {
  kernelName: nc,
  backendName: "cpu",
  kernelFunc: _L
};
var G1 = ce((n, t) => n >= t ? 1 : 0);
var YL = we(Gi, G1, null, "bool");
var QL = {
  kernelName: Gi,
  backendName: "cpu",
  kernelFunc: YL
};
var E1 = ce((n, t) => n < t ? 1 : 0);
var JL = we(oc, E1, null, "bool");
var jL = {
  kernelName: oc,
  backendName: "cpu",
  kernelFunc: JL
};
var L1 = ce((n, t) => n <= t ? 1 : 0);
var qL = we(rc, L1, null, "bool");
var t3 = {
  kernelName: rc,
  backendName: "cpu",
  kernelFunc: qL
};
function M1(n, t, e) {
  const s = (t - n) / (e - 1), o = Se(e, "float32");
  o[0] = n;
  for (let r = 1; r < o.length; r++)
    o[r] = o[r - 1] + s;
  return o;
}
var W1 = Js((n) => Math.log(n));
var e3 = Sr(Di, W1);
var n3 = {
  kernelName: Di,
  backendName: "cpu",
  kernelFunc: e3
};
function D1(n, t, e, s) {
  const o = xe(s, O(e));
  for (let r = 0; r < o.length; ++r) {
    const i6 = r * t;
    let a = n[i6];
    for (let l = 0; l < t; ++l) {
      const c = n[i6 + l];
      (Number.isNaN(c) || c > a) && (a = c);
    }
    o[r] = a;
  }
  return o;
}
var F1 = ce((n, t) => Math.max(n, t));
var s3 = we(Vi, F1);
var o3 = {
  kernelName: Vi,
  backendName: "cpu",
  kernelFunc: s3
};
var V1 = ce((n, t) => Math.min(n, t));
var r3 = we(zi, V1);
var i3 = {
  kernelName: zi,
  backendName: "cpu",
  kernelFunc: r3
};
var $f = ce((n, t) => n * t);
var a3 = Nf((n, t, e, s) => ({
  real: n * e - t * s,
  imag: n * s + t * e
}));
var uu = we(Pi, $f, a3);
var l3 = {
  kernelName: Pi,
  backendName: "cpu",
  kernelFunc: uu
};
function z1(n, t, e) {
  const s = bs(-1, e);
  return $f([], t, s, n, e);
}
function c3(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  it(s, "neg");
  const o = e.data.get(s.dataId).values, [r, i6] = z1(o, s.shape, s.dtype);
  return e.makeTensorInfo(i6, s.dtype, r);
}
var u3 = {
  kernelName: gc,
  backendName: "cpu",
  kernelFunc: c3
};
var X1 = ce((n, t) => n !== t ? 1 : 0);
var d3 = we(bc, X1, null, "bool");
var h3 = {
  kernelName: bc,
  backendName: "cpu",
  kernelFunc: d3
};
function Gf(n, t, e, s, o) {
  const r = t.length, i6 = O(t), a = dt(t), l = dt(o), c = xe(e, O(o));
  for (let u = 0; u < i6; ++u) {
    const d = Mo(u, r, a), h6 = new Array(d.length);
    for (let f = 0; f < h6.length; f++)
      h6[f] = d[s[f]];
    const p6 = zn(h6, r, l);
    c[p6] = n[u];
  }
  return c;
}
function Ze(n) {
  const { inputs: t, attrs: e, backend: s } = n, { x: o } = t, { perm: r } = e;
  it(o, "transpose");
  const i6 = o.shape.length, a = new Array(i6);
  for (let d = 0; d < a.length; d++)
    a[d] = o.shape[r[d]];
  const l = s.data.get(o.dataId).values, c = Gf(l, o.shape, o.dtype, r, a);
  return { dataId: s.write(c, a, o.dtype), shape: a, dtype: o.dtype };
}
var p3 = {
  kernelName: Jo,
  backendName: "cpu",
  kernelFunc: Ze
};
function P1(n, t, e, s) {
  const [o, r] = ye(n, s), i6 = je(t, "int32"), a = Se(O(o), i6), l = O(r);
  for (let c = 0; c < a.length; ++c) {
    const u = c * l;
    let d = 1;
    for (let h6 = 0; h6 < l; ++h6)
      d *= e[u + h6];
    a[c] = d;
  }
  return { outVals: a, outShape: o, outDtype: i6 };
}
function f3(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  it(o, "prod");
  const a = o.shape.length, l = Ct(r, o.shape), c = qt(l, a);
  let u = l, d = o;
  const h6 = [];
  c != null && (d = Ze({ inputs: { x: o }, backend: e, attrs: { perm: c } }), h6.push(d), u = ie(u.length, a));
  const p6 = e.data.get(d.dataId).values, { outVals: f, outShape: m, outDtype: g6 } = P1(d.shape, d.dtype, p6, u);
  let b6 = m;
  return i6 && (b6 = re(m, l)), h6.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), e.makeTensorInfo(b6, g6, f);
}
var m3 = {
  kernelName: vc,
  backendName: "cpu",
  kernelFunc: f3
};
function g3(n, t, e) {
  n.forEach((s, o) => {
    if (s < 0 || s >= e) {
      const r = Mo(o, t.length, dt(t)).join(",");
      throw new Error(`indices[${r}] = ${s} is not in [0, ${e})`);
    }
  });
}
function b3(n, t) {
  for (let e = 0; e < n.length; ++e) {
    const s = n[e], o = e === n.length - 1 ? t : n[e + 1].length;
    if (s.length === 0)
      throw new Error("Ragged splits may not be empty");
    if (s[0] < 0)
      throw new Error("Ragged splits must be non-negative");
    if (s[s.length - 1] > o)
      throw new Error("Ragged splits must not point past values");
    for (let r = 1; r < s.length; ++r)
      if (s[r - 1] > s[r])
        throw new Error("Ragged splits must be sorted in ascending order");
  }
}
function x3(n, t, e, s) {
  const o = [];
  let r = 0;
  const i6 = t.length - 1 + e.length, a = new Array(i6).fill(null).map(() => [0]);
  b3(e, s);
  let l = 1;
  for (let c = 0; c < t.length - 1; ++c) {
    l *= t[c];
    const u = t[c + 1];
    for (let d = 1; d < l + 1; ++d)
      a[c].push(d * u);
  }
  for (let c = 0; c < n.length; ++c) {
    let u = n[c], d = n[c] + 1;
    for (let h6 = 0; h6 < e.length; ++h6) {
      const p6 = e[h6], f = h6 + t.length - 1;
      if (f >= 0) {
        const m = a[f], g6 = m[m.length - 1] - p6[u];
        for (let b6 = u; b6 < d; ++b6)
          a[f].push(p6[b6 + 1] + g6);
      }
      u = p6[u], d = p6[d];
    }
    d !== u && (o.push([u, d]), r += d - u);
  }
  return { outSplits: a, valueSlices: o, numValues: r };
}
function y3(n) {
  const t = [];
  for (let e = 0; e < n.length; ++e) {
    const s = n[e].length, o = oe("int32", s);
    t.push(o), n[e].forEach((r, i6) => o[i6] = r);
  }
  return t;
}
function Zm(n, t) {
  const e = n.slice(0, t);
  for (; e.length < t; )
    e.push(1);
  for (let s = t; s < n.length; s++)
    e[t - 1] *= n[s];
  return e;
}
function w3(n, t, e, s, o, r) {
  const i6 = Zm(t, 2)[1], a = Zm(r, 2)[1];
  let l = 0;
  for (const c of e)
    for (let u = c[0]; u < c[1]; ++u) {
      for (let d = 0; d < s; ++d)
        o[l * a + d] = n[u * i6 + d];
      ++l;
    }
}
function I3(n, t, e, s, o) {
  const r = t.slice();
  r[0] = o;
  const i6 = oe(e, O(r)), a = n.length, l = a === 0 ? 0 : a / t[0];
  return w3(n, t, s, l, i6, r), [i6, r];
}
function A1(n, t, e, s, o, r, i6, a) {
  if (n.length === 0)
    throw new Error("paramsNestedSplits must be non empty");
  if (t[0].length === 0)
    throw new Error("Split tensors must not be scalars");
  const l = t[0][0] - 1;
  if (g3(r, i6, l), s.length === 0)
    throw new Error("params.rank must be nonzero");
  const c = s[0], { outSplits: u, valueSlices: d, numValues: h6 } = x3(r, i6, n, c), p6 = y3(u), f = I3(e, s, o, d, h6);
  return [p6, f[0], f[1]];
}
var Bm = 2147483647;
function O1(n, t, e, s, o, r, i6) {
  if (t.length > 1)
    throw new Error("starts must be a scalar or vector");
  if (o.length > 1)
    throw new Error("limits must be a scalar or vector");
  if (i6.length > 1)
    throw new Error("deltas must be a scalar or vector");
  const a = t.length === 0, l = o.length === 0, c = i6.length === 0, u = [];
  a || u.push(t[0]), l || u.push(o[0]), c || u.push(i6[0]);
  for (let g6 = 1; g6 < u.length; ++g6)
    if (u[g6] !== u[g6 - 1])
      throw new Error("starts, limits, and deltas must have the same shape");
  const d = u.length === 0 ? 1 : u[0], h6 = oe("int32", d + 1);
  h6[0] = 0;
  for (let g6 = 0; g6 < d; ++g6) {
    const b6 = a ? n[0] : n[g6], x6 = l ? s[0] : s[g6], w6 = c ? r[0] : r[g6];
    if (w6 === 0)
      throw new Error("Requires delta != 0");
    let y6;
    if (w6 > 0 && x6 < b6 || w6 < 0 && x6 > b6)
      y6 = 0;
    else if (y6 = Math.ceil(Math.abs((x6 - b6) / w6)), y6 > Bm)
      throw new Error(`Requires ((limit - start) / delta) <= ${Bm}`);
    h6[g6 + 1] = h6[g6] + y6;
  }
  const p6 = h6[d], f = oe(e, p6);
  let m = 0;
  for (let g6 = 0; g6 < d; ++g6) {
    const b6 = h6[g6 + 1] - h6[g6];
    let x6 = a ? n[0] : n[g6];
    const w6 = c ? r[0] : r[g6];
    for (let y6 = 0; y6 < b6; ++y6)
      f[m++] = x6, x6 += w6;
  }
  return [h6, f];
}
var gn = Fn;
var kl = class {
  constructor(t, e, s, o, r, i6, a, l, c, u) {
    this.shape = t, this.shapeShape = e, this.values = s, this.valuesShape = o, this.valuesDType = r, this.defaultValue = i6, this.defaultValueShape = a, this.rowPartitionValues = l, this.rowPartitionValuesShapes = c, this.rowPartitionTypes = N0(u), this.raggedRank = R0(this.rowPartitionTypes);
  }
  getRowPartitionTypeByDimension(t) {
    return this.rowPartitionTypes[0] === gn.FIRST_DIM_SIZE ? this.rowPartitionTypes[t + 1] : this.rowPartitionTypes[t];
  }
  // Returns the relationship between dimension and dimension + 1.
  getRowPartitionTensor(t) {
    return this.rowPartitionTypes[0] === gn.FIRST_DIM_SIZE ? this.rowPartitionValues[t + 1] : this.rowPartitionValues[t];
  }
  getMaxWidth(t) {
    const e = this.getRowPartitionTensor(t - 1);
    switch (this.getRowPartitionTypeByDimension(t - 1)) {
      case gn.VALUE_ROWIDS:
        return kl.getMaxWidthValueRowID(e);
      case gn.ROW_SPLITS:
        return kl.getMaxWidthRowSplit(e);
      default:
        throw new Error(`Cannot handle partition type ${gn[this.getRowPartitionTypeByDimension(t - 1)]}`);
    }
  }
  static getMaxWidthRowSplit(t) {
    const e = t.length;
    if (e === 0 || e === 1)
      return 0;
    let s = 0;
    for (let o = 0; o < e - 1; ++o) {
      const r = t[o + 1] - t[o];
      r > s && (s = r);
    }
    return s;
  }
  static getMaxWidthValueRowID(t) {
    const e = t.length;
    if (e === 0)
      return 0;
    let s = 0, o = t[0], r = 0;
    for (let i6 = 1; i6 < e; ++i6) {
      const a = t[i6];
      a !== o && (o = a, r = Math.max(i6 - s, r), s = i6);
    }
    return Math.max(e - s, r);
  }
  tensorShapeFromTensor(t, e, s = true) {
    if (e.length === 0) {
      if (t[0] === -1)
        return [];
      throw new Error("The only valid scalar shape tensor is the fully unknown shape specified as -1.");
    }
    return _m(t, s);
  }
  calculateOutputSize(t) {
    const e = this.valuesShape, s = this.defaultValueShape;
    $0(s, e);
    const o = this.tensorShapeFromTensor(this.shape, this.shapeShape), i6 = T0(this.raggedRank, o, e);
    i6[0] < 0 && (i6[0] = t);
    for (let a = 1; a <= this.raggedRank; ++a)
      i6[a] < 0 && (i6[a] = this.getMaxWidth(a));
    return i6;
  }
  /**
   * The outputIndex represents the index in the output tensor
   * where the first element of a particular dimension would be written.
   * If it is -1, it indicates that the index is out of scope.
   * Example, given firstDimension = 10, firstDimensionOutput = 6,
   * and outputIndexMultiplier = 100:
   * result = [0 100 200 300 400 500 -1 -1 -1 -1]
   * If firstDimensionOutput = 11 instead, then:
   * result = [0 100 200 300 400 500 600 700 800 900]
   */
  calculateFirstParentOutputIndex(t, e, s) {
    const o = Math.min(t, s), r = [];
    let i6 = 0;
    for (let a = 0; a < o; ++a, i6 += e)
      r.push(i6);
    for (let a = o; a < t; ++a)
      r.push(-1);
    return v2(r.length === t, () => "Final length of result must be equal to firstDimension."), r;
  }
  calculateOutputIndexRowSplit(t, e, s, o) {
    const r = t.length, i6 = [];
    for (let a = 0; a < r - 1; ++a) {
      const l = t[a + 1] - t[a];
      let c = Math.min(o, l), u = e[a];
      u === -1 && (c = 0);
      for (let d = 0; d < c; ++d)
        i6.push(u), u += s;
      for (let d = 0; d < l - c; ++d)
        i6.push(-1);
    }
    if (r > 0 && i6.length !== t[r - 1])
      throw new Error("Invalid row split size.");
    return i6;
  }
  // Calculate the output index of the first element of a list.
  // The parentOutputIndex is the same computation for the previous list.
  // -1 indicates an element or list that is out of range.
  // The outputIndexMultiplier is the number of output indices one moves
  // forward for each column.
  // E.g., given:
  // valueRowIds:[0 1 2 2 2 3 5 5 6]
  // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]
  // outputIndexMultiplier: 10
  // outputSize: 2
  // You get:
  // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]
  // result[0] = parentOutputIndex[valueRowIds[0]]
  // result[1] = parentOutputIndex[valueRowIds[1]]
  // result[2] = parentOutputIndex[valueRowIds[2]]
  // result[3] = parentOutputIndex[valueRowIds[2] + 10]
  // result[4] = -1 because it is the third element the size is 2.
  // result[5] = parentOutputIndex[valueRowIds[3]]
  // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1
  // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1
  // result[8] = parentOutputIndex[valueRowIds[7]]
  calculateOutputIndexValueRowID(t, e, s, o) {
    const r = t.length, i6 = [];
    if (r === 0)
      return [];
    let a = 0, l = t[0];
    if (l >= e.length)
      throw new Error(`Got currentValueRowId=${l}, which is not less than ${e.length}`);
    let c = e[l];
    i6.push(c);
    for (let u = 1; u < r; ++u) {
      const d = t[u];
      if (d === l)
        c >= 0 && (++a, a < o ? c += s : c = -1);
      else {
        if (a = 0, l = d, d >= e.length)
          throw new Error(`Got nextValueRowId=${d} which is not less than ${e.length}`);
        c = e[d];
      }
      i6.push(c);
    }
    if (i6.length !== t.length)
      throw new Error("Invalid row ids.");
    return i6;
  }
  calculateOutputIndex(t, e, s, o) {
    const r = this.getRowPartitionTensor(t), i6 = this.getRowPartitionTypeByDimension(t);
    switch (i6) {
      case gn.VALUE_ROWIDS:
        return this.calculateOutputIndexValueRowID(r, e, s, o);
      case gn.ROW_SPLITS:
        if (r.length - 1 > e.length)
          throw new Error(`Row partition size is greater than output size: ${r.length - 1} > ${e.length}`);
        return this.calculateOutputIndexRowSplit(r, e, s, o);
      default:
        throw new Error(`Unsupported partition type: ${gn[i6]}`);
    }
  }
  getFirstDimensionSize() {
    const t = this.rowPartitionValues[0];
    if (this.rowPartitionTypes.length === 0)
      throw new Error("No row_partition_types given.");
    const e = this.rowPartitionTypes[0];
    switch (e) {
      case gn.FIRST_DIM_SIZE:
        return t[0];
      case gn.VALUE_ROWIDS:
        throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
      case gn.ROW_SPLITS:
        return this.rowPartitionValuesShapes[0][0] - 1;
      default:
        throw new Error(`Cannot handle type ${gn[e]}`);
    }
  }
  compute() {
    if (this.rowPartitionValues[0].length <= 0)
      throw new Error("Invalid first partition input. Tensor requires at least one element.");
    const e = this.getFirstDimensionSize(), s = this.calculateOutputSize(e), o = new Array(this.raggedRank + 1);
    o[o.length - 1] = 1;
    for (let l = o.length - 2; l >= 0; --l)
      o[l] = o[l + 1] * s[l + 1];
    const r = _m(s, false), i6 = oe(this.valuesDType, O(r));
    if (o[0] * s[0] > 0) {
      let l = this.calculateFirstParentOutputIndex(e, o[0], s[0]);
      for (let c = 1; c <= this.raggedRank; ++c)
        l = this.calculateOutputIndex(c - 1, l, o[c], s[c]);
      this.setOutput(this.raggedRank, l, i6, r);
    }
    return [r, i6];
  }
  setOutput(t, e, s, o) {
    if (s.length === 0)
      return;
    const r = this.values, i6 = s;
    let a = o.slice();
    a = a.slice(t + 1);
    const l = O(a), c = e.length;
    let u = this.defaultValue;
    if (u.length !== l && u.length !== 1) {
      const f = this.defaultValueShape;
      D(() => {
        const m = W(u, f);
        u = Br(m, a).dataSync();
      });
    }
    let d = 0, h6 = 0, p6 = 0;
    for (let f = 0; f <= c; ++f) {
      let m = f < c ? e[f] : -1;
      if (m === p6) {
        ++p6;
        continue;
      }
      if (h6 < p6) {
        const g6 = r.subarray(d * l), b6 = i6.subarray(h6 * l), x6 = (p6 - h6) * l;
        Hm(b6, g6, x6);
      }
      if (f >= c) {
        const g6 = s.length;
        m = Math.floor(g6 / l);
      }
      if (m > p6)
        if (this.defaultValue.length === 1)
          i6.subarray(p6 * l, m * l).fill(this.defaultValue[0]), p6 = m;
        else
          for (; m > p6; ) {
            const g6 = i6.slice(p6 * l);
            Hm(g6, u, l), ++p6;
          }
      m < 0 ? (d = f + 1, h6 = p6) : (d = f, h6 = p6, p6 = h6 + 1);
    }
  }
};
function Hm(n, t, e) {
  for (let s = 0; s < e; s++)
    n[s] = t[s];
}
function _m(n, t) {
  const e = [];
  for (let s of n) {
    if (s < 0) {
      if (!t)
        throw new Error(`Dimension ${s} must be >= 0`);
      if (s < -1)
        throw new Error(`Dimension ${s} must be >= -1`);
      s = -1;
    }
    e.push(s);
  }
  return e;
}
function K1(n, t, e, s, o, r, i6, a, l, c) {
  return new kl(n, t, e, s, o, r, i6, a, l, c).compute();
}
function Z1(n, t, e, s) {
  const o = n === t, r = n < t && e < 0, i6 = t < n && e > 1;
  if (o || r || i6)
    return Se(0, s);
  const a = Math.abs(Math.ceil((t - n) / e)), l = Se(a, s);
  t < n && e === 1 && (e = -1), l[0] = n;
  for (let c = 1; c < l.length; c++)
    l[c] = l[c - 1] + e;
  return l;
}
var B1 = Js((n) => 1 / Math.sqrt(n));
var C3 = Sr(Hi, B1);
var v3 = {
  kernelName: Hi,
  backendName: "cpu",
  kernelFunc: C3
};
function Qo(n, t, e, s, o, r, i6, a, l, c) {
  const u = [s / o, o], d = n.values, h6 = t.values;
  if (s === 0)
    return vt(e, t.dtype);
  const p6 = vt(u, t.dtype);
  typeof l == "string" || typeof l == "number" ? p6.values.fill(l) : typeof l == "boolean" && p6.values.fill(+l);
  for (let f = 0; f < r; f++) {
    const m = [];
    let g6 = 0;
    for (let b6 = 0; b6 < i6; b6++) {
      const x6 = d[f * i6 + b6];
      m.push(x6), g6 += x6 * a[b6];
    }
    if (g6 < 0 || g6 >= s / o)
      throw new Error(`Invalid indices: ${m} does not index into ${e}`);
    for (let b6 = 0; b6 < o; b6++)
      c ? p6.values[g6 * o + b6] += h6[f * o + b6] : p6.values[g6 * o + b6] = t.rank === 0 ? h6[0] : h6[f * o + b6];
  }
  return p6;
}
var S3 = Js((n) => 1 / (1 + Math.exp(-n)));
var H1 = Mt(Ji, (n) => 1 / (1 + Math.exp(-n)));
var k3 = {
  kernelName: Ji,
  backendName: "cpu",
  kernelFunc: H1
};
function _1(n, t, e, s, o) {
  const r = Wp(s, t, e), i6 = O(e), a = dt(s);
  if (r) {
    const d = Dp(t, a);
    return o === "string" ? n.slice(d, d + i6) : n.subarray(d, d + i6);
  }
  const l = o === "string" ? No(n) : n, c = vt(s, o, l), u = vt(e, o);
  for (let d = 0; d < u.size; ++d) {
    const h6 = u.indexToLoc(d), p6 = h6.map((f, m) => f + t[m]);
    u.set(c.get(...p6), ...h6);
  }
  return o === "string" ? Y0(u.values) : u.values;
}
function Go(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { begin: r, size: i6 } = s;
  it(o, "slice");
  const [a, l] = Hc(o, r, i6);
  Lp(o, a, l);
  const c = e.data.get(o.dataId).values, u = _1(c, a, l, o.shape, o.dtype);
  return e.makeTensorInfo(l, o.dtype, u);
}
var T3 = {
  kernelName: $c,
  backendName: "cpu",
  kernelFunc: Go
};
function U1(n, t, e, s, o, r, i6) {
  const a = t[0], l = r[0], c = new Array(l), u = new Array(a), d = t[1];
  if (l === 0) {
    if (a !== 0)
      throw new Error(F0(a));
    const g6 = oe(e, 0), b6 = oe(o, 0);
    return [
      g6,
      [0, d],
      b6,
      c,
      u
    ];
  }
  let h6 = true, p6 = 0;
  const f = new Array(l).fill(0);
  for (let g6 = 0; g6 < a; ++g6) {
    const b6 = n[g6 * d];
    if (b6 < 0)
      throw new Error(V0(g6, b6));
    if (b6 >= l)
      throw new Error(z0(g6, b6, l));
    ++f[b6], h6 = h6 && b6 >= p6, p6 = b6;
  }
  let m = true;
  for (let g6 = 0; g6 < l; ++g6) {
    const b6 = f[g6] === 0;
    c[g6] = b6, m = m && !b6, f[g6] = Math.max(f[g6], 1), g6 > 0 && (f[g6] += f[g6 - 1]);
  }
  if (m && h6) {
    const g6 = n, b6 = s;
    for (let x6 = 0; x6 < a; ++x6)
      u[x6] = x6;
    return [
      g6,
      [a, d],
      b6,
      c,
      u
    ];
  } else {
    const g6 = f[l - 1], b6 = oe(e, g6 * d), x6 = oe(o, g6), w6 = new Array(l).fill(0);
    for (let y6 = 0; y6 < a; ++y6) {
      const I = n[y6 * d], C6 = w6[I], k7 = (I === 0 ? 0 : f[I - 1]) + C6;
      w6[I]++;
      for (let S = 0; S < d; ++S)
        b6[k7 * d + S] = n[y6 * d + S];
      x6[k7] = s[y6], u[y6] = k7;
    }
    for (let y6 = 0; y6 < l; ++y6)
      if (w6[y6] === 0) {
        const C6 = y6 === 0 ? 0 : f[y6 - 1];
        b6[C6 * d + 0] = y6;
        for (let k7 = 1; k7 < d; ++k7)
          b6[C6 * d + k7] = 0;
        x6[C6] = i6;
      }
    return [
      b6,
      [g6, d],
      x6,
      c,
      u
    ];
  }
}
function Y1(n, t, e, s, o) {
  const r = O(s), i6 = t[0], a = o.length, l = [];
  let c = 1, u = -1;
  for (let g6 = 0; g6 < a; ++g6) {
    const b6 = o[g6];
    if (b6 === -1) {
      if (u !== -1)
        throw new Error(X0(u, g6));
      u = g6, l.push(1);
    } else {
      if (b6 < 0)
        throw new Error(P0(g6, b6));
      c *= b6, l.push(b6);
    }
  }
  if (u !== -1) {
    if (c <= 0)
      throw new Error(A0());
    const g6 = Math.trunc(r / c);
    if (c * g6 !== r)
      throw new Error(O0(s, l));
    l[u] = g6;
  }
  if (O(l) !== r)
    throw new Error(K0(s, l));
  const h6 = s.length, p6 = [];
  if (h6 > 0) {
    p6[h6 - 1] = 1;
    for (let g6 = h6 - 2; g6 >= 0; --g6)
      p6[g6] = p6[g6 + 1] * s[g6 + 1];
  }
  const f = [];
  if (a > 0) {
    f[a - 1] = 1;
    for (let g6 = a - 2; g6 >= 0; --g6)
      f[g6] = f[g6 + 1] * l[g6 + 1];
  }
  const m = oe(e, i6 * a);
  for (let g6 = 0; g6 < i6; ++g6) {
    let b6 = 0;
    for (let x6 = 0; x6 < h6; ++x6)
      b6 += n[g6 * h6 + x6] * p6[x6];
    for (let x6 = 0; x6 < a; ++x6)
      m[g6 * a + x6] = Math.trunc(b6 / f[x6]), b6 %= f[x6];
  }
  return [m, [i6, a], l];
}
function Ef(n, t, e, s, o, r = false, i6 = 0) {
  const a = s.length, l = [t[0], n.length / t[0]], c = l[1], d = a > 0 ? o[a - 1] + 1 : 0;
  if (d < 0)
    throw new Error(Id());
  const h6 = t.slice();
  h6[0] = d;
  const p6 = h6.reduce((w6, y6) => w6 * y6, 1), f = oe(e, p6);
  if (a === 0)
    return d > 0 && f.fill(i6), [f, h6];
  if (d <= 0)
    throw new Error(Id());
  let m = 0, g6 = 1, b6 = 0, x6 = o[m];
  for (; ; ) {
    let w6 = 0;
    if (g6 < a) {
      if (w6 = o[g6], x6 === w6) {
        ++g6;
        continue;
      }
      if (x6 >= w6)
        throw new Error(Z0());
    }
    if (x6 < 0 || x6 >= d)
      throw new Error(B0(x6, d));
    x6 > b6 && f.fill(i6, b6 * c, x6 * c);
    for (let y6 = m; y6 < g6; ++y6) {
      const I = s[y6];
      if (I < 0 || I >= l[0])
        throw new Error(H0(y6, s[y6], l[0]));
      for (let C6 = 0; C6 < c; C6++)
        f[x6 * c + C6] += n[I * c + C6];
    }
    if (r)
      for (let y6 = 0; y6 < c; y6++)
        f[x6 * c + y6] /= g6 - m;
    if (m = g6, ++g6, b6 = x6 + 1, x6 = w6, g6 > a)
      break;
  }
  return b6 < d && f.fill(i6, b6 * c, d * c), [f, h6];
}
var N3 = Js((n) => Math.sqrt(n));
var R3 = Mt(qi, (n) => Math.sqrt(n));
var $3 = {
  kernelName: qi,
  backendName: "cpu",
  kernelFunc: R3
};
var Q1 = ce((n, t) => {
  const e = n - t;
  return e * e;
});
var G3 = we(ta, Q1);
var E3 = {
  kernelName: ta,
  backendName: "cpu",
  kernelFunc: G3
};
function J1(n, t, e, s) {
  const o = vt(n, t.dtype);
  for (let r = 0; r < o.size; r++) {
    const i6 = o.indexToLoc(r), a = new Array(i6.length);
    for (let l = 0; l < a.length; l++)
      a[l] = i6[l] * e[l] + s[l];
    o.set(t.get(...a), ...i6);
  }
  return o;
}
var L3 = class {
  constructor(t, e, s, o, r, i6) {
    this.separator = hs(t), this.nGramWidths = e, this.leftPad = hs(s), this.rightPad = hs(o), this.padWidth = r, this.preserveShort = i6;
  }
  getPadWidth(t) {
    return Math.min(this.padWidth < 0 ? t - 1 : this.padWidth, t - 1);
  }
  getNumNGrams(t, e) {
    const s = this.getPadWidth(e);
    return Math.max(0, t + 2 * s - e + 1);
  }
  createNGrams(t, e, s, o, r, i6) {
    for (let a = 0; a < r; ++a) {
      const l = this.getPadWidth(i6), c = Math.max(0, l - a), u = Math.max(0, l - (r - (a + 1))), d = i6 - (c + u), h6 = e + (c > 0 ? 0 : a - l);
      let p6 = 0;
      p6 += c * this.leftPad.length;
      for (let x6 = 0; x6 < d; ++x6)
        p6 += t[h6 + x6].length;
      p6 += u * this.rightPad.length;
      const f = c + u + d - 1;
      p6 += f * this.separator.length, s[o + a] = new Uint8Array(p6);
      const m = s[o + a];
      let g6 = 0;
      const b6 = (x6) => x6.forEach((w6) => m[g6++] = w6);
      for (let x6 = 0; x6 < c; ++x6)
        b6(this.leftPad), b6(this.separator);
      for (let x6 = 0; x6 < d - 1; ++x6)
        b6(t[h6 + x6]), b6(this.separator);
      if (d > 0) {
        b6(t[h6 + d - 1]);
        for (let x6 = 0; x6 < u; ++x6)
          b6(this.separator), b6(this.rightPad);
      } else {
        for (let x6 = 0; x6 < u - 1; ++x6)
          b6(this.rightPad), b6(this.separator);
        b6(this.rightPad);
      }
    }
  }
  // Data and splits together form the definition of the ragged tensor,
  // where data is 1 dimensional and contains the values of the tensor
  // and splits denotes the indices at which each row starts.
  compute(t, e) {
    const s = t.length, o = e.length;
    if (o > 0) {
      let l = e[0];
      if (l !== 0)
        throw new Error(`First split value must be 0, got ${l}`);
      for (let c = 1; c < o; ++c) {
        let u = e[c] >= l;
        if (u = u && e[c] <= s, !u)
          throw new Error(`Invalid split value ${e[c]}, must be in [${l}, ${s}]`);
        l = e[c];
      }
      if (l !== s)
        throw new Error(`Last split value must be data size. Expected ${s}, got ${l}`);
    }
    const r = o - 1, i6 = oe("int32", o);
    if (s === 0 || o === 0) {
      const l = new Array(s);
      for (let c = 0; c <= r; ++c)
        i6[c] = 0;
      return [l, i6];
    }
    i6[0] = 0;
    for (let l = 1; l <= r; ++l) {
      const c = e[l] - e[l - 1];
      let u = 0;
      this.nGramWidths.forEach((d) => {
        u += this.getNumNGrams(c, d);
      }), this.preserveShort && c > 0 && u === 0 && (u = 1), i6[l] = i6[l - 1] + u;
    }
    const a = new Array(i6[r]);
    for (let l = 0; l < r; ++l) {
      const c = e[l];
      let u = i6[l];
      if (this.nGramWidths.forEach((d) => {
        const h6 = e[l + 1] - e[l], p6 = this.getNumNGrams(h6, d);
        this.createNGrams(t, c, a, u, p6, d), u += p6;
      }), this.preserveShort && u === i6[l]) {
        const d = e[l + 1] - e[l];
        if (d === 0)
          continue;
        const h6 = d + 2 * this.padWidth, p6 = 1;
        this.createNGrams(t, c, a, u, p6, h6);
      }
    }
    return [a, i6];
  }
};
function j1(n, t, e, s, o, r, i6, a) {
  return new L3(e, s, o, r, i6, a).compute(n, t);
}
function M3(n, t, e, s) {
  if (!n.length)
    return;
  if (t.length === 0) {
    for (let r = 0; r < n.length; ++r)
      s.push(n.subarray(r, r + 1));
    return;
  }
  if (t.length === 1) {
    const r = t[0];
    let i6 = n.indexOf(r);
    for (; i6 !== -1; ) {
      const a = n.subarray(0, i6);
      (!e || a.length !== 0) && s.push(a), n = n.subarray(i6 + 1), i6 = n.indexOf(r);
    }
    (!e || n.length !== 0) && s.push(n);
    return;
  }
  let o = 0;
  for (let r = 0; r < n.length + 1; r++)
    if (r === n.length || t.indexOf(n[r]) !== -1) {
      const i6 = n.subarray(o, r);
      (!e || i6.length !== 0) && s.push(i6), o = r + 1;
    }
}
function q1(n, t, e) {
  const s = n.length, o = [];
  let r = 0, i6 = 0;
  const a = new Array(s);
  for (let h6 = 0; h6 < s; ++h6) {
    const p6 = o.length;
    M3(n[h6], t, e, o);
    const f = o.length - p6;
    a[h6] = f, r += f, i6 = Math.max(i6, f);
  }
  const l = oe("int32", r * 2), c = new Array(r), u = [s, i6];
  let d = 0;
  for (let h6 = 0; h6 < s; ++h6)
    for (let p6 = 0; p6 < a[h6]; ++p6)
      l[d * 2] = h6, l[d * 2 + 1] = p6, c[d] = o[d], ++d;
  return [l, c, u];
}
function tw(n, t) {
  const e = oe("int32", n.length);
  for (let s = 0; s < n.length; ++s)
    e[s] = db(n[s]).modulo(t).getLowBitsUnsigned();
  return e;
}
var ew = ce((n, t) => n - t);
var W3 = Nf((n, t, e, s) => ({ real: n - e, imag: t - s }));
var Lf = we(ea, ew, W3);
var D3 = {
  kernelName: ea,
  backendName: "cpu",
  kernelFunc: Lf
};
function nw(n, t) {
  const e = new Array(n.rank);
  for (let o = 0; o < e.length; o++)
    e[o] = n.shape[o] * t[o];
  const s = vt(e, n.dtype);
  for (let o = 0; o < s.values.length; ++o) {
    const r = s.indexToLoc(o), i6 = new Array(n.rank);
    for (let l = 0; l < i6.length; l++)
      i6[l] = r[l] % n.shape[l];
    const a = n.locToIndex(i6);
    s.values[o] = n.values[a];
  }
  return s;
}
var Or = (n, t) => {
  const e = t.value - n.value;
  return e === 0 ? n.index - t.index : e;
};
function sw(n, t, e = 0, s = n.length - 1) {
  for (; s > e; ) {
    if (s - e > 600) {
      const a = s - e + 1, l = t - e + 1, c = Math.log(a), u = 0.5 * Math.exp(2 * c / 3), d = 0.5 * Math.sqrt(c * u * (a - u) / a) * Math.sign(l - a / 2), h6 = Math.max(e, Math.floor(t - l * u / a + d)), p6 = Math.min(s, Math.floor(t + (a - l) * u / a + d));
      sw(n, t, h6, p6);
    }
    const o = n[t];
    let r = e, i6 = s;
    for (us(n, e, t), Or(n[s], o) > 0 && us(n, e, s); r < i6; ) {
      for (us(n, r, i6), r++, i6--; Or(n[r], o) < 0; )
        r = r + 1;
      for (; Or(n[i6], o) > 0; )
        i6 = i6 - 1;
    }
    Or(n[e], o) === 0 ? us(n, e, i6) : (i6 = i6 + 1, us(n, i6, s)), i6 <= t && (e = i6 + 1), t <= i6 && (s = i6 - 1);
  }
}
function ow(n, t, e, s, o) {
  const r = t[t.length - 1], [i6, a] = [n.length / r, r], l = xe(e, i6 * s), c = xe("int32", i6 * s);
  for (let d = 0; d < i6; d++) {
    const h6 = d * a, p6 = n.subarray(h6, h6 + a);
    let f = new Array(p6.length);
    p6.forEach((x6, w6) => f[w6] = { value: x6, index: w6 }), s < f.length && (sw(f, s), f = f.slice(0, s)), o && f.sort(Or);
    const m = d * s, g6 = l.subarray(m, m + s), b6 = c.subarray(m, m + s);
    for (let x6 = 0; x6 < s; x6++)
      g6[x6] = f[x6].value, b6[x6] = f[x6].index;
  }
  const u = t.slice();
  return u[u.length - 1] = s, [
    vt(u, e, l),
    vt(u, "int32", c)
  ];
}
function rw(n, t, e, s) {
  const o = Ct(t, e)[0], r = [1, e[0], 1];
  for (let f = 0; f < o; f++)
    r[0] *= e[f];
  r[1] = e[o];
  for (let f = o + 1; f < e.length; f++)
    r[2] *= e[f];
  const i6 = {}, a = new Int32Array(e[o]), l = new $e(r, s, n), c = [], u = r[0] === 1 && r[2] === 1;
  for (let f = 0; f < e[o]; f++) {
    let m;
    if (u)
      m = n[f].toString();
    else {
      const g6 = [];
      for (let b6 = 0; b6 < r[0]; b6++)
        for (let x6 = 0; x6 < r[2]; x6++)
          g6.push(l.get(b6, f, x6));
      m = g6.join(",");
    }
    if (i6[m] !== void 0)
      a[f] = i6[m];
    else {
      const g6 = Object.keys(i6).length;
      i6[m] = g6, a[f] = g6, c.push(f);
    }
  }
  const d = r.slice();
  d[1] = Object.keys(i6).length;
  const h6 = new $e(d, s);
  c.forEach((f, m) => {
    for (let g6 = 0; g6 < r[0]; g6++)
      for (let b6 = 0; b6 < r[2]; b6++)
        h6.set(l.get(g6, f, b6), g6, m, b6);
  });
  const p6 = e.slice();
  return p6[o] = d[1], {
    outputValues: h6.values,
    outputShape: p6,
    indices: a
  };
}
var F3 = Object.freeze(Object.defineProperty({
  __proto__: null,
  addImpl: b1,
  bincountImpl: Rf,
  bincountReduceImpl: x1,
  castImpl: g1,
  ceilImpl: y1,
  concatImpl: w1,
  equalImpl: I1,
  expImpl: v1,
  expm1Impl: k1,
  floorImpl: T1,
  gatherNdImpl: N1,
  gatherV2Impl: R1,
  greaterEqualImpl: G1,
  greaterImpl: $1,
  lessEqualImpl: L1,
  lessImpl: E1,
  linSpaceImpl: M1,
  logImpl: W1,
  maxImpl: D1,
  maximumImpl: F1,
  minimumImpl: V1,
  multiplyImpl: $f,
  negImpl: z1,
  notEqualImpl: X1,
  prodImpl: P1,
  raggedGatherImpl: A1,
  raggedRangeImpl: O1,
  raggedTensorToTensorImpl: K1,
  rangeImpl: Z1,
  rsqrtImpl: B1,
  scatterImpl: Qo,
  sigmoidImpl: S3,
  simpleAbsImpl: m1,
  sliceImpl: _1,
  sparseFillEmptyRowsImpl: U1,
  sparseReshapeImpl: Y1,
  sparseSegmentReductionImpl: Ef,
  sqrtImpl: N3,
  squaredDifferenceImpl: Q1,
  stridedSliceImpl: J1,
  stringNGramsImpl: j1,
  stringSplitImpl: q1,
  stringToHashBucketFastImpl: tw,
  subImpl: ew,
  tileImpl: nw,
  topKImpl: ow,
  transposeImpl: Gf,
  uniqueImpl: rw
}, Symbol.toStringTag, { value: "Module" }));
kb(
  "cpu",
  () => new cu(),
  1
  /* priority */
);
var iw = Mt(Si, (n) => n >= 0 ? n : Math.exp(n) - 1);
var V3 = {
  kernelName: Si,
  backendName: "cpu",
  kernelFunc: iw
};
function aw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { alpha: r } = s;
  it([o], "leakyRelu");
  const i6 = O(o.shape), a = e.data.get(o.dataId).values, l = xe("float32", i6);
  for (let c = 0; c < a.length; c++)
    l[c] = a[c] < 0 ? r * a[c] : a[c];
  return e.makeTensorInfo(o.shape, "float32", l);
}
var z3 = {
  kernelName: sc,
  backendName: "cpu",
  kernelFunc: aw
};
var X3 = ce((n, t) => n < 0 ? t * n : n);
function lw(n) {
  const { inputs: t, backend: e } = n, { x: s, alpha: o } = t;
  it([s, o], "prelu");
  const r = e.data.get(s.dataId).values, i6 = e.data.get(o.dataId).values, [a, l] = X3(s.shape, o.shape, r, i6, "float32");
  return e.makeTensorInfo(l, "float32", a);
}
var P3 = {
  kernelName: Cc,
  backendName: "cpu",
  kernelFunc: lw
};
var cw = Mt(Ki, (n) => Math.max(0, n));
var A3 = {
  kernelName: Ki,
  backendName: "cpu",
  kernelFunc: cw
};
var uw = Mt(Zi, (n) => Math.min(Math.max(0, n), 6));
var O3 = {
  kernelName: Zi,
  backendName: "cpu",
  kernelFunc: uw
};
function Tl(n, t, e, s, o) {
  if (e === "linear")
    return rs({ inputs: { x: t }, backend: n });
  if (e === "relu")
    return cw({ inputs: { x: t }, backend: n });
  if (e === "elu")
    return iw({ inputs: { x: t }, backend: n });
  if (e === "relu6")
    return uw({ inputs: { x: t }, backend: n });
  if (e === "prelu")
    return lw({ inputs: { x: t, alpha: s }, backend: n });
  if (e === "leakyrelu")
    return aw({ inputs: { x: t }, backend: n, attrs: { alpha: o } });
  if (e === "sigmoid")
    return H1({ inputs: { x: t }, backend: n });
  throw new Error(`Activation ${e} has not been implemented for the CPU backend.`);
}
function Ot(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { shape: r } = s, i6 = O(o.shape), a = Ad(r, i6), l = O(a);
  v2(i6 === l, () => `The new shape (${a}) has ${l} elements and the old shape (${o.shape}) has ${i6} elements. The new shape and old shape must have the same number of elements.`), e.incRef(o.dataId);
  const c = e.data.get(o.dataId);
  if (c.complexTensorInfos != null) {
    const u = c.complexTensorInfos.real, d = c.complexTensorInfos.imag;
    u.shape = a, d.shape = a;
  }
  return { dataId: o.dataId, shape: a, dtype: o.dtype };
}
var K3 = {
  kernelName: Sc,
  backendName: "cpu",
  kernelFunc: Ot
};
function dw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { a: o, b: r } = t, { transposeA: i6, transposeB: a } = s;
  it([o, r], "matMul");
  const l = o.shape.length, c = r.shape.length, u = i6 ? o.shape[l - 2] : o.shape[l - 1], d = a ? r.shape[c - 1] : r.shape[c - 2], h6 = i6 ? o.shape[l - 1] : o.shape[l - 2], p6 = a ? r.shape[c - 2] : r.shape[c - 1], f = o.shape.slice(0, -2), m = r.shape.slice(0, -2), g6 = O(f), b6 = O(m), w6 = bt(o.shape.slice(0, -2), r.shape.slice(0, -2)).concat([h6, p6]);
  v2(u === d, () => `Error in matMul: inner shapes (${u}) and (${d}) of Tensors with shapes ${o.shape} and ${r.shape} and transposeA=${i6} and transposeB=${a} must match.`);
  const y6 = i6 ? [g6, u, h6] : [g6, h6, u], I = a ? [b6, p6, d] : [b6, d, p6], C6 = Ot({ inputs: { x: o }, backend: e, attrs: { shape: y6 } }), k7 = Ot({ inputs: { x: r }, backend: e, attrs: { shape: I } }), S = i6 ? C6.shape[1] : C6.shape[2], N = i6 ? C6.shape[2] : C6.shape[1], R = a ? k7.shape[1] : k7.shape[2], M6 = Math.max(g6, b6), V = e.data.get(C6.dataId).values, z = e.data.get(k7.dataId).values, X = dt(C6.shape), P6 = dt(k7.shape), [A6, B6, Z] = i6 ? [X[0], 1, X[1]] : [X[0], X[1], 1], [H6, Y, Q] = a ? [1, P6[1], P6[0]] : [P6[1], 1, P6[0]], j = N * R, J6 = vt([M6, N, R], C6.dtype), nt = J6.values, q = e.blockSize;
  for (let rt = 0; rt < M6; rt++) {
    const ht = rt % g6, ft2 = rt % b6;
    for (let pt = 0; pt < N; pt += q) {
      const wt2 = Math.min(pt + q, N);
      for (let It = 0; It < R; It += q) {
        const Et = Math.min(It + q, R);
        for (let Vt2 = 0; Vt2 < S; Vt2 += q) {
          const te = Math.min(Vt2 + q, S);
          for (let zt = pt; zt < wt2; zt++)
            for (let Wt2 = It; Wt2 < Et; Wt2++) {
              let Qt = 0;
              for (let _t2 = Vt2; _t2 < te; _t2++) {
                const as = (
                  // tslint:disable-next-line: max-line-length
                  V[ht * A6 + zt * B6 + _t2 * Z]
                ), Ie = (
                  // tslint:disable-next-line: max-line-length
                  z[_t2 * H6 + Wt2 * Y + ft2 * Q]
                );
                Qt += as * Ie;
              }
              nt[rt * j + (zt * R + Wt2)] += Qt;
            }
        }
      }
    }
  }
  return e.disposeIntermediateTensorInfo(C6), e.disposeIntermediateTensorInfo(k7), e.makeTensorInfo(w6, J6.dtype, J6.values);
}
var Z3 = {
  kernelName: Ol,
  backendName: "cpu",
  kernelFunc: dw
};
function B3(n) {
  const { inputs: t, backend: e, attrs: s } = n, { a: o, b: r, bias: i6, preluActivationWeights: a } = t, { transposeA: l, transposeB: c, activation: u, leakyreluAlpha: d } = s;
  let h6, p6, f;
  const m = [];
  h6 = dw({ inputs: { a: o, b: r }, attrs: { transposeA: l, transposeB: c }, backend: e }), i6 && (p6 = cr({ inputs: { a: h6, b: i6 }, backend: e }), m.push(h6), h6 = p6), u && (f = Tl(e, h6, u, a, d), m.push(h6), h6 = f);
  for (const b6 of m)
    e.disposeIntermediateTensorInfo(b6);
  return h6;
}
var H3 = {
  kernelName: ol,
  backendName: "cpu",
  kernelFunc: B3
};
var _3 = Mt(di, (n) => Math.acos(n));
var U3 = {
  kernelName: di,
  backendName: "cpu",
  kernelFunc: _3
};
var Y3 = Mt(hi, (n) => Math.acosh(n));
var Q3 = {
  kernelName: hi,
  backendName: "cpu",
  kernelFunc: Y3
};
function J3(n) {
  const { inputs: t, backend: e } = n, s = t;
  it(t, "addN");
  const o = s.map((a) => e.data.get(a.dataId).values), r = vt(s[0].shape, s[0].dtype), i6 = r.values;
  for (let a = 0; a < s.length; a++) {
    const l = o[a];
    for (let c = 0; c < i6.length; c++)
      i6[c] += l[c];
  }
  return e.makeTensorInfo(r.shape, r.dtype, r.values);
}
var j3 = {
  kernelName: Bd,
  backendName: "cpu",
  kernelFunc: J3
};
function q3(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  it(o, "all");
  const a = Ct(r, o.shape);
  let l = a;
  const c = qt(l, o.shape.length);
  let u = o;
  c != null && (u = Ze({ inputs: { x: o }, backend: e, attrs: { perm: c } }), l = ie(l.length, o.shape.length)), Te("all", l, u.shape.length);
  const [d, h6] = ye(u.shape, l), p6 = O(h6), f = Se(O(d), u.dtype), m = e.data.get(u.dataId).values;
  for (let b6 = 0; b6 < f.length; ++b6) {
    const x6 = b6 * p6;
    let w6 = m[x6];
    for (let y6 = 0; y6 < p6; ++y6) {
      const I = m[x6 + y6];
      w6 = w6 && I;
    }
    f[b6] = w6;
  }
  c != null && e.disposeIntermediateTensorInfo(u);
  const g6 = e.makeTensorInfo(d, u.dtype, f);
  if (i6) {
    const b6 = re(d, a), x6 = Ot({ inputs: { x: g6 }, backend: e, attrs: { shape: b6 } });
    return e.disposeIntermediateTensorInfo(g6), x6;
  }
  return g6;
}
var tM = {
  kernelName: Hd,
  backendName: "cpu",
  kernelFunc: q3
};
function eM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  it(o, "any");
  const a = Ct(r, o.shape);
  let l = a;
  const c = qt(l, o.shape.length);
  let u = o;
  c != null && (u = Ze({ inputs: { x: o }, backend: e, attrs: { perm: c } }), l = ie(l.length, o.shape.length)), Te("any", l, u.shape.length);
  const [d, h6] = ye(u.shape, l), p6 = O(h6), f = Se(O(d), u.dtype), m = e.data.get(u.dataId).values;
  for (let b6 = 0; b6 < f.length; ++b6) {
    const x6 = b6 * p6;
    let w6 = m[x6];
    for (let y6 = 0; y6 < p6; ++y6) {
      const I = m[x6 + y6];
      w6 = w6 || I;
    }
    f[b6] = w6;
  }
  c != null && e.disposeIntermediateTensorInfo(u);
  const g6 = e.makeTensorInfo(d, u.dtype, f);
  if (i6) {
    const b6 = re(d, a), x6 = Ot({ inputs: { x: g6 }, backend: e, attrs: { shape: b6 } });
    return e.disposeIntermediateTensorInfo(g6), x6;
  }
  return g6;
}
var nM = {
  kernelName: _d,
  backendName: "cpu",
  kernelFunc: eM
};
function sM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r } = s;
  it(o, "argMax");
  let i6 = Ct(r, o.shape);
  const a = qt(i6, o.shape.length);
  let l = o;
  const c = [];
  a != null && (l = Ze({ inputs: { x: o }, backend: e, attrs: { perm: a } }), c.push(l), i6 = ie(i6.length, l.shape.length)), i6 = [i6[0]], Te("argMax", i6, l.shape.length);
  const [u, d] = ye(l.shape, i6), h6 = O(u), p6 = Se(h6, "int32"), f = O(d), m = e.data.get(l.dataId).values;
  for (let g6 = 0; g6 < p6.length; ++g6) {
    const b6 = g6 * f;
    let x6 = m[b6], w6 = 0;
    for (let y6 = 0; y6 < f; ++y6) {
      const I = m[b6 + y6];
      I > x6 && (x6 = I, w6 = y6);
    }
    p6[g6] = w6;
  }
  return c.forEach((g6) => e.disposeIntermediateTensorInfo(g6)), e.makeTensorInfo(u, "int32", p6);
}
var oM = {
  kernelName: zl,
  backendName: "cpu",
  kernelFunc: sM
};
function rM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r } = s;
  it(o, "argMin");
  let i6 = Ct(r, o.shape);
  const a = qt(i6, o.shape.length);
  let l = o;
  const c = [];
  a != null && (l = Ze({ inputs: { x: o }, backend: e, attrs: { perm: a } }), c.push(l), i6 = ie(i6.length, l.shape.length)), i6 = [i6[0]], Te("argMin", i6, l.shape.length);
  const [u, d] = ye(l.shape, i6), h6 = O(u), p6 = Se(h6, "int32"), f = O(d), m = e.data.get(l.dataId).values;
  for (let g6 = 0; g6 < p6.length; ++g6) {
    const b6 = g6 * f;
    let x6 = m[b6], w6 = 0;
    for (let y6 = 0; y6 < f; ++y6) {
      const I = m[b6 + y6];
      I < x6 && (x6 = I, w6 = y6);
    }
    p6[g6] = w6;
  }
  return c.forEach((g6) => e.disposeIntermediateTensorInfo(g6)), e.makeTensorInfo(u, "int32", p6);
}
var iM = {
  kernelName: Xl,
  backendName: "cpu",
  kernelFunc: rM
};
var aM = Mt(pi, (n) => Math.asin(n));
var lM = {
  kernelName: pi,
  backendName: "cpu",
  kernelFunc: aM
};
var cM = Mt(fi, (n) => Math.asinh(n));
var uM = {
  kernelName: fi,
  backendName: "cpu",
  kernelFunc: cM
};
var dM = Mt(mi, (n) => Math.atan(n));
var hM = {
  kernelName: mi,
  backendName: "cpu",
  kernelFunc: dM
};
var pM = ce((n, t) => Math.atan2(n, t));
var fM = we(bi, pM);
var mM = {
  kernelName: bi,
  backendName: "cpu",
  kernelFunc: fM
};
var gM = Mt(gi, (n) => Math.atanh(n));
var bM = {
  kernelName: gi,
  backendName: "cpu",
  kernelFunc: gM
};
function Mf(n, t, e, s, o, r) {
  const i6 = o.strideHeight, a = o.strideWidth, l = o.dilationHeight, c = o.dilationWidth, u = o.effectiveFilterHeight, d = o.effectiveFilterWidth, h6 = o.padInfo.top, p6 = o.padInfo.left, f = r === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY, m = vt(o.outShape, e), g6 = m.values, b6 = o.outShape[1] * o.outShape[2] * o.outShape[3], x6 = o.outShape[2] * o.outShape[3], w6 = o.outShape[3];
  for (let y6 = 0; y6 < o.batchSize; ++y6) {
    const I = y6 * b6, C6 = y6 * s[0];
    for (let k7 = 0; k7 < o.inChannels; ++k7)
      for (let S = 0; S < o.outHeight; ++S) {
        const N = S * i6 - h6, R = Math.max(0, N), M6 = Math.min(o.inHeight, u + N), V = I + S * x6;
        for (let z = 0; z < o.outWidth; ++z) {
          const X = z * a - p6, P6 = Math.max(0, X), A6 = Math.min(o.inWidth, d + X);
          let B6 = f, Z = 0, H6 = 0;
          for (let Q = R; Q < M6; Q += l) {
            const j = C6 + Q * s[1];
            for (let J6 = P6; J6 < A6; J6 += c) {
              const nt = j + J6 * s[2], q = n[nt + k7];
              r === "max" && q > B6 ? B6 = q : r === "avg" && (Z += q, H6++);
            }
            if (isNaN(B6))
              break;
          }
          const Y = V + z * w6 + k7;
          g6[Y] = r === "avg" ? Z / H6 : B6;
        }
      }
  }
  return m;
}
function hw(n, t, e, s, o = false, r = false) {
  const i6 = vt(s.outShape, "int32"), a = s.strideHeight, l = s.strideWidth, c = s.dilationHeight, u = s.dilationWidth, d = s.effectiveFilterHeight, h6 = s.effectiveFilterWidth, p6 = s.padInfo.top, f = s.padInfo.left, m = vt(t, e, n);
  for (let g6 = 0; g6 < s.batchSize; ++g6)
    for (let b6 = 0; b6 < s.inChannels; ++b6)
      for (let x6 = 0; x6 < s.outHeight; ++x6) {
        const w6 = x6 * a - p6;
        let y6 = w6;
        for (; y6 < 0; )
          y6 += c;
        const I = Math.min(s.inHeight, d + w6);
        for (let C6 = 0; C6 < s.outWidth; ++C6) {
          const k7 = C6 * l - f;
          let S = k7;
          for (; S < 0; )
            S += u;
          const N = Math.min(s.inWidth, h6 + k7);
          let R = Number.NEGATIVE_INFINITY, M6 = -1;
          for (let V = y6; V < I; V += c) {
            const z = V - w6;
            for (let X = S; X < N; X += u) {
              const P6 = X - k7, A6 = m.get(g6, V, X, b6);
              A6 > R && (R = A6, o ? M6 = r ? ((g6 * s.inHeight + V) * s.inWidth + X) * s.inChannels + b6 : (V * s.inWidth + X) * s.inChannels + b6 : M6 = z * h6 + P6);
            }
          }
          i6.set(M6, g6, x6, C6, b6);
        }
      }
  return i6;
}
function pw(n, t, e, s, o, r) {
  const i6 = o.strideDepth, a = o.strideHeight, l = o.strideWidth, c = o.dilationDepth, u = o.dilationHeight, d = o.dilationWidth, h6 = o.effectiveFilterDepth, p6 = o.effectiveFilterHeight, f = o.effectiveFilterWidth, m = o.padInfo.front, g6 = o.padInfo.top, b6 = o.padInfo.left, x6 = r === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY, w6 = vt(o.outShape, e), y6 = w6.values, I = o.outShape[1] * o.outShape[2] * o.outShape[3] * o.outShape[4], C6 = o.outShape[2] * o.outShape[3] * o.outShape[4], k7 = o.outShape[3] * o.outShape[4], S = o.outShape[4];
  for (let N = 0; N < o.batchSize; ++N) {
    const R = N * I, M6 = N * s[0];
    for (let V = 0; V < o.inChannels; ++V)
      for (let z = 0; z < o.outDepth; ++z) {
        const X = z * i6 - m;
        let P6 = X;
        for (; P6 < 0; )
          P6 += c;
        const A6 = Math.min(o.inDepth, h6 + X), B6 = R + z * C6;
        for (let Z = 0; Z < o.outHeight; ++Z) {
          const H6 = Z * a - g6;
          let Y = H6;
          for (; Y < 0; )
            Y += u;
          const Q = Math.min(o.inHeight, p6 + H6), j = B6 + Z * k7;
          for (let J6 = 0; J6 < o.outWidth; ++J6) {
            const nt = J6 * l - b6;
            let q = nt;
            for (; q < 0; )
              q += d;
            const rt = Math.min(o.inWidth, f + nt), ht = j + J6 * S;
            let ft2 = x6, pt = 0, wt2 = 0;
            for (let Et = P6; Et < A6; Et += c) {
              const Vt2 = M6 + Et * s[1];
              for (let te = Y; te < Q; te += u) {
                const zt = Vt2 + te * s[2];
                for (let Wt2 = q; Wt2 < rt; Wt2 += d) {
                  const Qt = zt + Wt2 * s[3], _t2 = n[Qt + V];
                  if (r === "max" && _t2 > ft2 ? ft2 = _t2 : r === "avg" && (pt += _t2, wt2++), isNaN(ft2))
                    break;
                }
                if (isNaN(ft2))
                  break;
              }
              if (isNaN(ft2))
                break;
            }
            const It = ht + V;
            y6[It] = r === "avg" ? pt / Math.max(wt2, 1) : ft2;
          }
        }
      }
  }
  return w6;
}
function xM(n, t) {
  const e = vt(t.outShape, "int32"), s = t.strideDepth, o = t.strideHeight, r = t.strideWidth, i6 = t.dilationDepth, a = t.dilationHeight, l = t.dilationWidth, c = t.effectiveFilterDepth, u = t.effectiveFilterHeight, d = t.effectiveFilterWidth, h6 = t.padInfo.front, p6 = t.padInfo.top, f = t.padInfo.left;
  for (let m = 0; m < t.batchSize; ++m)
    for (let g6 = 0; g6 < t.inChannels; ++g6)
      for (let b6 = 0; b6 < t.outDepth; ++b6) {
        const x6 = b6 * s - h6;
        let w6 = x6;
        for (; w6 < 0; )
          w6 += i6;
        const y6 = Math.min(t.inDepth, c + x6);
        for (let I = 0; I < t.outHeight; ++I) {
          const C6 = I * o - p6;
          let k7 = C6;
          for (; k7 < 0; )
            k7 += a;
          const S = Math.min(t.inHeight, u + C6);
          for (let N = 0; N < t.outWidth; ++N) {
            const R = N * r - f;
            let M6 = R;
            for (; M6 < 0; )
              M6 += l;
            const V = Math.min(t.inWidth, d + R);
            let z = Number.NEGATIVE_INFINITY, X = -1;
            for (let P6 = w6; P6 < y6; P6 += i6) {
              const A6 = P6 - x6;
              for (let B6 = k7; B6 < S; B6 += a) {
                const Z = B6 - C6;
                for (let H6 = M6; H6 < V; H6 += l) {
                  const Y = H6 - R, Q = n.get(m, P6, B6, H6, g6);
                  Q >= z && (z = Q, X = A6 * u * d + Z * u + Y);
                }
              }
            }
            e.set(X, m, b6, I, N, g6);
          }
        }
      }
  return e;
}
function yM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  it(o, "avgPool");
  const { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = s, c = 1;
  v2(Ee(i6, c), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${i6} and dilations '${c}'`);
  const u = $n(o.shape, r, i6, c, a, l);
  let d;
  if (u.filterWidth === 1 && u.filterHeight === 1 && Rt(u.inShape, u.outShape))
    d = rs({ inputs: { x: o }, backend: e });
  else {
    const h6 = e.data.get(o.dataId).values, p6 = dt(o.shape), f = Mf(h6, o.shape, o.dtype, p6, u, "avg");
    d = e.makeTensorInfo(u.outShape, o.dtype, f.values);
  }
  return d;
}
var wM = {
  kernelName: Pl,
  backendName: "cpu",
  kernelFunc: yM
};
function IM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { filterSize: r, strides: i6, pad: a, dimRoundingMode: l, dataFormat: c } = s;
  it(o, "avgPool3d");
  const u = xs(o.shape, r, i6, 1, a, l, c), d = e.data.get(o.dataId).values, h6 = pw(d, o.shape, o.dtype, dt(o.shape), u, "avg");
  return e.makeTensorInfo(h6.shape, "float32", h6.values);
}
var CM = {
  kernelName: Al,
  backendName: "cpu",
  kernelFunc: IM
};
function vM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, { filterSize: i6, strides: a, pad: l, dimRoundingMode: c } = s;
  it([o, r], "avgPool3DGrad");
  const u = xs(r.shape, i6, a, 1, l, c), d = u.strideDepth, h6 = u.strideHeight, p6 = u.strideWidth, f = u.filterDepth, m = u.filterHeight, g6 = u.filterWidth, b6 = u.dilationDepth, x6 = u.dilationHeight, w6 = u.dilationWidth, y6 = u.effectiveFilterDepth, I = u.effectiveFilterHeight, C6 = u.effectiveFilterWidth, k7 = y6 - 1 - u.padInfo.front, S = C6 - 1 - u.padInfo.left, N = I - 1 - u.padInfo.top, R = vt(r.shape, "float32"), M6 = 1 / (f * m * g6), V = e.bufferSync(o);
  for (let z = 0; z < u.batchSize; ++z)
    for (let X = 0; X < u.inChannels; ++X)
      for (let P6 = 0; P6 < u.inDepth; ++P6)
        for (let A6 = 0; A6 < u.inHeight; ++A6)
          for (let B6 = 0; B6 < u.inWidth; ++B6) {
            const Z = P6 - k7, H6 = A6 - N, Y = B6 - S;
            let Q = 0;
            for (let j = 0; j < y6; j += b6) {
              const J6 = (Z + j) / d;
              if (!(J6 < 0 || J6 >= u.outDepth || Math.floor(J6) !== J6))
                for (let nt = 0; nt < I; nt += x6) {
                  const q = (H6 + nt) / h6;
                  if (!(q < 0 || q >= u.outHeight || Math.floor(q) !== q))
                    for (let rt = 0; rt < C6; rt += w6) {
                      const ht = (Y + rt) / p6;
                      if (ht < 0 || ht >= u.outWidth || Math.floor(ht) !== ht)
                        continue;
                      const ft2 = V.get(z, J6, q, ht, X);
                      Q += ft2;
                    }
                }
            }
            R.set(Q * M6, z, P6, A6, B6, X);
          }
  return e.makeTensorInfo(R.shape, R.dtype, R.values);
}
var SM = {
  kernelName: Yd,
  backendName: "cpu",
  kernelFunc: vM
};
function kM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, i6 = r;
  it([o, r], "avgPoolGrad");
  const { filterSize: a, strides: l, pad: c } = s, u = $n(i6.shape, a, l, 1, c), d = u.strideHeight, h6 = u.strideWidth, p6 = u.filterHeight, f = u.filterWidth, m = u.dilationHeight, g6 = u.dilationWidth, b6 = u.effectiveFilterHeight, x6 = u.effectiveFilterWidth, w6 = x6 - 1 - u.padInfo.left, y6 = b6 - 1 - u.padInfo.top, I = vt(i6.shape, "float32"), C6 = 1 / (p6 * f), k7 = e.data.get(o.dataId).values, S = vt(o.shape, "float32", k7);
  for (let N = 0; N < u.batchSize; ++N)
    for (let R = 0; R < u.inChannels; ++R)
      for (let M6 = 0; M6 < u.inHeight; ++M6)
        for (let V = 0; V < u.inWidth; ++V) {
          const z = M6 - y6, X = V - w6;
          let P6 = 0;
          for (let A6 = 0; A6 < b6; A6 += m) {
            const B6 = (z + A6) / d;
            if (!(B6 < 0 || B6 >= u.outHeight || Math.floor(B6) !== B6))
              for (let Z = 0; Z < x6; Z += g6) {
                const H6 = (X + Z) / h6;
                if (H6 < 0 || H6 >= u.outWidth || Math.floor(H6) !== H6)
                  continue;
                const Y = S.get(N, B6, H6, R);
                P6 += Y;
              }
          }
          I.set(P6 * C6, N, M6, V, R);
        }
  return e.makeTensorInfo(I.shape, I.dtype, I.values);
}
var TM = {
  kernelName: Ud,
  backendName: "cpu",
  kernelFunc: kM
};
function NM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, scale: r, offset: i6, mean: a, variance: l } = t;
  v2(a.shape.length === l.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), v2(i6 == null || a.shape.length === i6.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), v2(r == null || a.shape.length === r.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks."), it([o, a, l, r, i6], "batchNorm");
  let { varianceEpsilon: c } = s;
  c == null && (c = 1e-3);
  const u = e.data.get(o.dataId).values, d = e.data.get(a.dataId).values, h6 = e.data.get(l.dataId).values, p6 = r ? e.data.get(r.dataId).values : new Float32Array([1]), f = i6 ? e.data.get(i6.dataId).values : new Float32Array([0]), m = new Float32Array(u.length), g6 = f.length, b6 = p6.length, x6 = h6.length, w6 = d.length;
  let y6 = 0, I = 0, C6 = 0, k7 = 0;
  for (let S = 0; S < u.length; ++S)
    m[S] = f[y6++] + (u[S] - d[I++]) * p6[C6++] / Math.sqrt(h6[k7++] + c), y6 >= g6 && (y6 = 0), I >= w6 && (I = 0), C6 >= b6 && (C6 = 0), k7 >= x6 && (k7 = 0);
  return e.makeTensorInfo(o.shape, o.dtype, m);
}
var RM = {
  kernelName: tc,
  backendName: "cpu",
  kernelFunc: NM
};
function $M(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockShape: r, crops: i6 } = s;
  it([o], "batchToSpaceND");
  const a = r.reduce((b6, x6) => b6 * x6), l = fa(o.shape, r, a), c = ma(l.length, r.length), u = ga(o.shape, r, a), d = Pp(i6, r.length), h6 = Ap(u, i6, r.length), p6 = Ot({ inputs: { x: o }, backend: e, attrs: { shape: l } }), f = Ze({ inputs: { x: p6 }, backend: e, attrs: { perm: c } }), m = Ot({ inputs: { x: f }, backend: e, attrs: { shape: u } }), g6 = Go({
    inputs: { x: m },
    backend: e,
    attrs: { begin: d, size: h6 }
  });
  return e.disposeIntermediateTensorInfo(p6), e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(m), g6;
}
var GM = {
  kernelName: Kl,
  backendName: "cpu",
  kernelFunc: $M
};
function EM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, weights: r } = t, { size: i6 } = s, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, c = Rf(a, l, r.dtype, r.shape, i6);
  return e.makeTensorInfo([i6], r.dtype, c);
}
var LM = {
  kernelName: Qd,
  backendName: "cpu",
  kernelFunc: EM
};
function MM(n) {
  const { inputs: t, backend: e } = n, { s0: s, s1: o } = t, r = e.data.get(s.dataId).values, i6 = e.data.get(o.dataId).values, a = bt(Array.from(r), Array.from(i6));
  return e.makeTensorInfo([a.length], "int32", Int32Array.from(a));
}
var WM = {
  kernelName: Kg,
  backendName: "cpu",
  kernelFunc: MM
};
var DM = Mt(wi, (n, t) => {
  const e = t;
  return n > e.clipValueMax ? e.clipValueMax : n < e.clipValueMin ? e.clipValueMin : n;
});
var FM = {
  kernelName: wi,
  backendName: "cpu",
  kernelFunc: DM
};
var VM = (n) => {
  const { x: t } = n.inputs, e = n.backend, s = new Float32Array(O(t.shape)), o = e.data.get(t.dataId), r = o.complexTensorInfos.real, i6 = o.complexTensorInfos.imag, a = e.data.get(r.dataId).values, l = e.data.get(i6.dataId).values;
  for (let c = 0; c < a.length; c++) {
    const u = a[c], d = l[c];
    s[c] = Math.hypot(u, d);
  }
  return e.makeOutput(s, t.shape, "float32");
};
var zM = {
  kernelName: Zl,
  backendName: "cpu",
  kernelFunc: VM
};
function ur(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = e.data.get(s.dataId).complexTensorInfos.imag, r = e.data.get(o.dataId).values;
  return e.makeTensorInfo(o.shape, o.dtype, r);
}
var XM = {
  kernelName: hh,
  backendName: "cpu",
  kernelFunc: ur
};
function dr(n) {
  const { inputs: t, backend: e, attrs: s } = n, { axis: o } = s, r = Ct(o, t[0].shape)[0], i6 = t.map((m) => m.shape);
  Vp(i6, r);
  let a = ts(t.map((m) => m.shape), r);
  if (O(a) === 0)
    return e.makeTensorInfo(a, t[0].dtype, []);
  const l = t.filter((m) => O(m.shape) > 0);
  if (l.length === 1)
    return rs({ inputs: { x: l[0] }, backend: e });
  if (l[0].dtype === "complex64") {
    const m = l.map((y6) => $o({ inputs: { input: y6 }, backend: e })), g6 = l.map((y6) => ur({ inputs: { input: y6 }, backend: e })), b6 = dr({ inputs: m, backend: e, attrs: { axis: r } }), x6 = dr({ inputs: g6, backend: e, attrs: { axis: r } }), w6 = Ye({ inputs: { real: b6, imag: x6 }, backend: e });
    return m.forEach((y6) => e.disposeIntermediateTensorInfo(y6)), g6.forEach((y6) => e.disposeIntermediateTensorInfo(y6)), e.disposeIntermediateTensorInfo(b6), e.disposeIntermediateTensorInfo(x6), w6;
  }
  const c = l.map((m) => {
    const b6 = [-1, O(m.shape.slice(r))];
    return Ot({ inputs: { x: m }, backend: e, attrs: { shape: b6 } });
  }), u = c.map((m) => ({ vals: e.data.get(m.dataId).values, shape: m.shape }));
  a = ts(
    c.map((m) => m.shape),
    1
    /* axis */
  );
  const d = c[0].shape[0] === 1, h6 = w1(u, a, t[0].dtype, d), p6 = ts(l.map((m) => m.shape), r), f = e.makeTensorInfo(p6, t[0].dtype, h6);
  return c.forEach((m) => e.disposeIntermediateTensorInfo(m)), f;
}
var PM = {
  kernelName: Bl,
  backendName: "cpu",
  kernelFunc: dr
};
function fw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dataFormat: l, dilations: c, dimRoundingMode: u } = s;
  it([o, r], "conv2d");
  const d = ys(l), h6 = ke(o.shape, r.shape, i6, c, a, u, false, d), p6 = h6.filterHeight, f = h6.filterWidth, m = h6.dilationHeight, g6 = h6.dilationWidth, b6 = h6.padInfo.left, x6 = h6.padInfo.top, w6 = h6.dataFormat === "channelsLast", y6 = new $e(h6.outShape, o.dtype), I = dt(o.shape), C6 = dt(r.shape), k7 = I[0], S = w6 ? I[1] : I[2], N = w6 ? I[2] : 1, R = w6 ? 1 : I[1], M6 = y6.strides[0], V = w6 ? y6.strides[1] : y6.strides[2], z = w6 ? y6.strides[2] : 1, X = w6 ? 1 : y6.strides[1], P6 = e.data.get(o.dataId).values, A6 = e.data.get(r.dataId).values, B6 = y6.values;
  for (let Z = 0; Z < h6.batchSize; ++Z) {
    const H6 = Z * k7, Y = Z * M6;
    for (let Q = 0; Q < h6.outHeight; ++Q) {
      const j = Y + Q * V, J6 = Q * h6.strideHeight - x6;
      for (let nt = 0; nt < p6; ++nt) {
        const q = J6 + nt * m;
        if (q < 0 || q >= h6.inHeight)
          continue;
        const rt = nt * C6[0], ht = H6 + q * S;
        for (let ft2 = 0; ft2 < h6.outWidth; ++ft2) {
          const pt = j + ft2 * z, wt2 = ft2 * h6.strideWidth - b6;
          for (let It = 0; It < f; ++It) {
            const Et = wt2 + It * g6;
            if (Et < 0 || Et >= h6.inWidth)
              continue;
            const Vt2 = rt + It * C6[1], te = ht + Et * N;
            let zt = Vt2;
            for (let Wt2 = 0; Wt2 < h6.inChannels; ++Wt2) {
              const Qt = P6[te + Wt2 * R];
              for (let _t2 = 0; _t2 < h6.outChannels; ++_t2)
                B6[pt + _t2 * X] += Qt * A6[zt + _t2];
              zt += h6.outChannels;
            }
          }
        }
      }
    }
  }
  return e.makeTensorInfo(y6.shape, y6.dtype, B6);
}
var AM = {
  kernelName: Hl,
  backendName: "cpu",
  kernelFunc: fw
};
function OM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, pad: a, dataFormat: l, dimRoundingMode: c, filterShape: u } = s;
  it([o, r], "conv2dBackpropFilter");
  const d = ys(l), h6 = ke(o.shape, u, i6, 1, a, c, false, d), { strideHeight: p6, strideWidth: f, filterHeight: m, filterWidth: g6 } = h6, b6 = h6.dataFormat === "channelsLast", x6 = new $e(h6.filterShape, "float32"), w6 = h6.padInfo.left, y6 = h6.padInfo.top, I = e.data.get(o.dataId).values, C6 = e.data.get(r.dataId).values, k7 = new $e(o.shape, o.dtype, I), S = new $e(r.shape, r.dtype, C6);
  for (let N = 0; N < m; ++N) {
    const R = Math.max(0, Math.ceil((y6 - N) / p6)), M6 = Math.min(h6.outHeight, (h6.inHeight + y6 - N) / p6);
    for (let V = 0; V < g6; ++V) {
      const z = Math.max(0, Math.ceil((w6 - V) / f)), X = Math.min(h6.outWidth, (h6.inWidth + w6 - V) / f);
      for (let P6 = 0; P6 < h6.inChannels; ++P6)
        for (let A6 = 0; A6 < h6.outChannels; ++A6) {
          let B6 = 0;
          for (let Z = 0; Z < h6.batchSize; ++Z)
            for (let H6 = R; H6 < M6; ++H6) {
              const Y = N + H6 * p6 - y6;
              for (let Q = z; Q < X; ++Q) {
                const j = V + Q * f - w6;
                b6 ? B6 += k7.get(Z, Y, j, P6) * S.get(Z, H6, Q, A6) : B6 += k7.get(Z, P6, Y, j) * S.get(Z, A6, H6, Q);
              }
            }
          x6.set(B6, N, V, P6, A6);
        }
    }
  }
  return e.makeTensorInfo(x6.shape, x6.dtype, x6.values);
}
var KM = {
  kernelName: jd,
  backendName: "cpu",
  kernelFunc: OM
};
function ZM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { inputShape: i6, strides: a, pad: l, dataFormat: c, dimRoundingMode: u } = s;
  it([o, r], "conv2dBackpropInput");
  const d = dt(r.shape), h6 = dt(o.shape);
  let p6 = ys(c);
  const f = ke(i6, r.shape, a, 1, l, u, false, p6), m = new $e(f.inShape, "float32"), g6 = m.values, b6 = e.data.get(o.dataId).values, x6 = e.data.get(r.dataId).values, [w6, y6, I] = d, { batchSize: C6, filterHeight: k7, filterWidth: S, inChannels: N, inHeight: R, inWidth: M6, outChannels: V, outHeight: z, outWidth: X, strideHeight: P6, strideWidth: A6 } = f;
  p6 = f.dataFormat;
  const B6 = k7 - 1 - f.padInfo.top, Z = S - 1 - f.padInfo.left, H6 = p6 === "channelsLast", Y = m.strides[0], Q = H6 ? m.strides[1] : m.strides[2], j = H6 ? m.strides[2] : 1, J6 = H6 ? 1 : m.strides[1], nt = h6[0], q = H6 ? h6[1] : h6[2], rt = H6 ? h6[2] : 1, ht = H6 ? 1 : h6[1];
  for (let ft2 = 0; ft2 < C6; ++ft2)
    for (let pt = 0; pt < N; ++pt)
      for (let wt2 = 0; wt2 < R; ++wt2) {
        const It = wt2 - B6, Et = Math.max(0, Math.ceil(It / P6)), Vt2 = Math.min(z, (k7 + It) / P6);
        for (let te = 0; te < M6; ++te) {
          const zt = te - Z, Wt2 = Math.max(0, Math.ceil(zt / A6)), Qt = Math.min(X, (S + zt) / A6);
          let _t2 = 0;
          for (let Ie = Et; Ie < Vt2; ++Ie) {
            const vs = Ie * P6 - It;
            for (let on2 = Wt2; on2 < Qt; ++on2) {
              const qs = on2 * A6 - zt, Ln2 = nt * ft2 + q * Ie + rt * on2, ls = w6 * (k7 - 1 - vs) + y6 * (S - 1 - qs) + I * pt;
              for (let Ss = 0; Ss < V; ++Ss) {
                const ks = b6[Ln2 + ht * Ss], Ts = x6[ls + Ss];
                _t2 += ks * Ts;
              }
            }
          }
          const as = Y * ft2 + Q * wt2 + j * te + J6 * pt;
          g6[as] = _t2;
        }
      }
  return e.makeTensorInfo(m.shape, m.dtype, m.values);
}
var BM = {
  kernelName: _l,
  backendName: "cpu",
  kernelFunc: ZM
};
function HM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l } = s;
  it([o, r], "conv3d");
  const c = Bs(o.shape, r.shape, i6, l, a), { filterDepth: u, filterHeight: d, filterWidth: h6, dilationDepth: p6, dilationHeight: f, dilationWidth: m, padInfo: g6 } = c, b6 = g6.front, x6 = g6.left, w6 = g6.top, y6 = new $e(c.outShape, o.dtype), I = e.data.get(o.dataId).values, C6 = e.data.get(r.dataId).values, k7 = y6.values, S = dt(o.shape), N = dt(r.shape);
  for (let R = 0; R < c.batchSize; ++R) {
    const M6 = R * S[0], V = R * y6.strides[0];
    for (let z = 0; z < c.outDepth; ++z) {
      const X = V + z * y6.strides[1], P6 = z * c.strideDepth - b6;
      for (let A6 = 0; A6 < u; ++A6) {
        const B6 = P6 + A6 * p6;
        if (B6 < 0 || B6 >= c.inDepth)
          continue;
        const Z = A6 * N[0], H6 = M6 + B6 * S[1];
        for (let Y = 0; Y < c.outHeight; ++Y) {
          const Q = X + Y * y6.strides[2], j = Y * c.strideHeight - w6;
          for (let J6 = 0; J6 < d; ++J6) {
            const nt = j + J6 * f;
            if (nt < 0 || nt >= c.inHeight)
              continue;
            const q = Z + J6 * N[1], rt = H6 + nt * S[2];
            for (let ht = 0; ht < c.outWidth; ++ht) {
              const ft2 = Q + ht * c.outChannels, pt = ht * c.strideWidth - x6;
              for (let wt2 = 0; wt2 < h6; ++wt2) {
                const It = pt + wt2 * m;
                if (It < 0 || It >= c.inWidth)
                  continue;
                const Et = q + wt2 * N[2], Vt2 = rt + It * c.inChannels;
                let te = Et;
                for (let zt = 0; zt < c.inChannels; ++zt) {
                  const Wt2 = I[Vt2 + zt];
                  for (let Qt = 0; Qt < c.outChannels; ++Qt)
                    k7[ft2 + Qt] += Wt2 * C6[te + Qt];
                  te += c.outChannels;
                }
              }
            }
          }
        }
      }
    }
  }
  return e.makeTensorInfo(y6.shape, y6.dtype, y6.values);
}
var _M = {
  kernelName: Ul,
  backendName: "cpu",
  kernelFunc: HM
};
function UM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, pad: a, filterShape: l } = s;
  it([o, r], "conv3dBackpropFilterV2");
  const c = dt(o.shape), u = dt(r.shape), d = Bs(o.shape, l, i6, 1, a), h6 = d.strideDepth, p6 = d.strideHeight, f = d.strideWidth, m = d.filterDepth, g6 = d.filterHeight, b6 = d.filterWidth, x6 = new $e(d.filterShape, "float32"), w6 = x6.values, [y6, I, C6, k7] = x6.strides, S = e.data.get(r.dataId).values, [N, R, M6, V] = u, z = e.data.get(o.dataId).values, [X, P6, A6, B6] = c, Z = d.padInfo.front, H6 = d.padInfo.left, Y = d.padInfo.top;
  for (let Q = 0; Q < m; ++Q) {
    const j = Math.max(0, Math.ceil((Z - Q) / h6)), J6 = Math.min(d.outDepth, (d.inDepth + Z - Q) / h6), nt = Q * y6;
    for (let q = 0; q < g6; ++q) {
      const rt = Math.max(0, Math.ceil((Y - q) / p6)), ht = Math.min(d.outHeight, (d.inHeight + Y - q) / p6), ft2 = q * I + nt;
      for (let pt = 0; pt < b6; ++pt) {
        const wt2 = Math.max(0, Math.ceil((H6 - pt) / f)), It = Math.min(d.outWidth, (d.inWidth + H6 - pt) / f), Et = pt * C6 + ft2;
        for (let Vt2 = 0; Vt2 < d.inChannels; ++Vt2) {
          const te = Vt2 * k7 + Et;
          for (let zt = 0; zt < d.outChannels; ++zt) {
            let Wt2 = 0;
            for (let Qt = 0; Qt < d.batchSize; ++Qt) {
              const _t2 = Qt * X, as = Qt * N;
              for (let Ie = j; Ie < J6; ++Ie) {
                const on2 = (Q + Ie * h6 - Z) * P6 + _t2, qs = Ie * R + as;
                for (let Ln2 = rt; Ln2 < ht; ++Ln2) {
                  const Ss = (q + Ln2 * p6 - Y) * A6 + on2, ks = Ln2 * M6 + qs;
                  for (let Ts = wt2; Ts < It; ++Ts) {
                    const bu = (pt + Ts * f - H6) * B6 + Ss, xu = Ts * V + ks;
                    Wt2 += z[bu + Vt2] * S[xu + zt];
                  }
                }
              }
            }
            w6[te + zt] = Wt2;
          }
        }
      }
    }
  }
  return e.makeTensorInfo(x6.shape, x6.dtype, x6.values);
}
var YM = {
  kernelName: qd,
  backendName: "cpu",
  kernelFunc: UM
};
function QM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { pad: i6, strides: a, inputShape: l } = s;
  it([o], "conv3dBackpropInputV2");
  const c = dt(o.shape), u = dt(r.shape), d = Bs(l, r.shape, a, 1, i6), h6 = new $e(d.inShape, "float32"), p6 = h6.values, [f, m, g6, b6] = h6.strides, x6 = e.data.get(o.dataId).values, [w6, y6, I, C6] = c, k7 = e.data.get(r.dataId).values, [S, N, R, M6] = u, { batchSize: V, filterDepth: z, filterHeight: X, filterWidth: P6, inChannels: A6, inDepth: B6, inHeight: Z, inWidth: H6, outChannels: Y, outDepth: Q, outHeight: j, outWidth: J6, strideDepth: nt, strideHeight: q, strideWidth: rt } = d, ht = z - 1 - d.padInfo.front, ft2 = X - 1 - d.padInfo.top, pt = P6 - 1 - d.padInfo.left;
  for (let wt2 = 0; wt2 < V; ++wt2)
    for (let It = 0; It < A6; ++It)
      for (let Et = 0; Et < B6; ++Et) {
        const Vt2 = Et - ht, te = Math.max(0, Math.ceil(Vt2 / nt)), zt = Math.min(Q, (z + Vt2) / nt);
        for (let Wt2 = 0; Wt2 < Z; ++Wt2) {
          const Qt = Wt2 - ft2, _t2 = Math.max(0, Math.ceil(Qt / q)), as = Math.min(j, (X + Qt) / q);
          for (let Ie = 0; Ie < H6; ++Ie) {
            const vs = Ie - pt, on2 = Math.max(0, Math.ceil(vs / rt)), qs = Math.min(J6, (P6 + vs) / rt);
            let Ln2 = 0;
            for (let ls = te; ls < zt; ++ls) {
              const Ss = ls * nt - Vt2;
              for (let ks = _t2; ks < as; ++ks) {
                const Ts = ks * q - Qt;
                for (let Lr = on2; Lr < qs; ++Lr) {
                  const bu = Lr * rt - vs, xu = w6 * wt2 + y6 * ls + I * ks + C6 * Lr, SI = S * (z - 1 - Ss) + N * (X - 1 - Ts) + R * (P6 - 1 - bu) + M6 * It;
                  for (let Ma = 0; Ma < Y; ++Ma) {
                    const kI = x6[xu + Ma], TI = k7[SI + Ma];
                    Ln2 += kI * TI;
                  }
                }
              }
            }
            p6[f * wt2 + m * Et + g6 * Wt2 + b6 * Ie + It] = Ln2;
          }
        }
      }
  return e.makeTensorInfo(h6.shape, h6.dtype, h6.values);
}
var JM = {
  kernelName: th,
  backendName: "cpu",
  kernelFunc: QM
};
var jM = Mt(Ii, (n) => Math.cos(n));
var qM = {
  kernelName: Ii,
  backendName: "cpu",
  kernelFunc: jM
};
var tW = Mt(Ci, (n) => Math.cosh(n));
var eW = {
  kernelName: Ci,
  backendName: "cpu",
  kernelFunc: tW
};
function nW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { image: o, boxes: r, boxInd: i6 } = t, { cropSize: a, method: l, extrapolationValue: c } = s, [u, d, h6, p6] = o.shape, f = r.shape[0], [m, g6] = a, b6 = vt([f, m, g6, p6], "float32"), x6 = e.data.get(r.dataId).values, w6 = e.data.get(i6.dataId).values, y6 = e.data.get(o.dataId).values, I = dt(o.shape), C6 = dt(b6.shape);
  for (let k7 = 0; k7 < f; k7++) {
    const S = k7 * 4, N = x6[S], R = x6[S + 1], M6 = x6[S + 2], V = x6[S + 3], z = w6[k7];
    if (z >= u)
      continue;
    const X = m > 1 ? (M6 - N) * (d - 1) / (m - 1) : 0, P6 = g6 > 1 ? (V - R) * (h6 - 1) / (g6 - 1) : 0;
    for (let A6 = 0; A6 < m; A6++) {
      const B6 = m > 1 ? N * (d - 1) + A6 * X : 0.5 * (N + M6) * (d - 1);
      if (B6 < 0 || B6 > d - 1) {
        for (let Z = 0; Z < g6; Z++)
          for (let H6 = 0; H6 < p6; H6++) {
            const Y = H6 + Z * C6[2] + A6 * C6[1] + k7 * C6[0];
            b6.values[Y] = c;
          }
        continue;
      }
      if (l === "bilinear") {
        const Z = Math.floor(B6), H6 = Math.ceil(B6), Y = B6 - Z;
        for (let Q = 0; Q < g6; Q++) {
          const j = g6 > 1 ? R * (h6 - 1) + Q * P6 : 0.5 * (R + V) * (h6 - 1);
          if (j < 0 || j > h6 - 1) {
            for (let rt = 0; rt < p6; rt++) {
              const ht = rt + Q * C6[2] + A6 * C6[1] + k7 * C6[0];
              b6.values[ht] = c;
            }
            continue;
          }
          const J6 = Math.floor(j), nt = Math.ceil(j), q = j - J6;
          for (let rt = 0; rt < p6; rt++) {
            let ht = rt + J6 * I[2] + Z * I[1] + z * I[0];
            const ft2 = y6[ht];
            ht = rt + nt * I[2] + Z * I[1] + z * I[0];
            const pt = y6[ht];
            ht = rt + J6 * I[2] + H6 * I[1] + z * I[0];
            const wt2 = y6[ht];
            ht = rt + nt * I[2] + H6 * I[1] + z * I[0];
            const It = y6[ht], Et = ft2 + (pt - ft2) * q, Vt2 = wt2 + (It - wt2) * q;
            ht = rt + Q * C6[2] + A6 * C6[1] + k7 * C6[0], b6.values[ht] = Et + (Vt2 - Et) * Y;
          }
        }
      } else
        for (let Z = 0; Z < g6; ++Z) {
          const H6 = g6 > 1 ? R * (h6 - 1) + Z * P6 : 0.5 * (R + V) * (h6 - 1);
          if (H6 < 0 || H6 > h6 - 1) {
            for (let j = 0; j < p6; j++) {
              const J6 = j + Z * C6[2] + A6 * C6[1] + k7 * C6[0];
              b6.values[J6] = c;
            }
            continue;
          }
          const Y = Math.round(H6), Q = Math.round(B6);
          for (let j = 0; j < p6; j++) {
            const J6 = j + Y * I[2] + Q * I[1] + z * I[0], nt = j + Z * C6[2] + A6 * C6[1] + k7 * C6[0];
            b6.values[nt] = y6[J6];
          }
        }
    }
  }
  return e.makeTensorInfo(b6.shape, b6.dtype, b6.values);
}
var sW = {
  kernelName: nh,
  backendName: "cpu",
  kernelFunc: nW
};
function oW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, exclusive: i6, reverse: a } = s;
  it(o, "cumprod");
  const l = qt([r], o.shape.length);
  let c = o;
  l != null && (c = Ze({ inputs: { x: o }, backend: e, attrs: { perm: l } }));
  const u = ie(1, o.shape.length)[0];
  if (u !== c.shape.length - 1)
    throw new Error(`backend.cumprod in CPU expects an inner-most axis=${c.shape.length - 1} but got axis=${u}`);
  const d = je(c.dtype, "int32"), h6 = Fl(O(c.shape), d), p6 = e.data.get(c.dataId).values, f = c.shape[c.shape.length - 1], m = a ? (b6, x6) => b6 + f - x6 - 1 : (b6, x6) => b6 + x6;
  for (let b6 = 0; b6 < p6.length; b6 += f)
    for (let x6 = 0; x6 < f; x6++) {
      const w6 = m(b6, x6);
      if (x6 === 0)
        h6[w6] = i6 ? 1 : p6[w6];
      else {
        const y6 = m(b6, x6 - 1);
        h6[w6] = i6 ? p6[y6] * h6[y6] : p6[w6] * h6[y6];
      }
    }
  const g6 = e.makeTensorInfo(c.shape, d, h6);
  if (l != null) {
    const b6 = Hs(l), x6 = Ze({ inputs: { x: g6 }, backend: e, attrs: { perm: b6 } });
    return e.disposeIntermediateTensorInfo(g6), e.disposeIntermediateTensorInfo(c), x6;
  }
  return g6;
}
var rW = {
  kernelName: eh,
  backendName: "cpu",
  kernelFunc: oW
};
function iW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, exclusive: i6, reverse: a } = s;
  it(o, "cumsum");
  const l = qt([r], o.shape.length);
  let c = o;
  l != null && (c = Ze({ inputs: { x: o }, backend: e, attrs: { perm: l } }));
  const u = ie(1, o.shape.length)[0];
  if (u !== c.shape.length - 1)
    throw new Error(`backend.cumsum in CPU expects an inner-most axis=${c.shape.length - 1} but got axis=${u}`);
  const d = je(c.dtype, "int32"), h6 = Se(O(c.shape), d), p6 = e.data.get(c.dataId).values, f = c.shape[c.shape.length - 1], m = a ? (b6, x6) => b6 + f - x6 - 1 : (b6, x6) => b6 + x6;
  for (let b6 = 0; b6 < p6.length; b6 += f)
    for (let x6 = 0; x6 < f; x6++) {
      const w6 = m(b6, x6);
      if (x6 === 0)
        h6[w6] = i6 ? 0 : p6[w6];
      else {
        const y6 = m(b6, x6 - 1);
        h6[w6] = i6 ? p6[y6] + h6[y6] : p6[w6] + h6[y6];
      }
    }
  const g6 = e.makeTensorInfo(c.shape, d, h6);
  if (l != null) {
    const b6 = Hs(l), x6 = Ze({ inputs: { x: g6 }, backend: e, attrs: { perm: b6 } });
    return e.disposeIntermediateTensorInfo(g6), e.disposeIntermediateTensorInfo(c), x6;
  }
  return g6;
}
var aW = {
  kernelName: Yl,
  backendName: "cpu",
  kernelFunc: iW
};
function lW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, weights: r } = t, { size: i6, binaryOutput: a } = s;
  if (o.shape.length === 1) {
    const l = e.data.get(o.dataId).values, c = e.data.get(r.dataId).values, u = Rf(l, c, r.dtype, r.shape, i6);
    return e.makeTensorInfo([i6], r.dtype, u);
  } else if (o.shape.length === 2) {
    const l = e.bufferSync(o), c = e.bufferSync(r), u = x1(l, c, i6, a);
    return e.makeTensorInfo(u.shape, r.dtype, u.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${o.shape.length}.`);
}
var cW = {
  kernelName: sh,
  backendName: "cpu",
  kernelFunc: lW
};
function uW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockSize: r, dataFormat: i6 } = s;
  v2(i6 === "NHWC", () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${i6}`);
  const a = o.shape[0], l = o.shape[1], c = o.shape[2], u = o.shape[3], d = l * r, h6 = c * r, p6 = u / (r * r), f = e.data.get(o.dataId).values, m = new Float32Array(a * d * h6 * p6);
  let g6 = 0;
  for (let b6 = 0; b6 < a; ++b6)
    for (let x6 = 0; x6 < d; ++x6) {
      const w6 = Math.floor(x6 / r), y6 = x6 % r;
      for (let I = 0; I < h6; ++I) {
        const C6 = Math.floor(I / r), k7 = I % r, S = (y6 * r + k7) * p6;
        for (let N = 0; N < p6; ++N) {
          const M6 = N + S + u * (C6 + c * (w6 + l * b6));
          m[g6++] = f[M6];
        }
      }
    }
  return e.makeTensorInfo([a, d, h6, p6], o.dtype, m);
}
var dW = {
  kernelName: oh,
  backendName: "cpu",
  kernelFunc: uW
};
function mw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l, dimRoundingMode: c } = s;
  it([o, r], "depthwiseConv2DNative");
  const u = dt(o.shape), d = dt(r.shape);
  let h6 = l;
  h6 == null && (h6 = [1, 1]), v2(Ee(i6, h6), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i6} and dilations '${h6}'`);
  const p6 = ke(
    o.shape,
    r.shape,
    i6,
    h6,
    a,
    c,
    true
    /* depthwise */
  ), { filterHeight: f, filterWidth: m, dilationHeight: g6, dilationWidth: b6, padInfo: x6 } = p6, w6 = x6.left, y6 = x6.top, I = p6.outChannels / p6.inChannels, C6 = new $e(p6.outShape, o.dtype), k7 = e.data.get(o.dataId).values, S = e.data.get(r.dataId).values, N = C6.values;
  for (let R = 0; R < p6.batchSize; ++R) {
    const M6 = R * u[0], V = R * C6.strides[0];
    for (let z = 0; z < p6.outHeight; ++z) {
      const X = V + z * C6.strides[1], P6 = z * p6.strideHeight - y6;
      for (let A6 = 0; A6 < f; ++A6) {
        const B6 = P6 + A6 * g6;
        if (B6 < 0 || B6 >= p6.inHeight)
          continue;
        const Z = A6 * d[0], H6 = M6 + B6 * u[1];
        for (let Y = 0; Y < p6.outWidth; ++Y) {
          const Q = X + Y * C6.strides[2], j = Y * p6.strideWidth - w6;
          for (let J6 = 0; J6 < m; ++J6) {
            const nt = j + J6 * b6;
            if (nt < 0 || nt >= p6.inWidth)
              continue;
            const q = Z + J6 * d[1], rt = H6 + nt * p6.inChannels;
            let ht = Q, ft2 = q;
            for (let pt = 0; pt < p6.inChannels; ++pt) {
              const wt2 = k7[rt + pt];
              for (let It = 0; It < I; ++It)
                N[ht + It] += wt2 * S[ft2 + It];
              ht += I, ft2 += I;
            }
          }
        }
      }
    }
  }
  return e.makeTensorInfo(C6.shape, C6.dtype, C6.values);
}
var hW = {
  kernelName: Ql,
  backendName: "cpu",
  kernelFunc: mw
};
function pW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, dilations: a, pad: l, dimRoundingMode: c, filterShape: u } = s;
  it([o, r], "depthwiseConv2dNativeBackpropFilter");
  const d = ke(
    o.shape,
    u,
    i6,
    a,
    l,
    c,
    true
    /* depthwise */
  ), { strideHeight: h6, strideWidth: p6, filterHeight: f, filterWidth: m } = d, g6 = new $e(d.filterShape, "float32"), b6 = d.padInfo.left, x6 = d.padInfo.top, w6 = d.outChannels / d.inChannels, y6 = e.data.get(o.dataId).values, I = new $e(o.shape, o.dtype, y6), C6 = e.data.get(r.dataId).values, k7 = new $e(r.shape, r.dtype, C6);
  for (let S = 0; S < f; ++S) {
    const N = Math.max(0, Math.ceil((x6 - S) / h6)), R = Math.min(d.outHeight, (d.inHeight + x6 - S) / h6);
    for (let M6 = 0; M6 < m; ++M6) {
      const V = Math.max(0, Math.ceil((b6 - M6) / p6)), z = Math.min(d.outWidth, (d.inWidth + b6 - M6) / p6);
      for (let X = 0; X < d.outChannels; ++X) {
        const P6 = Math.trunc(X / w6), A6 = X % w6;
        let B6 = 0;
        for (let Z = 0; Z < d.batchSize; ++Z)
          for (let H6 = N; H6 < R; ++H6) {
            const Y = S + H6 * h6 - x6;
            for (let Q = V; Q < z; ++Q) {
              const j = M6 + Q * p6 - b6;
              B6 += I.get(Z, Y, j, P6) * k7.get(Z, H6, Q, X);
            }
          }
        g6.set(B6, S, M6, P6, A6);
      }
    }
  }
  return e.makeTensorInfo(g6.shape, g6.dtype, g6.values);
}
var fW = {
  kernelName: rh,
  backendName: "cpu",
  kernelFunc: pW
};
function mW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { strides: i6, dilations: a, pad: l, dimRoundingMode: c, inputShape: u } = s;
  it([o, r], "depthwiseConv2DNativeBackpropInput");
  const d = dt(o.shape), h6 = dt(r.shape), p6 = ke(
    u,
    r.shape,
    i6,
    a,
    l,
    c,
    true
    /* depthwise */
  ), f = new $e(p6.inShape, "float32"), m = f.values, [g6, b6, x6] = f.strides, w6 = e.data.get(o.dataId).values, [y6, I, C6] = d, k7 = e.data.get(r.dataId).values, [S, N, R] = h6, { batchSize: M6, filterHeight: V, filterWidth: z, inChannels: X, inHeight: P6, inWidth: A6, outChannels: B6, outHeight: Z, outWidth: H6, strideHeight: Y, strideWidth: Q } = p6, j = V - 1 - p6.padInfo.top, J6 = z - 1 - p6.padInfo.left, nt = B6 / X;
  for (let q = 0; q < M6; ++q)
    for (let rt = 0; rt < X; ++rt)
      for (let ht = 0; ht < P6; ++ht) {
        const ft2 = ht - j, pt = Math.max(0, Math.ceil(ft2 / Y)), wt2 = Math.min(Z, (V + ft2) / Y);
        for (let It = 0; It < A6; ++It) {
          const Et = It - J6, Vt2 = Math.max(0, Math.ceil(Et / Q)), te = Math.min(H6, (z + Et) / Q);
          let zt = 0;
          for (let Wt2 = pt; Wt2 < wt2; ++Wt2) {
            const Qt = Wt2 * Y - ft2;
            for (let _t2 = Vt2; _t2 < te; ++_t2) {
              const as = _t2 * Q - Et, Ie = y6 * q + I * Wt2 + C6 * _t2, vs = S * (V - 1 - Qt) + N * (z - 1 - as) + R * rt;
              for (let on2 = 0; on2 < nt; ++on2) {
                const qs = rt * nt + on2, Ln2 = w6[Ie + qs], ls = k7[vs + on2];
                zt += Ln2 * ls;
              }
            }
          }
          m[g6 * q + b6 * ht + x6 * It + rt] = zt;
        }
      }
  return e.makeTensorInfo(f.shape, f.dtype, f.values);
}
var gW = {
  kernelName: ih,
  backendName: "cpu",
  kernelFunc: mW
};
function bW(n) {
  const { inputs: t, backend: e } = n, { x: s } = t, o = O(s.shape), r = e.data.get(s.dataId).values, i6 = vt([o, o], s.dtype), a = i6.values;
  for (let c = 0; c < r.length; c++)
    a[c * o + c] = r[c];
  const l = [...s.shape, ...s.shape];
  return e.makeTensorInfo(l, i6.dtype, i6.values);
}
var xW = {
  kernelName: Zg,
  backendName: "cpu",
  kernelFunc: bW
};
var yW = {
  kernelName: Jl,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, backend: t, attrs: e }) => {
    const { x: s, filter: o } = n, { strides: r, pad: i6, dilations: a } = e, l = t, c = l.data.get(s.dataId).values, u = s.shape.length, d = l.data.get(o.dataId).values, h6 = o.shape.length, { batchSize: p6, inHeight: f, inWidth: m, inChannels: g6, outHeight: b6, outWidth: x6, padInfo: w6, strideHeight: y6, strideWidth: I, filterHeight: C6, filterWidth: k7, dilationHeight: S, dilationWidth: N, outShape: R } = ca(s.shape, o.shape, r, i6, "NHWC", a), M6 = O(R), V = R.length, z = oe(s.dtype, M6);
    for (let P6 = 0; P6 < p6; ++P6)
      for (let A6 = 0; A6 < b6; ++A6) {
        const B6 = A6 * y6 - w6.top;
        for (let Z = 0; Z < x6; ++Z) {
          const H6 = Z * I - w6.left;
          for (let Y = 0; Y < g6; ++Y) {
            let Q = Number.MIN_SAFE_INTEGER;
            for (let J6 = 0; J6 < C6; ++J6) {
              const nt = B6 + J6 * S;
              if (nt >= 0 && nt < f)
                for (let q = 0; q < k7; ++q) {
                  const rt = H6 + q * N;
                  if (rt >= 0 && rt < m) {
                    const ht = zn([P6, nt, rt, Y], u, dt(s.shape)), ft2 = zn([J6, q, Y], h6, dt(o.shape)), pt = c[ht] + d[ft2];
                    pt > Q && (Q = pt);
                  }
                }
            }
            const j = zn([P6, A6, Z, Y], V, dt(R));
            z[j] = Q;
          }
        }
      }
    return { dataId: l.write(Zs(z, s.dtype), R, s.dtype), shape: R, dtype: s.dtype };
  }
};
var wW = {
  kernelName: nd,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, backend: t, attrs: e }) => {
    const { x: s, filter: o, dy: r } = n, { strides: i6, pad: a, dilations: l } = e, c = t, u = Sn(s.shape, c.data.get(s.dataId).values), d = Sn(o.shape, c.data.get(o.dataId).values), { batchSize: h6, inHeight: p6, inWidth: f, inChannels: m, outHeight: g6, outWidth: b6, padInfo: x6, strideHeight: w6, strideWidth: y6, filterHeight: I, filterWidth: C6, dilationHeight: k7, dilationWidth: S, outShape: N } = ca(s.shape, o.shape, i6, a, "NHWC", l);
    v2(r.rank === N.length, () => `Error in ${nd}, dy must have the same rank as output ${N.length}, but got ${r.rank}`);
    const R = Sn(N, c.data.get(r.dataId).values), M6 = Kd(o.shape, o.dtype);
    for (let z = 0; z < h6; ++z)
      for (let X = 0; X < g6; ++X) {
        const P6 = X * w6 - x6.top;
        for (let A6 = 0; A6 < b6; ++A6) {
          const B6 = A6 * y6 - x6.left;
          for (let Z = 0; Z < m; ++Z) {
            let H6 = Number.MIN_SAFE_INTEGER, Y = 0, Q = 0;
            for (let j = 0; j < I; ++j) {
              const J6 = P6 + j * k7;
              if (J6 >= 0 && J6 < p6)
                for (let nt = 0; nt < C6; ++nt) {
                  const q = B6 + nt * S;
                  if (q >= 0 && q < f) {
                    const rt = u[z][J6][q][Z] + d[j][nt][Z];
                    rt > H6 && (H6 = rt, Y = j, Q = nt);
                  }
                }
            }
            M6[Y][Q][Z] += R[z][X][A6][Z];
          }
        }
      }
    return { dataId: c.write(Zs(M6, s.dtype), o.shape, o.dtype), shape: o.shape, dtype: o.dtype };
  }
};
var IW = {
  kernelName: ed,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, backend: t, attrs: e }) => {
    const { x: s, filter: o, dy: r } = n, { strides: i6, pad: a, dilations: l } = e, c = t, u = Sn(s.shape, c.data.get(s.dataId).values), d = Sn(o.shape, c.data.get(o.dataId).values), { batchSize: h6, inHeight: p6, inWidth: f, inChannels: m, outHeight: g6, outWidth: b6, padInfo: x6, strideHeight: w6, strideWidth: y6, filterHeight: I, filterWidth: C6, dilationHeight: k7, dilationWidth: S, outShape: N } = ca(s.shape, o.shape, i6, a, "NHWC", l);
    v2(r.rank === N.length, () => `Error in ${ed}, dy must have the same rank as output ${N.length}, but got ${r.rank}`);
    const R = Sn(N, c.data.get(r.dataId).values), M6 = Kd(s.shape, s.dtype);
    for (let z = 0; z < h6; ++z)
      for (let X = 0; X < g6; ++X) {
        const P6 = X * w6 - x6.top;
        for (let A6 = 0; A6 < b6; ++A6) {
          const B6 = A6 * y6 - x6.left;
          for (let Z = 0; Z < m; ++Z) {
            let H6 = Number.MIN_SAFE_INTEGER, Y = P6 < 0 ? 0 : P6, Q = B6 < 0 ? 0 : B6;
            for (let j = 0; j < I; ++j) {
              const J6 = P6 + j * k7;
              if (J6 >= 0 && J6 < p6)
                for (let nt = 0; nt < C6; ++nt) {
                  const q = B6 + nt * S;
                  if (q >= 0 && q < f) {
                    const rt = u[z][J6][q][Z] + d[j][nt][Z];
                    rt > H6 && (H6 = rt, Y = J6, Q = q);
                  }
                }
            }
            M6[z][Y][Q][Z] += R[z][X][A6][Z];
          }
        }
      }
    return { dataId: c.write(Zs(M6, s.dtype), s.shape, s.dtype), shape: s.shape, dtype: s.dtype };
  }
};
function ka(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  it(o, "sum");
  let a;
  o.dtype === "bool" ? a = Ks({ inputs: { x: o }, backend: e, attrs: { dtype: "int32" } }) : a = rs({ inputs: { x: o }, backend: e });
  const l = a.shape.length, c = Ct(r, a.shape), u = qt(c, l);
  let d = c, h6 = a;
  u != null && (h6 = Ze({ inputs: { x: a }, backend: e, attrs: { perm: u } }), d = ie(d.length, l)), Te("sum", d, h6.shape.length);
  const [p6, f] = ye(h6.shape, d), m = je(h6.dtype, "int32");
  let g6 = Sl(e, p6, m);
  const b6 = O(f), x6 = e.data.get(g6.dataId).values, w6 = e.data.get(h6.dataId).values;
  for (let y6 = 0; y6 < x6.length; ++y6) {
    const I = y6 * b6;
    let C6 = 0;
    for (let k7 = 0; k7 < b6; ++k7)
      C6 += w6[I + k7];
    x6[y6] = C6;
  }
  if (i6) {
    const y6 = re(g6.shape, c), I = g6;
    g6 = Ot({ inputs: { x: g6 }, backend: e, attrs: { shape: y6 } }), e.disposeIntermediateTensorInfo(I);
  }
  return e.disposeIntermediateTensorInfo(a), u != null && e.disposeIntermediateTensorInfo(h6), g6;
}
var CW = {
  kernelName: Gc,
  backendName: "cpu",
  kernelFunc: ka
};
function vW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { equation: o } = s, r = t, { allDims: i6, summedDims: a, idDims: l } = Yp(o, r.length);
  Jp(i6.length, l, r);
  const { path: c, steps: u } = jp(a, l), d = u.length;
  let h6 = null, p6 = i6.length;
  const f = [];
  for (let m = 0; m < d; ++m) {
    for (const g6 of u[m]) {
      const { permutationIndices: b6, expandDims: x6 } = Qp(p6, l[g6]);
      let w6;
      qp(b6) ? w6 = r[g6] : (w6 = Ze({ inputs: { x: r[g6] }, backend: e, attrs: { perm: b6 } }), f.push(w6));
      const y6 = w6.shape.slice();
      for (let I = 0; I < x6.length; ++I)
        y6.splice(x6[I], 0, 1);
      Rt(w6.shape, y6) || (w6 = Ot({ inputs: { x: w6 }, backend: e, attrs: { shape: y6 } }), f.push(w6)), h6 === null ? h6 = w6 : (h6 = uu({ inputs: { a: w6, b: h6 }, backend: e }), f.push(h6));
    }
    m < d - 1 && (c[m] >= 0 && (h6 = ka({
      inputs: { x: h6 },
      backend: e,
      attrs: {
        axis: c[m] - (i6.length - p6),
        keepDims: false
      }
    }), f.push(h6)), p6--);
  }
  for (const m of f)
    m !== h6 && e.disposeIntermediateTensorInfo(m);
  return h6;
}
var SW = {
  kernelName: Bg,
  backendName: "cpu",
  kernelFunc: vW
};
function kW(n) {
  const { inputs: t, backend: e } = n, { dy: s, y: o } = t;
  it([s, o], "eluGrad");
  const r = new Float32Array(O(o.shape)), i6 = e.data.get(o.dataId).values, a = e.data.get(s.dataId).values;
  for (let l = 0; l < i6.length; ++l) {
    const c = i6[l];
    c >= 1 ? r[l] = a[l] : r[l] = a[l] * (c + 1);
  }
  return e.makeTensorInfo(o.shape, "float32", r);
}
var TW = {
  kernelName: ah,
  backendName: "cpu",
  kernelFunc: kW
};
var NW = Op;
var RW = Kp;
var $W = Zp;
var GW = Bp;
var EW = Hp;
var LW = _p;
var MW = Mt(ki, (n) => {
  const t = Math.sign(n), e = Math.abs(n), s = 1 / (1 + NW * e);
  return t * (1 - ((((LW * s + EW) * s + GW) * s + $W) * s + RW) * s * Math.exp(-e * e));
});
var WW = {
  kernelName: ki,
  backendName: "cpu",
  kernelFunc: MW
};
function Nl(n) {
  const { inputs: t, backend: e, attrs: s } = n, { input: o } = t, { dim: r } = s, i6 = o.shape.length, a = o.shape.slice();
  let l = r;
  return r < 0 && (v2(-(i6 + 1) <= r, () => `Axis must be in the interval [${-(i6 + 1)}, ${i6}]`), l = i6 + r + 1), a.splice(l, 0, 1), Ot({ inputs: { x: o }, backend: e, attrs: { shape: a } });
}
var DW = {
  kernelName: ql,
  backendName: "cpu",
  kernelFunc: Nl
};
var FW = ce((n, t) => n / t);
var Wf = we(vi, FW);
var Ed = {
  kernelName: vi,
  backendName: "cpu",
  kernelFunc: Wf
};
function gw(n, t, e) {
  const s = n.shape, o = s[0], r = s[1], i6 = e.data.get(n.dataId), a = i6.complexTensorInfos.real, l = i6.complexTensorInfos.imag, c = [o, r], u = O(c), d = xe("float32", u), h6 = xe("float32", u);
  for (let g6 = 0; g6 < o; g6++) {
    const b6 = Go({
      inputs: { x: a },
      backend: e,
      attrs: { begin: [g6, 0], size: [1, r] }
    }), x6 = Go({
      inputs: { x: l },
      backend: e,
      attrs: { begin: [g6, 0], size: [1, r] }
    }), w6 = Ye({ inputs: { real: b6, imag: x6 }, backend: e }), { real: y6, imag: I } = VW(w6, t, e), C6 = ms(y6, I);
    for (let k7 = 0; k7 < r; k7++) {
      const S = Up(C6, k7);
      d[g6 * r + k7] = S.real, h6[g6 * r + k7] = S.imag;
    }
    e.disposeIntermediateTensorInfo(b6), e.disposeIntermediateTensorInfo(x6), e.disposeIntermediateTensorInfo(w6);
  }
  const p6 = e.makeTensorInfo(c, "float32", d), f = e.makeTensorInfo(c, "float32", h6), m = Ye({ inputs: { real: p6, imag: f }, backend: e });
  return e.disposeIntermediateTensorInfo(p6), e.disposeIntermediateTensorInfo(f), m;
}
function VW(n, t, e) {
  const s = O(n.shape), o = e.data.get(n.dataId), r = e.data.get(o.complexTensorInfos.real.dataId).values, i6 = e.data.get(o.complexTensorInfos.imag.dataId).values;
  if (zW(s)) {
    const a = Ld(r, i6, s, t, e), l = [n.shape[0], n.shape[1]];
    if (t) {
      const c = e.makeTensorInfo(l, "float32", a.real), u = e.makeTensorInfo(l, "float32", a.imag), d = e.makeTensorInfo([], "float32", bs(s, "float32")), h6 = rs({ inputs: { x: d }, backend: e }), p6 = Ed.kernelFunc({ inputs: { a: c, b: d }, backend: e }), f = Ed.kernelFunc({ inputs: { a: u, b: h6 }, backend: e }), m = e.data.get(p6.dataId).values, g6 = e.data.get(f.dataId).values;
      return e.disposeIntermediateTensorInfo(c), e.disposeIntermediateTensorInfo(u), e.disposeIntermediateTensorInfo(d), e.disposeIntermediateTensorInfo(h6), e.disposeIntermediateTensorInfo(p6), e.disposeIntermediateTensorInfo(f), { real: m, imag: g6 };
    }
    return a;
  } else {
    const a = ms(r, i6), l = XW(a, s, t);
    return G0(l);
  }
}
function zW(n) {
  return (n & n - 1) === 0;
}
function Ld(n, t, e, s, o) {
  if (e === 1)
    return { real: n, imag: t };
  const r = ms(n, t), i6 = e / 2, a = E0(r), l = a.real, c = a.imag, u = [l.length], d = o.makeTensorInfo(u, "float32", l), h6 = o.makeTensorInfo(u, "float32", c), p6 = Ye({ inputs: { real: d, imag: h6 }, backend: o }), f = L0(r), m = f.real, g6 = f.imag, b6 = [m.length], x6 = o.makeTensorInfo(b6, "float32", m), w6 = o.makeTensorInfo(b6, "float32", g6), y6 = Ye({ inputs: { real: x6, imag: w6 }, backend: o }), I = Ld(l, c, i6, s, o), C6 = I.real, k7 = I.imag, S = [C6.length], N = o.makeTensorInfo(S, "float32", C6), R = o.makeTensorInfo(S, "float32", k7), M6 = Ye({
    inputs: { real: N, imag: R },
    backend: o
  }), V = Ld(m, g6, i6, s, o), z = V.real, X = V.imag, P6 = [z.length], A6 = o.makeTensorInfo(P6, "float32", z), B6 = o.makeTensorInfo(P6, "float32", X), Z = Ye({ inputs: { real: A6, imag: B6 }, backend: o }), H6 = W0(e, s), Y = [H6.real.length], Q = o.makeTensorInfo(Y, "float32", H6.real), j = o.makeTensorInfo(Y, "float32", H6.imag), J6 = Ye({ inputs: { real: Q, imag: j }, backend: o }), nt = uu({ inputs: { a: J6, b: Z }, backend: o }), q = cr({
    inputs: { a: M6, b: nt },
    backend: o
  }), rt = Lf({
    inputs: { a: M6, b: nt },
    backend: o
  }), ht = $o({ inputs: { input: q }, backend: o }), ft2 = $o({ inputs: { input: rt }, backend: o }), pt = ur({ inputs: { input: q }, backend: o }), wt2 = ur({ inputs: { input: rt }, backend: o }), It = dr({
    inputs: [ht, ft2],
    backend: o,
    attrs: { axis: 0 }
  }), Et = dr({
    inputs: [pt, wt2],
    backend: o,
    attrs: { axis: 0 }
  }), Vt2 = o.data.get(It.dataId).values, te = o.data.get(Et.dataId).values;
  return o.disposeIntermediateTensorInfo(d), o.disposeIntermediateTensorInfo(h6), o.disposeIntermediateTensorInfo(p6), o.disposeIntermediateTensorInfo(x6), o.disposeIntermediateTensorInfo(w6), o.disposeIntermediateTensorInfo(y6), o.disposeIntermediateTensorInfo(N), o.disposeIntermediateTensorInfo(R), o.disposeIntermediateTensorInfo(M6), o.disposeIntermediateTensorInfo(A6), o.disposeIntermediateTensorInfo(B6), o.disposeIntermediateTensorInfo(Z), o.disposeIntermediateTensorInfo(Q), o.disposeIntermediateTensorInfo(j), o.disposeIntermediateTensorInfo(J6), o.disposeIntermediateTensorInfo(nt), o.disposeIntermediateTensorInfo(q), o.disposeIntermediateTensorInfo(rt), o.disposeIntermediateTensorInfo(ht), o.disposeIntermediateTensorInfo(pt), o.disposeIntermediateTensorInfo(ft2), o.disposeIntermediateTensorInfo(wt2), o.disposeIntermediateTensorInfo(It), o.disposeIntermediateTensorInfo(Et), { real: Vt2, imag: te };
}
function XW(n, t, e) {
  const s = new Float32Array(t * 2);
  for (let o = 0; o < t; o++) {
    let r = 0, i6 = 0;
    for (let a = 0; a < t; a++) {
      const l = D0(o * a, t, e), c = Up(n, a);
      r += c.real * l.real - c.imag * l.imag, i6 += c.real * l.imag + c.imag * l.real;
    }
    e && (r /= t, i6 /= t), M0(s, r, i6, o);
  }
  return s;
}
function PW(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = O(s.shape), r = s.shape[s.shape.length - 1], i6 = o / r, a = Ot({
    inputs: { x: s },
    backend: e,
    attrs: { shape: [i6, r] }
  }), l = gw(a, false, e), c = Ot({ inputs: { x: l }, backend: e, attrs: { shape: s.shape } });
  return e.disposeIntermediateTensorInfo(a), e.disposeIntermediateTensorInfo(l), c;
}
var AW = {
  kernelName: lh,
  backendName: "cpu",
  kernelFunc: PW
};
function Df(n) {
  const { backend: t, attrs: e } = n, { shape: s, value: o, dtype: r } = e, i6 = r || gr(o), a = oe(i6, O(s));
  return KW(a, o, i6), t.makeTensorInfo(s, i6, a);
}
var OW = {
  kernelName: ch,
  backendName: "cpu",
  kernelFunc: Df
};
function KW(n, t, e) {
  n.fill(t);
}
var ZW = {
  kernelName: uh,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { image: s } = n, o = e, r = xe(s.dtype, O(s.shape)), [i6, a, l, c] = s.shape, u = o.data.get(s.dataId).values;
    for (let h6 = 0; h6 < i6; h6++) {
      const p6 = h6 * l * a * c;
      for (let f = 0; f < a; f++) {
        const m = f * (l * c);
        for (let g6 = 0; g6 < l; g6++) {
          const b6 = g6 * c;
          for (let x6 = 0; x6 < c; x6++) {
            const w6 = Math.round(l - g6 - 1), y6 = p6 + m + b6 + x6;
            let I = u[y6];
            if (w6 >= 0 && w6 < l) {
              const C6 = w6 * c, k7 = p6 + m + C6 + x6;
              I = u[k7];
            }
            r[y6] = I;
          }
        }
      }
    }
    return { dataId: o.write(r, s.shape, s.dtype), shape: s.shape, dtype: s.dtype };
  }
};
var BW = ce((n, t) => Math.floor(n / t));
var HW = we($i, BW, null, "int32");
var _W = {
  kernelName: $i,
  backendName: "cpu",
  kernelFunc: HW
};
function UW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r, bias: i6, preluActivationWeights: a } = t, { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h6, activation: p6, leakyreluAlpha: f } = s;
  let m = fw({
    inputs: { x: o, filter: r },
    backend: e,
    attrs: { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h6 }
  });
  if (i6) {
    const g6 = m;
    if (u === "NCHW" && i6.shape.length === 1 && i6.shape[0] !== 1) {
      const b6 = Ot({ inputs: { x: i6 }, backend: e, attrs: { shape: [i6.shape[0], 1, 1] } });
      m = cr({ inputs: { a: m, b: b6 }, backend: e }), e.disposeIntermediateTensorInfo(b6);
    } else
      m = cr({ inputs: { a: m, b: i6 }, backend: e });
    e.disposeIntermediateTensorInfo(g6);
  }
  if (p6) {
    const g6 = m;
    if (u === "NCHW" && p6 === "prelu" && a.shape.length === 1 && a.shape[0] !== 1) {
      const b6 = Ot({
        inputs: { x: a },
        backend: e,
        attrs: { shape: [a.shape[0], 1, 1] }
      });
      m = Tl(e, m, p6, b6, f), e.disposeIntermediateTensorInfo(b6);
    } else
      m = Tl(e, m, p6, a, f);
    e.disposeIntermediateTensorInfo(g6);
  }
  return m;
}
var YW = {
  kernelName: rl,
  backendName: "cpu",
  kernelFunc: UW
};
function QW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r, bias: i6, preluActivationWeights: a } = t, { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h6, activation: p6, leakyreluAlpha: f } = s;
  let m = mw({
    inputs: { x: o, filter: r },
    backend: e,
    attrs: { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h6 }
  });
  if (i6) {
    const g6 = m;
    m = cr({ inputs: { a: m, b: i6 }, backend: e }), e.disposeIntermediateTensorInfo(g6);
  }
  if (p6) {
    const g6 = m;
    m = Tl(e, m, p6, a, f), e.disposeIntermediateTensorInfo(g6);
  }
  return m;
}
var JW = {
  kernelName: nb,
  backendName: "cpu",
  kernelFunc: QW
};
function jW(n) {
  const { inputs: t, backend: e } = n, { params: s, indices: o } = t, r = O(s.shape), i6 = o.shape, a = i6[i6.length - 1], [l, c, u, d] = Bc(s, o);
  if (c === 0)
    return e.makeTensorInfo(l, s.dtype, []);
  const h6 = e.data.get(o.dataId).values, p6 = e.bufferSync(s), f = N1(h6, p6, s.dtype, c, a, u, d, s.shape, r);
  return e.makeTensorInfo(l, s.dtype, f.values);
}
var qW = {
  kernelName: Hg,
  backendName: "cpu",
  kernelFunc: jW
};
function tD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, indices: r } = t, { axis: i6, batchDims: a } = s;
  it([o, r], "gatherV2");
  const l = Ct(i6, o.shape)[0], c = e.data.get(r.dataId).values, u = o.shape[l];
  for (let y6 = 0; y6 < c.length; ++y6) {
    const I = c[y6];
    v2(I <= u - 1 && I >= 0, () => `GatherV2: the index value ${I} is not in [0, ${u - 1}]`);
  }
  let d = a;
  a == null && (d = 0);
  const h6 = O(r.shape), p6 = ef(o, r, l, d), f = Ot({
    inputs: { x: o },
    backend: e,
    attrs: {
      shape: [
        p6.batchSize,
        p6.outerSize,
        p6.dimSize,
        p6.sliceSize
      ]
    }
  }), m = Ot({
    inputs: { x: r },
    backend: e,
    attrs: { shape: [p6.batchSize, h6 / p6.batchSize] }
  }), g6 = [
    p6.batchSize,
    p6.outerSize,
    h6 / p6.batchSize,
    p6.sliceSize
  ], b6 = e.bufferSync(m), x6 = e.bufferSync(f), w6 = R1(x6, b6, g6);
  return e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(m), e.makeTensorInfo(p6.outputShape, w6.dtype, w6.values);
}
var eD = {
  kernelName: ec,
  backendName: "cpu",
  kernelFunc: tD
};
function nD(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = O(s.shape), r = s.shape[s.shape.length - 1], i6 = o / r, a = Ot({
    inputs: { x: s },
    backend: e,
    attrs: { shape: [i6, r] }
  }), l = gw(a, true, e), c = Ot({ inputs: { x: l }, backend: e, attrs: { shape: s.shape } });
  return e.disposeIntermediateTensorInfo(a), e.disposeIntermediateTensorInfo(l), c;
}
var sD = {
  kernelName: dh,
  backendName: "cpu",
  kernelFunc: nD
};
var oD = Mt(Li, (n) => Number.isFinite(n) ? 1 : 0, "bool");
var rD = {
  kernelName: Li,
  backendName: "cpu",
  kernelFunc: oD
};
var iD = Mt(Mi, (n) => Math.abs(n) === 1 / 0 ? 1 : 0, "bool");
var aD = {
  kernelName: Mi,
  backendName: "cpu",
  kernelFunc: iD
};
var lD = Mt(Wi, (n) => Number.isNaN(n) ? 1 : 0, "bool");
var cD = {
  kernelName: Wi,
  backendName: "cpu",
  kernelFunc: lD
};
function uD(n) {
  const { backend: t, attrs: e } = n, { start: s, stop: o, num: r } = e, i6 = M1(s, o, r);
  return t.makeTensorInfo([i6.length], "float32", i6);
}
var dD = {
  kernelName: _g,
  backendName: "cpu",
  kernelFunc: uD
};
var hD = Mt(Fi, (n) => Math.log1p(n));
var pD = {
  kernelName: Fi,
  backendName: "cpu",
  kernelFunc: hD
};
var fD = ce((n, t) => n && t);
var mD = we(ic, fD, null, "bool");
var gD = {
  kernelName: ic,
  backendName: "cpu",
  kernelFunc: mD
};
var bD = Mt(ac, (n) => n ? 0 : 1, "bool");
var xD = {
  kernelName: ac,
  backendName: "cpu",
  kernelFunc: bD
};
var yD = ce((n, t) => n || t);
var wD = we(lc, yD, null, "bool");
var ID = {
  kernelName: lc,
  backendName: "cpu",
  kernelFunc: wD
};
function CD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { depthRadius: r, bias: i6, alpha: a, beta: l } = s;
  it(o, "LRN");
  const c = o.shape[3], u = c - 1, d = e.data.get(o.dataId).values, h6 = O(o.shape), p6 = new Float32Array(h6);
  function f(m) {
    const g6 = m % c;
    let b6 = m - g6 + Math.max(0, g6 - r);
    const x6 = m - g6 + Math.min(g6 + r, u);
    let w6 = 0;
    for (; b6 <= x6; b6++) {
      const y6 = d[b6];
      w6 += y6 * y6;
    }
    return w6;
  }
  for (let m = 0; m < h6; m++) {
    const g6 = f(m), b6 = d[m] * Math.pow(i6 + a * g6, -l);
    p6[m] = b6;
  }
  return e.makeTensorInfo(o.shape, o.dtype, p6);
}
var vD = {
  kernelName: cc,
  backendName: "cpu",
  kernelFunc: CD
};
function SD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, y: r, dy: i6 } = t, { depthRadius: a, bias: l, alpha: c, beta: u } = s;
  it(i6, "LRNGrad");
  const d = O(i6.shape), h6 = i6.shape[3], p6 = e.data.get(i6.dataId).values, f = e.data.get(o.dataId).values, m = e.data.get(r.dataId).values, g6 = new Float32Array(d), b6 = d;
  for (let x6 = 0; x6 < b6; x6++) {
    const w6 = x6 % h6, y6 = x6 - w6 + Math.max(0, w6 - a), I = x6 - w6 + Math.min(h6, w6 + a + 1);
    let C6 = 0;
    for (let k7 = y6; k7 < I; k7++)
      C6 += Math.pow(f[k7], 2);
    C6 = c * C6 + l;
    for (let k7 = y6; k7 < I; k7++) {
      let S = -2 * c * u * f[k7] * m[x6] / C6;
      x6 === k7 && (S += Math.pow(C6, -u)), S *= p6[x6], g6[k7] += S;
    }
  }
  return e.makeTensorInfo(i6.shape, o.dtype, g6);
}
var kD = {
  kernelName: ph,
  backendName: "cpu",
  kernelFunc: SD
};
function bw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { reductionIndices: r, keepDims: i6 } = s, a = e;
  let l = o.shape;
  const c = l.length, u = Ct(r, l);
  let d = u;
  const h6 = qt(d, c);
  let p6 = a.data.get(o.dataId).values;
  if (h6 != null) {
    const y6 = new Array(c);
    for (let I = 0; I < y6.length; I++)
      y6[I] = l[h6[I]];
    p6 = Gf(p6, l, o.dtype, h6, y6), d = ie(d.length, c), l = y6;
  }
  it(o, "max"), Te("max", d, c);
  const [f, m] = ye(l, d), g6 = O(m), b6 = D1(p6, g6, f, o.dtype), x6 = a.write(b6, f, o.dtype);
  let w6 = f;
  return i6 && (w6 = re(f, u)), { dataId: x6, shape: w6, dtype: o.dtype };
}
var TD = {
  kernelName: uc,
  backendName: "cpu",
  kernelFunc: bw
};
function ND(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  it(o, "maxPool");
  const { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = s, c = 1;
  v2(Ee(i6, c), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${i6} and dilations '${c}'`);
  const u = $n(o.shape, r, i6, c, a, l);
  let d;
  if (u.filterWidth === 1 && u.filterHeight === 1 && Rt(u.inShape, u.outShape))
    d = rs({ inputs: { x: o }, backend: e });
  else {
    const h6 = e.data.get(o.dataId).values, p6 = dt(o.shape), f = Mf(h6, o.shape, o.dtype, p6, u, "max");
    d = e.makeTensorInfo(u.outShape, o.dtype, f.values);
  }
  return d;
}
var RD = {
  kernelName: dc,
  backendName: "cpu",
  kernelFunc: ND
};
function $D(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { filterSize: r, strides: i6, pad: a, dimRoundingMode: l, dataFormat: c } = s;
  it(o, "maxPool3d");
  const u = xs(o.shape, r, i6, 1, a, l, c), d = e.data.get(o.dataId).values, h6 = pw(d, o.shape, o.dtype, dt(o.shape), u, "max");
  return e.makeTensorInfo(h6.shape, "float32", h6.values);
}
var GD = {
  kernelName: hc,
  backendName: "cpu",
  kernelFunc: $D
};
function ED(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, { filterSize: i6, strides: a, pad: l, dimRoundingMode: c } = s;
  it([o, r], "maxPool3DGrad");
  const u = xs(r.shape, i6, a, 1, l, c), d = e.bufferSync(r), h6 = xM(d, u), p6 = u.strideDepth, f = u.strideHeight, m = u.strideWidth, g6 = u.dilationDepth, b6 = u.dilationHeight, x6 = u.dilationWidth, w6 = u.effectiveFilterDepth, y6 = u.effectiveFilterHeight, I = u.effectiveFilterWidth, C6 = w6 - 1 - u.padInfo.front, k7 = I - 1 - u.padInfo.left, S = y6 - 1 - u.padInfo.top, N = vt(r.shape, "float32"), R = e.bufferSync(o);
  for (let M6 = 0; M6 < u.batchSize; ++M6)
    for (let V = 0; V < u.inChannels; ++V)
      for (let z = 0; z < u.inDepth; ++z)
        for (let X = 0; X < u.inHeight; ++X)
          for (let P6 = 0; P6 < u.inWidth; ++P6) {
            const A6 = z - C6, B6 = X - S, Z = P6 - k7;
            let H6 = 0;
            for (let Y = 0; Y < w6; Y += g6) {
              const Q = (A6 + Y) / p6;
              if (!(Q < 0 || Q >= u.outDepth || Math.floor(Q) !== Q))
                for (let j = 0; j < y6; j += b6) {
                  const J6 = (B6 + j) / f;
                  if (!(J6 < 0 || J6 >= u.outHeight || Math.floor(J6) !== J6))
                    for (let nt = 0; nt < I; nt += x6) {
                      const q = (Z + nt) / m;
                      if (q < 0 || q >= u.outWidth || Math.floor(q) !== q)
                        continue;
                      const rt = w6 * y6 * I - 1 - h6.get(M6, Q, J6, q, V), ht = Y * y6 * I + j * I + nt, ft2 = rt === ht ? 1 : 0;
                      if (ft2 === 0)
                        continue;
                      const pt = R.get(M6, Q, J6, q, V);
                      H6 += pt * ft2;
                    }
                }
            }
            N.set(H6, M6, z, X, P6, V);
          }
  return e.makeTensorInfo(N.shape, N.dtype, N.values);
}
var LD = {
  kernelName: mh,
  backendName: "cpu",
  kernelFunc: ED
};
function MD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r, output: i6 } = t, a = r;
  it([r, i6], "maxPoolGrad");
  const { filterSize: l, strides: c, pad: u, dimRoundingMode: d } = s, h6 = $n(a.shape, l, c, 1, u, d), p6 = e.data.get(a.dataId).values, f = vt(h6.outShape, a.dtype, hw(p6, a.shape, a.dtype, h6).values), m = h6.strideHeight, g6 = h6.strideWidth, b6 = h6.dilationHeight, x6 = h6.dilationWidth, w6 = h6.effectiveFilterHeight, y6 = h6.effectiveFilterWidth, I = y6 - 1 - h6.padInfo.left, C6 = w6 - 1 - h6.padInfo.top, k7 = vt(a.shape, "float32"), S = e.data.get(o.dataId).values, N = vt(o.shape, "float32", S);
  for (let R = 0; R < h6.batchSize; ++R)
    for (let M6 = 0; M6 < h6.inChannels; ++M6)
      for (let V = 0; V < h6.inHeight; ++V)
        for (let z = 0; z < h6.inWidth; ++z) {
          const X = V - C6, P6 = z - I;
          let A6 = 0;
          for (let B6 = 0; B6 < w6; B6 += b6) {
            const Z = (X + B6) / m;
            if (!(Z < 0 || Z >= h6.outHeight || Math.floor(Z) !== Z))
              for (let H6 = 0; H6 < y6; H6 += x6) {
                const Y = (P6 + H6) / g6;
                if (Y < 0 || Y >= h6.outWidth || Math.floor(Y) !== Y)
                  continue;
                const Q = w6 * y6 - 1 - f.get(R, Z, Y, M6), j = B6 * y6 + H6, J6 = Q === j ? 1 : 0;
                if (J6 === 0)
                  continue;
                const nt = N.get(R, Z, Y, M6);
                A6 += nt * J6;
              }
          }
          k7.set(A6, R, V, z, M6);
        }
  return e.makeTensorInfo(k7.shape, k7.dtype, k7.values);
}
var WD = {
  kernelName: fh,
  backendName: "cpu",
  kernelFunc: MD
};
function DD(n, t, e, s, o) {
  const r = dt(t), i6 = Mf(n, t, e, r, o, "max"), a = hw(n, t, e, o, true, s);
  return [i6.values, a.values];
}
var FD = {
  kernelName: Ug,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { x: s } = n, { filterSize: o, strides: r, pad: i6, includeBatchInIndex: a } = t, l = e;
    it(s, "MaxPoolWithArgmax");
    const c = l.data.get(s.dataId).values, u = $n(s.shape, o, r, [1, 1], i6), [d, h6] = DD(c, s.shape, s.dtype, a, u), p6 = l.write(d, u.outShape, s.dtype), f = l.write(h6, u.outShape, s.dtype);
    return [
      { dataId: p6, shape: u.outShape, dtype: s.dtype },
      { dataId: f, shape: u.outShape, dtype: "int32" }
    ];
  }
};
function VD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = Ct(r, o.shape), c = ye(o.shape, a)[1], u = O(c), d = [], h6 = e.makeTensorInfo([], "float32", new Float32Array([u]));
  d.push(h6);
  const p6 = Ks({ inputs: { x: o }, backend: e, attrs: { dtype: "float32" } });
  d.push(p6);
  const f = Wf({ inputs: { a: p6, b: h6 }, backend: e });
  d.push(f);
  const m = ka({ inputs: { x: f }, backend: e, attrs: { axis: r, keepDims: i6 } });
  return d.forEach((g6) => e.disposeIntermediateTensorInfo(g6)), m;
}
var zD = {
  kernelName: pc,
  backendName: "cpu",
  kernelFunc: VD
};
function XD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  it(o, "min");
  const a = Ct(r, o.shape);
  let l = a;
  const c = qt(l, o.shape.length);
  let u = o;
  c != null && (u = Ze({ inputs: { x: o }, backend: e, attrs: { perm: c } }), l = ie(l.length, o.shape.length)), Te("min", l, u.shape.length);
  const [d, h6] = ye(u.shape, l), p6 = O(h6), f = Se(O(d), u.dtype), m = e.data.get(u.dataId).values;
  for (let b6 = 0; b6 < f.length; ++b6) {
    const x6 = b6 * p6;
    let w6 = m[x6];
    for (let y6 = 0; y6 < p6; ++y6) {
      const I = m[x6 + y6];
      (Number.isNaN(I) || I < w6) && (w6 = I);
    }
    f[b6] = w6;
  }
  c != null && e.disposeIntermediateTensorInfo(u);
  const g6 = e.makeTensorInfo(d, u.dtype, f);
  if (i6) {
    const b6 = re(d, a), x6 = Ot({ inputs: { x: g6 }, backend: e, attrs: { shape: b6 } });
    return e.disposeIntermediateTensorInfo(g6), x6;
  }
  return g6;
}
var PD = {
  kernelName: fc,
  backendName: "cpu",
  kernelFunc: XD
};
function AD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { paddings: r, mode: i6 } = s;
  it(o, "mirrorPad");
  const a = r.map(
    (w6, y6) => w6[0] + o.shape[y6] + w6[1]
    /* afterPad */
  ), l = r.map((w6) => w6[0]), c = r.map((w6, y6) => w6[0] + o.shape[y6]), u = i6 === "reflect" ? 0 : 1, d = e.data.get(o.dataId).values, h6 = o.shape.length, p6 = dt(o.shape), f = O(a), m = a.length, g6 = dt(a), b6 = xe(o.dtype, f);
  for (let w6 = 0; w6 < f; w6++) {
    let y6 = Mo(w6, m, g6);
    for (let C6 = 0; C6 < m; C6++)
      y6[C6] < l[C6] ? y6[C6] = l[C6] * 2 - y6[C6] - u : y6[C6] >= c[C6] && (y6[C6] = (c[C6] - 1) * 2 - y6[C6] + u);
    y6 = y6.map((C6, k7) => C6 - l[k7]);
    const I = zn(y6, h6, p6);
    b6[w6] = d[I];
  }
  return { dataId: e.write(b6, a, o.dtype), shape: a, dtype: o.dtype };
}
var OD = {
  kernelName: mc,
  backendName: "cpu",
  kernelFunc: AD
};
var KD = ce((n, t) => {
  const e = n % t;
  return n < 0 && t < 0 || n >= 0 && t >= 0 ? e : (e + t) % t;
});
var ZD = we(Xi, KD);
var BD = {
  kernelName: Xi,
  backendName: "cpu",
  kernelFunc: ZD
};
function xw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { logits: o } = t, { dim: r } = s, i6 = o.shape.length;
  let a = r;
  if (a === -1 && (a = i6 - 1), a !== i6 - 1)
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${i6} and dim was ${a}`);
  const l = Ct([a], o.shape), c = bw({
    inputs: { x: o },
    backend: e,
    attrs: { reductionIndices: l, keepDims: false }
  }), u = re(c.shape, l), d = Ot({ inputs: { x: c }, backend: e, attrs: { shape: u } }), h6 = Lf({ inputs: { a: o, b: d }, backend: e }), p6 = S1({ inputs: { x: h6 }, backend: e }), f = ka({ inputs: { x: p6 }, backend: e, attrs: { axis: l, keepDims: false } }), m = Ot({ inputs: { x: f }, backend: e, attrs: { shape: u } }), g6 = Wf({ inputs: { a: p6, b: m }, backend: e });
  return e.disposeIntermediateTensorInfo(c), e.disposeIntermediateTensorInfo(d), e.disposeIntermediateTensorInfo(h6), e.disposeIntermediateTensorInfo(p6), e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(m), g6;
}
var HD = {
  kernelName: Mc,
  backendName: "cpu",
  kernelFunc: xw
};
function _D(n) {
  const { inputs: t, backend: e, attrs: s } = n, { logits: o } = t, { numSamples: r, seed: i6, normalized: a } = s;
  it(o, "multinomial");
  const l = a ? o : xw({ inputs: { logits: o }, backend: e, attrs: { dim: -1 } }), c = l.shape[0], u = l.shape[1], d = e.data.get(l.dataId).values, h6 = [c, r], p6 = Se(O(h6), "int32");
  for (let f = 0; f < c; ++f) {
    const m = f * u, g6 = new Float32Array(u - 1);
    g6[0] = d[m];
    for (let w6 = 1; w6 < g6.length; ++w6)
      g6[w6] = g6[w6 - 1] + d[m + w6];
    const b6 = wr.alea(i6.toString()), x6 = f * r;
    for (let w6 = 0; w6 < r; ++w6) {
      const y6 = b6();
      p6[x6 + w6] = g6.length;
      for (let I = 0; I < g6.length; I++)
        if (y6 < g6[I]) {
          p6[x6 + w6] = I;
          break;
        }
    }
  }
  return a || e.disposeIntermediateTensorInfo(l), e.makeTensorInfo(h6, "int32", p6);
}
var UD = {
  kernelName: Yg,
  backendName: "cpu",
  kernelFunc: _D
};
var YD = Tp;
function QD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l } = s;
  it(o, "NonMaxSuppression");
  const c = e.data.get(o.dataId).values, u = e.data.get(r.dataId).values, { selectedIndices: d } = YD(c, u, i6, a, l);
  return e.makeTensorInfo([d.length], "int32", new Int32Array(d));
}
var JD = {
  kernelName: gh,
  backendName: "cpu",
  kernelFunc: QD
};
var jD = Np;
function qD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l, padToMaxOutputSize: c } = s;
  it(o, "NonMaxSuppressionPadded");
  const u = e.data.get(o.dataId).values, d = e.data.get(r.dataId).values, { selectedIndices: h6, validOutputs: p6 } = jD(u, d, i6, a, l, c);
  return [
    e.makeTensorInfo([h6.length], "int32", new Int32Array(h6)),
    e.makeTensorInfo([], "int32", new Int32Array([p6]))
  ];
}
var tF = {
  kernelName: bh,
  backendName: "cpu",
  kernelFunc: qD
};
var eF = Rp;
function nF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l, softNmsSigma: c } = s;
  it(o, "NonMaxSuppressionWithScore");
  const u = e.data.get(o.dataId).values, d = e.data.get(r.dataId).values, h6 = i6, p6 = a, f = l, m = c, { selectedIndices: g6, selectedScores: b6 } = eF(u, d, h6, p6, f, m);
  return [
    e.makeTensorInfo([g6.length], "int32", new Int32Array(g6)),
    e.makeTensorInfo([b6.length], "float32", new Float32Array(b6))
  ];
}
var sF = {
  kernelName: xh,
  backendName: "cpu",
  kernelFunc: nF
};
function oF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { indices: o } = t, { dtype: r, depth: i6, onValue: a, offValue: l } = s;
  it(o, "oneHot");
  const c = O(o.shape), u = new Float32Array(c * i6);
  u.fill(l);
  const d = e.data.get(o.dataId).values;
  for (let h6 = 0; h6 < c; ++h6)
    d[h6] >= 0 && d[h6] < i6 && (u[h6 * i6 + d[h6]] = a);
  return e.makeTensorInfo([...o.shape, i6], r, u);
}
var rF = {
  kernelName: yc,
  backendName: "cpu",
  kernelFunc: oF
};
function Rl(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (s.dtype === "string")
    throw new Error("zerosLike is not supported for string tensors");
  if (s.dtype === "complex64") {
    const o = $o({ inputs: { input: s }, backend: e }), r = Rl({ inputs: { x: o }, backend: e }), i6 = ur({ inputs: { input: s }, backend: e }), a = Rl({ inputs: { x: i6 }, backend: e }), l = Ye({ inputs: { real: r, imag: a }, backend: e });
    return e.disposeIntermediateTensorInfo(o), e.disposeIntermediateTensorInfo(r), e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(a), l;
  } else
    return Df({ backend: e, attrs: { shape: s.shape, value: 0, dtype: s.dtype } });
}
var iF = {
  kernelName: Fc,
  backendName: "cpu",
  kernelFunc: Rl
};
function yw(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (s.dtype === "string")
    throw new Error("onesLike is not supported for string tensors");
  if (s.dtype === "complex64") {
    const o = $o({ inputs: { input: s }, backend: e }), r = yw({ inputs: { x: o }, backend: e }), i6 = ur({ inputs: { input: s }, backend: e }), a = Rl({ inputs: { x: i6 }, backend: e }), l = Ye({ inputs: { real: r, imag: a }, backend: e });
    return e.disposeIntermediateTensorInfo(o), e.disposeIntermediateTensorInfo(r), e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(a), l;
  } else
    return Df({ backend: e, attrs: { shape: s.shape, value: 1, dtype: s.dtype } });
}
var aF = {
  kernelName: xc,
  backendName: "cpu",
  kernelFunc: yw
};
function ww(n) {
  const { inputs: t, backend: e, attrs: s } = n, { axis: o } = s;
  if (t.length === 1)
    return Nl({ inputs: { input: t[0] }, backend: e, attrs: { dim: o } });
  const r = t[0].shape, i6 = t[0].dtype;
  t.forEach((u) => {
    Ve(r, u.shape, "All tensors passed to stack must have matching shapes"), v2(i6 === u.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const a = [], l = t.map((u) => {
    const d = Nl({ inputs: { input: u }, backend: e, attrs: { dim: o } });
    return a.push(d), d;
  }), c = dr({ inputs: l, backend: e, attrs: { axis: o } });
  return a.forEach((u) => e.disposeIntermediateTensorInfo(u)), c;
}
var lF = {
  kernelName: wc,
  backendName: "cpu",
  kernelFunc: ww
};
function cF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { paddings: r, constantValue: i6 } = s;
  it(o, "pad");
  const a = r.map(
    (x6, w6) => x6[0] + o.shape[w6] + x6[1]
    /* afterPad */
  ), l = r.map((x6) => x6[0]), c = e.data.get(o.dataId).values, u = O(o.shape), d = o.shape.length, h6 = dt(o.shape), p6 = O(a), f = a.length, m = dt(a), g6 = xe(o.dtype, p6);
  i6 !== 0 && g6.fill(i6);
  for (let x6 = 0; x6 < u; x6++) {
    const y6 = Mo(x6, d, h6).map((C6, k7) => C6 + l[k7]), I = zn(y6, f, m);
    g6[I] = c[x6];
  }
  return { dataId: e.write(g6, a, o.dtype), shape: a, dtype: o.dtype };
}
var Iw = {
  kernelName: Ic,
  backendName: "cpu",
  kernelFunc: cF
};
var uF = ce((n, t) => Math.pow(n, t));
var dF = we(Ai, uF);
var hF = {
  kernelName: Ai,
  backendName: "cpu",
  kernelFunc: dF
};
function pF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { paramsNestedSplits: o, paramsDenseValues: r, indices: i6 } = t, a = o.map((g6) => e.data.get(g6.dataId).values), l = o.map((g6) => g6.shape), c = e.data.get(r.dataId).values, u = e.data.get(i6.dataId).values, [d, h6, p6] = A1(a, l, c, r.shape, r.dtype, u, i6.shape), f = d.map((g6) => e.makeTensorInfo([g6.length], "int32", g6)), m = e.makeTensorInfo(p6, r.dtype, h6);
  return f.concat([m]);
}
var fF = {
  kernelName: Qg,
  backendName: "cpu",
  kernelFunc: pF
};
function mF(n) {
  const { inputs: t, backend: e } = n, { starts: s, limits: o, deltas: r } = t, i6 = e.data.get(s.dataId).values, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, [c, u] = O1(i6, s.shape, s.dtype, a, o.shape, l, r.shape), d = e.makeTensorInfo([c.length], "int32", c), h6 = e.makeTensorInfo([u.length], s.dtype, u);
  return [d, h6];
}
var gF = {
  kernelName: Jg,
  backendName: "cpu",
  kernelFunc: mF
};
function bF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { shape: o, values: r, defaultValue: i6, rowPartitionTensors: a } = t, { rowPartitionTypes: l } = s, c = e.data.get(o.dataId).values, u = e.data.get(r.dataId).values, d = e.data.get(i6.dataId).values, h6 = a.map((g6) => e.data.get(g6.dataId).values), p6 = a.map((g6) => g6.shape), [f, m] = K1(c, o.shape, u, r.shape, r.dtype, d, i6.shape, h6, p6, l);
  return e.makeTensorInfo(f, r.dtype, m);
}
var xF = {
  kernelName: jg,
  backendName: "cpu",
  kernelFunc: bF
};
function yF(n) {
  const { backend: t, attrs: e } = n, { start: s, stop: o, dtype: r, step: i6 } = e, a = Z1(s, o, i6, r);
  return t.makeTensorInfo([a.length], r, a);
}
var wF = {
  kernelName: yh,
  backendName: "cpu",
  kernelFunc: yF
};
var IF = Mt(Oi, (n) => 1 / n);
var CF = {
  kernelName: Oi,
  backendName: "cpu",
  kernelFunc: IF
};
function vF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o } = t, { alignCorners: r, halfPixelCenters: i6, size: a } = s;
  it(o, "resizeBilinear");
  const l = dt(o.shape), [c, u] = a, [d, h6, p6, f] = o.shape, m = e.data.get(o.dataId).values, g6 = new Float32Array(O([d, c, u, f])), b6 = [
    r && c > 1 ? h6 - 1 : h6,
    r && u > 1 ? p6 - 1 : p6
  ], x6 = [
    r && c > 1 ? c - 1 : c,
    r && u > 1 ? u - 1 : u
  ];
  let w6 = 0;
  const y6 = b6[0] / x6[0], I = b6[1] / x6[1];
  for (let C6 = 0; C6 < d; C6++)
    for (let k7 = 0; k7 < c; k7++) {
      let S;
      i6 ? S = y6 * (k7 + 0.5) - 0.5 : S = y6 * k7;
      const N = Math.max(0, Math.floor(S)), R = S - N, M6 = Math.min(h6 - 1, Math.ceil(S)), V = C6 * l[0] + N * l[1], z = C6 * l[0] + M6 * l[1];
      for (let X = 0; X < u; X++) {
        let P6;
        i6 ? P6 = I * (X + 0.5) - 0.5 : P6 = I * X;
        const A6 = Math.max(0, Math.floor(P6)), B6 = P6 - A6, Z = Math.min(p6 - 1, Math.ceil(P6)), H6 = V + A6 * l[2], Y = z + A6 * l[2], Q = V + Z * l[2], j = z + Z * l[2];
        for (let J6 = 0; J6 < f; J6++) {
          const nt = m[H6 + J6], q = m[Y + J6], rt = m[Q + J6], ht = m[j + J6], ft2 = nt + (rt - nt) * B6, pt = q + (ht - q) * B6, wt2 = ft2 + (pt - ft2) * R;
          g6[w6++] = wt2;
        }
      }
    }
  return e.makeTensorInfo([d, c, u, f], "float32", g6);
}
var SF = {
  kernelName: Tc,
  backendName: "cpu",
  kernelFunc: vF
};
function kF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o, dy: r } = t, { alignCorners: i6 } = s;
  it([r, o], "resizeBilinearGrad");
  const a = dt(o.shape), [l, c, u, d] = o.shape, [, h6, p6] = r.shape, f = new Float32Array(l * c * u * d), m = [
    i6 && h6 > 1 ? c - 1 : c,
    i6 && p6 > 1 ? u - 1 : u
  ], g6 = [
    i6 && h6 > 1 ? h6 - 1 : h6,
    i6 && p6 > 1 ? p6 - 1 : p6
  ], b6 = m[0] / g6[0], x6 = m[1] / g6[1], w6 = e.data.get(r.dataId).values;
  let y6 = 0;
  for (let I = 0; I < l; I++) {
    const C6 = I * a[0];
    for (let k7 = 0; k7 < h6; k7++) {
      const S = k7 * b6, N = Math.floor(S), R = Math.min(Math.ceil(S), c - 1), M6 = C6 + N * a[1], V = C6 + R * a[1], z = S - N, X = 1 - z;
      for (let P6 = 0; P6 < p6; P6++) {
        const A6 = P6 * x6, B6 = Math.floor(A6), Z = Math.min(Math.ceil(A6), u - 1), H6 = A6 - B6, Y = 1 - H6, Q = M6 + B6 * a[2], j = M6 + Z * a[2], J6 = V + B6 * a[2], nt = V + Z * a[2], q = X * Y, rt = X * H6, ht = z * Y, ft2 = z * H6;
        for (let pt = 0; pt < d; pt++) {
          const wt2 = w6[y6++];
          f[Q + pt] += wt2 * q, f[j + pt] += wt2 * rt, f[J6 + pt] += wt2 * ht, f[nt + pt] += wt2 * ft2;
        }
      }
    }
  }
  return e.makeTensorInfo([l, u, c, d], "float32", f);
}
var TF = {
  kernelName: Ch,
  backendName: "cpu",
  kernelFunc: kF
};
function NF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o } = t, { alignCorners: r, halfPixelCenters: i6, size: a } = s;
  it(o, "resizeNearestNeighbor");
  const l = dt(o.shape), [c, u] = a, [d, h6, p6, f] = o.shape, m = e.data.get(o.dataId).values, g6 = new Float32Array(d * c * u * f), b6 = [
    r && c > 1 ? h6 - 1 : h6,
    r && u > 1 ? p6 - 1 : p6
  ], x6 = [
    r && c > 1 ? c - 1 : c,
    r && u > 1 ? u - 1 : u
  ], w6 = b6[0] / x6[0], y6 = b6[1] / x6[1];
  let I = 0;
  for (let C6 = 0; C6 < d; C6++) {
    const k7 = C6 * l[0];
    for (let S = 0; S < c; S++) {
      const N = i6 ? w6 * (S + 0.5) : w6 * S;
      let R = Math.min(h6 - 1, r ? Math.round(N) : Math.floor(N));
      i6 && (R = Math.max(0, R));
      const M6 = k7 + R * l[1];
      for (let V = 0; V < u; V++) {
        const z = i6 ? y6 * (V + 0.5) : y6 * V;
        let X = Math.min(p6 - 1, r ? Math.round(z) : Math.floor(z));
        i6 && (X = Math.max(0, X));
        const P6 = M6 + X * l[2];
        for (let A6 = 0; A6 < f; A6++) {
          const B6 = m[P6 + A6];
          g6[I++] = B6;
        }
      }
    }
  }
  return e.makeTensorInfo([d, c, u, f], o.dtype, g6);
}
var RF = {
  kernelName: kc,
  backendName: "cpu",
  kernelFunc: NF
};
function $F(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o, dy: r } = t, { alignCorners: i6 } = s;
  it([r, o], "resizeNearestNeighborGrad");
  const a = dt(o.shape), l = dt(r.shape), [c, u, d, h6] = o.shape, [, p6, f] = r.shape, m = new Float32Array(c * u * d * h6), g6 = e.data.get(r.dataId).values, b6 = [
    i6 && p6 > 1 ? u - 1 : u,
    i6 && f > 1 ? d - 1 : d
  ], x6 = [
    i6 && p6 > 1 ? p6 - 1 : p6,
    i6 && f > 1 ? f - 1 : f
  ], w6 = b6[0] / x6[0], y6 = b6[1] / x6[1], I = 1 / w6, C6 = 1 / y6, k7 = Math.ceil(I) * 2 + 2, S = Math.ceil(C6) * 2 + 2;
  for (let N = 0; N < c; N++) {
    const R = N * a[0];
    for (let M6 = 0; M6 < u; M6++) {
      const V = R + M6 * a[1], z = Math.floor(M6 * I), X = Math.floor(z - k7 / 2);
      for (let P6 = 0; P6 < d; P6++) {
        const A6 = V + P6 * a[2], B6 = Math.floor(P6 * C6), Z = Math.floor(B6 - S / 2);
        for (let H6 = 0; H6 < h6; H6++) {
          let Y = 0;
          for (let Q = 0; Q < k7; Q++) {
            const j = Q + X;
            if (j < 0 || j >= p6)
              continue;
            const J6 = R + j * l[1], nt = j * w6, q = Math.min(u - 1, i6 ? Math.round(nt) : Math.floor(nt));
            if (M6 === q)
              for (let rt = 0; rt < S; rt++) {
                const ht = rt + Z;
                if (ht < 0 || ht >= f)
                  continue;
                const ft2 = J6 + ht * l[2], pt = ht * y6, wt2 = Math.min(d - 1, i6 ? Math.round(pt) : Math.floor(pt));
                P6 === wt2 && (Y += g6[ft2 + H6]);
              }
          }
          m[A6 + H6] = Y;
        }
      }
    }
  }
  return e.makeTensorInfo(o.shape, o.dtype, m);
}
var GF = {
  kernelName: Ih,
  backendName: "cpu",
  kernelFunc: $F
};
function EF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { dims: r } = s;
  it(o, "reverse");
  const i6 = o.shape.length, a = Ct(r, o.shape);
  if (i6 === 0)
    return rs({ inputs: { x: o }, backend: e });
  const l = new $e(o.shape, o.dtype), c = e.bufferSync(o);
  for (let u = 0; u < l.size; u++) {
    const d = l.indexToLoc(u), h6 = d.slice();
    a.forEach((p6) => h6[p6] = o.shape[p6] - 1 - h6[p6]), l.set(c.get(...h6), ...d);
  }
  return e.makeTensorInfo(l.shape, l.dtype, l.values);
}
var LF = {
  kernelName: Nc,
  backendName: "cpu",
  kernelFunc: EF
};
var MF = {
  kernelName: Dh,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { image: s } = n, { radians: o, fillValue: r, center: i6 } = t, a = e, l = xe(s.dtype, O(s.shape)), [c, u, d, h6] = s.shape, [p6, f] = Xp(i6, u, d), m = 255, g6 = Math.sin(o), b6 = Math.cos(o), x6 = a.data.get(s.dataId).values;
    for (let y6 = 0; y6 < c; y6++) {
      const I = y6 * d * u * h6;
      for (let C6 = 0; C6 < u; C6++) {
        const k7 = C6 * (d * h6);
        for (let S = 0; S < d; S++) {
          const N = S * h6;
          for (let R = 0; R < h6; R++) {
            const M6 = [c, C6, S, R], V = M6[2], z = M6[1];
            let X = (V - p6) * b6 - (z - f) * g6, P6 = (V - p6) * g6 + (z - f) * b6;
            X = Math.round(X + p6), P6 = Math.round(P6 + f);
            let A6 = r;
            if (typeof r != "number" && (R === 3 ? A6 = m : A6 = r[R]), X >= 0 && X < d && P6 >= 0 && P6 < u) {
              const Z = P6 * (d * h6), H6 = X * h6, Y = I + Z + H6 + R;
              A6 = x6[Y];
            }
            const B6 = I + k7 + N + R;
            l[B6] = A6;
          }
        }
      }
    }
    return { dataId: a.write(l, s.shape, s.dtype), shape: s.shape, dtype: s.dtype };
  }
};
var WF = Mt(Bi, (n) => {
  const t = Math.floor(n);
  return n - t < 0.5 ? Math.floor(n) : n - t > 0.5 ? Math.ceil(n) : t % 2 === 0 ? t : t + 1;
});
var DF = {
  kernelName: Bi,
  backendName: "cpu",
  kernelFunc: WF
};
function FF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { indices: o, updates: r } = t, { shape: i6 } = s, { sliceRank: a, numUpdates: l, sliceSize: c, strides: u, outputSize: d } = Ir(r, o, i6), h6 = true, p6 = e.bufferSync(o), f = e.bufferSync(r), m = Qo(p6, f, i6, d, c, l, a, u, 0, h6);
  return e.makeTensorInfo(i6, m.dtype, m.values);
}
var VF = {
  kernelName: qg,
  backendName: "cpu",
  kernelFunc: FF
};
function zF(n, t) {
  let e = 0, s = n.length, o = 0;
  for (; e < s; )
    o = Math.floor((e + s) / 2), n[o] < t ? e = o + 1 : s = o;
  return s;
}
function XF(n, t) {
  let e = 0, s = n.length, o = 0;
  for (; e < s; )
    o = Math.floor((e + s) / 2), n[o] <= t ? e = o + 1 : s = o;
  return s;
}
function PF(n, t, e, s, o, r) {
  const i6 = oe("int32", e * o);
  for (let a = 0; a < e; ++a) {
    const l = n.slice(a * s, (a + 1) * s), c = a * o;
    for (let u = 0; u < o; ++u)
      i6[c + u] = r === "left" ? zF(l, t[u + c]) : XF(l, t[u + c]);
  }
  return i6;
}
function AF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { sortedSequence: o, values: r } = t, { side: i6 } = s, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, c = PF(a, l, o.shape[0], o.shape[1], r.shape[1], i6);
  return e.makeTensorInfo(r.shape, "int32", c);
}
var OF = {
  kernelName: tb,
  backendName: "cpu",
  kernelFunc: AF
};
function KF(n) {
  const { inputs: t, backend: e } = n, { condition: s, t: o, e: r } = t;
  it([s, o, r], "select");
  const i6 = s.shape.length, a = e.data.get(s.dataId).values, l = e.data.get(o.dataId).values, c = e.data.get(r.dataId).values, u = je(o.dtype, r.dtype), d = Se(O(o.shape), u);
  let h6 = 0;
  const p6 = i6 === 0 || i6 > 1 || o.shape.length === 1 ? 1 : O(o.shape.slice(1));
  for (let f = 0; f < a.length; f++)
    for (let m = 0; m < p6; m++)
      a[f] === 1 ? d[h6++] = l[f] : d[h6++] = c[f];
  return e.makeTensorInfo(o.shape, u, d);
}
var ZF = {
  kernelName: Rc,
  backendName: "cpu",
  kernelFunc: KF
};
var BF = Yc;
var HF = Qc;
var _F = Mt(_i, (n) => n >= 0 ? HF * n : BF * (Math.exp(n) - 1));
var UF = {
  kernelName: _i,
  backendName: "cpu",
  kernelFunc: _F
};
var YF = Mt(Qi, (n) => n < 0 ? -1 : n > 0 ? 1 : 0);
var QF = {
  kernelName: Qi,
  backendName: "cpu",
  kernelFunc: YF
};
var JF = Mt(Ui, (n) => Math.sin(n));
var jF = {
  kernelName: Ui,
  backendName: "cpu",
  kernelFunc: JF
};
var qF = Mt(Yi, (n) => Math.sinh(n));
var tV = {
  kernelName: Yi,
  backendName: "cpu",
  kernelFunc: qF
};
var eV = 11920928955078125e-23;
var Um = Math.log(eV) + 2;
var nV = Mt(ji, (n) => {
  const t = n > -Um, e = n < Um, s = Math.exp(n);
  let o;
  return e ? o = s : t ? o = n : o = Math.log(1 + s), o;
});
var sV = {
  kernelName: ji,
  backendName: "cpu",
  kernelFunc: nV
};
function oV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockShape: r, paddings: i6 } = s;
  it([o], "spaceToBatchND");
  const a = O(r), l = [[0, 0]];
  l.push(...i6);
  for (let C6 = 1 + r.length; C6 < o.shape.length; ++C6)
    l.push([0, 0]);
  const c = Iw.kernelFunc({
    inputs: { x: o },
    backend: e,
    attrs: { paddings: l, constantValue: 0 }
  }), u = fa(c.shape, r, a, false), d = ma(u.length, r.length, false), h6 = ga(c.shape, r, a, false), m = Ot({ inputs: { x: c }, backend: e, attrs: { shape: u } }), x6 = Ze({ inputs: { x: m }, backend: e, attrs: { perm: d } }), I = Ot({ inputs: { x: x6 }, backend: e, attrs: { shape: h6 } });
  return e.disposeIntermediateTensorInfo(c), e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(x6), I;
}
var rV = {
  kernelName: Ec,
  backendName: "cpu",
  kernelFunc: oV
};
function iV(n) {
  const { inputs: t, backend: e } = n, { indices: s, values: o, denseShape: r, defaultValue: i6 } = t;
  if (r.shape.length !== 1)
    throw new Error(`Dense shape must be a vector, saw:
        ${r.shape}`);
  if (s.shape.length !== 2)
    throw new Error(`Indices must be a matrix, saw:
        ${s.shape}`);
  if (o.shape.length !== 1)
    throw new Error(`Values must be a vector, saw:
        ${o.shape}`);
  if (i6.shape.length !== 0)
    throw new Error(`Default value must be a scalar, saw:
        ${i6.shape}`);
  const a = e.data.get(s.dataId).values, l = e.data.get(o.dataId).values, c = e.data.get(r.dataId).values, u = e.data.get(i6.dataId).values[0], [d, h6, p6, f, m] = U1(a, s.shape, s.dtype, l, o.dtype, c, u);
  return [
    e.makeTensorInfo(h6, s.dtype, d),
    e.makeTensorInfo([h6[0]], o.dtype, p6),
    e.makeTensorInfo([f.length], "bool", new Uint8Array(f.map((g6) => Number(g6)))),
    e.makeTensorInfo([m.length], s.dtype, new Int32Array(m))
  ];
}
var aV = {
  kernelName: vh,
  backendName: "cpu",
  kernelFunc: iV
};
function lV(n) {
  const { inputs: t, backend: e } = n, { inputIndices: s, inputShape: o, newShape: r } = t;
  if (s.shape.length !== 2)
    throw new Error(`Input indices should be a matrix but received shape
        ${s.shape}`);
  if (o.shape.length !== 1)
    throw new Error(`Input shape should be a vector but received shape
        ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Target shape should be a vector but received shape ${r.shape}`);
  const i6 = Array.from(e.data.get(o.dataId).values), a = e.data.get(s.dataId).values, l = Array.from(e.data.get(r.dataId).values), [c, u, d] = Y1(a, s.shape, s.dtype, i6, l);
  return [
    e.makeTensorInfo(u, s.dtype, c),
    e.makeTensorInfo([d.length], r.dtype, new Int32Array(d))
  ];
}
var cV = {
  kernelName: Sh,
  backendName: "cpu",
  kernelFunc: lV
};
function uV(n) {
  const { inputs: t, backend: e } = n, { data: s, indices: o, segmentIds: r } = t;
  if (s.shape.length < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.shape.length !== 1)
    throw new Error(`Indices should be a vector but received shape
          ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Segment ids should be a vector but received shape
          ${r.shape}`);
  if (o.shape[0] !== r.shape[0])
    throw new Error("segmentIds and indices should have same size.");
  const i6 = e.data.get(s.dataId).values, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, [c, u] = Ef(i6, s.shape, s.dtype, a, l, true);
  return e.makeTensorInfo(u, s.dtype, c);
}
var dV = {
  kernelName: kh,
  backendName: "cpu",
  kernelFunc: uV
};
function hV(n) {
  const { inputs: t, backend: e } = n, { data: s, indices: o, segmentIds: r } = t;
  if (s.shape.length < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.shape.length !== 1)
    throw new Error(`Indices should be a vector but received shape
         ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Segment ids should be a vector but received shape
         ${r.shape}`);
  if (o.shape[0] !== r.shape[0])
    throw new Error("segmentIds and indices should have same size.");
  const i6 = e.data.get(s.dataId).values, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, [c, u] = Ef(i6, s.shape, s.dtype, a, l);
  return e.makeTensorInfo(u, s.dtype, c);
}
var pV = {
  kernelName: Th,
  backendName: "cpu",
  kernelFunc: hV
};
function fV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { sparseIndices: o, sparseValues: r, defaultValue: i6 } = t, { outputShape: a } = s, { sliceRank: l, numUpdates: c, sliceSize: u, strides: d, outputSize: h6 } = Ir(r, o, a), p6 = false, f = e.bufferSync(o);
  let m;
  switch (r.dtype) {
    case "bool": {
      const g6 = e.bufferSync(r), b6 = !!e.data.get(i6.dataId).values[0];
      m = Qo(f, g6, a, h6, u, c, l, d, b6, p6);
      break;
    }
    case "float32": {
      const g6 = e.bufferSync(r), b6 = e.data.get(i6.dataId).values[0];
      m = Qo(f, g6, a, h6, u, c, l, d, b6, p6);
      break;
    }
    case "int32": {
      const g6 = e.bufferSync(r), b6 = e.data.get(i6.dataId).values[0];
      m = Qo(f, g6, a, h6, u, c, l, d, b6, p6);
      break;
    }
    case "string": {
      const g6 = e.bufferSync(r), b6 = ps(e.data.get(i6.dataId).values[0]);
      m = Qo(f, g6, a, h6, u, c, l, d, b6, p6);
      break;
    }
    default:
      throw new Error(`Unsupported type ${r.dtype}`);
  }
  return e.makeTensorInfo(a, m.dtype, m.values);
}
var mV = {
  kernelName: eb,
  backendName: "cpu",
  kernelFunc: fV
};
function gV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { numOrSizeSplits: r, axis: i6 } = s, a = Ct(i6, o.shape)[0], l = tf(o, r, a), c = new Array(o.shape.length).fill(0), u = o.shape.slice();
  return l.map((d) => {
    const h6 = [...u];
    h6[a] = d;
    const p6 = Go({ inputs: { x: o }, backend: e, attrs: { begin: c, size: h6 } });
    return c[a] += d, p6;
  });
}
var bV = {
  kernelName: Lc,
  backendName: "cpu",
  kernelFunc: gV
};
var xV = {
  kernelName: Nh,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, backend: t }) => {
    const { x: e } = n, s = t;
    it(e, "square");
    const o = s.data.get(e.dataId).values, r = new Float32Array(o.length);
    for (let a = 0; a < o.length; ++a) {
      const l = o[a];
      r[a] = l * l;
    }
    return { dataId: s.write(r, e.shape, e.dtype), shape: e.shape, dtype: e.dtype };
  }
};
var yV = Mt(ra, (n, t) => {
  const e = t;
  return isNaN(n) ? NaN : n > 0 ? 1 : e.alpha;
});
var wV = {
  kernelName: ra,
  backendName: "cpu",
  kernelFunc: yV
};
function IV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { begin: r, end: i6, strides: a, beginMask: l, endMask: c, ellipsisMask: u, newAxisMask: d, shrinkAxisMask: h6 } = s;
  it(o, "stridedSlice");
  const { finalShapeSparse: p6, finalShape: f, isIdentity: m, sliceDim0: g6, isSimpleSlice: b6, begin: x6, end: w6, strides: y6 } = Fp(o.shape, r, i6, a, l, c, u, d, h6);
  let I;
  if (m)
    I = Ot({ inputs: { x: o }, backend: e, attrs: { shape: f } });
  else if (g6 || b6) {
    v2(o.shape.length >= 1, () => `Input must have rank at least 1, got: ${o.shape.length}`);
    const C6 = Mp(x6, w6, y6), k7 = Go({ inputs: { x: o }, backend: e, attrs: { begin: x6, size: C6 } });
    I = Ot({ inputs: { x: k7 }, backend: e, attrs: { shape: f } }), e.disposeIntermediateTensorInfo(k7);
  } else {
    const C6 = e.bufferSync(o), k7 = J1(p6, C6, y6, x6);
    I = e.makeTensorInfo(f, k7.dtype, k7.values);
  }
  return I;
}
var CV = {
  kernelName: Rh,
  backendName: "cpu",
  kernelFunc: IV
};
function vV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { separator: o, nGramWidths: r, leftPad: i6, rightPad: a, padWidth: l, preserveShortSequences: c } = s, { data: u, dataSplits: d } = t, h6 = e.data.get(u.dataId).values, p6 = e.data.get(d.dataId).values, [f, m] = j1(h6, p6, o, r, i6, a, l, c);
  return [
    e.makeTensorInfo([f.length], "string", f),
    e.makeTensorInfo(d.shape, "int32", m)
  ];
}
var SV = {
  kernelName: $h,
  backendName: "cpu",
  kernelFunc: vV
};
function kV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { skipEmpty: o } = s, { input: r, delimiter: i6 } = t;
  if (r.dtype !== "string")
    throw new Error("Input must be of datatype string");
  if (r.shape.length !== 1)
    throw new Error(`Input must be a vector, got shape: ${r.shape}`);
  if (i6.shape.length !== 0)
    throw new Error(`Delimiter must be a scalar, got shape: ${i6.shape}`);
  const a = e.data.get(r.dataId).values, l = e.data.get(i6.dataId).values[0], [c, u, d] = q1(a, l, o), h6 = u.length;
  return [
    e.makeTensorInfo([h6, 2], "int32", c),
    e.makeTensorInfo([h6], "string", u),
    e.makeTensorInfo([2], "int32", new Int32Array(d))
  ];
}
var TV = {
  kernelName: Gh,
  backendName: "cpu",
  kernelFunc: kV
};
function NV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { numBuckets: o } = s, { input: r } = t;
  if (r.dtype !== "string")
    throw new Error("Input must be of datatype string");
  if (o <= 0)
    throw new Error("Number of buckets must be at least 1");
  const i6 = e.data.get(r.dataId).values, a = tw(i6, o);
  return e.makeTensorInfo(r.shape, "int32", a);
}
var RV = {
  kernelName: Eh,
  backendName: "cpu",
  kernelFunc: NV
};
var $V = Mt(na, (n) => Math.tan(n));
var GV = {
  kernelName: na,
  backendName: "cpu",
  kernelFunc: $V
};
var EV = Mt(sa, (n) => Math.tanh(n));
var LV = {
  kernelName: sa,
  backendName: "cpu",
  kernelFunc: EV
};
function MV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { reps: r } = s;
  it(o, "tile");
  const i6 = nw(e.bufferSync(o), r);
  return e.makeTensorInfo(i6.shape, i6.dtype, i6.values);
}
var WV = {
  kernelName: oa,
  backendName: "cpu",
  kernelFunc: MV
};
function DV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { k: r, sorted: i6 } = s;
  it(o, "topk");
  const a = e.data.get(o.dataId).values, [l, c] = ow(a, o.shape, o.dtype, r, i6);
  return [
    e.makeTensorInfo(l.shape, l.dtype, l.values),
    e.makeTensorInfo(c.shape, c.dtype, c.values)
  ];
}
var FV = {
  kernelName: Lh,
  backendName: "cpu",
  kernelFunc: DV
};
function VV(n) {
  const { inputs: t, attrs: e, backend: s } = n, { image: o, transforms: r } = t, { interpolation: i6, fillMode: a, fillValue: l, outputShape: c } = e, [u, d, h6, p6] = o.shape, [f, m] = c ?? [d, h6], g6 = [u, f, m, p6], b6 = dt(o.shape), x6 = b6[0], w6 = b6[1], y6 = b6[2], I = dt(g6), C6 = I[0], k7 = I[1], S = I[2], N = xe(o.dtype, O(g6));
  N.fill(l);
  const R = s.data.get(o.dataId).values, M6 = s.data.get(r.dataId).values;
  for (let z = 0; z < u; ++z) {
    const X = r.shape[0] === 1 ? M6 : M6.subarray(z * 8, z * 8 + 8);
    for (let P6 = 0; P6 < f; ++P6)
      for (let A6 = 0; A6 < m; ++A6)
        for (let B6 = 0; B6 < p6; ++B6) {
          let Z;
          const H6 = X[6] * A6 + X[7] * P6 + 1;
          if (H6 === 0)
            continue;
          const Y = (X[0] * A6 + X[1] * P6 + X[2]) / H6, Q = (X[3] * A6 + X[4] * P6 + X[5]) / H6, j = Ym(Y, h6, a), J6 = Ym(Q, d, a);
          switch (i6) {
            case "nearest":
              Z = KV(R, d, h6, x6, w6, y6, z, J6, j, B6, l);
              break;
            case "bilinear":
              Z = ZV(R, d, h6, x6, w6, y6, z, J6, j, B6, l);
              break;
            default:
              throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${i6}`);
          }
          const nt = z * C6 + P6 * k7 + A6 * S + B6;
          N[nt] = Z;
        }
    return s.makeTensorInfo(g6, o.dtype, N);
  }
  return { dataId: s.write(N, g6, o.dtype), shape: o.shape, dtype: o.dtype };
}
var zV = {
  kernelName: Mh,
  backendName: "cpu",
  kernelFunc: VV
};
function Ym(n, t, e) {
  switch (e) {
    case "reflect":
      return XV(n, t);
    case "wrap":
      return PV(n, t);
    case "nearest":
      return OV(n, t);
    case "constant":
    default:
      return AV(n);
  }
}
function XV(n, t) {
  let e = n;
  if (e < 0)
    if (t <= 1)
      e = 0;
    else {
      const s = 2 * t;
      e < s && (e = s * Math.trunc(-e / s) + e), e = e < -t ? e + s : -e - 1;
    }
  else if (e > t - 1)
    if (t <= 1)
      e = 0;
    else {
      const s = 2 * t;
      e -= s * Math.trunc(e / s), e >= t && (e = s - e - 1);
    }
  return Fs(0, e, t - 1);
}
function PV(n, t) {
  let e = n;
  if (e < 0)
    if (t <= 1)
      e = 0;
    else {
      const s = t - 1;
      e += t * (Math.trunc(-e / s) + 1);
    }
  else if (e > t - 1)
    if (t <= 1)
      e = 0;
    else {
      const s = t - 1;
      e -= t * Math.trunc(e / s);
    }
  return Fs(0, e, t - 1);
}
function AV(n, t) {
  return n;
}
function OV(n, t) {
  return Fs(0, n, t - 1);
}
function Kr(n, t, e, s, o, r, i6, a, l, c, u) {
  const d = i6 * s + a * o + l * r + c;
  return 0 <= a && a < t && 0 <= l && l < e ? n[d] : u;
}
function KV(n, t, e, s, o, r, i6, a, l, c, u) {
  const d = Math.round(a), h6 = Math.round(l);
  return Kr(n, t, e, s, o, r, i6, d, h6, c, u);
}
function ZV(n, t, e, s, o, r, i6, a, l, c, u) {
  const d = Math.floor(a), h6 = Math.floor(l), p6 = d + 1, f = h6 + 1, m = (f - l) * Kr(n, t, e, s, o, r, i6, d, h6, c, u) + (l - h6) * Kr(n, t, e, s, o, r, i6, d, f, c, u), g6 = (f - l) * Kr(n, t, e, s, o, r, i6, p6, h6, c, u) + (l - h6) * Kr(n, t, e, s, o, r, i6, p6, f, c, u);
  return (p6 - a) * m + (a - d) * g6;
}
function BV(n) {
  const { inputs: t, attrs: e, backend: s } = n, { axis: o } = e, { x: r } = t;
  it(r, "unique");
  const i6 = s.data.get(r.dataId).values, { outputValues: a, outputShape: l, indices: c } = rw(i6, o, r.shape, r.dtype);
  return [
    s.makeTensorInfo(l, r.dtype, a),
    s.makeTensorInfo([c.length], "int32", c)
  ];
}
var HV = {
  kernelName: Wh,
  backendName: "cpu",
  kernelFunc: BV
};
function _V(n) {
  const { inputs: t, backend: e, attrs: s } = n, { value: o } = t;
  let { axis: r } = s;
  r < 0 && (r += o.shape.length);
  const i6 = o.shape.length, a = o.shape[r], l = new Array(i6 - 1);
  let c = 0;
  for (let p6 = 0; p6 < i6; p6++)
    p6 !== r && (l[c++] = o.shape[p6]);
  const u = new Array(i6).fill(0), d = o.shape.slice();
  d[r] = 1;
  const h6 = new Array(a);
  for (let p6 = 0; p6 < h6.length; p6++) {
    u[r] = p6;
    const f = Go({ inputs: { x: o }, backend: e, attrs: { begin: u, size: d } });
    h6[p6] = Ot({ inputs: { x: f }, backend: e, attrs: { shape: l } }), e.disposeIntermediateTensorInfo(f);
  }
  return h6;
}
var UV = {
  kernelName: Wc,
  backendName: "cpu",
  kernelFunc: _V
};
function YV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, segmentIds: r } = t, { numSegments: i6 } = s;
  it(o, "unsortedSegmentSum");
  const a = o.shape.length, l = r.shape.length, c = [], u = [], d = a - l;
  let h6 = r;
  for (let f = 0; f < d; ++f) {
    const m = Nl({ inputs: { input: h6 }, backend: e, attrs: { dim: f + 1 } });
    h6 = m, u.push(m);
  }
  for (let f = 0; f < i6; ++f) {
    const m = bs(f, "int32"), g6 = e.makeTensorInfo([], "int32", m), b6 = C1({ inputs: { a: g6, b: h6 }, backend: e }), x6 = Ks({ inputs: { x: b6 }, backend: e, attrs: { dtype: "float32" } }), w6 = uu({ inputs: { a: x6, b: o }, backend: e }), y6 = ka({ inputs: { x: w6 }, backend: e, attrs: { axis: 0, keepDims: false } });
    c.push(y6), u.push(g6), u.push(b6), u.push(x6), u.push(w6), u.push(y6);
  }
  const p6 = ww({ inputs: c, backend: e, attrs: { axis: 0 } });
  return u.forEach((f) => e.disposeIntermediateTensorInfo(f)), p6;
}
var QV = {
  kernelName: Dc,
  backendName: "cpu",
  kernelFunc: YV
};
var JV = [
  H3,
  LL,
  U3,
  Q3,
  zL,
  j3,
  tM,
  nM,
  oM,
  iM,
  lM,
  uM,
  hM,
  mM,
  bM,
  wM,
  CM,
  SM,
  TM,
  Z3,
  RM,
  GM,
  LM,
  WM,
  FL,
  PL,
  FM,
  ML,
  zM,
  PM,
  AM,
  KM,
  BM,
  _M,
  YM,
  JM,
  qM,
  eW,
  sW,
  rW,
  aW,
  cW,
  dW,
  hW,
  fW,
  gW,
  xW,
  yW,
  wW,
  IW,
  SW,
  V3,
  TW,
  AL,
  WW,
  OL,
  DW,
  ZL,
  AW,
  OW,
  ZW,
  HL,
  _W,
  YW,
  JW,
  qW,
  eD,
  UL,
  QL,
  WL,
  sD,
  XM,
  rD,
  aD,
  cD,
  z3,
  jL,
  t3,
  dD,
  n3,
  pD,
  gD,
  xD,
  ID,
  vD,
  kD,
  TD,
  o3,
  RD,
  GD,
  LD,
  WD,
  FD,
  zD,
  PD,
  i3,
  OD,
  BD,
  UD,
  l3,
  u3,
  JD,
  tF,
  sF,
  h3,
  rF,
  aF,
  lF,
  Iw,
  hF,
  P3,
  m3,
  fF,
  gF,
  xF,
  wF,
  DL,
  Ed,
  CF,
  A3,
  O3,
  K3,
  SF,
  TF,
  RF,
  GF,
  LF,
  MF,
  DF,
  v3,
  VF,
  OF,
  ZF,
  UF,
  k3,
  QF,
  jF,
  tV,
  T3,
  HD,
  sV,
  rV,
  aV,
  cV,
  dV,
  pV,
  mV,
  bV,
  $3,
  xV,
  E3,
  wV,
  CV,
  SV,
  TV,
  RV,
  D3,
  CW,
  GV,
  LV,
  WV,
  FV,
  zV,
  p3,
  HV,
  UV,
  QV,
  iF
];
for (const n of JV)
  en(n);
var io = {};
var Xa = {
  alpha: false,
  antialias: false,
  premultipliedAlpha: false,
  preserveDrawingBuffer: false,
  depth: false,
  stencil: false,
  failIfMajorPerformanceCaveat: true
};
function jV(n, t) {
  io[n] = t;
}
function Zn(n, t) {
  if (!(n in io) || t != null) {
    const s = tz(n, t);
    if (s !== null)
      io[n] = s;
    else
      return console.log("Could not get context for WebGL version", n), null;
  }
  const e = io[n];
  return e == null || e.isContextLost() ? (delete io[n], Zn(n)) : (e.disable(e.DEPTH_TEST), e.disable(e.STENCIL_TEST), e.disable(e.BLEND), e.disable(e.DITHER), e.disable(e.POLYGON_OFFSET_FILL), e.disable(e.SAMPLE_COVERAGE), e.enable(e.SCISSOR_TEST), e.enable(e.CULL_FACE), e.cullFace(e.BACK), io[n]);
}
function qV(n) {
  if (typeof OffscreenCanvas < "u" && n === 2)
    return new OffscreenCanvas(300, 150);
  if (typeof document < "u")
    return document.createElement("canvas");
  throw new Error("Cannot create a canvas in this context");
}
function tz(n, t) {
  if (n !== 1 && n !== 2)
    throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
  const e = t ?? qV(n);
  return e.addEventListener("webglcontextlost", (s) => {
    s.preventDefault(), delete io[n];
  }, false), F().getBool("SOFTWARE_WEBGL_ENABLED") && (Xa.failIfMajorPerformanceCaveat = false), n === 1 ? e.getContext("webgl", Xa) || e.getContext("experimental-webgl", Xa) : e.getContext("webgl2", Xa);
}
var ii;
(function(n) {
  n[n.DENSE = 0] = "DENSE", n[n.SHARED_BATCH = 1] = "SHARED_BATCH";
})(ii || (ii = {}));
var ln;
(function(n) {
  n[n.RENDER = 0] = "RENDER", n[n.UPLOAD = 1] = "UPLOAD", n[n.PIXELS = 2] = "PIXELS", n[n.DOWNLOAD = 3] = "DOWNLOAD";
})(ln || (ln = {}));
var ve;
(function(n) {
  n[n.UNPACKED_FLOAT16 = 0] = "UNPACKED_FLOAT16", n[n.UNPACKED_FLOAT32 = 1] = "UNPACKED_FLOAT32", n[n.PACKED_4X1_UNSIGNED_BYTE = 2] = "PACKED_4X1_UNSIGNED_BYTE", n[n.PACKED_2X2_FLOAT32 = 3] = "PACKED_2X2_FLOAT32", n[n.PACKED_2X2_FLOAT16 = 4] = "PACKED_2X2_FLOAT16";
})(ve || (ve = {}));
function Ta(n, t) {
  return [t, n];
}
function ez(n, t) {
  return n * t;
}
function Pa(n) {
  const t = O(n), e = Math.ceil(t / 4);
  return el(e);
}
function kr(n, t) {
  return [
    Math.max(1, Math.ceil(t / 2)),
    Math.max(1, Math.ceil(n / 2))
  ];
}
function nz(n, t) {
  const [e, s] = kr(n, t);
  return e * s * 4;
}
function Ff(n, t) {
  const e = n;
  let s, o, r, i6, a, l, c, u, d, h6;
  return F().getNumber("WEBGL_VERSION") === 2 ? (s = e.R32F, o = e.R16F, r = e.RGBA16F, i6 = e.RGBA32F, a = e.RED, c = 4, u = 1, d = e.HALF_FLOAT, h6 = e.FLOAT, l = e.RGBA8) : (s = n.RGBA, o = n.RGBA, r = n.RGBA, i6 = e.RGBA, a = n.RGBA, c = 4, u = 4, d = t != null ? t.HALF_FLOAT_OES : null, h6 = n.FLOAT, l = n.RGBA), {
    internalFormatFloat: s,
    internalFormatHalfFloat: o,
    internalFormatPackedHalfFloat: r,
    internalFormatPackedFloat: i6,
    textureFormatFloat: a,
    downloadTextureFormat: l,
    downloadUnpackNumChannels: c,
    defaultNumChannels: u,
    textureTypeHalfFloat: d,
    textureTypeFloat: h6
  };
}
function ot(n, t) {
  const e = t();
  return F().getBool("DEBUG") && sz(n), e;
}
function sz(n) {
  const t = n.getError();
  if (t !== n.NO_ERROR)
    throw new Error("WebGL Error: " + az(n, t));
}
var oz = 596e-10;
var rz = 65504;
function iz(n) {
  return !!(F().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || n === 0 || oz < Math.abs(n) && Math.abs(n) < rz);
}
function az(n, t) {
  switch (t) {
    case n.NO_ERROR:
      return "NO_ERROR";
    case n.INVALID_ENUM:
      return "INVALID_ENUM";
    case n.INVALID_VALUE:
      return "INVALID_VALUE";
    case n.INVALID_OPERATION:
      return "INVALID_OPERATION";
    case n.INVALID_FRAMEBUFFER_OPERATION:
      return "INVALID_FRAMEBUFFER_OPERATION";
    case n.OUT_OF_MEMORY:
      return "OUT_OF_MEMORY";
    case n.CONTEXT_LOST_WEBGL:
      return "CONTEXT_LOST_WEBGL";
    default:
      return `Unknown error code ${t}`;
  }
}
function Aa(n, t) {
  return Cs(n, () => n.getExtension(t), 'Extension "' + t + '" not supported on this browser.');
}
function lz(n, t) {
  const e = Cs(n, () => n.createShader(n.VERTEX_SHADER), "Unable to create vertex WebGLShader.");
  if (ot(n, () => n.shaderSource(e, t)), ot(n, () => n.compileShader(e)), n.getShaderParameter(e, n.COMPILE_STATUS) === false)
    throw console.log(n.getShaderInfoLog(e)), new Error("Failed to compile vertex shader.");
  return e;
}
function cz(n, t) {
  const e = Cs(n, () => n.createShader(n.FRAGMENT_SHADER), "Unable to create fragment WebGLShader.");
  if (ot(n, () => n.shaderSource(e, t)), ot(n, () => n.compileShader(e)), F().get("ENGINE_COMPILE_ONLY"))
    return e;
  if (n.getShaderParameter(e, n.COMPILE_STATUS) === false)
    throw Cw(t, n.getShaderInfoLog(e)), new Error("Failed to compile fragment shader.");
  return e;
}
var uz = /ERROR: [0-9]+:([0-9]+):/g;
function Cw(n, t) {
  const e = uz.exec(t);
  if (e == null) {
    console.log(`Couldn't parse line number in error: ${t}`), console.log(n);
    return;
  }
  const s = +e[1], o = n.split(`
`), r = o.length.toString().length + 2, i6 = o.map((d, h6) => ho((h6 + 1).toString(), r) + d);
  let a = 0;
  for (let d = 0; d < i6.length; d++)
    a = Math.max(i6[d].length, a);
  const l = i6.slice(0, s - 1), c = i6.slice(s - 1, s), u = i6.slice(s);
  console.log(l.join(`
`)), console.log(t.split(`
`)[0]), console.log(`%c ${ho(c[0], a)}`, "border:1px solid red; background-color:#e3d2d2; color:#a61717"), console.log(u.join(`
`));
}
function dz(n) {
  return Cs(n, () => n.createProgram(), "Unable to create WebGLProgram.");
}
function hz(n, t) {
  if (ot(n, () => n.linkProgram(t)), !F().get("ENGINE_COMPILE_ONLY") && n.getProgramParameter(t, n.LINK_STATUS) === false)
    throw console.log(n.getProgramInfoLog(t)), new Error("Failed to link vertex and fragment shaders.");
}
function Gu(n, t) {
  if (ot(n, () => n.validateProgram(t)), n.getProgramParameter(t, n.VALIDATE_STATUS) === false)
    throw console.log(n.getProgramInfoLog(t)), new Error("Shader program validation failed.");
}
function pz(n, t) {
  const e = Cs(n, () => n.createBuffer(), "Unable to create WebGLBuffer");
  return ot(n, () => n.bindBuffer(n.ARRAY_BUFFER, e)), ot(n, () => n.bufferData(n.ARRAY_BUFFER, t, n.STATIC_DRAW)), e;
}
function fz(n, t) {
  const e = Cs(n, () => n.createBuffer(), "Unable to create WebGLBuffer");
  return ot(n, () => n.bindBuffer(n.ELEMENT_ARRAY_BUFFER, e)), ot(n, () => n.bufferData(n.ELEMENT_ARRAY_BUFFER, t, n.STATIC_DRAW)), e;
}
function mz(n) {
  return Cs(n, () => n.createTexture(), "Unable to create WebGLTexture.");
}
function gz(n, t) {
  const e = F().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  if (n <= 0 || t <= 0) {
    const s = `[${n}x${t}]`;
    throw new Error("Requested texture size " + s + " is invalid.");
  }
  if (n > e || t > e) {
    const s = `[${n}x${t}]`, o = `[${e}x${e}]`;
    throw new Error("Requested texture size " + s + " greater than WebGL maximum on this browser / GPU " + o + ".");
  }
}
function bz(n) {
  return Cs(n, () => n.createFramebuffer(), "Unable to create WebGLFramebuffer.");
}
function Qm(n, t, e, s, o, r, i6) {
  const a = n.getAttribLocation(t, e);
  return a === -1 ? false : (ot(n, () => n.bindBuffer(n.ARRAY_BUFFER, s)), ot(n, () => n.vertexAttribPointer(a, o, n.FLOAT, false, r, i6)), ot(n, () => n.enableVertexAttribArray(a)), true);
}
function xz(n, t, e) {
  vz(n, e), ot(n, () => n.activeTexture(n.TEXTURE0 + e)), ot(n, () => n.bindTexture(n.TEXTURE_2D, t));
}
function yz(n, t, e) {
  return Cs(n, () => n.getUniformLocation(t, e), 'uniform "' + e + '" not present in program.');
}
function wz(n, t, e) {
  return n.getUniformLocation(t, e);
}
function Iz(n, t, e, s) {
  ot(n, () => xz(n, t, s)), ot(n, () => n.uniform1i(e, s));
}
function Eu(n, t, e) {
  ot(n, () => n.bindFramebuffer(n.FRAMEBUFFER, e)), ot(n, () => n.framebufferTexture2D(n.FRAMEBUFFER, n.COLOR_ATTACHMENT0, n.TEXTURE_2D, t, 0));
}
function Jm(n, t) {
  ot(n, () => n.bindFramebuffer(n.FRAMEBUFFER, t)), ot(n, () => n.framebufferTexture2D(n.FRAMEBUFFER, n.COLOR_ATTACHMENT0, n.TEXTURE_2D, null, 0));
}
function Oa(n) {
  const t = n.checkFramebufferStatus(n.FRAMEBUFFER);
  if (t !== n.FRAMEBUFFER_COMPLETE)
    throw new Error("Error binding framebuffer: " + Cz(n, t));
}
function Cz(n, t) {
  switch (t) {
    case n.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
    case n.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
    case n.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
      return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
    case n.FRAMEBUFFER_UNSUPPORTED:
      return "FRAMEBUFFER_UNSUPPORTED";
    default:
      return `unknown error ${t}`;
  }
}
function Cs(n, t, e) {
  const s = ot(n, () => t());
  if (s == null)
    throw new Error(e);
  return s;
}
function vz(n, t) {
  const e = n.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1, s = t + n.TEXTURE0;
  if (s < n.TEXTURE0 || s > e) {
    const o = `[gl.TEXTURE0, gl.TEXTURE${e}]`;
    throw new Error(`textureUnit must be in ${o}.`);
  }
}
function hr(n, t = 2) {
  return O(n.slice(0, n.length - t));
}
function pr(n) {
  if (n.length === 0)
    throw Error("Cannot get rows and columns of an empty shape array.");
  return [
    n.length > 1 ? n[n.length - 2] : 1,
    n[n.length - 1]
  ];
}
function Ka(n) {
  let t = [1, 1, 1];
  return n.length === 0 || n.length === 1 && n[0] === 1 || (t = [hr(n), ...pr(n)]), t;
}
function Sz(n, t = false) {
  let e = F().getNumber("WEBGL_MAX_TEXTURE_SIZE"), s = F().getNumber("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE");
  s === 1 / 0 && F().getBool("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE") && (s = e / 2), t && (e = e * 2, s = s * 2, n = n.map((a, l) => l >= n.length - 2 ? Wl(n[l]) : n[l]), n.length === 1 && (n = [2, n[0]])), n.length !== 2 && (n = gs(n).newShape);
  let o = O(n), r = null;
  n.length <= 1 && o <= e ? r = [1, o] : n.length === 2 && n[0] <= e && n[1] <= e ? r = n : n.length === 3 && n[0] * n[1] <= e && n[2] <= e ? r = [n[0] * n[1], n[2]] : n.length === 3 && n[0] <= e && n[1] * n[2] <= e ? r = [n[0], n[1] * n[2]] : n.length === 4 && n[0] * n[1] * n[2] <= e && n[3] <= e ? r = [n[0] * n[1] * n[2], n[3]] : n.length === 4 && n[0] <= e && n[1] * n[2] * n[3] <= e && (r = [n[0], n[1] * n[2] * n[3]]);
  const i6 = r != null && Math.max(...r) > s && Math.min(...r) <= (t ? 2 : 1) && Math.min(...r) > 0;
  if (r == null || i6)
    if (t) {
      const a = hr(n);
      let l = 2, c = 2;
      n.length && ([l, c] = pr(n)), o = a * (l / 2) * (c / 2), r = el(o).map((u) => u * 2);
    } else
      r = el(o);
  return r;
}
function Za(n) {
  return n % 2 === 0;
}
function $l(n, t) {
  if (n = n.slice(-2), t = t.slice(-2), Rt(n, t) || !n.length || !t.length || n[0] === 0 || n[1] === 0 || t[0] === 0 || t[1] === 0)
    return true;
  if (n.length !== t.length) {
    const e = n.slice(-1)[0], s = t.slice(-1)[0];
    if (e === s || Za(e) && Za(s) && (n[0] === 1 || t[0] === 1))
      return true;
  }
  return n[1] === t[1] && Za(n[0]) && Za(t[0]);
}
var Lu;
var Mu;
function kz(n) {
  if (Lu == null) {
    const t = Zn(n);
    Lu = t.getParameter(t.MAX_TEXTURE_SIZE);
  }
  return Lu;
}
function Tz(n) {
  if (Mu == null) {
    const t = Zn(n);
    Mu = t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS);
  }
  return Math.min(16, Mu);
}
function Nz(n) {
  if (n === 0)
    return 0;
  let t;
  const e = Zn(n);
  return vn(e, "EXT_disjoint_timer_query_webgl2") && n === 2 ? t = 2 : vn(e, "EXT_disjoint_timer_query") ? t = 1 : t = 0, t;
}
function vn(n, t) {
  return n.getExtension(t) != null;
}
function jm(n) {
  try {
    if (Zn(n) != null)
      return true;
  } catch (t) {
    return console.log("Error when getting WebGL context: ", t), false;
  }
  return false;
}
function Rz(n) {
  if (n === 0)
    return false;
  const t = Zn(n);
  if (n === 1) {
    if (!vn(t, "OES_texture_float"))
      return false;
  } else if (!vn(t, "EXT_color_buffer_float"))
    return false;
  return Md(t);
}
function $z(n) {
  if (n === 0)
    return false;
  const t = Zn(n);
  if (n === 1) {
    if (!vn(t, "OES_texture_float") || !vn(t, "WEBGL_color_buffer_float"))
      return false;
  } else {
    if (vn(t, "EXT_color_buffer_float"))
      return Md(t);
    const s = "EXT_color_buffer_half_float";
    if (vn(t, s)) {
      const o = t.getExtension(s);
      return Gz(t, o);
    }
    return false;
  }
  return Md(t);
}
function Md(n) {
  const t = Ff(n), e = n.createTexture();
  n.bindTexture(n.TEXTURE_2D, e);
  const s = 1, o = 1;
  n.texImage2D(n.TEXTURE_2D, 0, t.internalFormatFloat, s, o, 0, t.textureFormatFloat, t.textureTypeFloat, null);
  const r = n.createFramebuffer();
  n.bindFramebuffer(n.FRAMEBUFFER, r), n.framebufferTexture2D(n.FRAMEBUFFER, n.COLOR_ATTACHMENT0, n.TEXTURE_2D, e, 0);
  const i6 = n.checkFramebufferStatus(n.FRAMEBUFFER) === n.FRAMEBUFFER_COMPLETE;
  return n.bindTexture(n.TEXTURE_2D, null), n.bindFramebuffer(n.FRAMEBUFFER, null), n.deleteTexture(e), n.deleteFramebuffer(r), i6;
}
function Gz(n, t) {
  const e = Ff(n, t), s = n.createTexture();
  n.bindTexture(n.TEXTURE_2D, s);
  const o = 1, r = 1;
  n.texImage2D(n.TEXTURE_2D, 0, e.internalFormatHalfFloat, o, r, 0, e.textureFormatFloat, e.textureTypeHalfFloat, null);
  const i6 = n.createFramebuffer();
  n.bindFramebuffer(n.FRAMEBUFFER, i6), n.framebufferTexture2D(n.FRAMEBUFFER, n.COLOR_ATTACHMENT0, n.TEXTURE_2D, s, 0);
  const a = n.checkFramebufferStatus(n.FRAMEBUFFER) === n.FRAMEBUFFER_COMPLETE;
  return n.bindTexture(n.TEXTURE_2D, null), n.bindFramebuffer(n.FRAMEBUFFER, null), n.deleteTexture(s), n.deleteFramebuffer(i6), a;
}
function Ez(n) {
  return n !== 2 ? false : Zn(n).fenceSync != null;
}
function Na(n, t) {
  Array.isArray(n) || (n = [n]), n.forEach((e) => {
    e != null && v2(e.dtype !== "complex64", () => `${t} does not support complex64 tensors in the WebGL backend.`);
  });
}
var ct = F();
ct.registerFlag("HAS_WEBGL", () => ct.getNumber("WEBGL_VERSION") > 0);
ct.registerFlag("WEBGL_VERSION", () => jm(2) ? 2 : jm(1) ? 1 : 0);
ct.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", () => false);
ct.registerFlag("WEBGL_BUFFER_SUPPORTED", () => ct.get("WEBGL_VERSION") === 2);
ct.registerFlag("WEBGL_CPU_FORWARD", () => true);
ct.registerFlag("WEBGL_FORCE_F16_TEXTURES", () => false);
ct.registerFlag("WEBGL_PACK", () => ct.getBool("HAS_WEBGL"));
ct.registerFlag("WEBGL_PACK_NORMALIZATION", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_CLIP", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_DEPTHWISECONV", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_REDUCE", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_LAZILY_UNPACK", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_CONV_IM2COL", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_MAX_TEXTURE_SIZE", () => kz(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", () => Tz(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", () => {
  const n = ct.getNumber("WEBGL_VERSION");
  return n === 0 ? 0 : Nz(n);
});
ct.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", () => ct.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !Xh());
ct.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", () => Rz(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", () => ct.getBool("WEBGL_FORCE_F16_TEXTURES") ? false : ct.getBool("WEBGL_RENDER_FLOAT32_CAPABLE"));
ct.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", () => $z(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_FENCE_API_ENABLED", () => Ez(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", () => ct.getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? 4 : 0);
ct.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", () => -1, (n) => {
  if (n < 0 && n !== -1)
    throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${n}.`);
});
ct.registerFlag("WEBGL_FLUSH_THRESHOLD", () => Xh() ? 1 : -1, (n) => {
  if (n < 0 && n !== -1)
    throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${n}.`);
});
ct.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", () => 128);
ct.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", () => false);
ct.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", () => 1e5);
ct.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", () => 128);
ct.registerFlag("WEBGL_EXP_CONV", () => false);
ct.registerFlag("SOFTWARE_WEBGL_ENABLED", () => ct.getBool("IS_TEST"));
ct.registerFlag("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE", () => 1 / 0);
ct.registerFlag("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE", () => false);
ct.registerFlag("WEBGL2_ISNAN_CUSTOM", () => false);
ct.registerFlag("ENGINE_COMPILE_ONLY", () => false);
function ze() {
  let n, t, e, s, o, r, i6, a, l, c;
  return F().getNumber("WEBGL_VERSION") === 2 ? (n = "#version 300 es", t = "in", e = "out", s = "in", o = "texture", r = "outputColor", i6 = "out vec4 outputColor;", a = F().getBool("WEBGL2_ISNAN_CUSTOM") ? `
      bool isnan_custom(float val) {
        uint floatToUint = floatBitsToUint(val);
        return (floatToUint & 0x7fffffffu) > 0x7f800000u;
      }

      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan_custom(val.x),
          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));
      }

      #define isnan(value) isnan_custom(value)
    ` : "", l = "", c = `
      #define round(value) newRound(value)
      int newRound(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 newRound(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `) : (n = "", t = "attribute", e = "varying", s = "varying", o = "texture2D", r = "gl_FragColor", i6 = "", a = `
      #define isnan(value) isnan_custom(value)
      bool isnan_custom(float val) {
        return (val > 0. || val < 1. || val == 0.) ? false : true;
      }
      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));
      }
    `, l = `
      uniform float INFINITY;

      bool isinf(float val) {
        return abs(val) == INFINITY;
      }
      bvec4 isinf(vec4 val) {
        return equal(abs(val), vec4(INFINITY));
      }
    `, c = `
      int round(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 round(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `), {
    version: n,
    attribute: t,
    varyingVs: e,
    varyingFs: s,
    texture2D: o,
    output: r,
    defineOutput: i6,
    defineSpecialNaN: a,
    defineSpecialInf: l,
    defineRound: c
  };
}
function Po(n, t, e = "index") {
  const s = dt(t);
  return s.map((o, r) => {
    const i6 = `int ${n[r]} = ${e} / ${o}`, a = r === s.length - 1 ? `int ${n[r + 1]} = ${e} - ${n[r]} * ${o}` : `index -= ${n[r]} * ${o}`;
    return `${i6}; ${a};`;
  }).join("");
}
function du(n, t, e = "index") {
  const s = dt(t);
  return s.map((o, r) => {
    const i6 = `int ${n[r]} = ${e} / outShapeStrides[${r}]`, a = r === s.length - 1 ? `int ${n[r + 1]} = ${e} - ${n[r]} * outShapeStrides[${r}]` : `index -= ${n[r]} * outShapeStrides[${r}]`;
    return `${i6}; ${a};`;
  }).join("");
}
function Lz(n, t) {
  const e = n.length, s = n.map((r) => `${t}[${r}]`), o = new Array(e - 1);
  o[e - 2] = s[e - 1];
  for (let r = e - 3; r >= 0; --r)
    o[r] = `(${o[r + 1]} * ${s[r + 1]})`;
  return o;
}
function Mz(n, t, e = "index") {
  const s = n.map((r, i6) => i6), o = Lz(s, t);
  return o.map((r, i6) => {
    const a = `int ${n[i6]} = ${e} / ${o[i6]}`, l = i6 === o.length - 1 ? `int ${n[i6 + 1]} = ${e} - ${n[i6]} * ${o[i6]}` : `index -= ${n[i6]} * ${o[i6]}`;
    return `${a}; ${l};`;
  }).join("");
}
function Vf(n) {
  const t = dt(n).map((e) => e.toString());
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * ${t[0]} + coords.y * ${t[1]} + coords.z;
  }
`;
}
function zf() {
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;
  }
`;
}
var vw = `
  const float FLOAT_MAX = 1.70141184e38;
  const float FLOAT_MIN = 1.17549435e-38;

  lowp vec4 encode_float(highp float v) {
    if (isnan(v)) {
      return vec4(255, 255, 255, 255);
    }

    highp float av = abs(v);

    if(av < FLOAT_MIN) {
      return vec4(0.0, 0.0, 0.0, 0.0);
    } else if(v > FLOAT_MAX) {
      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;
    } else if(v < -FLOAT_MAX) {
      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;
    }

    highp vec4 c = vec4(0,0,0,0);

    highp float e = floor(log2(av));
    highp float m = exp2(fract(log2(av))) - 1.0;

    c[2] = floor(128.0 * m);
    m -= c[2] / 128.0;
    c[1] = floor(32768.0 * m);
    m -= c[1] / 32768.0;
    c[0] = floor(8388608.0 * m);

    highp float ebias = e + 127.0;
    c[3] = floor(ebias / 2.0);
    ebias -= c[3] * 2.0;
    c[2] += floor(ebias) * 128.0;

    c[3] += 128.0 * step(0.0, -v);

    return c / 255.0;
  }
`;
var { getBroadcastDims: Sw } = cR;
function Wz(n, t, e) {
  const s = [];
  if (n.forEach((p6) => {
    const f = O(p6.shapeInfo.logicalShape);
    if (p6.shapeInfo.isUniform ? s.push(`uniform float ${p6.name}${f > 1 ? `[${f}]` : ""};`) : (s.push(`uniform sampler2D ${p6.name};`), s.push(`uniform int offset${p6.name};`)), e.enableShapeUniforms) {
      const { uniformShape: m } = Xf(e.packedInputs, p6.shapeInfo.logicalShape, p6.shapeInfo.texShape);
      switch (m.length) {
        case 1:
          s.push(`uniform int ${p6.name}Shape;`);
          break;
        case 2:
          s.push(`uniform ivec2 ${p6.name}Shape;`);
          break;
        case 3:
          s.push(`uniform ivec3 ${p6.name}Shape;`);
          break;
        case 4:
          s.push(`uniform ivec4 ${p6.name}Shape;`);
          break;
      }
      s.push(`uniform ivec2 ${p6.name}TexShape;`);
    }
  }), e.enableShapeUniforms) {
    switch (t.logicalShape.length) {
      case 1:
        s.push("uniform int outShape;");
        break;
      case 2:
        s.push("uniform ivec2 outShape;"), s.push("uniform int outShapeStrides;");
        break;
      case 3:
        s.push("uniform ivec3 outShape;"), s.push("uniform ivec2 outShapeStrides;");
        break;
      case 4:
        s.push("uniform ivec4 outShape;"), s.push("uniform ivec3 outShapeStrides;");
        break;
    }
    s.push("uniform ivec2 outTexShape;");
  }
  e.customUniforms && e.customUniforms.forEach((p6) => {
    s.push(`uniform ${p6.type} ${p6.name}${p6.arrayIndex ? `[${p6.arrayIndex}]` : ""};`);
  });
  const o = s.join(`
`), r = n.map((p6) => Dz(p6, t, e.packedInputs, e.enableShapeUniforms)).join(`
`), i6 = t.texShape, a = ze(), l = zz(a);
  let c, u, d = Az(a);
  return t.isPacked ? (c = Fz(t.logicalShape, i6, e.enableShapeUniforms), u = Pz(a)) : (c = Vz(t.logicalShape, i6, e.enableShapeUniforms), u = Xz(a)), e.packedInputs && (d += Bz), [
    d,
    l,
    u,
    o,
    c,
    r,
    e.userCode
  ].join(`
`);
}
function Tr(n, t = false) {
  const e = n.shapeInfo.logicalShape;
  switch (e.length) {
    case 0:
      return sX(n, t);
    case 1:
      return rX(n, t);
    case 2:
      return aX(n, t);
    case 3:
      return cX(n, t);
    case 4:
      return dX(n, t);
    case 5:
      return hX(n);
    case 6:
      return pX(n);
    default:
      throw new Error(`${e.length}-D input sampling is not yet supported`);
  }
}
function kw(n, t) {
  switch (n.shapeInfo.logicalShape.length) {
    case 0:
      return nX(n);
    case 1:
      return oX(n, t);
    case 2:
      return iX(n, t);
    case 3:
      return lX(n, t);
    default:
      return uX(n, t);
  }
}
function Dz(n, t, e = false, s) {
  let o = "";
  e ? o += kw(n, s) : o += Tr(n, s);
  const r = n.shapeInfo.logicalShape, i6 = t.logicalShape;
  return r.length <= i6.length && (e ? o += fX(n, t) : o += mX(n, t)), o;
}
function Fz(n, t, e) {
  switch (n.length) {
    case 0:
      return Tw();
    case 1:
      return Hz(n, t, e);
    case 2:
      return tX(n, t, e);
    case 3:
      return Uz(n, t, e);
    default:
      return Qz(n, t, e);
  }
}
function Vz(n, t, e) {
  switch (n.length) {
    case 0:
      return Tw();
    case 1:
      return _z(n, t, e);
    case 2:
      return eX(n, t, e);
    case 3:
      return Yz(n, t, e);
    case 4:
      return Jz(n, t, e);
    case 5:
      return jz(n, t);
    case 6:
      return qz(n, t);
    default:
      throw new Error(`${n.length}-D output sampling is not yet supported`);
  }
}
function zz(n) {
  return `
    float sampleTexture(sampler2D textureSampler, vec2 uv) {
      return ${n.texture2D}(textureSampler, uv).r;
    }
  `;
}
function Xz(n) {
  return `
    void setOutput(float val) {
      ${n.output} = vec4(val, 0, 0, 0);
    }
  `;
}
function Pz(n) {
  return `
    void setOutput(vec4 val) {
      ${n.output} = val;
    }
  `;
}
function Az(n) {
  return `${n.version}
    precision highp float;
    precision highp int;
    precision highp sampler2D;
    ${n.varyingFs} vec2 resultUV;
    ${n.defineOutput}
    const vec2 halfCR = vec2(0.5, 0.5);

    struct ivec5
    {
      int x;
      int y;
      int z;
      int w;
      int u;
    };

    struct ivec6
    {
      int x;
      int y;
      int z;
      int w;
      int u;
      int v;
    };

    uniform float NAN;
    ${n.defineSpecialNaN}
    ${n.defineSpecialInf}
    ${n.defineRound}

    int imod(int x, int y) {
      return x - y * (x / y);
    }

    int idiv(int a, int b, float sign) {
      int res = a / b;
      int mod = imod(a, b);
      if (sign < 0. && mod != 0) {
        res -= 1;
      }
      return res;
    }

    //Based on the work of Dave Hoskins
    //https://www.shadertoy.com/view/4djSRW
    #define HASHSCALE1 443.8975
    float random(float seed){
      vec2 p = resultUV * seed;
      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);
      p3 += dot(p3, p3.yzx + 19.19);
      return fract((p3.x + p3.y) * p3.z);
    }

    ${Oz}
    ${Kz}
    ${Zz}
  `;
}
var Oz = `
vec2 uvFromFlat(int texNumR, int texNumC, int index) {
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
vec2 packedUVfrom1D(int texNumR, int texNumC, int index) {
  int texelIndex = index / 2;
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var Kz = `
vec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,
  int texNumC, int row, int col) {
  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var Zz = `
vec2 packedUVfrom3D(int texNumR, int texNumC,
    int texelsInBatch, int texelsInLogicalRow, int b,
    int row, int col) {
  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var Bz = `
  float getChannel(vec4 frag, vec2 innerDims) {
    vec2 modCoord = mod(innerDims, 2.);
    return modCoord.x == 0. ?
      (modCoord.y == 0. ? frag.r : frag.g) :
      (modCoord.y == 0. ? frag.b : frag.a);
  }
  float getChannel(vec4 frag, int dim) {
    float modCoord = mod(float(dim), 2.);
    return modCoord == 0. ? frag.r : frag.g;
  }
`;
function Tw() {
  return `
    int getOutputCoords() {
      return 0;
    }
  `;
}
function Hz(n, t, e) {
  const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
  return s[0] === 1 ? e ? `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));
      }
    ` : `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ${s[1]}.0);
      }
    ` : s[1] === 1 ? e ? `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));
      }
    ` : `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ${s[0]}.0);
      }
    ` : e ? `
    int getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);
    }
  ` : `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${s[0]}, ${s[1]}));
      return 2 * (resTexRC.x * ${s[1]} + resTexRC.y);
    }
  `;
}
function _z(n, t, e) {
  return t[0] === 1 ? e ? `
      int getOutputCoords() {
        return int(resultUV.x * float(outTexShape[1]));
      }
    ` : `
      int getOutputCoords() {
        return int(resultUV.x * ${t[1]}.0);
      }
    ` : t[1] === 1 ? e ? `
      int getOutputCoords() {
        return int(resultUV.y * float(outTexShape[0]));
      }
    ` : `
      int getOutputCoords() {
        return int(resultUV.y * ${t[0]}.0);
      }
    ` : e ? `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      return resTexRC.x * outTexShape[1] + resTexRC.y;
    }
  ` : `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t[0]}, ${t[1]}));
      return resTexRC.x * ${t[1]} + resTexRC.y;
    }
  `;
}
function Uz(n, t, e) {
  if (e)
    return `
    ivec3 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec3(b, r, c);
    }
  `;
  const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)], o = Math.ceil(n[2] / 2), r = o * Math.ceil(n[1] / 2);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${s[0]}, ${s[1]}));
      int index = resTexRC.x * ${s[1]} + resTexRC.y;

      int b = index / ${r};
      index -= b * ${r};

      int r = 2 * (index / ${o});
      int c = imod(index, ${o}) * 2;

      return ivec3(b, r, c);
    }
  `;
}
function Yz(n, t, e) {
  if (e)
    return `
  ivec3 getOutputCoords() {
    ivec2 resTexRC = ivec2(resultUV.yx *
                           vec2(outTexShape[0], outTexShape[1]));
    int index = resTexRC.x * outTexShape[1] + resTexRC.y;
    ${du(["r", "c", "d"], n)}
    return ivec3(r, c, d);
  }
`;
  const s = Po(["r", "c", "d"], n);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t[0]}, ${t[1]}));
      int index = resTexRC.x * ${t[1]} + resTexRC.y;
      ${s}
      return ivec3(r, c, d);
    }
  `;
}
function Qz(n, t, e) {
  if (e)
    return `
    ivec4 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatchN = texelsInBatch * outShape[1];

      int b2 = index / texelsInBatchN;
      index -= b2 * texelsInBatchN;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec4(b2, b, r, c);
    }
  `;
  const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)], o = Math.ceil(n[n.length - 1] / 2), r = o * Math.ceil(n[n.length - 2] / 2);
  let i6 = r, a = "", l = "b, r, c";
  for (let c = 2; c < n.length - 1; c++)
    i6 *= n[n.length - c - 1], a = `
      int b${c} = index / ${i6};
      index -= b${c} * ${i6};
    ` + a, l = `b${c}, ` + l;
  return `
    ivec${n.length} getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${s[0]}, ${s[1]}));
      int index = resTexRC.x * ${s[1]} + resTexRC.y;

      ${a}

      int b = index / ${r};
      index -= b * ${r};

      int r = 2 * (index / ${o});
      int c = imod(index, ${o}) * 2;

      return ivec${n.length}(${l});
    }
  `;
}
function Jz(n, t, e) {
  if (e)
    return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      ${du(["r", "c", "d", "d2"], n)}
      return ivec4(r, c, d, d2);
    }
  `;
  const s = Po(["r", "c", "d", "d2"], n);
  return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${t[0]}, ${t[1]}));
      int index = resTexRC.x * ${t[1]} + resTexRC.y;
      ${s}
      return ivec4(r, c, d, d2);
    }
  `;
}
function jz(n, t) {
  const e = Po(["r", "c", "d", "d2", "d3"], n);
  return `
    ivec5 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${t[0]},
                             ${t[1]}));

      int index = resTexRC.x * ${t[1]} + resTexRC.y;

      ${e}

      ivec5 outShape = ivec5(r, c, d, d2, d3);
      return outShape;
    }
  `;
}
function qz(n, t) {
  const e = Po(["r", "c", "d", "d2", "d3", "d4"], n);
  return `
    ivec6 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${t[0]}, ${t[1]}));
      int index = resTexRC.x * ${t[1]} + resTexRC.y;

      ${e}

      ivec6 result = ivec6(r, c, d, d2, d3, d4);
      return result;
    }
  `;
}
function tX(n, t, e) {
  const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
  if (Rt(n, t))
    return e ? `
      ivec2 getOutputCoords() {
        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));
      }
    ` : `
      ivec2 getOutputCoords() {
        return 2 * ivec2(resultUV.yx * vec2(${s[0]}, ${s[1]}));
      }
    `;
  const o = Math.ceil(n[1] / 2);
  return e ? `
    ivec2 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));

      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;
      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec2(r, c);
    }
  ` : `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${s[0]}, ${s[1]}));

      int index = resTexRC.x * ${s[1]} + resTexRC.y;
      int r = 2 * (index / ${o});
      int c = imod(index, ${o}) * 2;

      return ivec2(r, c);
    }
  `;
}
function eX(n, t, e) {
  return Rt(n, t) ? e ? `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));
      }
    ` : `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(${t[0]}, ${t[1]}));
      }
    ` : n[1] === 1 ? e ? `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(index, 0);
      }
    ` : `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${t[0]}, ${t[1]}));
        int index = resTexRC.x * ${t[1]} + resTexRC.y;
        return ivec2(index, 0);
      }
    ` : n[0] === 1 ? e ? `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(0, index);
      }
    ` : `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${t[0]}, ${t[1]}));
        int index = resTexRC.x * ${t[1]} + resTexRC.y;
        return ivec2(0, index);
      }
    ` : e ? `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      int r = index / outShape[1];
      int c = index - r * outShape[1];
      return ivec2(r, c);
    }
  ` : `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t[0]}, ${t[1]}));
      int index = resTexRC.x * ${t[1]} + resTexRC.y;
      int r = index / ${n[1]};
      int c = index - r * ${n[1]};
      return ivec2(r, c);
    }
  `;
}
function Ao(n) {
  return `offset${n}`;
}
function nX(n) {
  const t = n.name, e = "get" + t.charAt(0).toUpperCase() + t.slice(1), s = ze();
  return `
    vec4 ${e}() {
      return ${s.texture2D}(${t}, halfCR);
    }
  `;
}
function sX(n, t) {
  const e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1);
  if (n.shapeInfo.isUniform)
    return `float ${s}() {return ${e};}`;
  const [o, r] = n.shapeInfo.texShape;
  if (o === 1 && r === 1)
    return `
      float ${s}() {
        return sampleTexture(${e}, halfCR);
      }
    `;
  const i6 = Ao(e);
  if (t)
    return `
    float ${s}() {
      vec2 uv = uvFromFlat(${e}TexShape[0], ${e}TexShape[1], ${i6});
      return sampleTexture(${e}, uv);
    }
  `;
  const [a, l] = n.shapeInfo.texShape;
  return `
    float ${s}() {
      vec2 uv = uvFromFlat(${a}, ${l}, ${i6});
      return sampleTexture(${e}, uv);
    }
  `;
}
function oX(n, t) {
  const e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1), o = n.shapeInfo.texShape, r = ze();
  if (t)
    return `
    vec4 ${s}(int index) {
      ivec2 packedTexShape = ivec2(ceil(float(${e}TexShape[0]) / 2.0), ceil(float(${e}TexShape[1]) / 2.0));
      vec2 uv = packedUVfrom1D(
        packedTexShape[0], packedTexShape[1], index);
      return ${r.texture2D}(${e}, uv);
    }
  `;
  const i6 = [Math.ceil(o[0] / 2), Math.ceil(o[1] / 2)];
  return `
    vec4 ${s}(int index) {
      vec2 uv = packedUVfrom1D(
        ${i6[0]}, ${i6[1]}, index);
      return ${r.texture2D}(${e}, uv);
    }
  `;
}
function rX(n, t) {
  const e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1);
  if (n.shapeInfo.isUniform)
    return `
      float ${s}(int index) {
        ${Nr(n)}
      }
    `;
  const o = n.shapeInfo.texShape, r = o[0], i6 = o[1];
  if (i6 === 1 && r === 1)
    return `
      float ${s}(int index) {
        return sampleTexture(${e}, halfCR);
      }
    `;
  const a = Ao(e);
  return i6 === 1 ? t ? `
      float ${s}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${a}) + 0.5) / float(${e}TexShape[0]));
        return sampleTexture(${e}, uv);
      }
    ` : `
      float ${s}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${a}) + 0.5) / ${r}.0);
        return sampleTexture(${e}, uv);
      }
    ` : r === 1 ? t ? `
      float ${s}(int index) {
        vec2 uv = vec2((float(index + ${a}) + 0.5) / float(${e}TexShape[1]), 0.5);
        return sampleTexture(${e}, uv);
      }
    ` : `
      float ${s}(int index) {
        vec2 uv = vec2((float(index + ${a}) + 0.5) / ${i6}.0, 0.5);
        return sampleTexture(${e}, uv);
      }
    ` : t ? `
    float ${s}(int index) {
      vec2 uv = uvFromFlat(${e}TexShape[0], ${e}TexShape[1], index + ${a});
      return sampleTexture(${e}, uv);
    }
  ` : `
    float ${s}(int index) {
      vec2 uv = uvFromFlat(${r}, ${i6}, index + ${a});
      return sampleTexture(${e}, uv);
    }
  `;
}
function iX(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = n.shapeInfo.texShape, i6 = r[0], a = r[1], l = ze();
  if (r != null && Rt(e, r))
    return t ? `
      vec4 ${o}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);

        return ${l.texture2D}(${s}, uv);
      }
    ` : `
      vec4 ${o}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${a}.0, ${i6}.0);

        return ${l.texture2D}(${s}, uv);
      }
    `;
  if (t)
    return `
    vec4 ${o}(int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${s}TexShape[0]) / 2.0), ceil(float(${s}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${s}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);
      return ${l.texture2D}(${s}, uv);
    }
  `;
  const c = [Math.ceil(r[0] / 2), Math.ceil(r[1] / 2)], u = Math.ceil(e[1] / 2);
  return `
    vec4 ${o}(int row, int col) {
      vec2 uv = packedUVfrom2D(${u}, ${c[0]}, ${c[1]}, row, col);
      return ${l.texture2D}(${s}, uv);
    }
  `;
}
function aX(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = n.shapeInfo.texShape;
  if (r != null && Rt(e, r)) {
    if (t)
      return `
      float ${o}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    `;
    const h6 = r[0], p6 = r[1];
    return `
    float ${o}(int row, int col) {
      vec2 uv = (vec2(col, row) + halfCR) / vec2(${p6}.0, ${h6}.0);
      return sampleTexture(${s}, uv);
    }
  `;
  }
  const { newShape: i6, keptDims: a } = gs(e), l = i6;
  if (l.length < e.length) {
    const h6 = Rr(n, l), p6 = ["row", "col"];
    return `
      ${Tr(h6, t)}
      float ${o}(int row, int col) {
        return ${o}(${$r(p6, a)});
      }
    `;
  }
  if (n.shapeInfo.isUniform)
    return `
      float ${o}(int row, int col) {
        int index = round(dot(vec2(row, col), vec2(${e[1]}, 1)));
        ${Nr(n)}
      }
    `;
  const c = r[0], u = r[1], d = Ao(s);
  return u === 1 ? t ? `
      float ${o}(int row, int col) {
        float index = dot(vec3(row, col, ${d}), vec3(${s}Shape[1], 1, 1));
        vec2 uv = vec2(0.5, (index + 0.5) / float(${s}TexShape[0]));
        return sampleTexture(${s}, uv);
      }
    ` : `
    float ${o}(int row, int col) {
      float index = dot(vec3(row, col, ${d}), vec3(${e[1]}, 1, 1));
      vec2 uv = vec2(0.5, (index + 0.5) / ${c}.0);
      return sampleTexture(${s}, uv);
    }
  ` : c === 1 ? t ? `
      float ${o}(int row, int col) {
        float index = dot(vec3(row, col, ${d}), vec3(${s}Shape[1], 1, 1));
        vec2 uv = vec2((index + 0.5) / float(${s}TexShape[1]), 0.5);
        return sampleTexture(${s}, uv);
      }
    ` : `
    float ${o}(int row, int col) {
      float index = dot(vec3(row, col, ${d}), vec3(${e[1]}, 1, 1));
      vec2 uv = vec2((index + 0.5) / ${u}.0, 0.5);
      return sampleTexture(${s}, uv);
    }
  ` : t ? `
      float ${o}(int row, int col) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${s}Shape[1] + col + ${d};
        vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index);
        return sampleTexture(${s}, uv);
      }
    ` : `
  float ${o}(int row, int col) {
    // Explicitly use integer operations as dot() only works on floats.
    int index = row * ${e[1]} + col + ${d};
    vec2 uv = uvFromFlat(${c}, ${u}, index);
    return sampleTexture(${s}, uv);
  }
`;
}
function lX(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = n.shapeInfo.texShape, i6 = [Math.ceil(r[0] / 2), Math.ceil(r[1] / 2)];
  if (e[0] === 1) {
    const h6 = e.slice(1), p6 = [1, 2], f = Rr(n, h6), m = ["b", "row", "col"];
    return `
        ${kw(f, t)}
        vec4 ${o}(int b, int row, int col) {
          return ${o}(${$r(m, p6)});
        }
      `;
  }
  const a = ze();
  if (t)
    return `
    vec4 ${o}(int b, int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${s}TexShape[0]) / 2.0), ceil(float(${s}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${s}Shape[2]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${s}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom3D(
        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);
      return ${a.texture2D}(${s}, uv);
    }
  `;
  const l = i6[0], c = i6[1], u = Math.ceil(e[2] / 2), d = u * Math.ceil(e[1] / 2);
  return `
    vec4 ${o}(int b, int row, int col) {
      vec2 uv = packedUVfrom3D(
        ${l}, ${c}, ${d}, ${u}, b, row, col);
      return ${a.texture2D}(${s}, uv);
    }
  `;
}
function cX(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = e[1] * e[2], i6 = e[2], { newShape: a, keptDims: l } = gs(e), c = a;
  if (c.length < e.length) {
    const m = Rr(n, c), g6 = ["row", "col", "depth"];
    return `
        ${Tr(m, t)}
        float ${o}(int row, int col, int depth) {
          return ${o}(${$r(g6, l)});
        }
      `;
  }
  if (n.shapeInfo.isUniform)
    return `
      float ${o}(int row, int col, int depth) {
        int index = round(dot(vec3(row, col, depth),
                          vec3(${r}, ${i6}, 1)));
        ${Nr(n)}
      }
    `;
  const u = n.shapeInfo.texShape, d = u[0], h6 = u[1], p6 = n.shapeInfo.flatOffset;
  if (h6 === r && p6 == null)
    return t ? `
      float ${o}(int row, int col, int depth) {
        int stride1 = ${s}Shape[2];
        float texR = float(row);
        float texC = dot(vec2(col, depth), vec2(stride1, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    ` : `
        float ${o}(int row, int col, int depth) {
          float texR = float(row);
          float texC = dot(vec2(col, depth), vec2(${i6}, 1));
          vec2 uv = (vec2(texC, texR) + halfCR) /
                     vec2(${h6}.0, ${d}.0);
          return sampleTexture(${s}, uv);
        }
      `;
  if (h6 === i6 && p6 == null)
    return t ? `
      float ${o}(int row, int col, int depth) {
        float texR = dot(vec2(row, col), vec2(${s}Shape[1], 1));
        float texC = float(depth);
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    ` : `
    float ${o}(int row, int col, int depth) {
      float texR = dot(vec2(row, col), vec2(${e[1]}, 1));
      float texC = float(depth);
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${h6}.0, ${d}.0);
      return sampleTexture(${s}, uv);
    }
  `;
  const f = Ao(s);
  return t ? `
    float ${o}(int row, int col, int depth) {
      // Explicitly use integer operations as dot() only works on floats.
      int stride0 = ${s}Shape[1] * ${s}Shape[2];
      int stride1 = ${s}Shape[2];
      int index = row * stride0 + col * stride1 + depth + ${f};
      vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index);
      return sampleTexture(${s}, uv);
    }
    ` : `
      float ${o}(int row, int col, int depth) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${r} + col * ${i6} + depth + ${f};
        vec2 uv = uvFromFlat(${d}, ${h6}, index);
        return sampleTexture(${s}, uv);
      }
  `;
}
function uX(n, t) {
  const e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1), o = ze();
  if (t)
    return `
    vec4 ${s}(int b2, int b, int row, int col) {
      int valuesPerRow = int(ceil(float(${e}Shape[3]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${e}Shape[2]) / 2.0));
      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);
      texelsInBatch *= ${e}Shape[1];
      index = b2 * texelsInBatch + index;
      ivec2 packedTexShape = ivec2(ceil(float(${e}TexShape[0]) / 2.0), ceil(float(${e}TexShape[1]) / 2.0));
      int texR = index / packedTexShape[1];
      int texC = index - texR * packedTexShape[1];
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${o.texture2D}(${e}, uv);
    }
  `;
  const r = n.shapeInfo.logicalShape, i6 = r.length, a = n.shapeInfo.texShape, l = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)], c = l[0], u = l[1], d = Math.ceil(r[i6 - 1] / 2);
  let h6 = d * Math.ceil(r[i6 - 2] / 2), p6 = "int b, int row, int col", f = `b * ${h6} + (row / 2) * ${d} + (col / 2)`;
  for (let m = 2; m < i6 - 1; m++)
    p6 = `int b${m}, ` + p6, h6 *= r[i6 - m - 1], f = `b${m} * ${h6} + ` + f;
  return `
    vec4 ${s}(${p6}) {
      int index = ${f};
      int texR = index / ${u};
      int texC = index - texR * ${u};
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${u}, ${c});
      return ${o.texture2D}(${e}, uv);
    }
  `;
}
function dX(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = e[3], i6 = e[2] * r, a = e[1] * i6, { newShape: l, keptDims: c } = gs(e);
  if (l.length < e.length) {
    const x6 = Rr(n, l), w6 = ["row", "col", "depth", "depth2"];
    return `
      ${Tr(x6, t)}
      float ${o}(int row, int col, int depth, int depth2) {
        return ${o}(${$r(w6, c)});
      }
    `;
  }
  if (n.shapeInfo.isUniform)
    return `
      float ${o}(int row, int col, int depth, int depth2) {
        int index = round(dot(vec4(row, col, depth, depth2),
                          vec4(${a}, ${i6}, ${r}, 1)));
        ${Nr(n)}
      }
    `;
  const u = n.shapeInfo.flatOffset, d = n.shapeInfo.texShape, h6 = d[0], p6 = d[1], f = `int stride2 = ${s}Shape[3];`, m = `int stride1 = ${s}Shape[2] * stride2;`, g6 = `int stride0 = ${s}Shape[1] * stride1;`;
  if (p6 === a && u == null)
    return t ? `
      float ${o}(int row, int col, int depth, int depth2) {
        ${f}
        ${m}
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(stride1, stride2, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    ` : `
      float ${o}(int row, int col, int depth, int depth2) {
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(${i6}, ${r}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${p6}.0, ${h6}.0);
        return sampleTexture(${s}, uv);
      }
    `;
  if (p6 === r && u == null)
    return t ? `
      float ${o}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${s}Shape[1] * ${s}Shape[2], ${s}Shape[2], 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    ` : `
      float ${o}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${e[1] * e[2]}, ${e[2]}, 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${p6}.0, ${h6}.0);
        return sampleTexture(${s}, uv);
      }
    `;
  const b6 = Ao(s);
  return t ? `
    float ${o}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      ${f}
      ${m}
      ${g6}
      int index = row * stride0 + col * stride1 +
          depth * stride2 + depth2;
      vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index + ${b6});
      return sampleTexture(${s}, uv);
    }
  ` : `
    float ${o}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${a} + col * ${i6} +
          depth * ${r} + depth2;
      vec2 uv = uvFromFlat(${h6}, ${p6}, index + ${b6});
      return sampleTexture(${s}, uv);
    }
  `;
}
function hX(n) {
  const t = n.shapeInfo.logicalShape, e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1), o = t[4], r = t[3] * o, i6 = t[2] * r, a = t[1] * i6, { newShape: l, keptDims: c } = gs(t);
  if (l.length < t.length) {
    const m = Rr(n, l), g6 = ["row", "col", "depth", "depth2", "depth3"];
    return `
      ${Tr(m)}
      float ${s}(int row, int col, int depth, int depth2, int depth3) {
        return ${s}(${$r(g6, c)});
      }
    `;
  }
  if (n.shapeInfo.isUniform)
    return `
      float ${s}(int row, int col, int depth, int depth2, int depth3) {
        float index = dot(
          vec4(row, col, depth, depth2),
          vec4(${a}, ${i6}, ${r}, ${o})) +
          depth3;
        ${Nr(n)}
      }
    `;
  const u = n.shapeInfo.flatOffset, d = n.shapeInfo.texShape, h6 = d[0], p6 = d[1];
  if (p6 === a && u == null)
    return `
      float ${s}(int row, int col, int depth, int depth2, int depth3) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
                         vec4(${i6}, ${r}, ${o}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${p6}.0, ${h6}.0);
        return sampleTexture(${e}, uv);
      }
    `;
  if (p6 === o && u == null)
    return `
      float ${s}(int row, int col, int depth, int depth2, int depth3) {
        float texR = dot(
          vec4(row, col, depth, depth2),
          vec4(${t[1] * t[2] * t[3]},
               ${t[2] * t[3]}, ${t[3]}, 1));
        int texC = depth3;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${p6}.0, ${h6}.0);
        return sampleTexture(${e}, uv);
      }
    `;
  const f = Ao(e);
  return `
    float ${s}(int row, int col, int depth, int depth2, int depth3) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${a} + col * ${i6} + depth * ${r} +
          depth2 * ${o} + depth3 + ${f};
      vec2 uv = uvFromFlat(${h6}, ${p6}, index);
      return sampleTexture(${e}, uv);
    }
  `;
}
function pX(n) {
  const t = n.shapeInfo.logicalShape, e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1), { newShape: o, keptDims: r } = gs(t);
  if (o.length < t.length) {
    const g6 = Rr(n, o), b6 = ["row", "col", "depth", "depth2", "depth3", "depth4"];
    return `
      ${Tr(g6)}
      float ${s}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        return ${s}(${$r(b6, r)});
      }
    `;
  }
  const i6 = t[5], a = t[4] * i6, l = t[3] * a, c = t[2] * l, u = t[1] * c;
  if (n.shapeInfo.isUniform)
    return `
      float ${s}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
        int index = round(dot(
          vec4(row, col, depth, depth2),
          vec4(${u}, ${c}, ${l}, ${a})) +
          dot(
            vec2(depth3, depth4),
            vec2(${i6}, 1)));
        ${Nr(n)}
      }
    `;
  const d = n.shapeInfo.flatOffset, h6 = n.shapeInfo.texShape, p6 = h6[0], f = h6[1];
  if (f === u && d == null)
    return `
      float ${s}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
          vec4(${c}, ${l}, ${a}, ${i6})) +
               float(depth4);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${f}.0, ${p6}.0);
        return sampleTexture(${e}, uv);
      }
    `;
  if (f === i6 && d == null)
    return `
      float ${s}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        float texR = dot(vec4(row, col, depth, depth2),
          vec4(${t[1] * t[2] * t[3] * t[4]},
               ${t[2] * t[3] * t[4]},
               ${t[3] * t[4]},
               ${t[4]})) + float(depth3);
        int texC = depth4;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${f}.0, ${p6}.0);
        return sampleTexture(${e}, uv);
      }
    `;
  const m = Ao(e);
  return `
    float ${s}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${u} + col * ${c} + depth * ${l} +
          depth2 * ${a} + depth3 * ${i6} + depth4 + ${m};
      vec2 uv = uvFromFlat(${p6}, ${f}, index);
      return sampleTexture(${e}, uv);
    }
  `;
}
function Nr(n) {
  const t = n.name, e = O(n.shapeInfo.logicalShape);
  return e < 2 ? `return ${t};` : `
    for (int i = 0; i < ${e}; i++) {
      if (i == index) {
        return ${t}[i];
      }
    }
  `;
}
function fX(n, t) {
  const e = n.name, s = e.charAt(0).toUpperCase() + e.slice(1), o = "get" + s + "AtOutCoords", r = n.shapeInfo.logicalShape.length, i6 = t.logicalShape.length, a = Sw(n.shapeInfo.logicalShape, t.logicalShape), l = Kt(i6), c = i6 - r;
  let u;
  const d = ["x", "y", "z", "w", "u", "v"];
  r === 0 ? u = "" : i6 < 2 && a.length >= 1 ? u = "coords = 0;" : u = a.map((x6) => `coords.${d[x6 + c]} = 0;`).join(`
`);
  let h6 = "";
  i6 < 2 && r > 0 ? h6 = "coords" : h6 = n.shapeInfo.logicalShape.map((x6, w6) => `coords.${d[w6 + c]}`).join(", ");
  let p6 = "return outputValue;";
  const m = O(n.shapeInfo.logicalShape) === 1, b6 = O(t.logicalShape) === 1;
  if (r === 1 && !m && !b6)
    p6 = `
      return vec4(outputValue.xy, outputValue.xy);
    `;
  else if (m && !b6)
    i6 === 1 ? p6 = `
        return vec4(outputValue.x, outputValue.x, 0., 0.);
      ` : p6 = `
        return vec4(outputValue.x);
      `;
  else if (a.length) {
    const x6 = r - 2, w6 = r - 1;
    a.indexOf(x6) > -1 && a.indexOf(w6) > -1 ? p6 = "return vec4(outputValue.x);" : a.indexOf(x6) > -1 ? p6 = "return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);" : a.indexOf(w6) > -1 && (p6 = "return vec4(outputValue.xx, outputValue.zz);");
  }
  return `
    vec4 ${o}() {
      ${l} coords = getOutputCoords();
      ${u}
      vec4 outputValue = get${s}(${h6});
      ${p6}
    }
  `;
}
function mX(n, t) {
  const e = n.name, s = e.charAt(0).toUpperCase() + e.slice(1), o = "get" + s + "AtOutCoords", r = t.texShape, i6 = n.shapeInfo.texShape, a = n.shapeInfo.logicalShape.length, l = t.logicalShape.length;
  if (!n.shapeInfo.isUniform && a === l && n.shapeInfo.flatOffset == null && Rt(i6, r))
    return `
      float ${o}() {
        return sampleTexture(${e}, resultUV);
      }
    `;
  const c = Kt(l), u = Sw(n.shapeInfo.logicalShape, t.logicalShape), d = l - a;
  let h6;
  const p6 = ["x", "y", "z", "w", "u", "v"];
  a === 0 ? h6 = "" : l < 2 && u.length >= 1 ? h6 = "coords = 0;" : h6 = u.map((m) => `coords.${p6[m + d]} = 0;`).join(`
`);
  let f = "";
  return l < 2 && a > 0 ? f = "coords" : f = n.shapeInfo.logicalShape.map((m, g6) => `coords.${p6[g6 + d]}`).join(", "), `
    float ${o}() {
      ${c} coords = getOutputCoords();
      ${h6}
      return get${s}(${f});
    }
  `;
}
function Kt(n) {
  if (n <= 1)
    return "int";
  if (n === 2)
    return "ivec2";
  if (n === 3)
    return "ivec3";
  if (n === 4)
    return "ivec4";
  if (n === 5)
    return "ivec5";
  if (n === 6)
    return "ivec6";
  throw Error(`GPU for rank ${n} is not yet supported`);
}
function Xf(n, t, e) {
  const { newShape: s, keptDims: o } = gs(t), r = t.length, i6 = n && r === 3 && t[0] === 1, a = i6 ? t.slice(1) : s, l = !n && r > 1 && !Rt(t, e) && s.length < r || i6;
  return { useSqueezeShape: l, uniformShape: l ? a : t, keptDims: o };
}
function Rr(n, t) {
  const e = JSON.parse(JSON.stringify(n));
  return e.shapeInfo.logicalShape = t, e;
}
function $r(n, t) {
  return t.map((e) => n[e]).join(", ");
}
function gX(n, t, e, s) {
  const o = e.map((u, d) => {
    const h6 = {
      logicalShape: u.shape,
      texShape: u.isUniform ? null : u.texData.texShape,
      isUniform: u.isUniform,
      isPacked: u.isUniform ? false : u.texData.isPacked,
      flatOffset: null
    };
    return u.texData != null && u.texData.slice != null && u.texData.slice.flatOffset > 0 && (h6.flatOffset = u.texData.slice.flatOffset), { name: t.variableNames[d], shapeInfo: h6 };
  }), r = o.map((u) => u.shapeInfo), i6 = {
    logicalShape: s.shape,
    texShape: s.texData.texShape,
    isUniform: false,
    isPacked: s.texData.isPacked,
    flatOffset: null
  }, a = Wz(o, i6, t), l = cz(n.gl, a), c = n.createProgram(l);
  return F().get("ENGINE_COMPILE_ONLY") ? {
    program: t,
    fragmentShader: l,
    source: a,
    webGLProgram: c,
    inShapeInfos: r,
    outShapeInfo: i6,
    uniformLocations: null,
    customUniformLocations: null,
    infLoc: null,
    nanLoc: null,
    inShapesLocations: null,
    inTexShapesLocations: null,
    outShapeLocation: null,
    outShapeStridesLocation: null,
    outTexShapeLocation: null
  } : Object.assign({
    program: t,
    fragmentShader: l,
    source: a,
    webGLProgram: c,
    inShapeInfos: r,
    outShapeInfo: i6
  }, Nw(n, t, c));
}
function Nw(n, t, e) {
  const s = {}, o = {}, r = {}, i6 = [];
  let a, l, c, u = null, d = null;
  d = n.getUniformLocation(e, "NAN", false), F().getNumber("WEBGL_VERSION") === 1 && (u = n.getUniformLocation(e, "INFINITY", false));
  const h6 = false;
  for (let p6 = 0; p6 < t.variableNames.length; p6++) {
    const f = t.variableNames[p6];
    s[f] = n.getUniformLocation(e, f, h6), s[`offset${f}`] = n.getUniformLocation(e, `offset${f}`, h6), t.enableShapeUniforms && (o[`${f}Shape`] = n.getUniformLocation(e, `${f}Shape`, h6), r[`${f}TexShape`] = n.getUniformLocation(e, `${f}TexShape`, h6));
  }
  return t.enableShapeUniforms && (a = n.getUniformLocation(e, "outShape", h6), c = n.getUniformLocation(e, "outShapeStrides", h6), l = n.getUniformLocation(e, "outTexShape", h6)), t.customUniforms && t.customUniforms.forEach((p6, f) => {
    i6[f] = n.getUniformLocation(e, p6.name, h6);
  }), {
    uniformLocations: s,
    customUniformLocations: i6,
    infLoc: u,
    nanLoc: d,
    inShapesLocations: o,
    inTexShapesLocations: r,
    outShapeLocation: a,
    outShapeStridesLocation: c,
    outTexShapeLocation: l
  };
}
function qm(n, t) {
  if (n.length !== t.length)
    throw Error(`Binary was compiled with ${n.length} inputs, but was executed with ${t.length} inputs`);
  n.forEach((e, s) => {
    const o = e.logicalShape, r = t[s], i6 = r.shape;
    if (!Rt(o, i6))
      throw Error(`Binary was compiled with different shapes than the current args. Shapes ${o} and ${i6} must match`);
    if (e.isUniform && r.isUniform)
      return;
    const a = e.texShape, l = r.isUniform ? null : r.texData.texShape;
    if (!Rt(a, l))
      throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${a} and ${l} must match`);
  });
}
function bX(n, t, e, s, o) {
  t.program.enableShapeUniforms || (qm(t.inShapeInfos, e), qm([t.outShapeInfo], [s]));
  const r = s.texData.texture, i6 = s.texData.texShape;
  s.texData.isPacked ? n.setOutputPackedMatrixTexture(r.texture, i6[0], i6[1]) : n.setOutputMatrixTexture(r.texture, i6[0], i6[1]), n.setProgram(t.webGLProgram), F().getNumber("WEBGL_VERSION") === 1 && t.infLoc !== null && n.gl.uniform1f(t.infLoc, 1 / 0), t.nanLoc !== null && n.gl.uniform1f(t.nanLoc, NaN), e.forEach((l, c) => {
    const u = t.program.variableNames[c], d = t.uniformLocations[u], h6 = t.uniformLocations[`offset${u}`], p6 = t.inShapesLocations[`${u}Shape`], f = t.inTexShapesLocations[`${u}TexShape`];
    if (p6) {
      const { uniformShape: m } = Xf(t.program.packedInputs, l.shape, l.texData.texShape);
      switch (m.length) {
        case 1:
          n.gl.uniform1iv(p6, new Int32Array(m));
          break;
        case 2:
          n.gl.uniform2iv(p6, new Int32Array(m));
          break;
        case 3:
          n.gl.uniform3iv(p6, new Int32Array(m));
          break;
        case 4:
          n.gl.uniform4iv(p6, new Int32Array(m));
          break;
      }
    }
    if (f && n.gl.uniform2i(f, l.texData.texShape[0], l.texData.texShape[1]), d != null) {
      if (l.isUniform) {
        if (O(l.shape) < 2)
          n.gl.uniform1f(d, l.uniformValues[0]);
        else {
          let m = l.uniformValues;
          m instanceof Float32Array || (m = new Float32Array(m)), n.gl.uniform1fv(d, m);
        }
        return;
      }
      l.texData.slice != null && h6 != null && n.gl.uniform1i(h6, l.texData.slice.flatOffset), n.setInputMatrixTexture(l.texData.texture.texture, d, c);
    }
  });
  const a = t.outShapeLocation;
  if (a)
    switch (s.shape.length) {
      case 1:
        n.gl.uniform1iv(a, new Int32Array(s.shape));
        break;
      case 2:
        n.gl.uniform2iv(a, new Int32Array(s.shape));
        break;
      case 3:
        n.gl.uniform3iv(a, new Int32Array(s.shape));
        break;
      case 4:
        n.gl.uniform4iv(a, new Int32Array(s.shape));
        break;
    }
  if (t.outShapeStridesLocation) {
    const l = dt(s.shape);
    switch (s.shape.length) {
      case 2:
        n.gl.uniform1iv(t.outShapeStridesLocation, new Int32Array(l));
        break;
      case 3:
        n.gl.uniform2iv(t.outShapeStridesLocation, new Int32Array(l));
        break;
      case 4:
        n.gl.uniform3iv(t.outShapeStridesLocation, new Int32Array(l));
        break;
    }
  }
  t.outTexShapeLocation && n.gl.uniform2i(t.outTexShapeLocation, s.texData.texShape[0], s.texData.texShape[1]), t.program.customUniforms && o && t.program.customUniforms.forEach((l, c) => {
    const u = t.customUniformLocations[c], d = o[c];
    if (l.type === "float")
      n.gl.uniform1fv(u, d);
    else if (l.type === "vec2")
      n.gl.uniform2fv(u, d);
    else if (l.type === "vec3")
      n.gl.uniform3fv(u, d);
    else if (l.type === "vec4")
      n.gl.uniform4fv(u, d);
    else if (l.type === "int")
      n.gl.uniform1iv(u, d);
    else if (l.type === "ivec2")
      n.gl.uniform2iv(u, d);
    else if (l.type === "ivec3")
      n.gl.uniform3iv(u, d);
    else if (l.type === "ivec4")
      n.gl.uniform4iv(u, d);
    else
      throw Error(`uniform type ${l.type} is not supported yet.`);
  }), n.executeProgram();
}
function xX(n, t, e) {
  let s = "";
  t.concat(e).forEach((i6) => {
    const a = i6.texData != null && i6.texData.slice != null && i6.texData.slice.flatOffset > 0;
    if (n.enableShapeUniforms && !i6.isUniform) {
      const l = i6.texData.texShape, { useSqueezeShape: c, uniformShape: u, keptDims: d } = Xf(n.packedInputs, i6.shape, l);
      let h6 = "", p6 = "", f = "";
      if (u.length === 1 && n.packedInputs) {
        const I = [Math.ceil(l[0] / 2), Math.ceil(l[1] / 2)];
        h6 = `${I[0] > 1}_${I[1] > 1}`;
      } else if (u.length === 2 && !n.packedInputs)
        p6 = `${u[0] > 1}_${u[1] > 1}`;
      else if (u.length > 2 && !n.packedInputs) {
        const I = dt(u);
        f = `${I[0] === l[1]}_${I[I.length - 1] === l[1]}`;
      }
      const m = i6.shape.length, g6 = u.length === 2 && Rt(i6.shape, l), b6 = O(i6.shape) === 1, x6 = vo(i6.shape, e.shape), w6 = !n.packedInputs && m === e.shape.length && Rt(l, e.texData.texShape), y6 = n.packedInputs || u.length > 2 ? "" : `${l[0] > 1}_${l[1] > 1}`;
      s += `${m}_${w6}_${c ? d : ""}_${u.length}_${b6}_${x6}_${g6}_${h6}_${p6}_${f}_${y6}_${a}`;
    } else {
      const l = i6.isUniform ? "uniform" : i6.texData.texShape;
      s += `${i6.shape}_${l}_${a}`;
    }
  });
  const o = n.userCode;
  let r = n.constructor.name;
  return r += "_" + s + "_" + o + `${F().getNumber("WEBGL_VERSION")}`, r;
}
function Xe(n) {
  return F().getBool("WEBGL_USE_SHAPES_UNIFORMS") && n <= 4;
}
var yX = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.outPackingScheme = ii.DENSE, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    const e = ze();
    this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length), this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? du(["r", "c", "d"], t) : Po(["r", "c", "d"], t)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getA(rc.x, rc.y, rc.z);
        }

        ${e.output} = result;
      }
    `;
  }
};
var wX = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outPackingScheme = ii.DENSE, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    const e = ze();
    this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length), this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? du(["r", "c", "d"], t) : Po(["r", "c", "d"], t)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));
        }

        ${e.output} = result;
      }
    `;
  }
};
var IX = class {
  constructor(t) {
    this.variableNames = ["A"], this.outTexUsage = ln.DOWNLOAD;
    const e = ze();
    this.outputShape = t, this.userCode = `
      ${vw}

      void main() {
        float x = getAAtOutCoords();
        ${e.output} = encode_float(x);
      }
    `;
  }
};
var CX = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = false, this.outTexUsage = ln.DOWNLOAD;
    const e = ze();
    this.outputShape = t, this.userCode = `
      ${vw}

      void main() {
        ivec3 coords = getOutputCoords();
        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));
        ${e.output} = encode_float(x);
      }
    `;
  }
};
var vX = {
  R: 0,
  G: 1,
  B: 2,
  A: 3
};
var tg = class {
  constructor(t, e = false, s = "RGBA") {
    this.variableNames = ["A"], this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    const o = ze();
    this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length);
    let r = "result";
    e && (r = "floor(result * 255. + 0.5)");
    let i6 = "";
    for (let a = 0; a < s.length; a++) {
      const l = s[a];
      i6 += `
          if(offset == ${a}) {
            result = values[${vX[l]}];
          }`;
    }
    this.userCode = `
      ${this.enableShapeUniforms ? zf() : Vf(t)}

      void main() {
        ivec3 coords = getOutputCoords();
        int flatIndex = getFlatIndex(coords);
        float result = 0.;
        int offset = imod(flatIndex, ${s.length});

        flatIndex = idiv(flatIndex, ${s.length}, 1.);

        int r = flatIndex / texShape[1];
        if (r < texShape[0]) {
          int c = imod(flatIndex, texShape[1]);
          vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
          vec4 values = ${o.texture2D}(A, uv);
          ${i6}
        }
        ${o.output} = vec4(${r}, 0., 0., 0.);
      }
    `;
  }
};
var SX = class {
  constructor(t, e = false) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    const s = ze();
    this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length);
    let o = "", r = "result";
    e && (r = "floor(result * 255. + 0.5)");
    for (let i6 = 0; i6 <= 1; i6++)
      for (let a = 0; a <= 1; a++) {
        const l = i6 * 2 + a;
        o += `
          localCoords = coords;
          if(localCoords[2] + ${a} < ${this.enableShapeUniforms ? "outShape[2]" : `${t[2]}`}) {
          localCoords[2] += ${a};
          if (localCoords[1] + ${i6} < ${this.enableShapeUniforms ? "outShape[1]" : `${t[1]}`}) {
            localCoords[1] += ${i6};

            flatIndex = getFlatIndex(localCoords);
            offset = imod(flatIndex, 4);

            flatIndex = idiv(flatIndex, 4, 1.);

            int r = flatIndex / texShape[1];
            int c = imod(flatIndex, texShape[1]);
            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
            values = ${s.texture2D}(A, uv);

            if (offset == 0) {
              result[${l}] = values[0];
            } else if (offset == 1) {
              result[${l}] = values[1];
            } else if (offset == 2) {
              result[${l}] = values[2];
            } else {
              result[${l}] = values[3];
            }
          }
        }
        `;
      }
    this.userCode = `
        ${this.enableShapeUniforms ? zf() : Vf(t)}

        void main() {
          ivec3 coords = getOutputCoords();

          vec4 result = vec4(0.);
          int flatIndex, r, c, offset;
          ivec3 localCoords;
          vec2 uv;
          vec4 values;

          ${o}

          ${s.output} = ${r};
        }
    `;
  }
};
function kX(n) {
  const t = ze(), e = `${t.version}
    precision highp float;
    ${t.attribute} vec3 clipSpacePos;
    ${t.attribute} vec2 uv;
    ${t.varyingVs} vec2 resultUV;

    void main() {
      gl_Position = vec4(clipSpacePos, 1);
      resultUV = uv;
    }`;
  return lz(n, e);
}
function TX(n) {
  const t = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);
  return pz(n, t);
}
function NX(n) {
  const t = new Uint16Array([0, 1, 2, 2, 1, 3]);
  return fz(n, t);
}
function Ra(n, t, e, s, o, r) {
  gz(t, e);
  const i6 = mz(n), a = n.TEXTURE_2D;
  return ot(n, () => n.bindTexture(a, i6)), ot(n, () => n.texParameteri(a, n.TEXTURE_WRAP_S, n.CLAMP_TO_EDGE)), ot(n, () => n.texParameteri(a, n.TEXTURE_WRAP_T, n.CLAMP_TO_EDGE)), ot(n, () => n.texParameteri(a, n.TEXTURE_MIN_FILTER, n.NEAREST)), ot(n, () => n.texParameteri(a, n.TEXTURE_MAG_FILTER, n.NEAREST)), F().getNumber("WEBGL_VERSION") === 1 ? ot(n, () => n.texImage2D(a, 0, s, t, e, 0, o, r, null)) : ot(n, () => n.texStorage2D(a, 1, s, t, e)), ot(n, () => n.bindTexture(n.TEXTURE_2D, null)), { texture: i6, texShape: [e, t] };
}
function Rw(n) {
  return n.internalFormatFloat;
}
function RX(n, t, e, s) {
  const [o, r] = Ta(t, e);
  return Ra(n, o, r, Rw(s), s.textureFormatFloat, n.FLOAT);
}
function $w(n) {
  return n.internalFormatHalfFloat;
}
function $X(n, t, e, s) {
  const [o, r] = Ta(t, e);
  return Ra(n, o, r, $w(s), s.textureFormatFloat, s.textureTypeHalfFloat);
}
function Gw(n) {
  return n.downloadTextureFormat;
}
function GX(n, t, e, s) {
  const [o, r] = Ta(t, e);
  return Ra(n, o, r, Gw(s), n.RGBA, n.UNSIGNED_BYTE);
}
function Ew(n) {
  return n.internalFormatPackedFloat;
}
function EX(n, t, e, s) {
  const [o, r] = kr(t, e);
  return Ra(n, o, r, Ew(s), n.RGBA, n.FLOAT);
}
function Lw(n) {
  return n.internalFormatPackedHalfFloat;
}
function LX(n, t, e, s) {
  const [o, r] = kr(t, e);
  return Ra(n, o, r, Lw(s), n.RGBA, s.textureTypeHalfFloat);
}
function MX(n, t, e) {
  return ot(n, () => n.bindBuffer(n.ARRAY_BUFFER, e)), Qm(n, t, "clipSpacePos", e, 3, 20, 0) && Qm(n, t, "uv", e, 2, 20, 12);
}
function WX(n, t, e, s, o, r) {
  ot(n, () => n.bindTexture(n.TEXTURE_2D, t));
  let i6, a, l;
  o instanceof Uint8Array ? (i6 = new Uint8Array(e * s * 4), a = n.UNSIGNED_BYTE, l = n.RGBA) : (i6 = new Float32Array(e * s * 4), a = n.FLOAT, l = r.internalFormatPackedFloat), i6.set(o), F().getNumber("WEBGL_VERSION") === 2 ? ot(n, () => n.texSubImage2D(n.TEXTURE_2D, 0, 0, 0, e, s, n.RGBA, a, i6)) : ot(n, () => n.texImage2D(n.TEXTURE_2D, 0, l, e, s, 0, n.RGBA, a, i6)), ot(n, () => n.bindTexture(n.TEXTURE_2D, null));
}
function DX(n, t, e) {
  ot(n, () => n.bindTexture(n.TEXTURE_2D, t)), e.data instanceof Uint8Array ? F().getNumber("WEBGL_VERSION") === 2 ? ot(n, () => n.texSubImage2D(n.TEXTURE_2D, 0, 0, 0, e.width, e.height, n.RGBA, n.UNSIGNED_BYTE, e.data)) : ot(n, () => n.texImage2D(n.TEXTURE_2D, 0, n.RGBA, e.width, e.height, 0, n.RGBA, n.UNSIGNED_BYTE, e.data)) : F().getNumber("WEBGL_VERSION") === 2 ? ot(n, () => n.texSubImage2D(n.TEXTURE_2D, 0, 0, 0, n.RGBA, n.UNSIGNED_BYTE, e)) : ot(n, () => n.texImage2D(n.TEXTURE_2D, 0, n.RGBA, n.RGBA, n.UNSIGNED_BYTE, e)), ot(n, () => n.bindTexture(n.TEXTURE_2D, null));
}
function FX(n, t, e, s) {
  const o = n.createBuffer();
  ot(n, () => n.bindBuffer(n.PIXEL_PACK_BUFFER, o));
  const a = 4 * 4 * t * e;
  return ot(n, () => n.bufferData(n.PIXEL_PACK_BUFFER, a, n.STREAM_READ)), ot(n, () => n.readPixels(0, 0, e, t, n.RGBA, n.FLOAT, 0)), ot(n, () => n.bindBuffer(n.PIXEL_PACK_BUFFER, null)), o;
}
function VX(n, t, e) {
  const s = n, o = new Float32Array(e);
  return s.bindBuffer(s.PIXEL_PACK_BUFFER, t), s.getBufferSubData(s.PIXEL_PACK_BUFFER, 0, o), s.bindBuffer(s.PIXEL_PACK_BUFFER, null), o;
}
function zX(n, t, e, s) {
  const [o, r] = Ta(t, e), i6 = 4, a = new Uint8Array(ez(t * e, i6));
  return ot(n, () => n.readPixels(0, 0, o, r, s.downloadTextureFormat, n.UNSIGNED_BYTE, a)), new Float32Array(a.buffer);
}
function XX(n, t, e, s, o, r, i6, a) {
  const l = n, c = new Float32Array(nz(r, i6));
  return l.bindBuffer(l.PIXEL_PACK_BUFFER, t), l.getBufferSubData(l.PIXEL_PACK_BUFFER, 0, c), l.bindBuffer(l.PIXEL_PACK_BUFFER, null), c;
}
function PX(n, t, e) {
  const s = new Float32Array(t * e * 4);
  return ot(n, () => n.readPixels(0, 0, e, t, n.RGBA, n.FLOAT, s)), s;
}
var Wu = class {
  constructor(t) {
    this.outputTexture = null, this.program = null, this.disposed = false, this.itemsToPoll = [];
    const e = F().getNumber("WEBGL_VERSION");
    if (t != null ? (this.gl = t, jV(e, t)) : this.gl = Zn(e), t = this.gl, F().getNumber("WEBGL_VERSION") === 2) {
      const r = t;
      this.createVertexArray = () => ot(r, () => r.createVertexArray()), this.bindVertexArray = (i6) => ot(r, () => r.bindVertexArray(i6)), this.deleteVertexArray = (i6) => ot(r, () => r.deleteVertexArray(i6)), this.getVertexArray = () => ot(r, () => r.getParameter(r.VERTEX_ARRAY_BINDING));
    } else if (t != null) {
      const r = t.getExtension("OES_vertex_array_object");
      if (r == null)
        throw new Error("All WebGL1 implementations are expected to offer OES_vertex_array_object.");
      this.createVertexArray = () => ot(t, () => r.createVertexArrayOES()), this.bindVertexArray = (i6) => ot(t, () => r.bindVertexArrayOES(i6)), this.deleteVertexArray = (i6) => ot(t, () => r.deleteVertexArrayOES(i6)), this.getVertexArray = () => ot(t, () => t.getParameter(r.VERTEX_ARRAY_BINDING_OES));
    }
    let s = "WEBGL_color_buffer_float";
    const o = "EXT_color_buffer_half_float";
    if (this.parallelCompilationExtension = this.gl.getExtension("KHR_parallel_shader_compile"), F().getNumber("WEBGL_VERSION") === 1) {
      const r = "OES_texture_float", i6 = "OES_texture_half_float";
      if (this.textureFloatExtension = Aa(this.gl, r), vn(this.gl, i6))
        this.textureHalfFloatExtension = Aa(this.gl, i6);
      else if (F().get("WEBGL_FORCE_F16_TEXTURES"))
        throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
      if (this.colorBufferFloatExtension = this.gl.getExtension(s), vn(this.gl, o))
        this.colorBufferHalfFloatExtension = Aa(this.gl, o);
      else if (F().get("WEBGL_FORCE_F16_TEXTURES"))
        throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
    } else if (s = "EXT_color_buffer_float", vn(this.gl, s))
      this.colorBufferFloatExtension = this.gl.getExtension(s);
    else if (vn(this.gl, o))
      this.colorBufferHalfFloatExtension = this.gl.getExtension(o);
    else
      throw new Error("GL context does not support color renderable floats");
    this.vertexBuffer = TX(this.gl), this.indexBuffer = NX(this.gl), this.framebuffer = bz(this.gl), this.textureConfig = Ff(this.gl, this.textureHalfFloatExtension);
  }
  get debug() {
    return F().getBool("DEBUG");
  }
  dispose() {
    if (this.disposed)
      return;
    this.program != null && console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."), this.outputTexture != null && console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
    const t = this.gl;
    ot(t, () => t.finish()), ot(t, () => t.bindFramebuffer(t.FRAMEBUFFER, null)), ot(t, () => t.deleteFramebuffer(this.framebuffer)), ot(t, () => t.bindBuffer(t.ARRAY_BUFFER, null)), ot(t, () => t.bindBuffer(t.ELEMENT_ARRAY_BUFFER, null)), ot(t, () => t.deleteBuffer(this.indexBuffer)), this.disposed = true;
  }
  createFloat32MatrixTexture(t, e) {
    return this.throwIfDisposed(), RX(this.gl, t, e, this.textureConfig);
  }
  createFloat16MatrixTexture(t, e) {
    return this.throwIfDisposed(), $X(this.gl, t, e, this.textureConfig);
  }
  createUnsignedBytesMatrixTexture(t, e) {
    return this.throwIfDisposed(), GX(this.gl, t, e, this.textureConfig);
  }
  uploadPixelDataToTexture(t, e) {
    this.throwIfDisposed(), DX(this.gl, t, e);
  }
  uploadDenseMatrixToTexture(t, e, s, o) {
    this.throwIfDisposed(), WX(this.gl, t, e, s, o, this.textureConfig);
  }
  createFloat16PackedMatrixTexture(t, e) {
    return this.throwIfDisposed(), LX(this.gl, t, e, this.textureConfig);
  }
  createPackedMatrixTexture(t, e) {
    return this.throwIfDisposed(), EX(this.gl, t, e, this.textureConfig);
  }
  deleteMatrixTexture(t) {
    this.throwIfDisposed(), this.outputTexture === t && (Jm(this.gl, this.framebuffer), this.outputTexture = null), ot(this.gl, () => this.gl.deleteTexture(t));
  }
  downloadByteEncodedFloatMatrixFromOutputTexture(t, e, s) {
    return this.downloadMatrixDriver(t, () => zX(this.gl, e, s, this.textureConfig));
  }
  downloadPackedMatrixFromBuffer(t, e, s, o, r, i6) {
    return XX(this.gl, t, e, s, o, r, i6, this.textureConfig);
  }
  downloadFloat32MatrixFromBuffer(t, e) {
    return VX(this.gl, t, e);
  }
  createBufferFromTexture(t, e, s) {
    this.bindTextureToFrameBuffer(t);
    const o = FX(this.gl, e, s, this.textureConfig);
    return this.unbindTextureToFrameBuffer(), o;
  }
  createAndWaitForFence() {
    const t = this.createFence(this.gl);
    return this.pollFence(t);
  }
  createFence(t) {
    let e, s;
    if (F().getBool("WEBGL_FENCE_API_ENABLED")) {
      const o = t, r = o.fenceSync(o.SYNC_GPU_COMMANDS_COMPLETE, 0);
      t.flush(), s = () => {
        const i6 = o.clientWaitSync(r, 0, 0);
        return i6 === o.ALREADY_SIGNALED || i6 === o.CONDITION_SATISFIED;
      }, e = r;
    } else
      F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 ? (e = this.beginQuery(), this.endQuery(), s = () => this.isQueryAvailable(e, F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))) : s = () => true;
    return { query: e, isFencePassed: s };
  }
  downloadMatrixFromPackedTexture(t, e, s) {
    return this.downloadMatrixDriver(t, () => PX(this.gl, e, s));
  }
  createProgram(t) {
    this.throwIfDisposed();
    const e = this.gl;
    this.vertexShader == null && (this.vertexShader = kX(e));
    const s = dz(e);
    ot(e, () => e.attachShader(s, this.vertexShader)), ot(e, () => e.attachShader(s, t)), hz(e, s);
    let o;
    return o = Object.assign(s, {
      vao: this.createVertexArray()
    }), this.bindVertexArray(o.vao), ot(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, this.indexBuffer)), console.assert(MX(e, o, this.vertexBuffer), "gpgpu_util.bindVertexProgramAttributeStreams not fully successful."), this.debug && Gu(e, o), this.setProgram(o), o;
  }
  deleteProgram(t) {
    this.throwIfDisposed(), t === this.program && (this.program = null), t != null && (ot(this.gl, () => this.gl.deleteProgram(t)), this.deleteVertexArray(t.vao));
  }
  setProgram(t) {
    this.throwIfDisposed(), this.program = t, this.program != null && (this.bindVertexArray(this.program.vao), this.debug && Gu(this.gl, this.program)), ot(this.gl, () => this.gl.useProgram(t));
  }
  getUniformLocation(t, e, s = true) {
    return this.throwIfDisposed(), s ? yz(this.gl, t, e) : wz(this.gl, t, e);
  }
  getAttributeLocation(t, e) {
    return this.throwIfDisposed(), ot(this.gl, () => this.gl.getAttribLocation(t, e));
  }
  getUniformLocationNoThrow(t, e) {
    return this.throwIfDisposed(), this.gl.getUniformLocation(t, e);
  }
  setInputMatrixTexture(t, e, s) {
    this.throwIfDisposed(), this.throwIfNoProgram(), Iz(this.gl, t, e, s);
  }
  setOutputMatrixTexture(t, e, s) {
    this.setOutputMatrixTextureDriver(t, s, e);
  }
  setOutputPackedMatrixTexture(t, e, s) {
    this.throwIfDisposed();
    const [o, r] = kr(e, s);
    this.setOutputMatrixTextureDriver(t, o, r);
  }
  setOutputMatrixWriteRegion(t, e, s, o) {
    this.setOutputMatrixWriteRegionDriver(s, t, o, e);
  }
  setOutputPackedMatrixWriteRegion(t, e, s, o) {
    throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
  }
  debugValidate() {
    this.program != null && Gu(this.gl, this.program), Oa(this.gl);
  }
  executeProgram() {
    this.throwIfDisposed(), this.throwIfNoProgram();
    const t = this.gl;
    if (this.debug) {
      const e = this.getVertexArray();
      console.assert(e === this.program.vao, "VAO changed between setProgram and executeProgram!"), this.debugValidate();
    }
    ot(t, () => t.drawElements(t.TRIANGLES, 6, t.UNSIGNED_SHORT, 0));
  }
  blockUntilAllProgramsCompleted() {
    this.throwIfDisposed(), ot(this.gl, () => this.gl.finish());
  }
  getQueryTimerExtension() {
    return this.disjointQueryTimerExtension == null && (this.disjointQueryTimerExtension = Aa(this.gl, F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2 ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query")), this.disjointQueryTimerExtension;
  }
  getQueryTimerExtensionWebGL2() {
    return this.getQueryTimerExtension();
  }
  getQueryTimerExtensionWebGL1() {
    return this.getQueryTimerExtension();
  }
  beginQuery() {
    if (F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
      const s = this.gl, o = this.getQueryTimerExtensionWebGL2(), r = s.createQuery();
      return s.beginQuery(o.TIME_ELAPSED_EXT, r), r;
    }
    const t = this.getQueryTimerExtensionWebGL1(), e = t.createQueryEXT();
    return t.beginQueryEXT(t.TIME_ELAPSED_EXT, e), e;
  }
  endQuery() {
    if (F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
      const e = this.gl, s = this.getQueryTimerExtensionWebGL2();
      e.endQuery(s.TIME_ELAPSED_EXT);
      return;
    }
    const t = this.getQueryTimerExtensionWebGL1();
    t.endQueryEXT(t.TIME_ELAPSED_EXT);
  }
  async waitForQueryAndGetTime(t) {
    return await td(() => this.disposed || // while testing contexts are created / disposed
    // in rapid succession, so without this check we
    // may poll for the query timer indefinitely
    this.isQueryAvailable(t, F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))), this.getQueryTime(t, F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
  }
  getQueryTime(t, e) {
    if (e === 0)
      return null;
    if (e === 2) {
      const s = this.gl;
      return s.getQueryParameter(t, s.QUERY_RESULT) / 1e6;
    } else {
      const s = this.getQueryTimerExtensionWebGL1();
      return s.getQueryObjectEXT(t, s.QUERY_RESULT_EXT) / 1e6;
    }
  }
  isQueryAvailable(t, e) {
    if (e === 0)
      return true;
    if (e === 2) {
      const s = this.gl, o = this.getQueryTimerExtensionWebGL2(), r = s.getQueryParameter(t, s.QUERY_RESULT_AVAILABLE);
      return this.disjoint == null && (this.disjoint = this.gl.getParameter(o.GPU_DISJOINT_EXT)), r && !this.disjoint;
    } else {
      const s = this.getQueryTimerExtensionWebGL1(), o = s.getQueryObjectEXT(t, s.QUERY_RESULT_AVAILABLE_EXT);
      return this.disjoint == null && (this.disjoint = this.gl.getParameter(s.GPU_DISJOINT_EXT)), o && !this.disjoint;
    }
  }
  pollFence(t) {
    return new Promise((e) => {
      this.addItemToPoll(() => t.isFencePassed(), () => e());
    });
  }
  pollItems() {
    const t = AX(this.itemsToPoll.map((e) => e.isDoneFn));
    for (let e = 0; e <= t; ++e) {
      const { resolveFn: s } = this.itemsToPoll[e];
      s();
    }
    this.itemsToPoll = this.itemsToPoll.slice(t + 1);
  }
  addItemToPoll(t, e) {
    if (this.itemsToPoll.push({ isDoneFn: t, resolveFn: e }), this.itemsToPoll.length > 1)
      return;
    let s;
    "setTimeoutCustom" in F().platform && (s = F().platform.setTimeoutCustom.bind(F().platform)), td(() => (this.pollItems(), this.itemsToPoll.length === 0), () => 0, null, s);
  }
  bindTextureToFrameBuffer(t) {
    this.throwIfDisposed(), Eu(this.gl, t, this.framebuffer), this.debug && Oa(this.gl);
  }
  unbindTextureToFrameBuffer() {
    this.outputTexture != null ? (Eu(this.gl, this.outputTexture, this.framebuffer), this.debug && Oa(this.gl)) : Jm(this.gl, this.framebuffer);
  }
  downloadMatrixDriver(t, e) {
    this.bindTextureToFrameBuffer(t);
    const s = e();
    return this.unbindTextureToFrameBuffer(), s;
  }
  setOutputMatrixTextureDriver(t, e, s) {
    this.throwIfDisposed();
    const o = this.gl;
    Eu(o, t, this.framebuffer), this.debug && Oa(o), this.outputTexture = t, ot(o, () => o.viewport(0, 0, e, s)), ot(o, () => o.scissor(0, 0, e, s));
  }
  setOutputMatrixWriteRegionDriver(t, e, s, o) {
    this.throwIfDisposed(), ot(this.gl, () => this.gl.scissor(t, e, s, o));
  }
  throwIfDisposed() {
    if (this.disposed)
      throw new Error("Attempted to use disposed GPGPUContext.");
  }
  throwIfNoProgram() {
    if (this.program == null)
      throw new Error("No GPU program is currently set.");
  }
};
function AX(n) {
  let t = 0;
  for (; t < n.length && n[t](); ++t)
    ;
  return t - 1;
}
var { addImpl: OX, bincountImpl: Mw, bincountReduceImpl: KX, castImpl: ZX, ceilImpl: BX, concatImpl: HX, equalImpl: _X, expImpl: UX, expm1Impl: YX, floorImpl: QX, gatherNdImpl: JX, gatherV2Impl: jX, greaterImpl: qX, greaterEqualImpl: tP, lessImpl: eP, lessEqualImpl: nP, linSpaceImpl: sP, logImpl: oP, maxImpl: rP, maximumImpl: iP, minimumImpl: aP, multiplyImpl: lP, negImpl: cP, notEqualImpl: uP, prodImpl: dP, raggedGatherImpl: hP, raggedRangeImpl: pP, raggedTensorToTensorImpl: fP, rangeImpl: mP, rsqrtImpl: gP, scatterImpl: bP, sigmoidImpl: xP, simpleAbsImpl: Ww, sliceImpl: yP, sparseFillEmptyRowsImpl: wP, sparseReshapeImpl: IP, sparseSegmentReductionImpl: Dw, sqrtImpl: CP, stridedSliceImpl: vP, stringNGramsImpl: SP, stringSplitImpl: kP, stringToHashBucketFastImpl: TP, subImpl: NP, tileImpl: RP, topKImpl: $P, transposeImpl: Pf, uniqueImpl: GP } = F3;
function Fw(n, t) {
  return ["x", "y", "z", "w", "u", "v"].slice(0, t).map((e) => `${n}.${e}`);
}
function We(n, t) {
  return t === 1 ? [n] : Fw(n, t);
}
function EP(n, t) {
  if (n === 1)
    return "rc";
  let e = "";
  for (let s = 0; s < n; s++)
    e += t[s], s < n - 1 && (e += ",");
  return e;
}
var LP = class {
  constructor(t) {
    if (this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.outputShape = t, this.rank = t.length, this.enableShapeUniforms = Xe(this.outputShape.length), this.rank === 0)
      this.userCode = `
        void main() {
          setOutput(vec4(getA(), 0., 0., 0.));
        }
      `;
    else {
      const e = We("rc", this.rank), s = Kt(this.rank), o = this.getOutOfBoundsCondition(e), r = this.getSetup(e), i6 = this.getOutput(e);
      this.userCode = `
        void main() {
          ${s} rc = getOutputCoords();

          if(${o}) {
            setOutput(vec4(0));
          } else {
            ${r}

            setOutput(vec4(${i6}));
          }
        }
      `;
    }
  }
  getSourceCoordsArr(t) {
    const e = [];
    for (let s = 0; s <= 1; s++)
      for (let o = 0; o <= 1; o++) {
        let r = `${s === 0 ? "r" : "rp1"}, ${o === 0 ? "c" : "cp1"}`;
        for (let i6 = 2; i6 < this.rank; i6++)
          r = `${t[t.length - 1 - i6]},` + r;
        e.push(r);
      }
    return e;
  }
  getOutOfBoundsCondition(t) {
    if (this.rank === 1)
      return `rc > ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]}`;
    let e = "";
    for (let s = this.rank - 2; s < this.rank; s++)
      e += `${t[s]} >= ${this.enableShapeUniforms ? `outShape[${s}]` : this.outputShape[s]}`, s < this.rank - 1 && (e += "||");
    return e;
  }
  getSetup(t) {
    if (this.rank === 1)
      return "";
    const e = t.slice(-2), s = this.enableShapeUniforms ? `outShape[${this.rank} - 1]` : this.outputShape[this.rank - 1], o = this.enableShapeUniforms ? `outShape[${this.rank} - 2]` : this.outputShape[this.rank - 2];
    return `
      int r = ${e[0]};
      int c = ${e[1]};
      int rp1 = r + 1;
      int cp1 = c + 1;

      bool cEdge = cp1 >= ${s};
      bool rEdge = rp1 >= ${o};
    `;
  }
  getOutput(t) {
    const e = this.getSourceCoordsArr(t);
    return this.rank === 1 ? `getA(rc), (rc + 1 >= ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]} ? 0. : getA(rc + 1)), 0, 0` : `getA(${e[0]}),
            cEdge ? 0. : getA(${e[1]}),
            rEdge ? 0. : getA(${e[2]}),
            rEdge || cEdge ? 0. : getA(${e[3]})`;
  }
};
var Vw = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "inputShape", type: "ivec3" }], this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length);
    let s = "";
    for (let o = 0; o < 4; o++) {
      let r = "thisRC = rc;";
      o % 2 === 1 && (r += "thisRC.z += 1;"), o > 1 && (r += "thisRC.y += 1;"), s += `
        ${r}
        ${o > 0 ? "if(thisRC.y < rows && thisRC.z < cols){" : ""}
          int flatIndex = getFlatIndex(thisRC);

          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);
          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));

          result[${o}] =
            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);
        ${o > 0 ? "}" : ""}
      `;
    }
    this.userCode = `
      ${MP(e, this.enableShapeUniforms)}
      ${this.enableShapeUniforms ? zf() : Vf(t)}

      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0.);

        ivec3 thisRC;
        int rows = ${this.enableShapeUniforms ? "outShape[1]" : t[1]};
        int cols = ${this.enableShapeUniforms ? "outShape[2]" : t[2]};

        ${s}

        setOutput(result);
      }
    `;
  }
};
function MP(n, t) {
  return `
    ivec3 inputCoordsFromReshapedOutCoords(int index) {
      ${t ? Mz(["r", "c", "d"], "inputShape") : Po(["r", "c", "d"], n)}
      return ivec3(r, c, d);
    }
  `;
}
var WP = class {
  constructor(t) {
    this.gpgpu = t, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0, this.freeTextures = {}, this.logEnabled = false, this.usedTextures = {};
  }
  acquireTexture(t, e, s) {
    const o = ng(e, s), r = sg(t, o, s);
    r in this.freeTextures || (this.freeTextures[r] = []), r in this.usedTextures || (this.usedTextures[r] = []);
    const i6 = eg(t, o, this.gpgpu.gl, this.gpgpu.textureConfig, s);
    if (this.freeTextures[r].length > 0) {
      this.numFreeTextures--, this.numUsedTextures++, this._numBytesFree -= i6, this.log();
      const l = this.freeTextures[r].shift();
      return this.usedTextures[r].push(l), l;
    }
    let a;
    return o === ve.PACKED_2X2_FLOAT32 ? a = this.gpgpu.createPackedMatrixTexture(t[0], t[1]) : o === ve.PACKED_2X2_FLOAT16 ? a = this.gpgpu.createFloat16PackedMatrixTexture(t[0], t[1]) : o === ve.UNPACKED_FLOAT32 ? a = this.gpgpu.createFloat32MatrixTexture(t[0], t[1]) : o === ve.UNPACKED_FLOAT16 ? a = this.gpgpu.createFloat16MatrixTexture(t[0], t[1]) : o === ve.PACKED_4X1_UNSIGNED_BYTE && (a = this.gpgpu.createUnsignedBytesMatrixTexture(t[0], t[1])), this.usedTextures[r].push(a), this.numUsedTextures++, this._numBytesAllocated += i6, this.log(), a;
  }
  releaseTexture(t, e, s, o) {
    if (this.freeTextures == null)
      return;
    const r = ng(s, o), i6 = sg(e, r, o);
    i6 in this.freeTextures || (this.freeTextures[i6] = []);
    const a = eg(e, r, this.gpgpu.gl, this.gpgpu.textureConfig, o), l = F().get("WEBGL_DELETE_TEXTURE_THRESHOLD");
    l !== -1 && this._numBytesAllocated > l ? (this.gpgpu.deleteMatrixTexture(t.texture), this._numBytesAllocated -= a) : (this.freeTextures[i6].push(t), this.numFreeTextures++, this._numBytesFree += a), this.numUsedTextures--;
    const c = this.usedTextures[i6], u = c.indexOf(t);
    if (u < 0)
      throw new Error("Cannot release a texture that was never provided by this texture manager");
    c.splice(u, 1), this.log();
  }
  log() {
    if (!this.logEnabled)
      return;
    const t = this.numFreeTextures + this.numUsedTextures;
    console.log("Free/Used", `${this.numFreeTextures} / ${this.numUsedTextures}`, `(${t})`);
    const e = this._numBytesFree / this._numBytesAllocated;
    console.log(`Bytes allocated: ${this._numBytesAllocated}`), console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100 * e)}%)`);
  }
  get numBytesAllocated() {
    return this._numBytesAllocated;
  }
  get numBytesFree() {
    return this._numBytesFree;
  }
  getNumUsedTextures() {
    return this.numUsedTextures;
  }
  getNumFreeTextures() {
    return this.numFreeTextures;
  }
  dispose() {
    if (this.freeTextures != null) {
      for (const t in this.freeTextures)
        this.freeTextures[t].forEach((e) => {
          this.gpgpu.deleteMatrixTexture(e.texture);
        });
      for (const t in this.usedTextures)
        this.usedTextures[t].forEach((e) => {
          this.gpgpu.deleteMatrixTexture(e.texture);
        });
      this.freeTextures = null, this.usedTextures = null, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0;
    }
  }
};
function DP(n, t) {
  const e = n;
  if (t === e.R32F)
    return 4;
  if (t === e.R16F)
    return 2;
  if (t === e.RGBA32F)
    return 16;
  if (t === n.RGBA)
    return 16;
  if (t === e.RGBA16F)
    return 8;
  if (t === e.RGBA8)
    return 4;
  throw new Error(`Unknown internal format ${t}`);
}
function eg(n, t, e, s, o) {
  const r = FP(t, s);
  let i6;
  if (o) {
    const [l, c] = kr(n[0], n[1]);
    i6 = l * c;
  } else {
    const [l, c] = Ta(n[0], n[1]);
    i6 = l * c;
  }
  const a = DP(e, r);
  return i6 * a;
}
function FP(n, t) {
  switch (n) {
    case ve.PACKED_2X2_FLOAT32:
      return Ew(t);
    case ve.PACKED_2X2_FLOAT16:
      return Lw(t);
    case ve.UNPACKED_FLOAT32:
      return Rw(t);
    case ve.UNPACKED_FLOAT16:
      return $w(t);
    case ve.PACKED_4X1_UNSIGNED_BYTE:
      return Gw(t);
    default:
      throw new Error(`Unknown physical texture type ${n}`);
  }
}
function VP(n) {
  return F().getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? n ? ve.PACKED_2X2_FLOAT32 : ve.UNPACKED_FLOAT32 : n ? ve.PACKED_2X2_FLOAT16 : ve.UNPACKED_FLOAT16;
}
function ng(n, t) {
  if (n === ln.UPLOAD)
    return ve.PACKED_2X2_FLOAT32;
  if (n === ln.RENDER || n == null)
    return VP(t);
  if (n === ln.DOWNLOAD || n === ln.PIXELS)
    return ve.PACKED_4X1_UNSIGNED_BYTE;
  throw new Error(`Unknown logical texture type ${n}`);
}
function sg(n, t, e) {
  return `${n[0]}_${n[1]}_${t}_${e}`;
}
var qn = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length), this.userCode = `
      float unaryOperation(float x) {
        ${e}
      }

      void main() {
        float x = getAAtOutCoords();
        float y = unaryOperation(x);

        setOutput(y);
      }
    `;
  }
};
var En = "if (isnan(x)) return x;";
var zP = "return x;";
var og = "return abs(x);";
var XP = "return (x >= 0.0) ? x : (exp(x) - 1.0);";
var PP = En + `
  return (x < 0.0) ? 0.0 : x;
`;
var AP = En + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
var Ns = "return x;";
var OP = "return 1.0 / (1.0 + exp(-1.0 * x));";
var KP = "return x;";
var ZP = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
var BP = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var HP = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var _P = "return 1.0 / (1.0 + exp(-1.0 * x));";
var Ls = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length), this.userCode = `
      vec4 unaryOperation(vec4 x) {
        ${e}
      }

      void main() {
        vec4 x = getAAtOutCoords();
        vec4 y = unaryOperation(x);

        setOutput(y);
      }
    `;
  }
};
var UP = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = false, this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length);
    const e = t.length, s = We("rc", e), o = Kt(e), r = EP(e, s), i6 = s.slice(-2), a = e <= 1 ? "rc" : `vec2(${i6.join(",")})`;
    this.userCode = `
      void main() {
        ${o} rc = getOutputCoords();
        vec4 packedInput = getA(${r});

        setOutput(getChannel(packedInput, ${a}));
      }
    `;
  }
};
var YP = t0;
var QP = 1e-7;
var JP = 1e-4;
var Ba = {};
function jP(n) {
  return n in Ba || (Ba[n] = {}), Ba[n];
}
var qP = F().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");
var tA = 600;
function eA() {
  return F().global.screen == null ? 1024 : F().global.screen.height * F().global.screen.width * window.devicePixelRatio * tA / 1024 / 1024;
}
var hu = class extends Xd {
  constructor(t) {
    if (super(), this.pendingRead = /* @__PURE__ */ new WeakMap(), this.pendingDisposal = /* @__PURE__ */ new WeakSet(), this.dataRefCount = /* @__PURE__ */ new WeakMap(), this.numBytesInGPU = 0, this.uploadWaitMs = 0, this.downloadWaitMs = 0, this.lastGlFlushTime = 0, this.warnedAboutMemory = false, this.pendingDeletes = 0, this.disposed = false, !F().getBool("HAS_WEBGL"))
      throw new Error("WebGL is not supported on this device");
    let e;
    if (t != null) {
      if (t instanceof Wu)
        e = t;
      else {
        const s = Zn(F().getNumber("WEBGL_VERSION"), t);
        e = new Wu(s);
      }
      this.binaryCache = {}, this.gpgpuCreatedLocally = false;
    } else {
      const s = Zn(F().getNumber("WEBGL_VERSION"));
      e = new Wu(s), this.binaryCache = jP(F().getNumber("WEBGL_VERSION")), this.gpgpuCreatedLocally = true;
    }
    this.gpgpu = e, this.canvas = this.gpgpu.gl.canvas, this.textureManager = new WP(this.gpgpu), this.numMBBeforeWarning = eA(), this.texData = new Mg(this, Xt());
  }
  nextDataId() {
    return hu.nextDataId++;
  }
  numDataIds() {
    return this.texData.numDataIds() - this.pendingDeletes;
  }
  // Writes a new entry to the data store with a WebGL texture, and registers it
  // to the texture manager.
  writeTexture(t, e, s, o, r, i6) {
    const a = this.makeTensorInfo(e, s), l = this.texData.get(a.dataId);
    l.isPacked = false, l.texture = { texture: t, texShape: [o, r] }, l.texShape = [o, r];
    const c = Ka(e), u = new tg(c, false, i6), d = this.runWebGLProgram(u, [a], s, [[o, r]]);
    return d.shape = e, l.texture = null, this.disposeIntermediateTensorInfo(a), d.dataId;
  }
  write(t, e, s) {
    if ((F().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || F().getBool("DEBUG")) && this.checkNumericalProblems(t), s === "complex64" && t != null)
      throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    const o = { id: this.nextDataId() };
    return this.texData.set(o, { shape: e, dtype: s, values: t, usage: ln.UPLOAD, refCount: 1 }), o;
  }
  /** Return refCount of a `TensorData`. */
  refCount(t) {
    return this.texData.has(t) ? this.texData.get(t).refCount : 0;
  }
  /** Increase refCount of a `TextureData`. */
  incRef(t) {
    const e = this.texData.get(t);
    e.refCount++;
  }
  /** Decrease refCount of a `TextureData`. */
  decRef(t) {
    if (this.texData.has(t)) {
      const e = this.texData.get(t);
      e.refCount--;
    }
  }
  move(t, e, s, o, r) {
    if (F().getBool("DEBUG") && this.checkNumericalProblems(e), o === "complex64")
      throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    this.texData.set(t, { shape: s, dtype: o, values: e, usage: ln.UPLOAD, refCount: r });
  }
  disposeIntermediateTensorInfo(t) {
    this.disposeData(t.dataId);
  }
  readSync(t) {
    const e = this.texData.get(t), { values: s, dtype: o, complexTensorInfos: r, slice: i6, shape: a, isPacked: l } = e;
    if (i6 != null) {
      let h6;
      l ? h6 = new Ls(a, Ns) : h6 = new qn(a, Ns);
      const p6 = this.runWebGLProgram(h6, [{ dataId: t, shape: a, dtype: o }], o), f = this.readSync(p6.dataId);
      return this.disposeIntermediateTensorInfo(p6), f;
    }
    if (s != null)
      return this.convertAndCacheOnCPU(t);
    if (o === "string")
      return s;
    const c = this.activeTimers != null;
    let u;
    c && (u = Ce());
    let d;
    if (o === "complex64") {
      const h6 = this.readSync(r.real.dataId), p6 = this.readSync(r.imag.dataId);
      d = ms(h6, p6);
    } else
      d = this.getValuesFromTexture(t);
    return c && (this.downloadWaitMs += Ce() - u), this.convertAndCacheOnCPU(t, d);
  }
  async read(t) {
    if (this.pendingRead.has(t)) {
      const f = this.pendingRead.get(t);
      return new Promise((m) => f.push(m));
    }
    const e = this.texData.get(t), { values: s, shape: o, slice: r, dtype: i6, complexTensorInfos: a, isPacked: l } = e;
    if (r != null) {
      let f;
      l ? f = new Ls(o, Ns) : f = new qn(o, Ns);
      const m = this.runWebGLProgram(f, [{ dataId: t, shape: o, dtype: i6 }], i6), g6 = this.read(m.dataId);
      return this.disposeIntermediateTensorInfo(m), g6;
    }
    if (s != null)
      return this.convertAndCacheOnCPU(t);
    if (F().getBool("DEBUG") && !F().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && F().getNumber("WEBGL_VERSION") === 2)
      throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");
    let c = null, u;
    if (i6 !== "complex64" && F().get("WEBGL_BUFFER_SUPPORTED")) {
      u = this.decode(t);
      const f = this.texData.get(u.dataId);
      c = this.gpgpu.createBufferFromTexture(f.texture.texture, ...Pa(o));
    }
    this.pendingRead.set(t, []), i6 !== "complex64" && await this.gpgpu.createAndWaitForFence();
    let d;
    if (i6 === "complex64") {
      const f = await Promise.all([
        this.read(a.real.dataId),
        this.read(a.imag.dataId)
      ]), m = f[0], g6 = f[1];
      d = ms(m, g6);
    } else if (c == null)
      d = this.getValuesFromTexture(t);
    else {
      const f = O(o);
      d = this.gpgpu.downloadFloat32MatrixFromBuffer(c, f);
    }
    if (u != null && this.disposeIntermediateTensorInfo(u), c != null) {
      const f = this.gpgpu.gl;
      ot(f, () => f.deleteBuffer(c));
    }
    const h6 = this.convertAndCacheOnCPU(t, d), p6 = this.pendingRead.get(t);
    return this.pendingRead.delete(t), p6.forEach((f) => f(h6)), this.pendingDisposal.has(t) && (this.pendingDisposal.delete(t), this.disposeData(t) && Xt().removeDataId(t, this), this.pendingDeletes--), h6;
  }
  /**
   * Read tensor to a new texture that is densely packed for ease of use.
   * @param dataId The source tensor.
   * @param options
   *     customTexShape: Optional. If set, will use the user defined texture
   *     shape to create the texture.
   */
  readToGPU(t, e = {}) {
    const s = this.texData.get(t), { values: o, shape: r, slice: i6, dtype: a, isPacked: l, texture: c } = s;
    if (a === "complex64")
      throw new Error("Does not support reading texture for complex64 dtype.");
    if (i6 != null) {
      let p6;
      l ? p6 = new Ls(r, Ns) : p6 = new qn(r, Ns);
      const f = this.runWebGLProgram(p6, [{ dataId: t, shape: r, dtype: a }], a), m = this.readToGPU(f, e);
      return this.disposeIntermediateTensorInfo(f), m;
    }
    if (c == null)
      throw o != null ? new Error("Data is not on GPU but on CPU.") : new Error("There is no data on GPU or CPU.");
    const u = this.decode(t, e.customTexShape), d = Xt().makeTensorFromTensorInfo(u), h6 = this.texData.get(u.dataId);
    return Object.assign({ tensorRef: d }, h6.texture);
  }
  bufferSync(t) {
    const e = this.readSync(t.dataId);
    if (t.dtype === "string")
      try {
        const s = e.map((o) => ps(o));
        return vt(t.shape, t.dtype, s);
      } catch {
        throw new Error("Failed to decode encoded string bytes into utf-8");
      }
    return vt(t.shape, t.dtype, e);
  }
  checkNumericalProblems(t) {
    if (t != null)
      for (let e = 0; e < t.length; e++) {
        const s = t[e];
        if (!iz(s))
          throw F().getBool("WEBGL_RENDER_FLOAT32_CAPABLE") ? Error(`The value ${s} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`) : Error(`The value ${s} cannot be represented on this device.`);
      }
  }
  getValuesFromTexture(t) {
    const { shape: e, dtype: s, isPacked: o } = this.texData.get(t), r = O(e);
    if (F().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
      const h6 = this.decode(t), p6 = this.texData.get(h6.dataId), f = this.gpgpu.downloadMatrixFromPackedTexture(p6.texture.texture, ...Pa(e)).subarray(0, r);
      return this.disposeIntermediateTensorInfo(h6), f;
    }
    const i6 = F().getBool("WEBGL_PACK") && o === true, a = i6 ? Ka(e) : e, l = i6 ? new CX(a) : new IX(a), c = this.runWebGLProgram(l, [{ shape: a, dtype: s, dataId: t }], "float32"), u = this.texData.get(c.dataId), d = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture.texture, u.texShape[0], u.texShape[1]).subarray(0, r);
    return this.disposeIntermediateTensorInfo(c), d;
  }
  timerAvailable() {
    return F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
  }
  time(t) {
    const e = this.activeTimers, s = [];
    let o = false;
    this.programTimersStack == null ? (this.programTimersStack = s, o = true) : this.activeTimers.push(s), this.activeTimers = s, t();
    const r = zs(this.activeTimers.map((l) => l.query)).filter((l) => l != null), i6 = zs(this.activeTimers.map((l) => l.name)).filter((l) => l != null);
    this.activeTimers = e, o && (this.programTimersStack = null);
    const a = {
      uploadWaitMs: this.uploadWaitMs,
      downloadWaitMs: this.downloadWaitMs,
      kernelMs: null,
      wallMs: null
      // will be filled by the engine
    };
    return (async () => {
      if (F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        const l = await Promise.all(r);
        a.kernelMs = Wg(l), a.getExtraProfileInfo = () => l.map((c, u) => ({ name: i6[u], ms: c })).map((c) => `${c.name}: ${c.ms}`).join(", ");
      } else
        a.kernelMs = {
          error: "WebGL query timers are not supported in this environment."
        };
      return this.uploadWaitMs = 0, this.downloadWaitMs = 0, a;
    })();
  }
  memory() {
    return {
      unreliable: false,
      numBytesInGPU: this.numBytesInGPU,
      numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
      numBytesInGPUFree: this.textureManager.numBytesFree
    };
  }
  startTimer() {
    return F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? this.gpgpu.beginQuery() : { startMs: Ce(), endMs: null };
  }
  endTimer(t) {
    return F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? (this.gpgpu.endQuery(), t) : (t.endMs = Ce(), t);
  }
  async getQueryTime(t) {
    if (F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0)
      return this.gpgpu.waitForQueryAndGetTime(t);
    const e = t;
    return e.endMs - e.startMs;
  }
  /**
   * Decrease the RefCount on the dataId and dispose the memory if the dataId
   * has 0 refCount. If there are pending read on the data, the disposal would
   * added to the pending delete queue. Return true if the dataId is removed
   * from backend or the backend does not contain the dataId, false if the
   * dataId is not removed. Memory may or may not be released even when dataId
   * is removed, which also depends on dataRefCount, see `releaseGPU`.
   * @param dataId
   * @oaram force Optional, remove the data regardless of refCount
   */
  disposeData(t, e = false) {
    if (this.pendingDisposal.has(t))
      return false;
    if (!this.texData.has(t))
      return true;
    if (e ? this.texData.get(t).refCount = 0 : this.texData.get(t).refCount--, !e && this.texData.get(t).refCount > 0)
      return false;
    if (this.pendingRead.has(t))
      return this.pendingDisposal.add(t), this.pendingDeletes++, false;
    this.releaseGPUData(t);
    const { complexTensorInfos: s } = this.texData.get(t);
    return s != null && (this.disposeData(s.real.dataId, e), this.disposeData(s.imag.dataId, e)), this.texData.delete(t), true;
  }
  releaseGPUData(t) {
    const { texture: e, dtype: s, texShape: o, usage: r, isPacked: i6, slice: a } = this.texData.get(t), l = a && a.origDataId || t, c = this.dataRefCount.get(l);
    c > 1 ? this.dataRefCount.set(l, c - 1) : (this.dataRefCount.delete(l), e != null && (this.numBytesInGPU -= this.computeBytes(o, s), this.textureManager.releaseTexture(e, o, r, i6)));
    const u = this.texData.get(t);
    u.texture = null, u.texShape = null, u.isPacked = false, u.slice = null;
  }
  getTexture(t) {
    return this.uploadToGPU(t), this.texData.get(t).texture.texture;
  }
  /**
   * Returns internal information for the specific data bucket. Used in unit
   * tests.
   */
  getDataInfo(t) {
    return this.texData.get(t);
  }
  /*
  Tests whether all the inputs to an op are small and on the CPU. This heuristic
  determines when it would be faster to execute a kernel on the CPU. WebGL
  kernels opt into running this check and forwarding when appropriate.
  TODO(https://github.com/tensorflow/tfjs/issues/872): Develop a more
  sustainable strategy for optimizing backend execution of ops.
   */
  shouldExecuteOnCPU(t, e = qP) {
    return F().getBool("WEBGL_CPU_FORWARD") && t.every((s) => this.texData.get(s.dataId).texture == null && O(s.shape) < e);
  }
  getGPGPUContext() {
    return this.gpgpu;
  }
  where(t) {
    rn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
    const e = t.dataSync();
    return YP(t.shape, e);
  }
  packedUnaryOp(t, e, s) {
    const o = new Ls(t.shape, e), r = this.compileAndRun(o, [t], s);
    return Xt().makeTensorFromTensorInfo(r);
  }
  // TODO(msoulanille) remove this once the backend has been modularized
  // a copy is needed here to break a circular dependency.
  // Also remove the op from unary_op.
  abs(t) {
    if (this.shouldExecuteOnCPU([t]) && t.dtype !== "complex64") {
      const o = Ww(this.texData.get(t.dataId).values);
      return this.makeOutput(t.shape, t.dtype, o);
    }
    if (F().getBool("WEBGL_PACK_UNARY_OPERATIONS"))
      return this.packedUnaryOp(t, og, t.dtype);
    const e = new qn(t.shape, og), s = this.compileAndRun(e, [t]);
    return Xt().makeTensorFromTensorInfo(s);
  }
  makeTensorInfo(t, e, s) {
    let o;
    if (e === "string" && s != null && s.length > 0 && mr(s[0])) {
      const r = s.map((i6) => hs(i6));
      o = this.write(r, t, e);
    } else
      o = this.write(s, t, e);
    return this.texData.get(o).usage = null, { dataId: o, shape: t, dtype: e };
  }
  makeOutput(t, e, s) {
    return Xt().makeTensorFromTensorInfo(this.makeTensorInfo(t, e, s), this);
  }
  unpackTensor(t) {
    const e = new UP(t.shape);
    return this.runWebGLProgram(e, [t], t.dtype);
  }
  packTensor(t) {
    const e = new LP(t.shape), s = true;
    return this.runWebGLProgram(e, [t], t.dtype, null, s);
  }
  packedReshape(t, e) {
    const s = [
      hr(t.shape),
      ...pr(t.shape)
    ], o = {
      dtype: t.dtype,
      shape: s,
      dataId: t.dataId
    }, r = [
      hr(e),
      ...pr(e)
    ], i6 = new Vw(r, s), a = true, l = [s], c = this.runWebGLProgram(i6, [o], t.dtype, l, a);
    return { dataId: c.dataId, shape: e, dtype: c.dtype };
  }
  decode(t, e) {
    const s = this.texData.get(t), { isPacked: o, shape: r, dtype: i6 } = s;
    if (e != null) {
      const h6 = O(r), p6 = e[0] * e[1] * 4;
      v2(h6 <= p6, () => "customTexShape is too small. Row * Column * 4 should be equal or larger than the size of the tensor data.");
    }
    const a = Ka(r);
    let l;
    o ? l = new wX(a) : l = new yX(a);
    const c = true, u = [e ?? Pa(a)], d = this.runWebGLProgram(l, [{ shape: a, dtype: i6, dataId: t }], i6, u, c, e);
    return { dtype: i6, shape: r, dataId: d.dataId };
  }
  runWebGLProgram(t, e, s, o, r = false, i6) {
    const a = this.makeTensorInfo(t.outputShape, s), l = this.texData.get(a.dataId);
    if (t.packedOutput && (l.isPacked = true), t.outPackingScheme === ii.DENSE) {
      const b6 = i6 ?? Pa(t.outputShape);
      l.texShape = b6.map((x6) => x6 * 2);
    }
    if (t.outTexUsage != null && (l.usage = t.outTexUsage), O(a.shape) === 0)
      return l.values = xe(a.dtype, 0), a;
    const c = [], u = e.map((b6) => {
      if (b6.dtype === "complex64")
        throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");
      let x6 = this.texData.get(b6.dataId);
      if (x6.texture == null) {
        if (!t.packedInputs && O(b6.shape) <= F().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))
          return {
            shape: b6.shape,
            texData: null,
            isUniform: true,
            uniformValues: x6.values
          };
        t.packedInputs && (x6.isPacked = true, x6.shape = b6.shape);
      }
      if (this.uploadToGPU(b6.dataId), !!x6.isPacked != !!t.packedInputs)
        b6 = x6.isPacked ? this.unpackTensor(b6) : this.packTensor(b6), c.push(b6), x6 = this.texData.get(b6.dataId);
      else if (x6.isPacked && !$l(x6.shape, b6.shape)) {
        const w6 = b6, y6 = b6.shape;
        b6.shape = x6.shape, b6 = this.packedReshape(b6, y6), c.push(b6), x6 = this.texData.get(b6.dataId), w6.shape = y6;
      }
      return { shape: b6.shape, texData: x6, isUniform: false };
    });
    this.uploadToGPU(a.dataId);
    const d = { shape: a.shape, texData: l, isUniform: false }, h6 = xX(t, u, d), p6 = this.getAndSaveBinary(h6, () => gX(this.gpgpu, t, u, d)), f = this.activeTimers != null;
    let m;
    f && (m = this.startTimer()), F().get("ENGINE_COMPILE_ONLY") || bX(this.gpgpu, p6, u, d, o), c.forEach((b6) => this.disposeIntermediateTensorInfo(b6)), f && (m = this.endTimer(m), this.activeTimers.push({ name: t.constructor.name, query: this.getQueryTime(m) }));
    const g6 = F().get("WEBGL_FLUSH_THRESHOLD");
    if (g6 > 0) {
      const b6 = Ce();
      b6 - this.lastGlFlushTime > g6 && (this.gpgpu.gl.flush(), this.lastGlFlushTime = b6);
    }
    if (!F().getBool("WEBGL_LAZILY_UNPACK") && l.isPacked && r === false) {
      const b6 = this.unpackTensor(a);
      return this.disposeIntermediateTensorInfo(a), b6;
    }
    return a;
  }
  compileAndRun(t, e, s, o, r = false) {
    return s = s || e[0].dtype, this.runWebGLProgram(t, e, s, o, r);
  }
  getAndSaveBinary(t, e) {
    return t in this.binaryCache || (this.binaryCache[t] = e()), this.binaryCache[t];
  }
  getTextureManager() {
    return this.textureManager;
  }
  dispose() {
    this.disposed || (F().getBool("IS_TEST") || Object.keys(this.binaryCache).forEach((e) => {
      this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram), delete this.binaryCache[e];
    }), this.textureManager.dispose(), this.canvas != null && typeof HTMLCanvasElement < "u" && this.canvas instanceof HTMLCanvasElement ? this.canvas.remove() : this.canvas = null, this.gpgpuCreatedLocally && (this.gpgpu.program = null, this.gpgpu.dispose()), this.disposed = true);
  }
  floatPrecision() {
    return this.floatPrecisionValue == null && (this.floatPrecisionValue = D(() => {
      if (!F().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
        const t = F().getBool("DEBUG");
        F().set("DEBUG", false);
        const e = this.abs(gt(1e-8)).dataSync()[0];
        if (F().set("DEBUG", t), e > 0)
          return 32;
      }
      return 16;
    })), this.floatPrecisionValue;
  }
  /** Returns the smallest representable number.  */
  epsilon() {
    return this.floatPrecision() === 32 ? QP : JP;
  }
  uploadToGPU(t) {
    const e = this.texData.get(t), { shape: s, dtype: o, values: r, texture: i6, usage: a, isPacked: l } = e;
    if (i6 != null)
      return;
    const c = this.activeTimers != null;
    let u;
    c && (u = Ce());
    let d = e.texShape;
    if (d == null && (d = Sz(s, l), e.texShape = d), r != null) {
      const h6 = Ka(s);
      let p6, f = d[1], m = d[0];
      const g6 = r instanceof Uint8Array || r instanceof Uint8ClampedArray;
      (l || !g6) && ([f, m] = kr(d[0], d[1])), l ? p6 = new SX(h6, g6) : p6 = new tg(h6, g6);
      const b6 = g6 ? [m, f] : d, x6 = this.makeTensorInfo(b6, o), w6 = this.texData.get(x6.dataId);
      g6 ? w6.usage = ln.PIXELS : w6.usage = ln.UPLOAD, w6.texShape = b6, this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(x6.dataId), f, m, r);
      const y6 = [[m, f]], I = true, C6 = this.runWebGLProgram(p6, [x6], o, y6, I), k7 = this.texData.get(C6.dataId);
      e.texShape = k7.texShape, e.isPacked = k7.isPacked, e.usage = k7.usage, F().get("ENGINE_COMPILE_ONLY") ? this.disposeData(C6.dataId) : (e.texture = k7.texture, e.values = null, this.texData.delete(C6.dataId)), this.disposeIntermediateTensorInfo(x6), c && (this.uploadWaitMs += Ce() - u);
    } else {
      const h6 = this.acquireTexture(d, a, o, l);
      e.texture = h6;
    }
  }
  convertAndCacheOnCPU(t, e) {
    const s = this.texData.get(t), { dtype: o } = s;
    return e != null && (s.values = nA(e, o)), s.values;
  }
  acquireTexture(t, e, s, o) {
    if (this.numBytesInGPU += this.computeBytes(t, s), !this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {
      const r = (this.numBytesInGPU / 1024 / 1024).toFixed(2);
      this.warnedAboutMemory = true, console.warn(`High memory usage in GPU: ${r} MB, most likely due to a memory leak`);
    }
    return this.textureManager.acquireTexture(t, e, o);
  }
  computeBytes(t, e) {
    return t[0] * t[1] * Ur(e);
  }
  checkCompileCompletion() {
    for (const [, t] of Object.entries(this.binaryCache))
      this.checkCompletion_(t);
  }
  async checkCompileCompletionAsync() {
    const t = [];
    if (this.gpgpu.parallelCompilationExtension) {
      for (const [, e] of Object.entries(this.binaryCache))
        t.push(this.checkCompletionAsync_(e));
      return Promise.all(t);
    } else {
      for (const [, e] of Object.entries(this.binaryCache)) {
        const s = new Promise((o) => {
          try {
            this.checkCompletion_(e), o(true);
          } catch (r) {
            throw r;
          }
        });
        t.push(s);
      }
      return Promise.all(t);
    }
  }
  async checkCompletionAsync_(t) {
    return this.gpgpu.gl.getProgramParameter(t.webGLProgram, this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR) ? this.checkCompletion_(t) : (await _c(), this.checkCompletionAsync_(t));
  }
  checkCompletion_(t) {
    if (this.gpgpu.gl.getProgramParameter(t.webGLProgram, this.gpgpu.gl.LINK_STATUS) === false)
      throw console.log(this.gpgpu.gl.getProgramInfoLog(t.webGLProgram)), this.gpgpu.gl.getShaderParameter(t.fragmentShader, this.gpgpu.gl.COMPILE_STATUS) === false ? (Cw(t.source, this.gpgpu.gl.getShaderInfoLog(t.fragmentShader)), new Error("Failed to compile fragment shader.")) : new Error("Failed to link vertex and fragment shaders.");
    return true;
  }
  getUniformLocations() {
    for (const [, t] of Object.entries(this.binaryCache)) {
      const { uniformLocations: e, customUniformLocations: s, infLoc: o, nanLoc: r, inShapesLocations: i6, inTexShapesLocations: a, outShapeLocation: l, outShapeStridesLocation: c, outTexShapeLocation: u } = Nw(this.gpgpu, t.program, t.webGLProgram);
      t.uniformLocations = e, t.customUniformLocations = s, t.infLoc = o, t.nanLoc = r, t.inShapesLocations = i6, t.inTexShapesLocations = a, t.outShapeLocation = l, t.outShapeStridesLocation = c, t.outTexShapeLocation = u;
    }
  }
  /**
   * Create a TF.js tensor out of an existing WebGL texture. A new texture will
   * be created.
   */
  createTensorFromGPUData(t, e, s) {
    t.channels = t.channels || "RGBA";
    const { texture: o, height: r, width: i6, channels: a } = t, l = Xt().backend;
    if (!l.gpgpu.gl.isTexture(o))
      throw new Error("The texture is invalid. Also, please make sure the texture and the TFJS WebGL backend are using the same canvas. If you want to use your own custom canvas, you have to create and use the custom TFJS WebGL backend created from the canvas through 'new tf.MathBackendWebGL(customCanvas)'.");
    const c = l.writeTexture(o, e, s, r, i6, a);
    return Xt().makeTensorFromDataId(c, e, s, l);
  }
};
hu.nextDataId = 0;
function nA(n, t) {
  if (t === "float32" || t === "complex64")
    return n;
  if (t === "int32" || t === "bool") {
    const e = t === "int32" ? new Int32Array(n.length) : new Uint8Array(n.length);
    for (let s = 0; s < e.length; ++s)
      e[s] = Math.round(n[s]);
    return e;
  } else
    throw new Error(`Unknown dtype ${t}`);
}
Ph() && kb(
  "webgl",
  () => new hu(),
  2
  /* priority */
);
var Af = `
  if (isnan(a)) return a;
  if (isnan(b)) return b;
`;
var fr = class {
  constructor(t, e, s) {
    this.variableNames = ["A", "B"], this.outputShape = bt(e, s), this.enableShapeUniforms = Xe(this.outputShape.length), this.userCode = `
      float binaryOperation(float a, float b) {
        ${t}
      }

      void main() {
        float a = getAAtOutCoords();
        float b = getBAtOutCoords();
        setOutput(binaryOperation(a, b));
      }
    `;
  }
};
var $a = `
  result.r = isNaN.r ? NAN : result.r;
  result.g = isNaN.g ? NAN : result.g;
  result.b = isNaN.b ? NAN : result.b;
  result.a = isNaN.a ? NAN : result.a;
`;
var Ga = class {
  constructor(t, e, s, o = false) {
    this.variableNames = ["A", "B"], this.supportsBroadcasting = true, this.packedInputs = true, this.packedOutput = true, this.outputShape = bt(e, s);
    const r = this.outputShape.length;
    this.enableShapeUniforms = Xe(r);
    let i6 = "";
    if (o)
      if (r === 0 || O(this.outputShape) === 1)
        i6 = `
          result.y = 0.;
          result.z = 0.;
          result.w = 0.;
        `;
      else if (i6 = `
          ${Kt(r)} coords = getOutputCoords();
        `, r === 1)
        this.enableShapeUniforms ? i6 += `
            result.y = (coords + 1) >= outShape ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          ` : i6 += `
            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          `;
      else {
        const l = We("coords", r);
        this.enableShapeUniforms ? i6 += `
            bool nextRowOutOfBounds =
              (${l[r - 2]} + 1) >= outShape[${r} - 2];
            bool nextColOutOfBounds =
              (${l[r - 1]} + 1) >= outShape[${r} - 1];
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          ` : i6 += `
            bool nextRowOutOfBounds =
              (${l[r - 2]} + 1) >= ${this.outputShape[r - 2]};
            bool nextColOutOfBounds =
              (${l[r - 1]} + 1) >= ${this.outputShape[r - 1]};
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          `;
      }
    this.userCode = `
      vec4 binaryOperation(vec4 a, vec4 b) {
        ${t}
      }

      void main() {
        vec4 a = getAAtOutCoords();
        vec4 b = getBAtOutCoords();

        vec4 result = binaryOperation(a, b);
        ${i6}

        setOutput(result);
      }
    `;
  }
};
function tn(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  return e.incRef(s.dataId), { dataId: s.dataId, shape: s.shape, dtype: s.dtype };
}
var sA = {
  kernelName: Ei,
  backendName: "webgl",
  kernelFunc: tn
};
function js(n) {
  const { inputs: t, backend: e } = n, { real: s, imag: o } = t, r = e.makeTensorInfo(s.shape, "complex64"), i6 = e.texData.get(r.dataId), a = tn({ inputs: { x: s }, backend: e }), l = tn({ inputs: { x: o }, backend: e });
  return i6.complexTensorInfos = { real: a, imag: l }, r;
}
var oA = {
  kernelName: Jd,
  backendName: "webgl",
  kernelFunc: js
};
var zw = "return (a < 0.) ? b * a : a;";
var Xw = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
function rA(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { alpha: r } = s, i6 = e.makeTensorInfo([], "float32", bs(r, "float32")), a = F().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new Ga(Xw, o.shape, i6.shape) : new fr(zw, o.shape, i6.shape), l = e.runWebGLProgram(a, [o, i6], "float32");
  return e.disposeIntermediateTensorInfo(i6), l;
}
var iA = {
  kernelName: sc,
  backendName: "webgl",
  kernelFunc: rA
};
var Pw = "return (a < 0.) ? b * a : a;";
var Aw = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
function aA(n) {
  const { inputs: t, backend: e } = n, { x: s, alpha: o } = t, r = F().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new Ga(Aw, s.shape, o.shape) : new fr(Pw, s.shape, o.shape);
  return e.runWebGLProgram(r, [s, o], "float32");
}
var lA = {
  kernelName: Cc,
  backendName: "webgl",
  kernelFunc: aA
};
var Gr = "if (isnan(x)) return x;";
function Nt({ opSnippet: n, packedOpSnippet: t, cpuKernelImpl: e, dtype: s }) {
  return ({ inputs: o, backend: r }) => {
    const { x: i6 } = o, a = r, l = s || i6.dtype;
    if (a.shouldExecuteOnCPU([i6]) && e != null) {
      const d = a.texData.get(i6.dataId), h6 = e(d.values, l);
      return a.makeTensorInfo(i6.shape, l, h6);
    }
    const c = F().getBool("WEBGL_PACK_UNARY_OPERATIONS") && t != null;
    let u;
    return c ? u = new Ls(i6.shape, t) : u = new qn(i6.shape, n), a.runWebGLProgram(u, [i6], l);
  };
}
function Ne({ opSnippet: n, packedOpSnippet: t, checkOutOfBounds: e = false, supportsComplex: s = false, cpuKernelImpl: o, dtype: r }) {
  return ({ inputs: i6, backend: a }) => {
    const { a: l, b: c } = i6, u = a;
    if (s && l.dtype === "complex64") {
      const f = u.texData.get(l.dataId), m = u.texData.get(c.dataId), [g6, b6] = [
        [f.complexTensorInfos.real, m.complexTensorInfos.real],
        [f.complexTensorInfos.imag, m.complexTensorInfos.imag]
      ].map((w6) => {
        const [y6, I] = w6, C6 = {
          dataId: y6.dataId,
          dtype: y6.dtype,
          shape: l.shape
        }, k7 = {
          dataId: I.dataId,
          dtype: I.dtype,
          shape: c.shape
        }, S = new fr(n, l.shape, c.shape);
        return u.runWebGLProgram(S, [C6, k7], je(y6.dtype, I.dtype));
      }), x6 = js({ inputs: { real: g6, imag: b6 }, backend: u });
      return u.disposeIntermediateTensorInfo(g6), u.disposeIntermediateTensorInfo(b6), x6;
    }
    const d = r || je(l.dtype, c.dtype);
    if ((l.dtype === "string" || c.dtype === "string" || u.shouldExecuteOnCPU([l, c])) && o != null) {
      const f = u.texData.get(l.dataId).values, m = u.texData.get(c.dataId).values, g6 = l.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        No(f)
      ) : f, b6 = l.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        No(m)
      ) : m, [x6, w6] = o(l.shape, c.shape, g6, b6, d), y6 = u.makeTensorInfo(w6, d), I = u.texData.get(y6.dataId);
      return I.values = x6, y6;
    }
    const h6 = F().getBool("WEBGL_PACK_BINARY_OPERATIONS") && t != null;
    let p6;
    return h6 ? p6 = new Ga(t, l.shape, c.shape, e) : p6 = new fr(n, l.shape, c.shape), u.runWebGLProgram(p6, [l, c], d);
  };
}
function ai(n, t = false) {
  if (n === "linear")
    return t ? KP : zP;
  if (n === "relu")
    return t ? BP : PP;
  if (n === "elu")
    return t ? ZP : XP;
  if (n === "relu6")
    return t ? HP : AP;
  if (n === "prelu")
    return t ? Aw : Pw;
  if (n === "leakyrelu")
    return t ? Xw : zw;
  if (n === "sigmoid")
    return t ? _P : OP;
  throw new Error(`Activation ${n} has not been implemented for the WebGL backend.`);
}
var Ow = class {
  constructor(t, e, s, o = false, r = false, i6 = false, a = null, l = false, c = false) {
    this.variableNames = ["matrixA", "matrixB"], this.packedInputs = true, this.packedOutput = true, this.outputShape = s, this.enableShapeUniforms = Xe(this.outputShape.length);
    const u = o ? t[1] : t[2], d = Math.ceil(u / 2), h6 = o ? "i * 2, rc.y" : "rc.y, i * 2", p6 = r ? "rc.z, i * 2" : "i * 2, rc.z", f = o ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"], m = r ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
    let g6 = "", b6 = "";
    a && (l ? g6 = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${a}
        }` : c ? g6 = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${a}
        }` : g6 = `vec4 activation(vec4 x) {
          ${a}
        }`, b6 = "result = activation(result);");
    const x6 = i6 ? "result += getBiasAtOutCoords();" : "";
    i6 && this.variableNames.push("bias"), l && this.variableNames.push("preluActivationWeights"), c && this.variableNames.push("leakyreluAlpha");
    let w6 = "rc.x", y6 = "rc.x";
    t[0] < e[0] ? w6 = `imod(rc.x, ${t[0]})` : e[0] < t[0] && (y6 = `imod(rc.x, ${e[0]})`), this.userCode = `
      ${g6}
      // Don't use uniform for sharedDimensionPacked for performance.
      const float sharedDimension = ${d}.0;

      vec4 dot2x2ARowBCol(ivec3 rc) {
        vec4 result = vec4(0);
        int batchA = ${w6};
        int batchB = ${y6};
        for (int i = 0; i < ${d}; i++) {
          vec4 a = getMatrixA(batchA, ${h6});
          vec4 b = getMatrixB(batchB, ${p6});

          // These swizzled products need to be separately added.
          // See: https://github.com/tensorflow/tfjs/issues/1735
          result += (${f[0]} * ${m[0]});
          result += (${f[1]} * ${m[1]});
        }
        return result;
      }

      void main() {
        ivec3 rc = getOutputCoords();
        vec4 result = dot2x2ARowBCol(rc);

        ${x6}

        ${b6}

        setOutput(result);
      }
    `;
  }
};
var rg = {
  REAL: "return areal * breal - aimag * bimag;",
  IMAG: "return areal * bimag + aimag * breal;"
};
var ig = class {
  constructor(t, e, s) {
    this.variableNames = ["AReal", "AImag", "BReal", "BImag"], this.outputShape = bt(e, s), this.userCode = `
      float binaryOpComplex(
          float areal, float aimag, float breal, float bimag) {
        ${t}
      }

      void main() {
        float areal = getARealAtOutCoords();
        float aimag = getAImagAtOutCoords();
        float breal = getBRealAtOutCoords();
        float bimag = getBImagAtOutCoords();
        setOutput(binaryOpComplex(areal, aimag, breal, bimag));
      }
    `;
  }
};
var ag = "return a * b;";
function Of(n) {
  const { inputs: t, backend: e } = n, { a: s, b: o } = t, r = je(s.dtype, o.dtype);
  if (s.dtype === "complex64") {
    const a = e.texData.get(s.dataId), l = e.texData.get(o.dataId), c = new ig(rg.REAL, s.shape, o.shape), u = new ig(rg.IMAG, s.shape, o.shape), d = [
      {
        dataId: a.complexTensorInfos.real.dataId,
        dtype: a.complexTensorInfos.real.dtype,
        shape: s.shape
      },
      {
        dataId: a.complexTensorInfos.imag.dataId,
        dtype: a.complexTensorInfos.imag.dtype,
        shape: s.shape
      },
      {
        dataId: l.complexTensorInfos.real.dataId,
        dtype: l.complexTensorInfos.real.dtype,
        shape: o.shape
      },
      {
        dataId: l.complexTensorInfos.imag.dataId,
        dtype: l.complexTensorInfos.imag.dtype,
        shape: o.shape
      }
    ], h6 = e.runWebGLProgram(c, d, "float32"), p6 = e.runWebGLProgram(u, d, "float32"), f = js({ inputs: { real: h6, imag: p6 }, backend: e });
    return e.disposeIntermediateTensorInfo(h6), e.disposeIntermediateTensorInfo(p6), f;
  }
  if (e.shouldExecuteOnCPU([s, o])) {
    const a = e.texData.get(s.dataId), l = e.texData.get(o.dataId), [c, u] = lP(s.shape, o.shape, a.values, l.values, r), d = e.makeTensorInfo(u, r), h6 = e.texData.get(d.dataId);
    return h6.values = c, d;
  }
  let i6;
  return F().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? i6 = new Ga(ag, s.shape, o.shape) : i6 = new fr(ag, s.shape, o.shape), e.runWebGLProgram(i6, [s, o], r);
}
var cA = {
  kernelName: Pi,
  backendName: "webgl",
  kernelFunc: Of
};
function uA(n, t, e) {
  const s = [
    hr(n.shape),
    ...pr(n.shape)
  ], o = {
    dtype: n.dtype,
    shape: s,
    dataId: n.dataId
  }, r = [
    hr(t),
    ...pr(t)
  ], i6 = new Vw(r, s), a = true, l = [s], c = e.runWebGLProgram(i6, [o], n.dtype, l, a);
  return { dataId: c.dataId, shape: t, dtype: c.dtype };
}
function st(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { shape: r } = s, i6 = e, a = O(o.shape), l = Ad(r, a), c = O(l);
  v2(a === c, () => `The new shape (${l}) has ${c} elements and the old shape (${o.shape}) has ${a} elements. The new shape and old shape must have the same number of elements.`);
  const u = i6.texData.get(o.dataId);
  return u.isPacked && !$l(o.shape, l) && !(u.texture !== null && $l(u.shape, l)) ? uA(o, l, i6) : (i6.incRef(o.dataId), { dataId: o.dataId, shape: l, dtype: o.dtype });
}
var dA = {
  kernelName: Sc,
  backendName: "webgl",
  kernelFunc: st
};
var lg = class {
  constructor(t, e) {
    this.variableNames = ["x"];
    const { windowSize: s, batchSize: o, inSize: r, outSize: i6 } = t;
    this.outputShape = [o, i6];
    const a = Math.floor(s / 4) * 4, l = s % 4;
    let c = "sumValue += dot(values, ones);";
    if (e != null) {
      const d = 1 / e;
      c = `sumValue += dot(values * ${go(d) ? d.toPrecision(2) : d}, ones);`;
    }
    let u = "";
    r % s > 0 && (u = `
        if (inIdx < 0 || inIdx >= ${r}) {
          return 0.0;
        }
      `), this.userCode = `
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${u}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${s};

        float sumValue = 0.0;

        for (int i = 0; i < ${a}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${c}
        }

        int inIdx = inOffset + ${a};
        if (${l === 1}) {
          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);

          ${c}
        } else if (${l === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1), 0.0, 0.0);

          ${c}
        } else if (${l === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2), 0.0);

          ${c}
        }
        setOutput(sumValue);
      }
    `;
  }
};
var hA = class {
  constructor(t, e) {
    this.variableNames = ["x"];
    const { windowSize: s, batchSize: o, inSize: r, outSize: i6 } = t;
    this.outputShape = [o, i6];
    let a = "0.0", l = "";
    e === "prod" ? a = "1.0" : e === "min" ? (a = "1.0 / 1e-20", l = "min") : e === "max" && (a = "-1.0 / 1e-20", l = "max");
    let c = `${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    e === "sum" ? c = "sumValue" : e === "prod" ? c = "prodValue" : e === "all" ? c = "allValue" : e === "any" && (c = "anyValue");
    const u = Math.floor(s / 4) * 4, d = s % 4;
    let h6 = `
      if (${e === "sum"}) {
        sumValue += dot(values, ones);
      } else if (${e === "prod"}) {
        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);
        prodValue *= tmp[0] * tmp[1];
      } else {
        minMaxValue = ${l}(values, minMaxValue);
        if (${e === "min"} || ${e === "max"}) {
          minMaxValue = ${l}(values, minMaxValue);
          bvec4 isNaN = isnan(values);
          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {
            minMaxValue = vec4(NAN);
          }
        }
      }
    `, p6 = "vec4";
    e === "all" ? (a = "1.0", h6 = `
        bool reducedAllValue = all(values);
        float floatedReducedAllValue = float(reducedAllValue);
        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);
      `, p6 = "bvec4") : e === "any" && (a = "0.0", h6 = `
        bool reducedAnyValue = any(values);
        float floatedReducedAnyValue = float(reducedAnyValue);
        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);
      `, p6 = "bvec4");
    let f = "";
    r % s > 0 && (f = `
        if (inIdx < 0 || inIdx >= ${r}) {
          return initializationValue;
        }
      `), this.userCode = `
      const float initializationValue = ${a};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${f}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${s};

        vec4 minMaxValue = vec4(${a});
        float prodValue = 1.0;
        float sumValue = 0.0;
        float allValue = 1.0;
        float anyValue = 0.0;

        for (int i = 0; i < ${u}; i += 4) {
          int inIdx = inOffset + i;
          ${p6} values = ${p6}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${h6}
        }

        int inIdx = inOffset + ${u};
        if (${d === 1}) {
          ${p6} values = ${p6}(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          ${h6}
        } else if (${d === 2}) {
          ${p6} values = ${p6}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          ${h6}
        } else if (${d === 3}) {
          ${p6} values = ${p6}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          ${h6}
        }
        setOutput(${c});
      }
    `;
  }
};
function pA(n) {
  const t = [];
  for (; t.length === 0 || t[t.length - 1].outSize !== 1; ) {
    const e = t.length ? t[t.length - 1].outSize : n[1], s = Uc(e);
    t.push({
      inSize: e,
      windowSize: s,
      outSize: Math.ceil(e / s)
    });
  }
  return t;
}
function Oo(n, t, e, s) {
  const o = pA(n.shape);
  let r = n;
  for (let i6 = 0; i6 < o.length; i6++) {
    const { inSize: a, windowSize: l, outSize: c } = o[i6];
    let u, d;
    e === "mean" ? u = i6 === 0 ? new lg({ windowSize: l, inSize: a, batchSize: n.shape[0], outSize: c }, a) : new lg({ windowSize: l, inSize: a, batchSize: n.shape[0], outSize: c }) : u = new hA({ windowSize: l, inSize: a, batchSize: n.shape[0], outSize: c }, e), d = r, r = s.runWebGLProgram(u, [r], t), d.dataId !== n.dataId && s.disposeIntermediateTensorInfo(d);
  }
  return r;
}
var fA = class {
  constructor(t, e) {
    this.variableNames = ["A"];
    const s = new Array(t.length);
    for (let i6 = 0; i6 < s.length; i6++)
      s[i6] = t[e[i6]];
    this.outputShape = s, this.rank = s.length;
    const o = Kt(this.rank), r = mA(e);
    this.userCode = `
    void main() {
      ${o} resRC = getOutputCoords();
      setOutput(getA(${r}));
    }
    `;
  }
};
function mA(n) {
  const t = n.length;
  if (t > 6)
    throw Error(`Transpose for rank ${t} is not yet supported`);
  const e = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"], s = new Array(t);
  for (let o = 0; o < n.length; o++)
    s[n[o]] = e[o];
  return s.join();
}
var gA = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true;
    const s = new Array(t.length);
    for (let u = 0; u < s.length; u++)
      s[u] = t[e[u]];
    if (this.outputShape = s, this.rank = s.length, this.rank > 6)
      throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);
    const o = Kt(this.rank), r = Fw("rc", this.rank), i6 = new Array(this.rank);
    for (let u = 0; u < e.length; u++)
      i6[e[u]] = r[u];
    const a = `vec2(${i6.slice(-2).join()})`, l = `++${r[this.rank - 1]} < ${s[this.rank - 1]}`, c = `getChannel(getA(${i6.join()}), ${a})`;
    this.userCode = `
    void main() {
      ${o} rc = getOutputCoords();
      vec4 result = vec4(0.);
      result[0] = ${c};
      if(${l}) {
        result[1] = ${c};
      }
      --${r[this.rank - 1]};
      if(++${r[this.rank - 2]} < ${s[this.rank - 2]}) {
        result[2] = ${c};
        if(${l}) {
          result[3] = ${c};
        }
      }
      setOutput(result);
    }
    `;
  }
};
function pu(n, t, e) {
  const s = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new gA(n.shape, t) : new fA(n.shape, t);
  return e.runWebGLProgram(s, [n], n.dtype);
}
function bA(n, t, e, s) {
  const o = t, r = n.shape.length, i6 = Ct(o, n.shape);
  let a = i6;
  const l = qt(a, r), c = l != null;
  let u = n;
  c && (u = pu(n, l, s), a = ie(a.length, r)), Te("sum", a, r);
  const [d, h6] = ye(u.shape, a);
  let p6 = d;
  e && (p6 = re(d, i6));
  const f = O(h6), g6 = O(n.shape) / f, b6 = st({ inputs: { x: u }, attrs: { shape: [g6, f] }, backend: s }), x6 = zh(n.dtype), w6 = Oo(b6, x6, "sum", s), y6 = st({ inputs: { x: w6 }, attrs: { shape: p6 }, backend: s });
  return s.disposeIntermediateTensorInfo(b6), s.disposeIntermediateTensorInfo(w6), c && s.disposeIntermediateTensorInfo(u), y6;
}
function fu(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  return bA(o, r, i6, e);
}
var xA = {
  kernelName: Gc,
  backendName: "webgl",
  kernelFunc: fu
};
function Fe(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { perm: r } = s, i6 = e, a = o.shape.length, l = new Array(a);
  for (let u = 0; u < l.length; u++)
    l[u] = o.shape[r[u]];
  let c;
  if (i6.shouldExecuteOnCPU([o])) {
    const d = i6.texData.get(o.dataId).values, h6 = Pf(d, o.shape, o.dtype, r, l);
    c = i6.makeTensorInfo(l, o.dtype);
    const p6 = i6.texData.get(c.dataId);
    p6.values = h6;
  } else
    c = pu(o, r, i6);
  return c;
}
var yA = {
  kernelName: Jo,
  backendName: "webgl",
  kernelFunc: Fe
};
var Kw = 1e3;
function Gl({ a: n, b: t, transposeA: e, transposeB: s, backend: o, bias: r = null, preluActivationWeights: i6 = null, leakyreluAlpha: a = 0, activation: l = null }) {
  const c = n.shape.length, u = t.shape.length, d = e ? n.shape[c - 2] : n.shape[c - 1], h6 = s ? t.shape[u - 1] : t.shape[u - 2], p6 = e ? n.shape[c - 1] : n.shape[c - 2], f = s ? t.shape[u - 2] : t.shape[u - 1], m = n.shape.slice(0, -2), g6 = t.shape.slice(0, -2), b6 = O(m), x6 = O(g6), y6 = bt(n.shape.slice(0, -2), t.shape.slice(0, -2)).concat([p6, f]);
  v2(d === h6, () => `Error in matMul: inner shapes (${d}) and (${h6}) of Tensors with shapes ${n.shape} and ${t.shape} and transposeA=${e} and transposeB=${s} must match.`);
  const I = e ? [b6, d, p6] : [b6, p6, d], C6 = s ? [x6, f, h6] : [x6, h6, f], k7 = st({ inputs: { x: n }, backend: o, attrs: { shape: I } }), S = st({ inputs: { x: t }, backend: o, attrs: { shape: C6 } }), N = [k7, S], R = Math.max(b6, x6), M6 = e ? k7.shape[1] : k7.shape[2], V = r != null, z = i6 != null, X = l === "leakyrelu", P6 = l != null ? ai(l, true) : null, A6 = V || z || X || P6 != null;
  let B6;
  if ((p6 === 1 || f === 1) && M6 > Kw && A6 === false) {
    let H6 = k7, Y = S;
    e && (H6 = Fe({ inputs: { x: k7 }, backend: o, attrs: { perm: [0, 2, 1] } }), N.push(H6)), s && (Y = Fe({ inputs: { x: S }, backend: o, attrs: { perm: [0, 2, 1] } }), N.push(Y));
    const Q = f !== 1, j = f === 1;
    let J6 = H6;
    Q && (J6 = st({
      inputs: { x: H6 },
      backend: o,
      attrs: { shape: [R, M6, 1] }
    }), N.push(J6));
    const nt = f === 1 ? 2 : 1;
    let q = Y;
    j && (q = st({
      inputs: { x: Y },
      backend: o,
      attrs: { shape: [R, 1, M6] }
    }), N.push(q));
    const rt = Of({ inputs: { a: J6, b: q }, backend: o });
    B6 = fu({ inputs: { x: rt }, backend: o, attrs: { axis: nt, keepDims: true } }), N.push(rt);
  } else {
    const H6 = je(n.dtype, t.dtype), Y = new Ow(I, C6, [R, p6, f], e, s, V, P6, z, X), Q = [k7, S];
    if (r != null && Q.push(r), z && Q.push(i6), X) {
      const j = o.makeTensorInfo([], "float32", bs(a, "float32"));
      Q.push(j), N.push(j);
    }
    B6 = o.runWebGLProgram(Y, Q, H6);
  }
  const Z = st({ inputs: { x: B6 }, backend: o, attrs: { shape: y6 } });
  N.push(B6);
  for (const H6 of N)
    o.disposeIntermediateTensorInfo(H6);
  return Z;
}
function wA(n) {
  const { inputs: t, backend: e, attrs: s } = n, { a: o, b: r, bias: i6, preluActivationWeights: a } = t, { transposeA: l, transposeB: c, activation: u, leakyreluAlpha: d } = s;
  return Gl({
    a: o,
    b: r,
    transposeA: l,
    transposeB: c,
    backend: e,
    bias: i6,
    preluActivationWeights: a,
    leakyreluAlpha: d,
    activation: u
  });
}
var IA = {
  kernelName: ol,
  backendName: "webgl",
  kernelFunc: wA
};
var cg = "return abs(x);";
function CA(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (e.shouldExecuteOnCPU([s]) && s.dtype !== "complex64") {
    const r = e.texData.get(s.dataId), i6 = Ww(r.values);
    return e.makeTensorInfo(s.shape, s.dtype, i6);
  }
  let o;
  return F().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? o = new Ls(s.shape, cg) : o = new qn(s.shape, cg), e.runWebGLProgram(o, [s], s.dtype);
}
var vA = {
  kernelName: Vl,
  backendName: "webgl",
  kernelFunc: CA
};
var SA = En + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return acos(x);
`;
var kA = Nt({ opSnippet: SA });
var TA = {
  kernelName: di,
  backendName: "webgl",
  kernelFunc: kA
};
var NA = En + `
  if (x < 1.0) return NAN;
return log(x + sqrt(x * x - 1.0));`;
var RA = Nt({ opSnippet: NA });
var $A = {
  kernelName: hi,
  backendName: "webgl",
  kernelFunc: RA
};
var ug = "return a + b;";
var GA = Ne({
  opSnippet: ug,
  packedOpSnippet: ug,
  supportsComplex: true,
  cpuKernelImpl: OX
});
var EA = {
  kernelName: br,
  backendName: "webgl",
  kernelFunc: GA
};
var LA = class {
  constructor(t, e) {
    this.outputShape = [], this.outputShape = t, this.variableNames = e.map((r, i6) => `T${i6}`);
    const s = [];
    this.variableNames.forEach((r) => {
      s.push(`float v${r} = get${r}AtOutCoords();`);
    });
    const o = this.variableNames.map((r) => `v${r}`).join(" + ");
    this.userCode = `
      void main() {
        ${s.join(`
        `)}

        float result = ${o};
        setOutput(result);
      }
    `;
  }
};
var MA = class {
  constructor(t, e) {
    this.outputShape = [], this.packedInputs = true, this.packedOutput = true, this.outputShape = t, this.variableNames = e.map((r, i6) => `T${i6}`);
    const s = [];
    this.variableNames.forEach((r) => {
      s.push(`vec4 v${r} = get${r}AtOutCoords();`);
    });
    const o = this.variableNames.map((r) => `v${r}`).join(" + ");
    this.userCode = `
      void main() {
        ${s.join(`
        `)}

        vec4 result = ${o};
        setOutput(result);
      }
    `;
  }
};
function tl(n) {
  const { inputs: t, backend: e } = n, s = t;
  if (s.length === 1)
    return tn({ inputs: { x: s[0] }, backend: e });
  if (s.length > F().get("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    const l = Math.floor(s.length / 2), c = tl({ inputs: s.slice(0, l), backend: e }), u = tl({ inputs: s.slice(l), backend: e });
    return tl({ inputs: [c, u], backend: e });
  }
  const o = s.map((l) => l.dtype).reduce((l, c) => je(l, c)), r = s.map((l) => l.shape), a = F().getBool("WEBGL_PACK") ? new MA(s[0].shape, r) : new LA(s[0].shape, r);
  return e.runWebGLProgram(a, s, o);
}
var WA = {
  kernelName: Bd,
  backendName: "webgl",
  kernelFunc: tl
};
function DA(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = o.shape.length, l = Ct(r, o.shape);
  let c = l;
  const u = qt(c, a);
  let d = o;
  u != null && (d = Fe({ inputs: { x: o }, backend: e, attrs: { perm: u } }), c = ie(c.length, a)), Te("all", c, a);
  const [h6, p6] = ye(d.shape, c), f = O(p6), m = st({ inputs: { x: d }, backend: e, attrs: { shape: [-1, f] } }), g6 = Oo(m, m.dtype, "all", e);
  let b6;
  if (i6) {
    const x6 = re(h6, l);
    b6 = st({ inputs: { x: g6 }, backend: e, attrs: { shape: x6 } });
  } else
    b6 = st({ inputs: { x: g6 }, backend: e, attrs: { shape: h6 } });
  return e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(g6), u != null && e.disposeIntermediateTensorInfo(d), b6;
}
var FA = {
  kernelName: Hd,
  backendName: "webgl",
  kernelFunc: DA
};
function VA(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = o.shape.length, l = Ct(r, o.shape);
  let c = l;
  const u = qt(c, a);
  let d = o;
  u != null && (d = Fe({ inputs: { x: o }, backend: e, attrs: { perm: u } }), c = ie(c.length, a)), Te("any", c, a);
  const [h6, p6] = ye(d.shape, c), f = O(p6), m = st({ inputs: { x: d }, backend: e, attrs: { shape: [-1, f] } }), g6 = Oo(m, m.dtype, "any", e);
  let b6;
  if (i6) {
    const x6 = re(h6, l);
    b6 = st({ inputs: { x: g6 }, backend: e, attrs: { shape: x6 } });
  } else
    b6 = st({ inputs: { x: g6 }, backend: e, attrs: { shape: h6 } });
  return e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(g6), u != null && e.disposeIntermediateTensorInfo(d), b6;
}
var zA = {
  kernelName: _d,
  backendName: "webgl",
  kernelFunc: VA
};
var XA = class {
  constructor(t, e, s) {
    this.variableNames = ["A"];
    const { windowSize: o, batchSize: r, outSize: i6 } = t;
    s || this.variableNames.push("bestIndicesA"), this.outputShape = [r, i6];
    const a = e === "max" ? ">" : "<", l = s ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));";
    this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${o};

        int bestIndex = inOffset;
        float bestValue = getA(batch, bestIndex);

        for (int i = 0; i < ${o}; i++) {
          int inIdx = ${l};
          float candidate = getA(batch, inIdx);
          if (candidate ${a} bestValue) {
            bestValue = candidate;
            bestIndex = inIdx;
          }
        }
        setOutput(float(bestIndex));
      }
    `;
  }
};
var PA = class {
  constructor(t, e, s, o) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, v2(t.length > 2, () => `Packed arg${s.charAt(0).toUpperCase() + s.slice(1)} supports only inputs with rank above 2.`);
    const r = t[t.length - 1], i6 = Math.ceil(r / e);
    this.outputShape = t.slice(0, -1), i6 > 1 && this.outputShape.push(i6), o || this.variableNames.push("bestIndicesA");
    const a = this.outputShape, l = a.length, c = Kt(l), u = We("coords", l);
    let d, h6;
    if (i6 === 1) {
      h6 = l + 1;
      const S = Kt(h6);
      d = `
        ${S} sourceLocR = ${S}(${u.join()}, 0);
        ++${u[l - 1]};
        ${S} sourceLocG = ${S}(${u.join()}, 0);
        ++${u[l - 2]};
        ${S} sourceLocA = ${S}(${u.join()}, 0);
        --${u[l - 1]};
        ${S} sourceLocB = ${S}(${u.join()}, 0);
        --${u[l - 2]};`;
    } else
      h6 = l, d = `
        ${c} sourceLocR = coords;
        ++${u[l - 1]};
        ${c} sourceLocG = coords;
        ++${u[l - 2]};
        ${c} sourceLocA = coords;
        --${u[l - 1]};
        ${c} sourceLocB = coords;
        --${u[l - 2]};`;
    const p6 = ["x", "y", "z", "w", "u", "v"].slice(0, h6), f = "." + p6[h6 - 1], m = p6.map((S) => "int " + S), g6 = We("sourceLocR", h6 - 1).concat("inIdx.r"), b6 = We("sourceLocG", h6 - 1).concat("inIdx.g"), x6 = We("sourceLocB", h6 - 1).concat("inIdx.b"), w6 = We("sourceLocA", h6 - 1).concat("inIdx.a"), y6 = s === "max" ? "greaterThan" : "lessThan", I = o ? "" : `
          inIdx = round(vec4(getBestIndicesAChannel(${g6.join()}),
                             getBestIndicesAChannel(${b6.join()}),
                             getBestIndicesAChannel(${x6.join()}),
                             getBestIndicesAChannel(${w6.join()})));`, C6 = `vec4(
            getAChannel(${g6.join()}),
            hasNextCol ? getAChannel(${b6.join()}) : 0.,
            hasNextRow ? getAChannel(${x6.join()}) : 0.,
            hasNextRow && hasNextCol ? getAChannel(${w6.join()}) : 0.)`, k7 = o ? "" : `
      float getBestIndicesAChannel(${m.join()}) {
        return getChannel(getBestIndicesA(${p6.join()}),
                                          vec2(${p6.slice(-2).join()}));
      }`;
    this.userCode = `
      float getAChannel(${m.join()}) {
        return getChannel(getA(${p6.join()}),
                               vec2(${p6.slice(-2).join()}));
      }
      ${k7}
      void main() {
        ${c} coords = getOutputCoords();
        bool hasNextCol = ${u[l - 1]} < ${a[l - 1] - 1};
        bool hasNextRow = ${u[l - 2]} < ${a[l - 2] - 1};
        ${d}
        ivec4 srcIdx = ivec4(sourceLocR${f}, sourceLocG${f},
          sourceLocB${f}, sourceLocA${f}) * ${e};
        ivec4 inIdx = srcIdx;
        vec4 bestIndex = vec4(inIdx);
        vec4 bestValue = ${C6};

        for (int i = 0; i < ${e}; i++) {
          inIdx = srcIdx;
          ${I}
          vec4 candidate = ${C6};
          bvec4 nan = isnan(candidate);
          bvec4 replace = bvec4(
            vec4(${y6}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));

          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,
                           replace.y  ? candidate.y : bestValue.y,
                           replace.z  ? candidate.z : bestValue.z,
                           replace.w  ? candidate.w : bestValue.w);
          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));
          srcIdx++;
        }
        setOutput(bestIndex);
      }
    `;
  }
};
function Zw(n, t, e, s = null) {
  let o = t.shape[0], r = t.shape[1];
  s != null && (o = s.shape[0], r = s.shape[1]);
  const i6 = Uc(r), a = { windowSize: i6, inSize: r, batchSize: o, outSize: Math.ceil(r / i6) }, l = new XA(a, e, s == null), c = [t];
  s != null && c.push(s);
  const u = n.runWebGLProgram(l, c, "int32");
  if (u.shape[1] === 1)
    return u;
  const d = Zw(n, t, e, u);
  return n.disposeIntermediateTensorInfo(u), d;
}
function Bw(n, t, e, s = null) {
  const o = s != null ? s.shape : t.shape, r = o[o.length - 1], i6 = Uc(r), a = new PA(o, i6, e, s == null), l = s == null ? [t] : [t, s], c = n.runWebGLProgram(a, l, "int32");
  if (c.shape.length === t.shape.length) {
    const u = Bw(n, t, e, c);
    return n.disposeIntermediateTensorInfo(c), u;
  }
  return c;
}
function Hw(n, t, e, s) {
  const o = [e];
  if (Te("arg" + s.charAt(0).toUpperCase() + s.slice(1), o, t.shape.length), !F().getBool("WEBGL_PACK_REDUCE") || t.shape.length <= 2) {
    const r = [], i6 = n.texData.get(t.dataId), a = i6 !== null && i6.isPacked;
    let l = t;
    a && (l = n.unpackTensor(t), r.push(l));
    const [c, u] = ye(l.shape, o), d = O(u), h6 = st({ inputs: { x: l }, backend: n, attrs: { shape: [-1, d] } });
    r.push(h6);
    const p6 = Zw(n, h6, s);
    r.push(p6);
    const f = st({ inputs: { x: p6 }, backend: n, attrs: { shape: c } });
    return r.forEach((m) => n.disposeIntermediateTensorInfo(m)), f;
  }
  return Bw(n, t, s);
}
function AA(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r } = s;
  let i6 = Ct(r, o.shape);
  const a = qt(i6, o.shape.length);
  let l = o;
  const c = [];
  a != null && (l = Fe({ inputs: { x: o }, backend: e, attrs: { perm: a } }), c.push(l), i6 = ie(i6.length, l.shape.length)), Te("argMax", [i6[0]], l.shape.length);
  const u = Hw(e, l, i6[0], "max");
  return c.forEach((d) => e.disposeIntermediateTensorInfo(d)), u;
}
var OA = {
  kernelName: zl,
  backendName: "webgl",
  kernelFunc: AA
};
function KA(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r } = s;
  let i6 = Ct(r, o.shape);
  const a = qt(i6, o.shape.length);
  let l = o;
  const c = [];
  a != null && (l = Fe({ inputs: { x: o }, backend: e, attrs: { perm: a } }), c.push(l), i6 = ie(i6.length, l.shape.length)), Te("argMin", [i6[0]], l.shape.length);
  const u = Hw(e, l, i6[0], "min");
  return c.forEach((d) => e.disposeIntermediateTensorInfo(d)), u;
}
var ZA = {
  kernelName: Xl,
  backendName: "webgl",
  kernelFunc: KA
};
var BA = En + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return asin(x);
`;
var HA = Nt({ opSnippet: BA });
var _A = {
  kernelName: pi,
  backendName: "webgl",
  kernelFunc: HA
};
var UA = En + "return log(x + sqrt(x * x + 1.0));";
var YA = Nt({ opSnippet: UA });
var QA = {
  kernelName: fi,
  backendName: "webgl",
  kernelFunc: YA
};
var JA = En + `
  return atan(x);
`;
var jA = Nt({ opSnippet: JA });
var qA = {
  kernelName: mi,
  backendName: "webgl",
  kernelFunc: jA
};
var tO = Af + `
  return atan(a, b);
`;
var eO = `
  vec4 result = atan(a, b);
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + $a + `
  return result;
`;
var nO = Ne({ opSnippet: tO, packedOpSnippet: eO });
var sO = {
  kernelName: bi,
  backendName: "webgl",
  kernelFunc: nO
};
var oO = En + `
  if ((x < -1.0) || (x > 1.0)) return NAN;
return (log(1.0 + x) - log(1.0 - x)) / 2.0;`;
var rO = Nt({ opSnippet: oO });
var iO = {
  kernelName: gi,
  backendName: "webgl",
  kernelFunc: rO
};
var li = class {
  constructor(t, e, s, o = false, r = false) {
    if (this.variableNames = ["x"], e === "avg" && s)
      throw new Error("Cannot compute positions for average pool.");
    const i6 = t.filterWidth, a = t.strideHeight, l = t.strideWidth, c = t.dilationHeight, u = t.dilationWidth, d = t.effectiveFilterHeight, h6 = t.effectiveFilterWidth, p6 = t.padInfo.top, f = t.padInfo.left;
    this.outputShape = t.outShape;
    const m = e === "avg", g6 = `((batch  * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + d`, b6 = `(xR * ${t.inWidth} + xC) * ${t.inChannels} + d`;
    let x6 = "0.0";
    if (m || (x6 = "-1.0 / 1e-20"), s) {
      const S = ">=";
      this.userCode = `
        const ivec2 strides = ivec2(${a}, ${l});
        const ivec2 pads = ivec2(${p6}, ${f});

        void main() {
          ivec4 coords = getOutputCoords();
          int batch = coords[0];
          int d = coords[3];

          ivec2 xRCCorner = coords.yz * strides - pads;
          int xRCorner = xRCCorner.x;
          int xCCorner = xRCCorner.y;

          // max/min x(?, ?, d) to get y(yR, yC, d).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;
          float avgValue = 0.0;

          for (int wR = 0; wR < ${d};
              wR += ${c}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${h6};
                wC += ${u}) {
              int xC = xCCorner + wC;

              if (xC < 0 || xC >= ${t.inWidth}) {
                continue;
              }

              float value = getX(batch, xR, xC, d);

              // If a min / max value has already been found, use it. If not,
              // use the current value.
              float currMinMaxValue = mix(
                  value, minMaxValue, minMaxValueFound);
              if (value ${S} currMinMaxValue) {
                minMaxValue = value;
                minMaxValueFound = 1.0;
                minMaxPosition = ${o ? r ? g6 : b6 : `wR * ${h6} + wC`};
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
      return;
    }
    const w6 = "max";
    let y6 = `${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    e === "avg" && (y6 = "avgValue / max(count, 1.0)");
    const I = Math.floor(i6 / 4) * 4, C6 = i6 % 4, k7 = `
      if (${m}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${w6}(values, minMaxValue);
      }
    `;
    this.userCode = `
      const ivec2 strides = ivec2(${a}, ${l});
      const ivec2 pads = ivec2(${p6}, ${f});
      const float initializationValue = ${x6};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xR, int xC, int d) {
        if (xC < 0 || xC >= ${t.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xR, xC, d);
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d = coords[3];

        ivec2 xRCCorner = coords.yz * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // max/min x(?, ?, d) to get y(yR, yC, d).
        // ? = to be determined
        vec4 minMaxValue = vec4(${x6});
        float avgValue = 0.0;
        count = 0.0;

        for (int wR = 0; wR < ${d};
            wR += ${c}) {
          int xR = xRCorner + wR;

          if (xR < 0 || xR >= ${t.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${I}; wC += 4) {
            int xC = xCCorner + wC * ${u};

            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${u}, d),
              getValue(batch, xR, xC + 2 * ${u}, d),
              getValue(batch, xR, xC + 3 * ${u}, d)
            );

            ${k7}
          }

          int xC = xCCorner + ${I};
          if (${C6 === 1}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              initializationValue,
              initializationValue,
              initializationValue
            );

            ${k7}
          } else if (${C6 === 2}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${u}, d),
              initializationValue,
              initializationValue
            );

            ${k7}
          } else if (${C6 === 3}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${u}, d),
              getValue(batch, xR, xC + 2 * ${u}, d),
              initializationValue
            );

            ${k7}
          }
        }
        setOutput(${y6});
      }
    `;
  }
};
var Kf = class {
  constructor(t, e, s, o = false, r = false) {
    if (this.variableNames = ["x"], e === "avg" && s)
      throw new Error("Cannot compute positions for average pool.");
    const i6 = t.filterWidth, a = t.strideDepth, l = t.strideHeight, c = t.strideWidth, u = t.dilationDepth, d = t.dilationHeight, h6 = t.dilationWidth, p6 = t.effectiveFilterDepth, f = t.effectiveFilterHeight, m = t.effectiveFilterWidth, g6 = t.padInfo.front, b6 = t.padInfo.top, x6 = t.padInfo.left;
    this.outputShape = t.outShape;
    const w6 = e === "avg";
    let y6 = "0.0";
    if (w6 || (y6 = "-1.0 / 1e-20"), s) {
      const R = ">=";
      this.userCode = `
        const ivec3 strides =
            ivec3(${a}, ${l}, ${c});
        const ivec3 pads = ivec3(${g6}, ${b6}, ${x6});

        void main() {
          ivec5 coords = getOutputCoords();
          int batch = coords.x;
          int ch = coords.u;

          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
          int xDCorner = xCorner.x;
          int xRCorner = xCorner.y;
          int xCCorner = xCorner.z;

          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;

          for (int wD = 0; wD < ${p6};
              wD += ${u}) {
            int xD = xDCorner + wD;

            if (xD < 0 || xD >= ${t.inDepth}) {
              continue;
            }

            for (int wR = 0; wR < ${f};
                wR += ${d}) {
              int xR = xRCorner + wR;

              if (xR < 0 || xR >= ${t.inHeight}) {
                continue;
              }

              for (int wC = 0; wC < ${m};
                  wC += ${h6}) {
                int xC = xCCorner + wC;

                if (xC < 0 || xC >= ${t.inWidth}) {
                  continue;
                }

                float value = getX(batch, xD, xR, xC, ch);

                // If a min / max value has already been found, use it. If not,
                // use the current value.
                float currMinMaxValue = mix(
                    value, minMaxValue, minMaxValueFound);
                if (value ${R} currMinMaxValue) {
                  minMaxValue = value;
                  minMaxValueFound = 1.0;
                  minMaxPosition = ${o ? r ? `(((batch * ${t.inDepth} + xD) * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + ch` : `((xD * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + ch` : `wD * ${f} * ${m} +
                      wR * ${m} + wC`};
                }
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
      return;
    }
    const I = "max";
    let C6 = `${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    e === "avg" && (C6 = "avgValue / max(count, 1.0)");
    const k7 = Math.floor(i6 / 4) * 4, S = i6 % 4, N = `
      if (${w6}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${I}(values, minMaxValue);
      }
    `;
    this.userCode = `
      const ivec3 strides =
        ivec3(${a}, ${l}, ${c});
      const ivec3 pads = ivec3(${g6}, ${b6}, ${x6});
      const float initializationValue = ${y6};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xD, int xR, int xC, int ch) {
        if (xC < 0 || xC >= ${t.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xD, xR, xC, ch);
      }

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xDCorner = xCorner.x;
        int xRCorner = xCorner.y;
        int xCCorner = xCorner.z;

        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).
        // ? = to be determined
        vec4 minMaxValue = vec4(${y6});
        float avgValue = 0.0;
        count = 0.0;

        for (int wD = 0; wD < ${p6};
            wD += ${u}) {
          int xD = xDCorner + wD;

          if (xD < 0 || xD >= ${t.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${f};
            wR += ${d}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${k7}; wC += 4) {
              int xC = xCCorner + wC * ${h6};

              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${h6}, ch),
                getValue(batch, xD, xR, xC + 2 * ${h6}, ch),
                getValue(batch, xD, xR, xC + 3 * ${h6}, ch)
              );

              ${N}
            }

            int xC = xCCorner + ${k7};
            if (${S === 1}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                initializationValue,
                initializationValue,
                initializationValue
              );

              ${N}
            } else if (${S === 2}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${h6}, ch),
                initializationValue,
                initializationValue
              );

              ${N}
            } else if (${S === 3}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${h6}, ch),
                getValue(batch, xD, xR, xC + 2 * ${h6}, ch),
                initializationValue
              );

              ${N}
            }
          }
        }
        setOutput(${C6});
      }
    `;
  }
};
function aO(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  Na(o, "avgPool");
  const { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = s, c = 1;
  v2(Ee(i6, c), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${i6} and dilations '${c}'`);
  const u = $n(o.shape, r, i6, c, a, l);
  if (u.filterWidth === 1 && u.filterHeight === 1 && Rt(u.inShape, u.outShape))
    return tn({ inputs: { x: o }, backend: e });
  const d = new li(u, "avg", false);
  return e.runWebGLProgram(d, [o], "float32");
}
var lO = {
  kernelName: Pl,
  backendName: "webgl",
  kernelFunc: aO
};
function cO(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { filterSize: r, strides: i6, pad: a, dimRoundingMode: l, dataFormat: c } = s, u = [1, 1, 1], d = xs(o.shape, r, i6, u, a, l, c), h6 = new Kf(d, "avg", false);
  return e.runWebGLProgram(h6, [o], "float32");
}
var uO = {
  kernelName: Al,
  backendName: "webgl",
  kernelFunc: cO
};
var dO = class {
  constructor(t) {
    this.variableNames = ["dy"], this.outputShape = t.inShape;
    const e = t.filterHeight, s = t.filterWidth, o = t.strideHeight, r = t.strideWidth, i6 = t.dilationHeight, a = t.dilationWidth, l = t.effectiveFilterHeight, c = t.effectiveFilterWidth, u = l - 1 - t.padInfo.top, d = c - 1 - t.padInfo.left, h6 = 1 / (e * s);
    this.userCode = `
      const ivec2 pads = ivec2(${u}, ${d});
      const float avgMultiplier = float(${h6});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${l};
            wR += ${i6}) {
          float dyR = float(dyRCorner + wR) / ${o}.0;

          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${c};
            wC+= ${a}) {
            float dyC = float(dyCCorner + wC) / ${r}.0;

            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);

            dotProd += dyValue * avgMultiplier;
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var hO = class {
  constructor(t) {
    this.variableNames = ["dy"], this.outputShape = t.inShape;
    const e = t.filterDepth, s = t.filterHeight, o = t.filterWidth, r = t.strideDepth, i6 = t.strideHeight, a = t.strideWidth, l = t.dilationDepth, c = t.dilationHeight, u = t.dilationWidth, d = t.effectiveFilterDepth, h6 = t.effectiveFilterHeight, p6 = t.effectiveFilterWidth, f = d - 1 - t.padInfo.front, m = h6 - 1 - t.padInfo.top, g6 = p6 - 1 - t.padInfo.left, b6 = 1 / (e * s * o);
    this.userCode = `
      const ivec3 pads = ivec3(${f}, ${m}, ${g6});
      const float avgMultiplier = float(${b6});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${d};
            wD += ${l}) {
          float dyD = float(dyDCorner + wD) / ${r}.0;

          if (dyD < 0.0 || dyD >= ${t.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${h6};
              wR += ${c}) {
            float dyR = float(dyRCorner + wR) / ${i6}.0;

            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${p6};
                wC += ${u}) {
              float dyC = float(dyCCorner + wC) / ${a}.0;

              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);

              dotProd += dyValue * avgMultiplier;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
function pO(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, i6 = r, { filterSize: a, strides: l, pad: c, dimRoundingMode: u } = s, d = [1, 1, 1], h6 = xs(i6.shape, a, l, d, c, u), p6 = new hO(h6);
  return e.runWebGLProgram(p6, [o], i6.dtype);
}
var fO = {
  kernelName: Yd,
  backendName: "webgl",
  kernelFunc: pO
};
function mO(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, i6 = r;
  Na([o, r], "avgPoolGrad");
  const { filterSize: a, strides: l, pad: c } = s, u = $n(i6.shape, a, l, 1, c), d = new dO(u);
  return e.runWebGLProgram(d, [o], i6.dtype);
}
var gO = {
  kernelName: Ud,
  backendName: "webgl",
  kernelFunc: mO
};
function bO(n) {
  const { inputs: t, backend: e, attrs: s } = n, { a: o, b: r } = t, { transposeA: i6, transposeB: a } = s;
  return Gl({ a: o, b: r, transposeA: i6, transposeB: a, backend: e });
}
var xO = {
  kernelName: Ol,
  backendName: "webgl",
  kernelFunc: bO
};
var yO = class {
  constructor(t, e, s, o, r, i6) {
    this.outputShape = [], this.variableNames = ["x", "mean", "variance"], bt(t, e), bt(t, s);
    let a = "0.0";
    o != null && (bt(t, o), this.variableNames.push("offset"), a = "getOffsetAtOutCoords()");
    let l = "1.0";
    r != null && (bt(t, r), this.variableNames.push("scale"), l = "getScaleAtOutCoords()"), this.outputShape = t, this.userCode = `
      void main() {
        float x = getXAtOutCoords();
        float mean = getMeanAtOutCoords();
        float variance = getVarianceAtOutCoords();
        float offset = ${a};
        float scale = ${l};
        float inv = scale * inversesqrt(variance + float(${i6}));
        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));
      }
    `;
  }
};
var wO = class {
  constructor(t, e, s, o, r, i6) {
    this.packedInputs = true, this.packedOutput = true, this.variableNames = ["x", "mean", "variance"], bt(t, e), bt(t, s);
    let a = "vec4(0.0)";
    o != null && (bt(t, o), this.variableNames.push("offset"), a = "getOffsetAtOutCoords()");
    let l = "vec4(1.0)";
    r != null && (bt(t, r), this.variableNames.push("scale"), l = "getScaleAtOutCoords()"), this.outputShape = t, this.userCode = `
      void main() {
        vec4 offset = ${a};
        vec4 scale = ${l};

        vec4 x = getXAtOutCoords();
        vec4 mean = getMeanAtOutCoords();
        vec4 variance = getVarianceAtOutCoords();

        vec4 inv = scale * inversesqrt(variance + vec4(${i6}));

        setOutput((x - mean) * inv + offset);
      }
    `;
  }
};
var IO = ({ inputs: n, backend: t, attrs: e }) => {
  const { x: s, mean: o, variance: r, offset: i6, scale: a } = n;
  v2(o.shape.length === r.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), v2(i6 == null || o.shape.length === i6.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), v2(a == null || o.shape.length === a.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  let { varianceEpsilon: l } = e;
  l == null && (l = 1e-3);
  const c = [s, o, r];
  let u = null;
  i6 != null && (u = i6.shape, c.push(i6));
  let d = null;
  a != null && (d = a.shape, c.push(a));
  const h6 = F().getBool("WEBGL_PACK_NORMALIZATION") ? new wO(s.shape, o.shape, r.shape, u, d, l) : new yO(s.shape, o.shape, r.shape, u, d, l);
  return t.runWebGLProgram(h6, c, c[0].dtype);
};
var CO = {
  kernelName: tc,
  backendName: "webgl",
  kernelFunc: IO
};
var vO = class {
  constructor(t) {
    this.variableNames = ["source"], this.outputShape = t, this.rank = t.length;
    const e = Kt(this.rank);
    this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
    const s = SO(this.rank);
    let o;
    const r = t.map((i6, a) => `sourceLoc.${Wd[a]} = start[${a}] + coords.${Wd[a]};`);
    o = `
        ${e} sourceLoc;
        ${e} coords = getOutputCoords();
        ${r.join(`
`)}
      `, this.userCode = `
      void main() {
        ${o}
        setOutput(getSource(${s}));
      }
    `;
  }
};
var Wd = ["x", "y", "z", "w", "u", "v"];
function SO(n) {
  if (n === 1)
    return "sourceLoc";
  if (n <= 6)
    return Wd.slice(0, n).map((t) => "sourceLoc." + t).join(",");
  throw Error(`Slicing for rank ${n} is not yet supported`);
}
var kO = class {
  constructor(t) {
    this.variableNames = ["source"], this.packedInputs = true, this.packedOutput = true, this.outputShape = t, this.rank = t.length, this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
    const e = Kt(this.rank), s = We("coords", this.rank), o = We("sourceLoc", this.rank), r = this.rank === 1 ? "sourceLoc" : `vec2(${o.slice(-2).join()})`, i6 = `getChannel(getSource(${o.join()}), ${r})`, a = `
      result.x = ${i6};
      if (++${s[this.rank - 1]} < ${t[this.rank - 1]}) {
        ++${o[this.rank - 1]};
        result.y = ${i6};
        --${o[this.rank - 1]};
      }
    `, l = this.rank === 1 ? "" : `
      --${s[this.rank - 1]};
      if (++${s[this.rank - 2]} < ${t[this.rank - 2]}) {
        ++${o[this.rank - 2]};
        result.z = ${i6};
        if (++${s[this.rank - 1]} < ${t[this.rank - 1]}) {
          ++${o[this.rank - 1]};
          result.w = ${i6};
        }
      }
    `, c = this.rank <= 4 ? `sourceLoc = coords +
            ${e}(${t.map((u, d) => `start[${d}]`).join()});` : t.map((u, d) => `${o[d]} = ${s[d]} + start[${d}];`).join(`
`);
    this.userCode = `
      void main() {
        ${e} coords = getOutputCoords();
        ${e} sourceLoc;
        ${c}
        vec4 result = vec4(0.);
        ${a}
        ${l}
        setOutput(result);
      }
    `;
  }
};
function TO(n, t, e, s) {
  const o = s.texData.get(n.dataId), r = s.makeTensorInfo(e, n.dtype), i6 = s.texData.get(r.dataId);
  Object.assign(i6, o), i6.refCount = 1, i6.shape = e, i6.dtype = n.dtype;
  let a = Dp(t, dt(n.shape));
  o.slice && (a += o.slice.flatOffset), i6.slice = {
    flatOffset: a,
    // Point to the original dataId, which is used to do ref counting.
    origDataId: o.slice && o.slice.origDataId || n.dataId
  };
  const l = s.dataRefCount.get(i6.slice.origDataId) || 1;
  return s.dataRefCount.set(i6.slice.origDataId, l + 1), r;
}
function Er(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { begin: r, size: i6 } = s, [a, l] = Hc(o, r, i6);
  if (Lp(o, a, l), O(l) === 0)
    return e.makeTensorInfo(l, o.dtype, []);
  if (e.shouldExecuteOnCPU([o]) || o.dtype === "string") {
    const d = e.texData.get(o.dataId), h6 = yP(d.values, a, l, o.shape, o.dtype);
    return e.makeTensorInfo(l, o.dtype, h6);
  }
  const { isPacked: c } = e.texData.get(o.dataId), u = Wp(o.shape, a, l);
  if (c || !u) {
    const d = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new kO(l) : new vO(l), h6 = [a];
    return e.runWebGLProgram(d, [o], o.dtype, h6);
  }
  return e.uploadToGPU(o.dataId), TO(o, a, l, e);
}
var NO = {
  kernelName: $c,
  backendName: "webgl",
  kernelFunc: Er
};
var RO = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockShape: r, crops: i6 } = s;
  v2(o.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");
  const a = r.reduce((x6, w6) => x6 * w6), l = fa(o.shape, r, a), c = ma(l.length, r.length), u = ga(o.shape, r, a), d = Pp(i6, r.length), h6 = Ap(u, i6, r.length), p6 = [], f = st({ inputs: { x: o }, backend: e, attrs: { shape: l } }), m = Fe({ inputs: { x: f }, backend: e, attrs: { perm: c } }), g6 = st({
    inputs: { x: m },
    backend: e,
    attrs: { shape: u }
  }), b6 = Er({
    inputs: { x: g6 },
    backend: e,
    attrs: { begin: d, size: h6 }
  });
  return p6.push(f), p6.push(m), p6.push(g6), p6.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), b6;
};
var $O = {
  kernelName: Kl,
  backendName: "webgl",
  kernelFunc: RO
};
function GO(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, weights: r } = t, { size: i6 } = s, a = e.readSync(o.dataId), l = e.readSync(r.dataId), c = Mw(a, l, r.dtype, r.shape, i6);
  return e.makeTensorInfo([i6], r.dtype, c);
}
var EO = {
  kernelName: Qd,
  backendName: "webgl",
  kernelFunc: GO
};
function LO(n) {
  const { inputs: t, backend: e } = n, { s0: s, s1: o } = t, r = e.readSync(s.dataId), i6 = e.readSync(o.dataId), a = bt(Array.from(r), Array.from(i6));
  return e.makeTensorInfo([a.length], "int32", Int32Array.from(a));
}
var MO = {
  kernelName: Kg,
  backendName: "webgl",
  kernelFunc: LO
};
var WO = "return float(a != b);";
var _w = Ne({ opSnippet: WO, cpuKernelImpl: uP, dtype: "bool" });
var DO = {
  kernelName: bc,
  backendName: "webgl",
  kernelFunc: _w
};
function Ea(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = e.texData.get(s.dataId);
  return tn({ inputs: { x: o.complexTensorInfos.real }, backend: e });
}
var FO = {
  kernelName: wh,
  backendName: "webgl",
  kernelFunc: Ea
};
var VO = "return float(int(x));";
function zO(n, t) {
  const e = new qn(n.shape, VO), s = t.runWebGLProgram(e, [n], "int32");
  return { dataId: s.dataId, shape: s.shape, dtype: s.dtype };
}
function Dd(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { dtype: r } = s;
  if (r === "complex64") {
    if (o.dtype === "complex64")
      return tn({ inputs: { x: o }, backend: e });
    const i6 = ge(o.shape), a = Dd({ inputs: { x: o }, backend: e, attrs: { dtype: "float32" } }), l = js({ inputs: { real: a, imag: i6 }, backend: e });
    return i6.dispose(), e.disposeIntermediateTensorInfo(a), l;
  }
  if (o.dtype === "complex64") {
    const i6 = Ea({ inputs: { input: o }, backend: e }), a = Dd({ inputs: { x: i6 }, backend: e, attrs: { dtype: r } });
    return e.disposeIntermediateTensorInfo(i6), a;
  }
  if (!Od(o.dtype, r)) {
    const i6 = tn({ inputs: { x: o }, backend: e });
    return { dataId: i6.dataId, shape: i6.shape, dtype: r };
  }
  if (e.shouldExecuteOnCPU([o])) {
    const i6 = e.texData.get(o.dataId).values, [a, l, c] = ZX(i6, o.shape, o.dtype, r);
    return e.makeTensorInfo(a, l, c);
  }
  if (r === "int32")
    return zO(o, e);
  if (r === "bool") {
    const i6 = e.makeTensorInfo([], "bool", xe("bool", 1)), l = _w({ inputs: { a: o, b: i6 }, backend: e });
    return e.disposeIntermediateTensorInfo(i6), l;
  }
  throw new Error(`Error in Cast: failed to cast ${o.dtype} to ${r}`);
}
var XO = {
  kernelName: xi,
  backendName: "webgl",
  kernelFunc: Dd
};
var dg = "return ceil(x);";
var PO = Nt({ opSnippet: dg, packedOpSnippet: dg, cpuKernelImpl: BX });
var AO = {
  kernelName: yi,
  backendName: "webgl",
  kernelFunc: PO
};
var OO = class {
  constructor(t) {
    this.variableNames = ["A"], this.customUniforms = [
      { name: "minVal", type: "float" },
      { name: "maxVal", type: "float" }
    ], this.outputShape = t, this.userCode = `

      void main() {
        float value = getAAtOutCoords();
        if (isnan(value)) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, minVal, maxVal));
      }
    `;
  }
};
var KO = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "minVal", type: "float" },
      { name: "maxVal", type: "float" }
    ], this.outputShape = t, this.userCode = `
      void main() {
        vec4 value = getAAtOutCoords();

        if (any(isnan(value))) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));
      }
    `;
  }
};
function ZO(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { clipValueMin: r, clipValueMax: i6 } = s;
  let a;
  F().getBool("WEBGL_PACK_CLIP") ? a = new KO(o.shape) : a = new OO(o.shape);
  const l = [[r], [i6]];
  return e.runWebGLProgram(a, [o], o.dtype, l);
}
var BO = {
  kernelName: wi,
  backendName: "webgl",
  kernelFunc: ZO
};
var HO = class {
  constructor(t) {
    this.variableNames = ["real", "imag"], this.outputShape = t, this.userCode = `
      void main() {
        float re = abs(getRealAtOutCoords());
        float im = abs(getImagAtOutCoords());
        float mx = max(re, im);

        // sadly the length function in glsl is not underflow-safe
        // (at least not on Intel GPUs). So the safe solution is
        // to ensure underflow-safety in all cases.
        setOutput(
          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))
        );
      }
    `;
  }
};
function hg(n, t) {
  return {
    dataId: t.dataId,
    dtype: t.dtype,
    shape: n.shape
  };
}
function _O(n) {
  const { inputs: t, backend: e } = n, { x: s } = t, o = e.texData.get(s.dataId), r = new HO(s.shape), i6 = [
    hg(s, o.complexTensorInfos.real),
    hg(s, o.complexTensorInfos.imag)
  ];
  return e.runWebGLProgram(r, i6, i6[0].dtype);
}
var UO = {
  kernelName: Zl,
  backendName: "webgl",
  kernelFunc: _O
};
var YO = class {
  // Concats 2d tensors along axis=1. See comments in MathBackendWebGL.concat().
  constructor(t) {
    this.outputShape = [], this.outputShape = ts(
      t,
      1
      /* axis */
    ), this.variableNames = t.map((i6, a) => `T${a}`);
    const e = new Array(t.length - 1);
    e[0] = t[0][1];
    for (let i6 = 1; i6 < e.length; i6++)
      e[i6] = e[i6 - 1] + t[i6][1];
    const s = [`if (yC < ${e[0]}) setOutput(getT0(yR, yC));`];
    for (let i6 = 1; i6 < e.length; i6++) {
      const a = e[i6 - 1];
      s.push(`else if (yC < ${e[i6]}) setOutput(getT${i6}(yR, yC-${a}));`);
    }
    const o = e.length, r = e[e.length - 1];
    s.push(`else setOutput(getT${o}(yR, yC-${r}));`), this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int yR = coords.x;
        int yC = coords.y;

        ${s.join(`
        `)}
      }
    `;
  }
};
var QO = class {
  constructor(t, e) {
    this.packedInputs = true, this.packedOutput = true, this.outputShape = [], this.outputShape = ts(t, e);
    const s = this.outputShape, o = s.length, r = Kt(o), i6 = We("coords", o), a = ["x", "y", "z", "w", "u", "v"].slice(0, o);
    this.variableNames = t.map((m, g6) => `T${g6}`);
    const l = new Array(t.length - 1);
    l[0] = t[0][e];
    for (let m = 1; m < l.length; m++)
      l[m] = l[m - 1] + t[m][e];
    const c = a[e], u = a.slice(-2), d = a.join();
    let h6 = `if (${c} < ${l[0]}) {
        return getChannel(
            getT0(${d}), vec2(${u.join()}));
        }`;
    for (let m = 1; m < l.length; m++) {
      const g6 = l[m - 1];
      h6 += `
        if (${c} < ${l[m]}  && ${c} >= ${l[m - 1]}) {
          return getChannel(
            getT${m}(${Ha(a, c, g6)}),
            vec2(${Ha(u, c, g6)}));
        }`;
    }
    const p6 = l.length, f = l[l.length - 1];
    h6 += `
        return getChannel(
          getT${p6}(${Ha(a, c, f)}),
          vec2(${Ha(u, c, f)}));`, this.userCode = `
      float getValue(${a.map((m) => "int " + m)}) {
        ${h6}
      }

      void main() {
        ${r} coords = getOutputCoords();
        vec4 result = vec4(getValue(${i6}), 0., 0., 0.);

        ${i6[o - 1]} = ${i6[o - 1]} + 1;
        if (${i6[o - 1]} < ${s[o - 1]}) {
          result.g = getValue(${i6});
        }

        ${i6[o - 2]} = ${i6[o - 2]} + 1;
        if (${i6[o - 2]} < ${s[o - 2]}) {
          result.a = getValue(${i6});
        }

        ${i6[o - 1]} = ${i6[o - 1]} - 1;
        if (${i6[o - 2]} < ${s[o - 2]} &&
            ${i6[o - 1]} < ${s[o - 1]}) {
          result.b = getValue(${i6});
        }
        setOutput(result);
      }
    `;
  }
};
function Ha(n, t, e) {
  const s = n.indexOf(t);
  return n.map((r, i6) => i6 === s ? `${r} - ${e}` : r).join();
}
function mu(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = e.texData.get(s.dataId);
  return tn({ inputs: { x: o.complexTensorInfos.imag }, backend: e });
}
var JO = {
  kernelName: hh,
  backendName: "webgl",
  kernelFunc: mu
};
function Zr(n, t, e) {
  const s = n[0].dtype;
  if (s === "complex64") {
    const p6 = n.map((x6) => Ea({ inputs: { input: x6 }, backend: e })), f = n.map((x6) => mu({ inputs: { input: x6 }, backend: e })), m = Zr(p6, t, e), g6 = Zr(f, t, e), b6 = js({ inputs: { real: m, imag: g6 }, backend: e });
    return p6.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), f.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(g6), b6;
  }
  let o = e.shouldExecuteOnCPU(n);
  if (s === "string" && (o = true), o) {
    const p6 = n.map((y6) => {
      const C6 = [-1, O(y6.shape.slice(t))];
      return st({ inputs: { x: y6 }, backend: e, attrs: { shape: C6 } });
    }), f = p6.map((y6) => ({ vals: e.readSync(y6.dataId), shape: y6.shape })), m = ts(
      p6.map((y6) => y6.shape),
      1
      /* axis */
    ), g6 = p6[0].shape[0] === 1, b6 = HX(f, m, s, g6), x6 = ts(n.map((y6) => y6.shape), t), w6 = e.makeTensorInfo(x6, s, b6);
    return p6.forEach((y6) => e.disposeIntermediateTensorInfo(y6)), w6;
  }
  const r = n.filter((p6) => O(p6.shape) > 0), i6 = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && r[0].shape.length > 1;
  if (r.length === 1) {
    const p6 = i6 ? new qn(n[0].shape, Ns) : new Ls(n[0].shape, Ns);
    return e.runWebGLProgram(p6, n, s);
  }
  const a = F().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER");
  if (r.length > a) {
    const p6 = [];
    for (let m = 0; m < r.length; m += a) {
      const g6 = r.slice(m, m + a);
      p6.push(Zr(g6, t, e));
    }
    const f = Zr(p6, t, e);
    for (const m of p6)
      e.disposeIntermediateTensorInfo(m);
    return f;
  }
  if (i6) {
    const p6 = new QO(r.map((f) => f.shape), t);
    return e.runWebGLProgram(p6, r, s);
  }
  const { tensors2D: l, outShape: c } = jO(r, t, e), u = new YO(l.map((p6) => p6.shape)), d = e.runWebGLProgram(u, l, s);
  l.forEach((p6) => e.disposeIntermediateTensorInfo(p6));
  const h6 = st({ inputs: { x: d }, attrs: { shape: c }, backend: e });
  return e.disposeIntermediateTensorInfo(d), h6;
}
function jO(n, t, e) {
  const s = ts(n.map((r) => r.shape), t);
  return { tensors2D: n.map((r) => st({
    inputs: { x: r },
    attrs: { shape: [-1, O(r.shape.slice(t))] },
    backend: e
  })), outShape: s };
}
function Uw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { axis: o } = s, r = Ct(o, t[0].shape)[0], i6 = t.map((c) => c.shape);
  Vp(i6, r);
  const a = ts(t.map((c) => c.shape), r);
  if (O(a) === 0)
    return e.makeTensorInfo(a, t[0].dtype, []);
  const l = t.filter((c) => O(c.shape) > 0);
  return l.length === 1 ? tn({ inputs: { x: l[0] }, backend: e }) : Zr(l, r, e);
}
var qO = {
  kernelName: Bl,
  backendName: "webgl",
  kernelFunc: Uw
};
var Yw = class {
  constructor(t, e = false, s = null, o = false, r = false) {
    this.variableNames = ["x", "W"], this.outputShape = t.outShape;
    const i6 = t.padInfo.top, a = t.padInfo.left, l = t.strideHeight, c = t.strideWidth, u = t.dilationHeight, d = t.dilationWidth, h6 = t.filterHeight, p6 = t.filterWidth, f = Math.floor(t.inChannels / 4) * 4, m = t.inChannels % 4, g6 = t.dataFormat === "channelsLast", b6 = g6 ? 1 : 2, x6 = g6 ? 2 : 3, w6 = g6 ? 3 : 1;
    let y6 = "", I = "";
    s && (o ? y6 = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${s}
        }` : r ? y6 = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${s}
        }` : y6 = `
          float activation(float x) {
            ${s}
          }
        `, I = "result = activation(result);");
    const C6 = e ? "result += getBiasAtOutCoords();" : "";
    e && this.variableNames.push("bias"), o && this.variableNames.push("preluActivationWeights"), r && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${y6}

      const ivec2 strides = ivec2(${l}, ${c});
      const ivec2 pads = ivec2(${i6}, ${a});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d2 = coords[${w6}];

        ivec2 xRCCorner =
            ivec2(coords[${b6}], coords[${x6}]) * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${h6}; wR++) {
          int xR = xRCorner + wR * ${u};

          if (xR < 0 || xR >= ${t.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${p6}; wC++) {
            int xC = xCCorner + wC * ${d};

            if (xC < 0 || xC >= ${t.inWidth}) {
              continue;
            }

            for (int d1 = 0; d1 < ${f}; d1 += 4) {
              vec4 wValues = vec4(
                getW(wR, wC, d1, d2),
                getW(wR, wC, d1 + 1, d2),
                getW(wR, wC, d1 + 2, d2),
                getW(wR, wC, d1 + 3, d2)
              );

              if (${g6}) {
                vec4 xValues = vec4(
                  getX(batch, xR, xC, d1),
                  getX(batch, xR, xC, d1 + 1),
                  getX(batch, xR, xC, d1 + 2),
                  getX(batch, xR, xC, d1 + 3)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec4 xValues = vec4(
                  getX(batch, d1, xR, xC),
                  getX(batch, d1 + 1, xR, xC),
                  getX(batch, d1 + 2, xR, xC),
                  getX(batch, d1 + 3, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }
            }

            if (${m === 1}) {

              if (${g6}) {
                dotProd +=
                    getX(batch, xR, xC, ${f}) *
                    getW(wR, wC, ${f}, d2);
              } else {
                dotProd +=
                    getX(batch, ${f}, xR, xC) *
                    getW(wR, wC, ${f}, d2);
              }

            } else if (${m === 2}) {
              vec2 wValues = vec2(
                getW(wR, wC, ${f}, d2),
                getW(wR, wC, ${f} + 1, d2)
              );

              if (${g6}) {
                vec2 xValues = vec2(
                  getX(batch, xR, xC, ${f}),
                  getX(batch, xR, xC, ${f} + 1)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec2 xValues = vec2(
                  getX(batch, ${f}, xR, xC),
                  getX(batch, ${f} + 1, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            } else if (${m === 3}) {
              vec3 wValues = vec3(
                getW(wR, wC, ${f}, d2),
                getW(wR, wC, ${f} + 1, d2),
                getW(wR, wC, ${f} + 2, d2)
              );

              if (${g6}) {
                vec3 xValues = vec3(
                  getX(batch, xR, xC, ${f}),
                  getX(batch, xR, xC, ${f} + 1),
                  getX(batch, xR, xC, ${f} + 2)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec3 xValues = vec3(
                  getX(batch, ${f}, xR, xC),
                  getX(batch, ${f} + 1, xR, xC),
                  getX(batch, ${f} + 2, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            }
          }
        }

        float result = dotProd;
        ${C6}
        ${I}
        setOutput(result);
      }
    `;
  }
};
var tK = class {
  constructor(t) {
    this.variableNames = ["x", "W"], this.outputShape = t.outShape;
    const e = t.padInfo.front, s = t.padInfo.top, o = t.padInfo.left, r = t.strideDepth, i6 = t.strideHeight, a = t.strideWidth, l = t.dilationDepth, c = t.dilationHeight, u = t.dilationWidth, d = t.filterDepth, h6 = t.filterHeight, p6 = t.filterWidth, f = Math.floor(t.inChannels / 4) * 4, m = t.inChannels % 4;
    this.userCode = `
      const ivec3 strides = ivec3(${r}, ${i6}, ${a});
      const ivec3 pads = ivec3(${e}, ${s}, ${o});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d2 = coords.u;

        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xFCorner = xFRCCorner.x;
        int xRCorner = xFRCCorner.y;
        int xCCorner = xFRCCorner.z;

        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get
        // y(yF, yR, yC, d2). ? = to be determined. : = across all
        // values in that axis.
        float dotProd = 0.0;
        for (int wF = 0; wF < ${d}; wF++) {
          int xF = xFCorner + wF * ${l};

          if (xF < 0 || xF >= ${t.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${h6}; wR++) {
            int xR = xRCorner + wR * ${c};

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${p6}; wC++) {
              int xC = xCCorner + wC * ${u};

              if (xC < 0 || xC >= ${t.inWidth}) {
                continue;
              }

              for (int d1 = 0; d1 < ${f}; d1 += 4) {
                vec4 xValues = vec4(
                  getX(batch, xF, xR, xC, d1),
                  getX(batch, xF, xR, xC, d1 + 1),
                  getX(batch, xF, xR, xC, d1 + 2),
                  getX(batch, xF, xR, xC, d1 + 3)
                );
                vec4 wValues = vec4(
                  getW(wF, wR, wC, d1, d2),
                  getW(wF, wR, wC, d1 + 1, d2),
                  getW(wF, wR, wC, d1 + 2, d2),
                  getW(wF, wR, wC, d1 + 3, d2)
                );

                dotProd += dot(xValues, wValues);
              }

              if (${m === 1}) {
                dotProd +=
                  getX(batch, xF, xR, xC, ${f}) *
                  getW(wF, wR, wC, ${f}, d2);
              } else if (${m === 2}) {
                vec2 xValues = vec2(
                  getX(batch, xF, xR, xC, ${f}),
                  getX(batch, xF, xR, xC, ${f} + 1)
                );
                vec2 wValues = vec2(
                  getW(wF, wR, wC, ${f}, d2),
                  getW(wF, wR, wC, ${f} + 1, d2)
                );
                dotProd += dot(xValues, wValues);
              } else if (${m === 3}) {
                vec3 xValues = vec3(
                  getX(batch, xF, xR, xC, ${f}),
                  getX(batch, xF, xR, xC, ${f} + 1),
                  getX(batch, xF, xR, xC, ${f} + 2)
                );
                vec3 wValues = vec3(
                  getW(wF, wR, wC, ${f}, d2),
                  getW(wF, wR, wC, ${f} + 1, d2),
                  getW(wF, wR, wC, ${f} + 2, d2)
                );
                dotProd += dot(xValues, wValues);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var Qw = class {
  constructor(t, e = false, s = null, o = false, r = false) {
    this.variableNames = ["x", "W"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "pads", type: "ivec2" },
      { name: "strides", type: "ivec2" },
      { name: "dilations", type: "ivec2" },
      { name: "inDims", type: "ivec2" }
    ], this.outputShape = t.outShape, this.enableShapeUniforms = Xe(this.outputShape.length);
    const i6 = t.padInfo.left, a = t.strideWidth, l = t.dilationWidth, c = t.filterHeight, u = t.filterWidth, d = u;
    let h6 = `
       int xR; int xC; int xCOffset;
       vec4 wTexel; vec4 previous; vec4 final;`;
    for (let g6 = 0; g6 < u; g6++)
      h6 += `
           vec4 xTexelC${g6 * 2};
           int xTexelC${g6 * 2}Ready;
           vec4 xTexelC${g6 * 2 + 1};
           int xTexelC${g6 * 2 + 1}Ready;
           vec4 xC${g6};`;
    h6 += `
     for (int r = 0; r < ${c}; r++) {
      for (int d1 = 0; d1 < ${t.inChannels}; d1 += 2) {
       `;
    for (let g6 = 0; g6 < u; g6++)
      h6 += `
           xTexelC${g6 * 2} = vec4(0.0);
           xTexelC${g6 * 2}Ready = 0;
           xTexelC${g6 * 2 + 1} = vec4(0.0);
           xTexelC${g6 * 2 + 1}Ready = 0;
           xC${g6} = vec4(0.0);`;
    h6 += `
         xR = xRCorner + r * dilations[0];
         if (xR >=0 && xR < inDims[0]) {
       `;
    for (let g6 = 0; g6 < (d + 1) / 2; g6++) {
      const b6 = g6 * 2;
      if (h6 += `
           xC = xCCorner + ${b6 * l};
           `, a === 1) {
        if (b6 < u && (i6 % 2 === 1 ? (h6 += `
                 xCOffset = xC + 1;
                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b6}Ready == 0) {
                   xTexelC${b6} = getX(batch, xR, xCOffset, d1);

                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${b6}.zw = vec2(0.0);
                   }
                   xTexelC${b6}Ready = 1;
                 }
               `, l === 1 && b6 > 0 ? h6 += `
                 xC${b6} = vec4(xTexelC${b6 - 2}.zw, xTexelC${b6}.xy);
                 ` : h6 += `
                   xCOffset = xC + 1 - 2;

                   if (xCOffset >= 0 && xCOffset < inDims[1]) {
                     previous = getX(batch, xR, xCOffset, d1);

                     // Need to manually clear unused channels in case
                     // we're reading from recycled texture.
                     if (xCOffset + 1 >= inDims[1]) {
                       previous.zw = vec2(0.0);
                     }

                     xC${b6} = vec4(previous.zw, xTexelC${b6}.xy);
                   } else {
                     xC${b6} = vec4(0.0, 0.0, xTexelC${b6}.xy);
                   }
                   `) : h6 += `
                 if (xC >= 0 && xC < inDims[1] && xTexelC${b6}Ready == 0) {
                   xTexelC${b6} = getX(batch, xR, xC, d1);
                   if (xC + 1 >= inDims[1]) {
                     xTexelC${b6}.zw = vec2(0.0);
                   }
                   xTexelC${b6}Ready = 1;
                 }

                 xC${b6} = xTexelC${b6};
                 `, b6 + 1 < u)) {
          const x6 = i6 % 2 === 0 ? Wl(l) : l;
          l % 2 === 0 && i6 % 2 === 1 || l % 2 !== 0 && i6 % 2 !== 1 ? (h6 += `
                   xCOffset = xC + imod(pads[1], 2) + ${x6};

                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b6 + 1}Ready == 0) {
                     xTexelC${b6 + 1} = getX(batch, xR, xCOffset, d1);

                     // Need to manually clear unused channels in case
                     // we're reading from recycled texture.
                     if (xCOffset + 1 >= inDims[1]) {
                       xTexelC${b6 + 1}.zw = vec2(0.0);
                     }
                     xTexelC${b6 + 1}Ready = 1;
                   }
                   `, l > 1 ? h6 += `
                     xCOffset -= 2;
                     if (xCOffset >= 0 && xCOffset < inDims[1]) {
                      previous = getX(batch, xR, xCOffset, d1);
                      xC${b6 + 1} = vec4(previous.zw, xTexelC${b6 + 1}.xy);
                     } else {
                      xC${b6 + 1} = vec4(0.0, 0.0, xTexelC${b6 + 1}.xy);
                     }
                     ` : h6 += `
                     xC${b6 + 1} = vec4(xTexelC${b6}.zw, xTexelC${b6 + 1}.xy);
                     `) : x6 === 1 ? h6 += `
                     xC${b6 + 1} = xTexelC${b6};
                     ` : h6 += `
                     xCOffset = xC + ${x6};

                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b6 + 1}Ready == 0) {
                       xTexelC${b6 + 1} = getX(batch, xR, xCOffset, d1);
                       if (xCOffset + 1 >= inDims[1]) {
                         xTexelC${b6 + 1}.zw = vec2(0.0);
                       }
                       xTexelC${b6 + 1}Ready = 1;
                     }

                     xC${b6 + 1} = xTexelC${b6 + 1};
                     `;
        }
      } else
        b6 < u && (i6 % 2 === 1 ? (h6 += `
                 xCOffset = xC + 1 - strides[1];
                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b6}Ready == 0) {
                   xTexelC${b6} = getX(batch, xR, xCOffset, d1);
                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${b6}.zw = vec2(0.0);
                   }
                   xTexelC${b6}Ready = 1;
                 }

                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${b6 + 1}Ready == 0) {
                   xTexelC${b6 + 1} = getX(batch, xR, xC + 1, d1);
                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xC + 2 >= inDims[1]) {
                     xTexelC${b6 + 1}.zw = vec2(0.0);
                   }
                   xTexelC${b6 + 1}Ready = 1;
                 }

                 xC${b6} = vec4(xTexelC${b6}.zw, xTexelC${b6 + 1}.zw);
               `, b6 + 1 < u && (h6 += `
                   final = vec4(0.0);
                   xCOffset = xC + 1 + strides[1];
                   if(xCOffset >= 0 && xCOffset < inDims[1]) {
                     final = getX(batch, xR, xCOffset, d1);
                   }
                   xC${b6 + 1} = vec4(xTexelC${b6 + 1}.xy, final.xy);
                 `)) : (h6 += `
                 if(xC >= 0 && xC < inDims[1] && xTexelC${b6}Ready == 0) {
                   xTexelC${b6} = getX(batch, xR, xC, d1);
                   if (xC + 1 >= inDims[1]) {
                     xTexelC${b6}.zw = vec2(0.0);
                   }
                   xTexelC${b6}Ready = 1;
                 }

                 xCOffset = xC + strides[1];
                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b6 + 1}Ready == 0) {
                   xTexelC${b6 + 1} = getX(batch, xR, xCOffset, d1);
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${b6 + 1}.zw = vec2(0.);
                   }
                   xTexelC${b6 + 1}Ready = 1;
                 }

                 xC${b6} = vec4(
                   xTexelC${b6}.xy, xTexelC${b6 + 1}.xy);
               `, b6 + 1 < u && (h6 += `
                   xC${b6 + 1} = vec4(xTexelC${b6}.zw, xTexelC${b6 + 1}.zw);
                 `)));
      b6 < u && (h6 += `
             wTexel = getW(r, ${b6}, d1, d2);
             dotProd += xC${b6}.xxzz * vec4(wTexel.xy, wTexel.xy);
             if(d1 + 1 < ${t.inChannels}) {
               dotProd += xC${b6}.yyww * vec4(wTexel.zw, wTexel.zw);
             }
           `, b6 + 1 < u && (h6 += `
               wTexel = getW(r, ${b6 + 1}, d1, d2);
               dotProd += xC${b6 + 1}.xxzz * vec4(wTexel.xy, wTexel.xy);
               if(d1 + 1 < ${t.inChannels}) {
                 dotProd += xC${b6 + 1}.yyww * vec4(wTexel.zw, wTexel.zw);
               }
             `));
    }
    h6 += `
     }
   `, h6 += `
     }
   `, h6 += `
     }
   `;
    let p6 = "", f = "";
    s && (o ? p6 = `vec4 activation(vec4 a) {
           vec4 b = getPreluActivationWeightsAtOutCoords();
           ${s}
         }` : r ? p6 = `vec4 activation(vec4 a) {
           vec4 b = getLeakyreluAlphaAtOutCoords();
           ${s}
         }` : p6 = `vec4 activation(vec4 x) {
           ${s}
         }`, f = "result = activation(result);");
    const m = e ? "result += getBiasAtOutCoords();" : "";
    e && this.variableNames.push("bias"), o && this.variableNames.push("preluActivationWeights"), r && this.variableNames.push("leakyreluAlpha"), this.userCode = `
       ${p6}

       void main() {
         ivec4 coords = getOutputCoords();
         int batch = coords.x;
         ivec2 xRCCorner = coords.yz * strides - pads;
         int d2 = coords.w;
         int xRCorner = xRCCorner.x;
         int xCCorner = xRCCorner.y;

         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
         vec4 dotProd = vec4(0.000000000000001);

         ${h6}

         vec4 result = dotProd - vec4(0.000000000000001);
         ${m}
         ${f}
         setOutput(result);
       }
     `;
  }
};
var eK = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "inputShape", type: "ivec4" },
      { name: "pad", type: "ivec2" },
      { name: "stride", type: "ivec2" },
      { name: "dilation", type: "ivec2" },
      { name: "inChannels", type: "int" },
      { name: "itemsPerBlockRow", type: "int" },
      { name: "outWidth", type: "int" }
    ], this.outputShape = t, this.enableShapeUniforms = Xe(this.outputShape.length);
    const { dataFormat: s } = e, o = ze(), r = s === "channelsLast", i6 = r ? 1 : 2, a = r ? 2 : 3, l = this.enableShapeUniforms ? "if(blockIndex < outShape[2] && pos < outShape[1]) {" : `if(blockIndex < ${t[2]} && pos < ${t[1]}) {`;
    let c = "";
    for (let u = 0; u <= 1; u++)
      for (let d = 0; d <= 1; d++)
        c += `
          blockIndex = rc.z + ${d};
          pos = rc.y + ${u};

          ${l}
            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];
            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);

            if(d0 < inputShape[${i6}] && d0 >= 0) {
              // Use custom imod instead mod. On Intel GPU, mod may generate
              // unexpected value.
              // https://github.com/tensorflow/tfjs/issues/5447
              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];
              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /
                  inChannels);

              if(d1 < inputShape[${a}] && d1 >= 0) {

                ch = imod(pos, inChannels);

                if (${r}) {
                  innerDims = vec2(d1, ch);
                  result[${u * 2 + d}] = getChannel(
                    getA(rc.x, d0, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                } else {
                  innerDims = vec2(d0, d1);
                  result[${u * 2 + d}] = getChannel(
                    getA(rc.x, ch, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                }
              }
            }
          }
        `;
    this.userCode = `
      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0);

        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;
        vec2 innerDims;

        ${c}

        ${o.output} = result;
      }
    `;
  }
};
function El(n, t) {
  const e = n.length;
  return e >= 3 ? t ? [
    ...n.slice(0, -3),
    n[e - 3] * n[e - 2],
    n[e - 1]
    /* channel */
  ] : [
    ...n.slice(0, -3),
    n[e - 3],
    n[e - 2] * n[e - 1]
    /* height * width */
  ] : !t && e === 1 && n[0] > 1 ? [n[0], 1] : null;
}
function Jw({ x: n, filter: t, convInfo: e, backend: s, bias: o = null, preluActivationWeights: r = null, leakyreluAlpha: i6 = 0, activation: a = null }) {
  const l = n.shape, c = s.texData.get(n.dataId), u = e.inChannels, d = l[0] * l[1] * l[2], h6 = e.outChannels, p6 = e.dataFormat === "channelsLast", f = false, m = false;
  let g6;
  const b6 = [];
  if (r != null) {
    const y6 = El(r.shape, p6);
    y6 != null && (r = st({
      inputs: { x: r },
      backend: s,
      attrs: { shape: y6 }
    }), b6.push(r));
  }
  if (o != null) {
    const y6 = El(o.shape, p6);
    y6 != null && (o = st({ inputs: { x: o }, backend: s, attrs: { shape: y6 } }), b6.push(o));
  }
  if (!((d === 1 || h6 === 1) && u > Kw) && c.isPacked && p6 && c.texture != null && l[2] % 2 !== 0 && Rt(c.shape.slice(-3), l.slice(-3))) {
    const y6 = l[0] * l[1] * (l[2] + 1), I = {
      dataId: n.dataId,
      shape: [1, y6, e.inChannels],
      dtype: n.dtype
    }, C6 = c.shape;
    c.shape = c.shape.slice(), c.shape[c.shape.length - 2]++, v2($l(c.shape, I.shape), () => `packed reshape ${c.shape} to ${I.shape} isn't free`);
    const k7 = st({
      inputs: { x: t },
      backend: s,
      attrs: { shape: [1, e.inChannels, e.outChannels] }
    });
    b6.push(k7);
    const S = Gl({
      a: I,
      b: k7,
      backend: s,
      transposeA: f,
      transposeB: m,
      bias: o,
      activation: a,
      preluActivationWeights: r,
      leakyreluAlpha: i6
    }), N = s.texData.get(S.dataId);
    v2(N.isPacked, () => "batchMatMul result is expected to be packed"), c.shape = C6, N.shape = e.outShape, g6 = tn({ inputs: { x: S }, backend: s }), g6.shape = e.outShape, b6.push(S);
  } else {
    const y6 = e.outHeight * e.outWidth, I = st({
      inputs: { x: n },
      backend: s,
      attrs: {
        shape: p6 ? [e.batchSize, y6, e.inChannels] : [e.batchSize, e.inChannels, y6]
      }
    }), C6 = st({
      inputs: { x: t },
      backend: s,
      attrs: { shape: [1, e.inChannels, e.outChannels] }
    }), k7 = Gl({
      a: p6 ? I : C6,
      b: p6 ? C6 : I,
      transposeA: !p6,
      transposeB: m,
      backend: s,
      bias: o,
      activation: a,
      preluActivationWeights: r,
      leakyreluAlpha: i6
    });
    g6 = st({ inputs: { x: k7 }, backend: s, attrs: { shape: e.outShape } }), b6.push(I), b6.push(C6), b6.push(k7);
  }
  for (const y6 of b6)
    s.disposeIntermediateTensorInfo(y6);
  return g6;
}
function jw({ x: n, filter: t, convInfo: e, backend: s, bias: o = null, preluActivationWeights: r = null, leakyreluAlpha: i6 = 0, activation: a = null }) {
  const { filterWidth: l, filterHeight: c, inChannels: u, outWidth: d, outHeight: h6, dataFormat: p6 } = e, f = p6 === "channelsLast", m = l * c * u, g6 = h6 * d, b6 = [e.batchSize, m, g6], x6 = true, w6 = false, y6 = [];
  if (r != null) {
    const Z = El(r.shape, f);
    Z != null && (r = st({
      inputs: { x: r },
      backend: s,
      attrs: { shape: Z }
    }), y6.push(r));
  }
  if (o != null) {
    const Z = El(o.shape, f);
    Z != null && (o = st({ inputs: { x: o }, backend: s, attrs: { shape: Z } }), y6.push(o));
  }
  const I = st({
    inputs: { x: t },
    backend: s,
    attrs: { shape: [1, m, O(t.shape) / m] }
  });
  y6.push(I);
  const C6 = new eK(b6, e), k7 = [
    n.shape,
    [e.padInfo.top, e.padInfo.left],
    [e.strideHeight, e.strideWidth],
    [e.dilationHeight, e.dilationWidth],
    [e.inChannels],
    [e.filterWidth * e.inChannels],
    [e.outWidth]
  ], S = s.runWebGLProgram(C6, [n], "float32", k7), N = st({ inputs: { x: S }, backend: s, attrs: { shape: b6 } });
  y6.push(S), y6.push(N);
  const R = o != null, M6 = r != null, V = a === "leakyrelu", z = a ? ai(a, true) : null, X = new Ow(f ? N.shape : I.shape, f ? I.shape : N.shape, f ? [e.batchSize, g6, e.outChannels] : [e.batchSize, e.outChannels, g6], x6, w6, R, z, M6, V), P6 = f ? [N, I] : [I, N];
  if (o && P6.push(o), M6 && P6.push(r), V) {
    const Z = s.makeTensorInfo([], "float32", bs(i6, "float32"));
    P6.push(Z), y6.push(Z);
  }
  const A6 = s.runWebGLProgram(X, P6, "float32"), B6 = st({ inputs: { x: A6 }, backend: s, attrs: { shape: e.outShape } });
  y6.push(A6);
  for (const Z of y6)
    s.disposeIntermediateTensorInfo(Z);
  return B6;
}
function nK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dataFormat: l, dilations: c, dimRoundingMode: u } = s, d = ys(l), h6 = ke(o.shape, r.shape, i6, c, a, u, false, d);
  let p6;
  if (h6.filterHeight === 1 && h6.filterWidth === 1 && h6.dilationHeight === 1 && h6.dilationWidth === 1 && h6.strideHeight === 1 && h6.strideWidth === 1 && (h6.padInfo.type === "SAME" || h6.padInfo.type === "VALID"))
    p6 = Jw({ x: o, filter: r, convInfo: h6, backend: e });
  else if (h6.strideWidth <= 2 && d === "channelsLast" && F().getBool("WEBGL_EXP_CONV")) {
    const m = new Qw(h6), g6 = [
      [h6.padInfo.top, h6.padInfo.left],
      [h6.strideHeight, h6.strideWidth],
      [h6.dilationHeight, h6.dilationWidth],
      [h6.inHeight, h6.inWidth]
    ];
    p6 = e.runWebGLProgram(m, [o, r], "float32", g6);
  } else if (F().getBool("WEBGL_CONV_IM2COL"))
    p6 = jw({ x: o, filter: r, convInfo: h6, backend: e });
  else {
    const m = new Yw(h6);
    p6 = e.runWebGLProgram(m, [o, r], "float32");
  }
  const f = st({ inputs: { x: p6 }, backend: e, attrs: { shape: h6.outShape } });
  return e.disposeIntermediateTensorInfo(p6), f;
}
var sK = {
  kernelName: Hl,
  backendName: "webgl",
  kernelFunc: nK
};
var oK = class {
  constructor(t) {
    this.variableNames = ["x", "dy"], this.outputShape = t.filterShape;
    const e = t.strideHeight, s = t.strideWidth, o = t.padInfo.top, r = t.padInfo.left, i6 = t.dataFormat === "channelsLast";
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int d2 = coords.w;

        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int b = 0; b < ${t.batchSize}; b++) {
          for (int yR = 0; yR < ${t.outHeight}; yR++) {
            int xR = wR + yR * ${e} - ${o};

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${t.outWidth}; yC++) {
              int xC = wC + yC * ${s} - ${r};

              if (xC < 0 || xC >= ${t.inWidth}) {
                continue;
              }

              if (${i6}) {
                float dyValue = getDy(b, yR, yC, d2);
                float xValue = getX(b, xR, xC, d1);
                dotProd += (xValue * dyValue);
              } else {
                float dyValue = getDy(b, d2, yR, yC);
                float xValue = getX(b, d1, xR, xC);
                dotProd += (xValue * dyValue);
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var rK = class {
  constructor(t) {
    this.variableNames = ["dy", "W"], this.outputShape = t.inShape;
    const e = t.filterHeight, s = t.filterWidth, o = t.strideHeight, r = t.strideWidth, i6 = t.dataFormat === "channelsLast", a = e - 1 - t.padInfo.top, l = s - 1 - t.padInfo.left, c = i6 ? 1 : 2, u = i6 ? 2 : 3, d = i6 ? 3 : 1;
    this.userCode = `
      const ivec2 pads = ivec2(${a}, ${l});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[${d}];

        ivec2 dyCorner = ivec2(coords[${c}], coords[${u}]) - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${e}; wR++) {
          float dyR = float(dyRCorner + wR) / ${o}.0;

          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${e} - 1 - wR;

          for (int wC = 0; wC < ${s}; wC++) {
            float dyC = float(dyCCorner + wC) / ${r}.0;

            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${s} - 1 - wC;

            for (int d2 = 0; d2 < ${t.outChannels}; d2++) {

              if (${i6}) {
                float xValue = getDy(batch, idyR, idyC, d2);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              } else {
                float xValue = getDy(batch, d2, idyR, idyC);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var iK = class {
  constructor(t) {
    this.variableNames = ["x", "dy"], this.outputShape = t.filterShape;
    const e = t.strideDepth, s = t.strideHeight, o = t.strideWidth, r = t.padInfo.front, i6 = t.padInfo.top, a = t.padInfo.left;
    this.userCode = `
      void main() {
        ivec5 coords = getOutputCoords();
        int wF = coords.x;
        int wR = coords.y;
        int wC = coords.z;
        int d1 = coords.w;
        int d2 = coords.u;

        float dotProd = 0.0;

        for (int b = 0; b < ${t.batchSize}; b++) {
          for (int yF = 0; yF < ${t.outDepth}; yF++) {
            int xF = wF + yF * ${e} - ${r};

            if (xF < 0 || xF >= ${t.inDepth}) {
              continue;
            }

            for (int yR = 0; yR < ${t.outHeight}; yR++) {
              int xR = wR + yR * ${s} - ${i6};

              if (xR < 0 || xR >= ${t.inHeight}) {
                continue;
              }

              for (int yC = 0; yC < ${t.outWidth}; yC++) {
                int xC = wC + yC * ${o} - ${a};

                if (xC < 0 || xC >= ${t.inWidth}) {
                  continue;
                }

                float dyValue = getDy(b, yF, yR, yC, d2);
                float xValue = getX(b, xF, xR, xC, d1);
                dotProd += (xValue * dyValue);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var aK = class {
  constructor(t) {
    this.variableNames = ["dy", "W"], this.outputShape = t.inShape;
    const e = t.filterDepth, s = t.filterHeight, o = t.filterWidth, r = t.strideDepth, i6 = t.strideHeight, a = t.strideWidth, l = e - 1 - t.padInfo.front, c = s - 1 - t.padInfo.top, u = o - 1 - t.padInfo.left;
    this.userCode = `
      const ivec3 pads = ivec3(${l}, ${c}, ${u});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.u;


        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyFCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        float dotProd = 0.0;
        for (int wF = 0; wF < ${e}; wF++) {
          float dyF = float(dyFCorner + wF) / ${r}.0;

          if (dyF < 0.0 || dyF >= ${t.outDepth}.0 || fract(dyF) > 0.0) {
            continue;
          }
          int idyF = int(dyF);

          int wFPerm = ${e} - 1 - wF;

          for (int wR = 0; wR < ${s}; wR++) {
            float dyR = float(dyRCorner + wR) / ${i6}.0;

            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||
              fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            int wRPerm = ${s} - 1 - wR;

            for (int wC = 0; wC < ${o}; wC++) {
              float dyC = float(dyCCorner + wC) / ${a}.0;

              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              int wCPerm = ${o} - 1 - wC;

              for (int d2 = 0; d2 < ${t.outChannels}; d2++) {
                float xValue = getDy(batch, idyF, idyR, idyC, d2);
                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
function lK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, pad: a, dataFormat: l, dimRoundingMode: c, filterShape: u } = s, d = ys(l), h6 = ke(o.shape, u, i6, 1, a, c, false, d), p6 = new oK(h6);
  return e.runWebGLProgram(p6, [o, r], "float32");
}
var cK = {
  kernelName: jd,
  backendName: "webgl",
  kernelFunc: lK
};
function uK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { inputShape: i6, strides: a, pad: l, dataFormat: c, dimRoundingMode: u } = s, d = ys(c), h6 = ke(i6, r.shape, a, 1, l, u, false, d), p6 = new rK(h6);
  return e.runWebGLProgram(p6, [o, r], "float32");
}
var dK = {
  kernelName: _l,
  backendName: "webgl",
  kernelFunc: uK
};
function hK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l } = s, c = Bs(o.shape, r.shape, i6, l, a), u = new tK(c);
  return e.runWebGLProgram(u, [o, r], "float32");
}
var pK = {
  kernelName: Ul,
  backendName: "webgl",
  kernelFunc: hK
};
function fK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, pad: a, filterShape: l } = s, c = Bs(o.shape, l, i6, 1, a), u = new iK(c);
  return e.runWebGLProgram(u, [o, r], "float32");
}
var mK = {
  kernelName: qd,
  backendName: "webgl",
  kernelFunc: fK
};
function gK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { pad: i6, strides: a, inputShape: l } = s, c = Bs(l, r.shape, a, 1, i6), u = new aK(c);
  return e.runWebGLProgram(u, [o, r], "float32");
}
var bK = {
  kernelName: th,
  backendName: "webgl",
  kernelFunc: gK
};
var xK = Gr + `
  return cos(x);
`;
var yK = Nt({ opSnippet: xK });
var wK = {
  kernelName: Ii,
  backendName: "webgl",
  kernelFunc: yK
};
var IK = `
  float e2x = exp(-x);
  return (e2x + 1.0 / e2x) / 2.0;
`;
var CK = Nt({ opSnippet: IK });
var vK = {
  kernelName: Ci,
  backendName: "webgl",
  kernelFunc: CK
};
var SK = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["Image", "Boxes", "BoxInd"], this.outputShape = [];
    const [i6, a, l, c] = t, [u] = e, [d, h6] = s;
    this.outputShape = [u, d, h6, c];
    const p6 = o === "bilinear" ? 1 : 0, [f, m] = [`${a - 1}.0`, `${l - 1}.0`], [g6, b6, x6] = d > 1 ? [
      `${(a - 1) / (d - 1)}`,
      "(y2-y1) * height_ratio",
      `y1*${f} + float(y)*(height_scale)`
    ] : [
      "0.0",
      "0.0",
      `0.5 * (y1+y2) * ${f}`
    ], [w6, y6, I] = h6 > 1 ? [
      `${(l - 1) / (h6 - 1)}`,
      "(x2-x1) * width_ratio",
      `x1*${m} + float(x)*(width_scale)`
    ] : [
      "0.0",
      "0.0",
      `0.5 * (x1+x2) * ${m}`
    ];
    this.userCode = `
      const float height_ratio = float(${g6});
      const float width_ratio = float(${w6});
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int y = coords[1];
        int x = coords[2];
        int d = coords[3];

        // get box vals
        float y1 = getBoxes(b,0);
        float x1 = getBoxes(b,1);
        float y2 = getBoxes(b,2);
        float x2 = getBoxes(b,3);

        // get image in batch index
        int bInd = round(getBoxInd(b));
        if(bInd < 0 || bInd >= ${i6}) {
          return;
        }

        float height_scale = ${b6};
        float width_scale = ${y6};

        float in_y = ${x6};
        if( in_y < 0.0 || in_y > ${f} ) {
          setOutput(float(${r}));
          return;
        }
        float in_x = ${I};
        if( in_x < 0.0 || in_x > ${m} ) {
          setOutput(float(${r}));
          return;
        }

        vec2 sourceFracIndexCR = vec2(in_x,in_y);
        if(${p6} == 1) {
          // Compute the four integer indices.
          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);
          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));

          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);
          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);
          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);
          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);

          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);

          float top = topLeft + (topRight - topLeft) * fracCR.x;
          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;
          float newValue = top + (bottom - top) * fracCR.y;
          setOutput(newValue);
        } else {
          // Compute the coordinators of nearest neighbor point.
          ivec2 sourceNearestCR = ivec2(floor(
            sourceFracIndexCR + vec2(0.5,0.5)));
          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);
          setOutput(newValue);
        }
      }
    `;
  }
};
var kK = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { image: o, boxes: r, boxInd: i6 } = t, { cropSize: a, method: l, extrapolationValue: c } = s, u = new SK(o.shape, r.shape, a, l, c);
  return e.runWebGLProgram(u, [o, r, i6], "float32");
};
var TK = {
  kernelName: nh,
  backendName: "webgl",
  kernelFunc: kK
};
var ci;
(function(n) {
  n.Prod = "*", n.Sum = "+";
})(ci || (ci = {}));
var pg = class {
  constructor(t, e, s, o) {
    this.op = t, this.outputShape = e, this.variableNames = ["x"], this.customUniforms = [{ name: "index", type: "float" }];
    const r = this.outputShape.length, i6 = this.op === ci.Prod ? "1.0" : "0.0", a = s ? i6 : `getX(${fg(r, "coords", this.op)})`, l = this.outputShape[this.outputShape.length - 1];
    let c = "", u = "";
    s ? (c = o ? `end != ${l - 1}` : "end != 0", u = o ? "end + 1" : "end - 1") : (c = o ? `end + pow2 < ${l}` : "end >= pow2", u = o ? "end + pow2" : "end - pow2"), this.userCode = `
      void main() {
        ${Kt(r)} coords = getOutputCoords();
        int end = ${mg(r, "coords", this.op)};
        float val = ${a};
        int pow2 = int(pow(2.0, index));
        if (${c}) {
          int idx = ${u};
          ${mg(r, "coords", this.op)} = idx;
          val ${this.op}= getX(${fg(r, "coords", this.op)});
        }
        setOutput(val);
      }
    `;
  }
};
function fg(n, t, e) {
  if (n === 1)
    return `${t}`;
  if (n === 2)
    return `${t}.x, ${t}.y`;
  if (n === 3)
    return `${t}.x, ${t}.y, ${t}.z`;
  if (n === 4)
    return `${t}.x, ${t}.y, ${t}.z, ${t}.w`;
  throw new Error(`Cumulative ${e} for rank ${n} is not yet supported`);
}
function mg(n, t, e) {
  if (n === 1)
    return `${t}`;
  if (n === 2)
    return `${t}.y`;
  if (n === 3)
    return `${t}.z`;
  if (n === 4)
    return `${t}.w`;
  throw new Error(`Cumulative ${e} for rank ${n} is not yet supported`);
}
function qw(n, t, e, s, o, r) {
  const i6 = t.shape.length, a = qt([s], i6);
  let l = t;
  a != null && (l = Fe({ inputs: { x: t }, backend: e, attrs: { perm: a } }));
  const c = ie(1, i6)[0];
  if (c !== i6 - 1)
    throw new Error(`WebGL cumprod shader expects an inner-most axis=${t.shape.length - 1} but got axis=${s}`);
  const u = l.shape[c];
  let d = tn({ inputs: { x: l }, backend: e });
  for (let h6 = 0; h6 <= Math.ceil(Math.log2(u)) - 1; h6++) {
    const p6 = new pg(n, l.shape, false, r), f = [[h6]], m = d;
    d = e.runWebGLProgram(p6, [d], d.dtype, f), e.disposeIntermediateTensorInfo(m);
  }
  if (o) {
    const h6 = new pg(n, l.shape, o, r), p6 = d;
    d = e.runWebGLProgram(h6, [d], d.dtype), e.disposeIntermediateTensorInfo(p6);
  }
  if (a != null) {
    const h6 = Hs(a), p6 = Fe({ inputs: { x: d }, backend: e, attrs: { perm: h6 } });
    return e.disposeIntermediateTensorInfo(d), e.disposeIntermediateTensorInfo(l), p6;
  }
  return d;
}
function NK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, exclusive: i6, reverse: a } = s;
  return qw(ci.Prod, o, e, r, i6, a);
}
var RK = {
  kernelName: eh,
  backendName: "webgl",
  kernelFunc: NK
};
function $K(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, exclusive: i6, reverse: a } = s;
  return qw(ci.Sum, o, e, r, i6, a);
}
var GK = {
  kernelName: Yl,
  backendName: "webgl",
  kernelFunc: $K
};
function EK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, weights: r } = t, { size: i6, binaryOutput: a } = s;
  if (o.shape.length === 1) {
    const l = e.readSync(o.dataId), c = e.readSync(r.dataId), u = Mw(l, c, r.dtype, r.shape, i6);
    return e.makeTensorInfo([i6], r.dtype, u);
  } else if (o.shape.length === 2) {
    const l = e.bufferSync(o), c = e.bufferSync(r), u = KX(l, c, i6, a);
    return e.makeTensorInfo(u.shape, r.dtype, u.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${o.shape.length}.`);
}
var LK = {
  kernelName: sh,
  backendName: "webgl",
  kernelFunc: EK
};
var MK = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.outputShape = [], this.outputShape = t, this.blockSize = e, this.dataFormat = s, this.userCode = `
    void main() {
      ivec4 coords = getOutputCoords();
      int b = coords[0];
      int h = ${this.getHeightCoordString()};
      int w = ${this.getWidthCoordString()};
      int d = ${this.getDepthCoordString()};

      int in_h = h / ${e};
      int offset_h = imod(h, ${e});
      int in_w = w / ${e};
      int offset_w = imod(w, ${e});
      int offset_d = (offset_h * ${e} + offset_w) *
        ${this.getOutputDepthSize()};
      int in_d = d + offset_d;

      float result = ${this.getInputSamplingString()};
      setOutput(result);
    }
  `;
  }
  getHeightCoordString() {
    return this.dataFormat === "NHWC" ? "coords[1]" : "coords[2]";
  }
  getWidthCoordString() {
    return this.dataFormat === "NHWC" ? "coords[2]" : "coords[3]";
  }
  getDepthCoordString() {
    return this.dataFormat === "NHWC" ? "coords[3]" : "coords[1]";
  }
  getOutputDepthSize() {
    return this.dataFormat === "NHWC" ? this.outputShape[3] : this.outputShape[1];
  }
  getInputSamplingString() {
    return this.dataFormat === "NHWC" ? "getX(b, in_h, in_w, in_d)" : "getX(b, in_d, in_h, in_w)";
  }
};
function WK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockSize: r, dataFormat: i6 } = s, a = o.shape[0], l = i6 === "NHWC" ? o.shape[1] : o.shape[2], c = i6 === "NHWC" ? o.shape[2] : o.shape[3], u = i6 === "NHWC" ? o.shape[3] : o.shape[1], d = l * r, h6 = c * r, p6 = u / (r * r), f = i6 === "NHWC" ? [a, d, h6, p6] : [a, p6, d, h6], m = new MK(f, r, i6);
  return e.runWebGLProgram(m, [o], o.dtype);
}
var DK = {
  kernelName: oh,
  backendName: "webgl",
  kernelFunc: WK
};
var tI = class {
  constructor(t, e = false, s = null, o = false, r = false) {
    this.variableNames = ["x", "W"], this.customUniforms = [
      { name: "pads", type: "ivec2" },
      { name: "strides", type: "ivec2" },
      { name: "dilations", type: "ivec2" },
      { name: "inDims", type: "ivec2" }
    ], this.outputShape = t.outShape, this.enableShapeUniforms = Xe(this.outputShape.length);
    const i6 = t.filterHeight, a = t.filterWidth, l = t.outChannels / t.inChannels;
    let c = "", u = "";
    s && (o ? c = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${s}
        }` : r ? c = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${s}
        }` : c = `
          float activation(float x) {
            ${s}
          }
        `, u = "result = activation(result);");
    const d = e ? "result += getBiasAtOutCoords();" : "";
    e && this.variableNames.push("bias"), o && this.variableNames.push("preluActivationWeights"), r && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${c}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${l};
        int q = d2 - d1 * ${l};

        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.
        for (int wR = 0; wR < ${i6}; wR++) {
          int xR = xRCorner + wR * dilations[0];

          if (xR < 0 || xR >= inDims[0]) {
            continue;
          }

          for (int wC = 0; wC < ${a}; wC++) {
            int xC = xCCorner + wC * dilations[1];

            if (xC < 0 || xC >= inDims[1]) {
              continue;
            }

            float xVal = getX(batch, xR, xC, d1);
            float wVal = getW(wR, wC, d1, q);
            dotProd += xVal * wVal;
          }
        }

        float result = dotProd;
        ${d}
        ${u}
        setOutput(result);
      }
    `;
  }
};
var eI = class {
  constructor(t, e = false, s = null, o = false, r = false) {
    this.variableNames = ["x", "W"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "pads", type: "ivec2" },
      { name: "strides", type: "ivec2" },
      { name: "dilations", type: "ivec2" },
      { name: "inDims", type: "ivec2" }
    ], this.outputShape = t.outShape, this.enableShapeUniforms = Xe(this.outputShape.length);
    const i6 = t.outChannels / t.inChannels, a = t.padInfo.left, l = t.strideWidth, c = t.dilationWidth, u = t.filterHeight, d = t.filterWidth, h6 = d;
    let p6 = `
      int xR; int xC; int xCOffset;
      vec4 wTexel; vec4 previous; vec4 final;`;
    for (let b6 = 0; b6 < d; b6++)
      p6 += `
          vec4 xTexelC${b6 * 2};
          int xTexelC${b6 * 2}Ready;
          vec4 xTexelC${b6 * 2 + 1};
          int xTexelC${b6 * 2 + 1}Ready;
          vec4 xC${b6};`;
    p6 += `
    for (int r = 0; r < ${u}; r++) {
      `;
    for (let b6 = 0; b6 < d; b6++)
      p6 += `
          xTexelC${b6 * 2} = vec4(0.0);
          xTexelC${b6 * 2}Ready = 0;
          xTexelC${b6 * 2 + 1} = vec4(0.0);
          xTexelC${b6 * 2 + 1}Ready = 0;
          xC${b6} = vec4(0.0);`;
    p6 += `
        xR = xRCorner + r * dilations[0];
        if (xR >=0 && xR < inDims[0]) {
      `;
    for (let b6 = 0; b6 < (h6 + 1) / 2; b6++) {
      const x6 = b6 * 2;
      if (p6 += `
          xC = xCCorner + ${x6 * c};
          `, l === 1) {
        if (x6 < d && (a % 2 === 1 ? (p6 += `
                xCOffset = xC + 1;
                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6}Ready == 0) {
                  xTexelC${x6} = getX(batch, xR, xCOffset, d1);

                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${x6}.zw = vec2(0.0);
                  }
                  xTexelC${x6}Ready = 1;
                }
              `, c === 1 && x6 > 0 ? p6 += `
                xC${x6} = vec4(xTexelC${x6 - 2}.zw, xTexelC${x6}.xy);
                ` : p6 += `
                  xCOffset = xC + 1 - 2;

                  if (xCOffset >= 0 && xCOffset < inDims[1]) {
                    previous = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      previous.zw = vec2(0.0);
                    }

                    xC${x6} = vec4(previous.zw, xTexelC${x6}.xy);
                  } else {
                    xC${x6} = vec4(0.0, 0.0, xTexelC${x6}.xy);
                  }
                  `) : p6 += `
                if (xC >= 0 && xC < inDims[1] && xTexelC${x6}Ready == 0) {
                  xTexelC${x6} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${x6}.zw = vec2(0.0);
                  }
                  xTexelC${x6}Ready = 1;
                }

                xC${x6} = xTexelC${x6};
                `, x6 + 1 < d)) {
          const w6 = a % 2 === 0 ? Wl(c) : c;
          c % 2 === 0 && a % 2 === 1 || c % 2 !== 0 && a % 2 !== 1 ? (p6 += `
                  xCOffset = xC + imod(pads[1], 2) + ${w6};

                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6 + 1}Ready == 0) {
                    xTexelC${x6 + 1} = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      xTexelC${x6 + 1}.zw = vec2(0.0);
                    }
                    xTexelC${x6 + 1}Ready = 1;
                  }
                  `, c > 1 ? p6 += `
                    xCOffset -= 2;
                    if (xCOffset >= 0 && xCOffset < inDims[1]) {
                     previous = getX(batch, xR, xCOffset, d1);
                     xC${x6 + 1} = vec4(previous.zw, xTexelC${x6 + 1}.xy);
                    } else {
                     xC${x6 + 1} = vec4(0.0, 0.0, xTexelC${x6 + 1}.xy);
                    }
                    ` : p6 += `
                    xC${x6 + 1} = vec4(xTexelC${x6}.zw, xTexelC${x6 + 1}.xy);
                    `) : w6 === 1 ? p6 += `
                    xC${x6 + 1} = xTexelC${x6};
                    ` : p6 += `
                    xCOffset = xC + ${w6};

                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6 + 1}Ready == 0) {
                      xTexelC${x6 + 1} = getX(batch, xR, xCOffset, d1);
                      if (xCOffset + 1 >= inDims[1]) {
                        xTexelC${x6 + 1}.zw = vec2(0.0);
                      }
                      xTexelC${x6 + 1}Ready = 1;
                    }

                    xC${x6 + 1} = xTexelC${x6 + 1};
                    `;
        }
      } else
        x6 < d && (a % 2 === 1 ? (p6 += `
                xCOffset = xC + 1 - strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6}Ready == 0) {
                  xTexelC${x6} = getX(batch, xR, xCOffset, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${x6}.zw = vec2(0.0);
                  }
                  xTexelC${x6}Ready = 1;
                }

                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${x6 + 1}Ready == 0) {
                  xTexelC${x6 + 1} = getX(batch, xR, xC + 1, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xC + 2 >= inDims[1]) {
                    xTexelC${x6 + 1}.zw = vec2(0.0);
                  }
                  xTexelC${x6 + 1}Ready = 1;
                }

                xC${x6} = vec4(xTexelC${x6}.zw, xTexelC${x6 + 1}.zw);
              `, x6 + 1 < d && (p6 += `
                  final = vec4(0.0);
                  xCOffset = xC + 1 + strides[1];
                  if(xCOffset >= 0 && xCOffset < inDims[1]) {
                    final = getX(batch, xR, xCOffset, d1);
                  }
                  xC${x6 + 1} = vec4(xTexelC${x6 + 1}.xy, final.xy);
                `)) : (p6 += `
                if(xC >= 0 && xC < inDims[1] && xTexelC${x6}Ready == 0) {
                  xTexelC${x6} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${x6}.zw = vec2(0.0);
                  }
                  xTexelC${x6}Ready = 1;
                }

                xCOffset = xC + strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6 + 1}Ready == 0) {
                  xTexelC${x6 + 1} = getX(batch, xR, xCOffset, d1);
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${x6 + 1}.zw = vec2(0.);
                  }
                  xTexelC${x6 + 1}Ready = 1;
                }

                xC${x6} = vec4(
                  xTexelC${x6}.xy, xTexelC${x6 + 1}.xy);
              `, x6 + 1 < d && (p6 += `
                  xC${x6 + 1} = vec4(xTexelC${x6}.zw, xTexelC${x6 + 1}.zw);
                `)));
      x6 < d && (p6 += `
            wTexel = getW(r, ${x6}, d1, q);
            dotProd += xC${x6} * vec4(wTexel.xz, wTexel.xz);
          `, x6 + 1 < d && (p6 += `
              wTexel = getW(r, ${x6 + 1}, d1, q);
              dotProd += xC${x6 + 1} * vec4(wTexel.xz, wTexel.xz);
            `));
    }
    p6 += `
    }
  `, p6 += `
      }
    `;
    let f = "", m = "";
    s && (o ? f = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${s}
        }` : r ? f = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${s}
        }` : f = `vec4 activation(vec4 x) {
          ${s}
        }`, m = "result = activation(result);");
    const g6 = e ? "result += getBiasAtOutCoords();" : "";
    e && this.variableNames.push("bias"), o && this.variableNames.push("preluActivationWeights"), r && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${f}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${i6};
        int q = d2 - d1 * ${i6};
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
        vec4 dotProd = vec4(0.000000000000001);

        ${p6}

        vec4 result = dotProd - vec4(0.000000000000001);
        ${g6}
        ${m}
        setOutput(result);
      }
    `;
  }
};
function FK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l, dimRoundingMode: c } = s;
  let u = l;
  u == null && (u = [1, 1]), v2(Ee(i6, u), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i6} and dilations '${u}'`);
  const d = ke(
    o.shape,
    r.shape,
    i6,
    u,
    a,
    c,
    true
    /* depthwise */
  );
  let h6;
  F().getBool("WEBGL_PACK_DEPTHWISECONV") && d.strideWidth <= 2 && d.outChannels / d.inChannels === 1 ? h6 = new eI(d) : h6 = new tI(d);
  const p6 = [
    [d.padInfo.top, d.padInfo.left],
    [d.strideHeight, d.strideWidth],
    [d.dilationHeight, d.dilationWidth],
    [d.inHeight, d.inWidth]
  ];
  return e.runWebGLProgram(h6, [o, r], "float32", p6);
}
var VK = {
  kernelName: Ql,
  backendName: "webgl",
  kernelFunc: FK
};
var zK = class {
  constructor(t) {
    this.variableNames = ["x", "dy"], this.outputShape = t.filterShape;
    const e = t.strideHeight, s = t.strideWidth, o = t.padInfo.top, r = t.padInfo.left, i6 = t.outChannels / t.inChannels;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int dm = coords.w;
        int d2 = d1 * ${i6} + dm;

        float dotProd = 0.0;

        // TO DO: Vec4 over the batch size
        for (int b = 0; b < ${t.batchSize}; b++) {
          for (int yR = 0; yR < ${t.outHeight}; yR++) {
            int xR = wR + yR * ${e} - ${o};

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${t.outWidth}; yC++) {
              int xC = wC + yC * ${s} - ${r};

              if (xC < 0 || xC >= ${t.inWidth}) {
                continue;
              }

              float dyValue = getDy(b, yR, yC, d2);
              float xValue = getX(b, xR, xC, d1);
              dotProd += (xValue * dyValue);
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var XK = class {
  constructor(t) {
    this.variableNames = ["dy", "W"], this.outputShape = t.inShape;
    const e = t.filterHeight, s = t.filterWidth, o = t.strideHeight, r = t.strideWidth, i6 = e - 1 - t.padInfo.top, a = s - 1 - t.padInfo.left, l = t.outChannels / t.inChannels;
    this.userCode = `
      const ivec2 pads = ivec2(${i6}, ${a});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[3];
        ivec2 dyCorner = coords.yz - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        float dotProd = 0.0;

        for (int wR = 0; wR < ${e}; wR++) {
          float dyR = float(dyRCorner + wR) / ${o}.0;

          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${e} - 1 - wR;

          for (int wC = 0; wC < ${s}; wC++) {
            float dyC = float(dyCCorner + wC) / ${r}.0;

            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${s} - 1 - wC;

            // TO DO: Vec4 over the channelMul
            for (int dm = 0; dm < ${l}; dm++) {
              int d2 = d1 * ${l} + dm;
              float xValue = getDy(batch, idyR, idyC, d2);
              float wValue = getW(wRPerm, wCPerm, d1, dm);
              dotProd += xValue * wValue;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
function PK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, dilations: a, pad: l, dimRoundingMode: c, filterShape: u } = s, d = ke(
    o.shape,
    u,
    i6,
    a,
    l,
    c,
    true
    /* depthwise */
  ), h6 = new zK(d);
  return e.runWebGLProgram(h6, [o, r], "float32");
}
var AK = {
  kernelName: rh,
  backendName: "webgl",
  kernelFunc: PK
};
function OK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { strides: i6, dilations: a, pad: l, dimRoundingMode: c, inputShape: u } = s, d = ke(
    u,
    r.shape,
    i6,
    a,
    l,
    c,
    true
    /* depthwise */
  ), h6 = new XK(d);
  return e.runWebGLProgram(h6, [o, r], "float32");
}
var KK = {
  kernelName: ih,
  backendName: "webgl",
  kernelFunc: OK
};
var ZK = class {
  constructor(t) {
    this.variableNames = ["X"], this.outputShape = [t, t], this.userCode = `
      void main() {
          ivec2 coords = getOutputCoords();
          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;
          setOutput(val);
      }
    `;
  }
};
function BK(n) {
  const { inputs: t, backend: e } = n, { x: s } = t, o = [...s.shape, ...s.shape], r = O(s.shape), i6 = st({ inputs: { x: s }, backend: e, attrs: { shape: [r] } }), a = new ZK(r), l = e.runWebGLProgram(a, [i6], i6.dtype), c = st({ inputs: { x: l }, backend: e, attrs: { shape: o } });
  return e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(l), c;
}
var HK = {
  kernelName: Zg,
  backendName: "webgl",
  kernelFunc: BK
};
var _K = class {
  constructor(t) {
    this.variableNames = ["x", "W"], this.outputShape = t.outShape;
    const { inHeight: e, inWidth: s, padInfo: o, strideHeight: r, strideWidth: i6, filterHeight: a, filterWidth: l, dilationHeight: c, dilationWidth: u } = t, { top: d, left: h6 } = o;
    this.userCode = `
      const ivec2 strides = ivec2(${r}, ${i6});
      const ivec2 pads = ivec2(${d}, ${h6});
      const float neg_infinity = -3.4e38;

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.w;
        ivec2 outTopLeftCorner =
            coords.yz * strides - pads;
        int hBeg = outTopLeftCorner.x;
        int wBeg = outTopLeftCorner.y;

        float curVal = neg_infinity;
        for (int h = 0; h < ${a}; h++) {
          int hIn = hBeg + h * ${c};

          if (hIn >= 0 && hIn < ${e}) {
            for (int w = 0; w < ${l}; w++) {
              int wIn = wBeg + w * ${u};

              if (wIn >= 0 && wIn < ${s}) {
                float xVal = getX(batch, hIn, wIn, d1);
                float wVal = getW(h, w, d1);

                float val = xVal + wVal;
                if (val > curVal) {
                  curVal = val;
                }
              }
            }
          }
        }

        float result = curVal;
        setOutput(result);
      }
    `;
  }
};
function UK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l } = s, c = ca(o.shape, r.shape, i6, a, "NHWC", l);
  let u;
  const d = new _K(c);
  u = e.runWebGLProgram(d, [o, r], "float32");
  const h6 = st({ inputs: { x: u }, backend: e, attrs: { shape: c.outShape } });
  return e.disposeIntermediateTensorInfo(u), h6;
}
var YK = {
  kernelName: Jl,
  backendName: "webgl",
  kernelFunc: UK
};
function QK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { equation: o } = s, r = t, { allDims: i6, summedDims: a, idDims: l } = Yp(o, r.length);
  Jp(i6.length, l, r);
  const { path: c, steps: u } = jp(a, l), d = u.length;
  let h6 = null, p6 = i6.length;
  const f = [];
  for (let m = 0; m < d; ++m) {
    for (const g6 of u[m]) {
      const { permutationIndices: b6, expandDims: x6 } = Qp(p6, l[g6]);
      let w6;
      qp(b6) ? w6 = r[g6] : (w6 = Fe({ inputs: { x: r[g6] }, backend: e, attrs: { perm: b6 } }), f.push(w6));
      const y6 = w6.shape.slice();
      for (let I = 0; I < x6.length; ++I)
        y6.splice(x6[I], 0, 1);
      Rt(w6.shape, y6) || (w6 = st({ inputs: { x: w6 }, backend: e, attrs: { shape: y6 } }), f.push(w6)), h6 === null ? h6 = w6 : (h6 = Of({ inputs: { a: w6, b: h6 }, backend: e }), f.push(h6));
    }
    m < d - 1 && (c[m] >= 0 && (h6 = fu({
      inputs: { x: h6 },
      backend: e,
      attrs: {
        axis: c[m] - (i6.length - p6),
        keepDims: false
      }
    }), f.push(h6)), p6--);
  }
  for (const m of f)
    m !== h6 && e.disposeIntermediateTensorInfo(m);
  return h6;
}
var JK = {
  kernelName: Bg,
  backendName: "webgl",
  kernelFunc: QK
};
var jK = "return (x >= 0.0) ? x : (exp(x) - 1.0);";
var qK = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
var tZ = Nt({ opSnippet: jK, packedOpSnippet: qK });
var eZ = {
  kernelName: Si,
  backendName: "webgl",
  kernelFunc: tZ
};
var nZ = "return (b >= 1.0) ? a : a * (b + 1.0);";
var sZ = `
  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));
  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));
`;
var oZ = (n) => {
  const { inputs: t, backend: e } = n, { dy: s, y: o } = t, r = F().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new Ga(sZ, s.shape, o.shape) : new fr(nZ, s.shape, o.shape);
  return e.runWebGLProgram(r, [s, o], s.dtype);
};
var rZ = {
  kernelName: ah,
  backendName: "webgl",
  kernelFunc: oZ
};
var iZ = `
  return vec4(equal(a, b));
`;
var aZ = "return float(a == b);";
var lZ = Ne({
  opSnippet: aZ,
  packedOpSnippet: iZ,
  dtype: "bool",
  cpuKernelImpl: _X
});
var cZ = {
  kernelName: jl,
  backendName: "webgl",
  kernelFunc: lZ
};
var uZ = `
  // Error function is calculated approximately with elementary function.
  // See "Handbook of Mathematical Functions with Formulas,
  // Graphs, and Mathematical Tables", Abramowitz and Stegun.
  float p = ${Op};
  float a1 = ${Kp};
  float a2 = ${Zp};
  float a3 = ${Bp};
  float a4 = ${Hp};
  float a5 = ${_p};

  float sign = sign(x);
  x = abs(x);
  float t = 1.0 / (1.0 + p * x);
  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));
`;
var dZ = Nt({ opSnippet: uZ });
var hZ = {
  kernelName: ki,
  backendName: "webgl",
  kernelFunc: dZ
};
var pZ = Gr + `
  return exp(x);
`;
var fZ = `
  vec4 result = exp(x);
  bvec4 isNaN = isnan(x);
  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var nI = Nt({
  opSnippet: pZ,
  packedOpSnippet: fZ,
  cpuKernelImpl: UX,
  dtype: "float32"
});
var mZ = {
  kernelName: Ti,
  backendName: "webgl",
  kernelFunc: nI
};
function Fd(n) {
  const { inputs: t, attrs: e, backend: s } = n, { dim: o } = e, { input: r } = t, i6 = r.shape.length, a = r.shape.slice();
  let l = o;
  return o < 0 && (v2(-(i6 + 1) <= o, () => `Axis must be in the interval [${-(i6 + 1)}, ${i6}]`), l = i6 + o + 1), a.splice(l, 0, 1), st({ inputs: { x: r }, backend: s, attrs: { shape: a } });
}
var gZ = {
  kernelName: ql,
  backendName: "webgl",
  kernelFunc: Fd
};
var gg = "return exp(x) - 1.0;";
var bZ = Nt({ opSnippet: gg, packedOpSnippet: gg, cpuKernelImpl: YX });
var xZ = {
  kernelName: Ni,
  backendName: "webgl",
  kernelFunc: bZ
};
var bg = class {
  constructor(t, e, s) {
    this.variableNames = ["real", "imag"];
    const o = e[1];
    this.outputShape = e;
    const r = s ? `2.0 * ${Math.PI}` : `-2.0 * ${Math.PI}`, i6 = s ? `${o}.0` : "1.0";
    let a;
    if (t === "real")
      a = "return real * expR - imag * expI;";
    else if (t === "imag")
      a = "return real * expI + imag * expR;";
    else
      throw new Error(`FFT component must be either "real" or "imag", got ${t}.`);
    this.userCode = `
      const float exponentMultiplier = ${r};

      float unaryOpComplex(float real, float expR, float imag, float expI) {
        ${a}
      }

      float mulMatDFT(int batch, int index) {
        float indexRatio = float(index) / float(${o});
        float exponentMultiplierTimesIndexRatio =
            exponentMultiplier * indexRatio;

        float result = 0.0;

        for (int i = 0; i < ${o}; i++) {
          // x = (-2|2 * PI / N) * index * i;
          float x = exponentMultiplierTimesIndexRatio * float(i);
          float expR = cos(x);
          float expI = sin(x);
          float real = getReal(batch, i);
          float imag = getImag(batch, i);

          result +=
              unaryOpComplex(real, expR, imag, expI) / ${i6};
        }

        return result;
      }

      void main() {
        ivec2 coords = getOutputCoords();
        setOutput(mulMatDFT(coords[0], coords[1]));
      }
    `;
  }
};
function sI(n, t, e) {
  const s = e.texData.get(n.dataId), o = O(n.shape), r = n.shape[n.shape.length - 1], i6 = o / r, a = st({ inputs: { x: n }, backend: e, attrs: { shape: [i6, r] } }), l = a.shape, c = new bg("real", l, t), u = new bg("imag", l, t), d = [
    {
      dataId: s.complexTensorInfos.real.dataId,
      dtype: s.complexTensorInfos.real.dtype,
      shape: l
    },
    {
      dataId: s.complexTensorInfos.imag.dataId,
      dtype: s.complexTensorInfos.imag.dtype,
      shape: l
    }
  ], h6 = e.runWebGLProgram(c, d, "float32"), p6 = e.runWebGLProgram(u, d, "float32"), f = js({ inputs: { real: h6, imag: p6 }, backend: e });
  e.disposeIntermediateTensorInfo(h6), e.disposeIntermediateTensorInfo(p6);
  const m = st({ inputs: { x: f }, backend: e, attrs: { shape: n.shape } });
  return e.disposeIntermediateTensorInfo(a), e.disposeIntermediateTensorInfo(f), m;
}
function yZ(n) {
  const { inputs: t, backend: e } = n, { input: s } = t;
  return sI(s, false, e);
}
var wZ = {
  kernelName: lh,
  backendName: "webgl",
  kernelFunc: yZ
};
var IZ = class {
  constructor(t, e) {
    this.outputShape = [], this.customUniforms = [{ name: "value", type: "float" }], this.variableNames = ["x"], this.outputShape = t, this.userCode = `
      void main() {
        // Input can be obtained from uniform value.
        setOutput(value);
      }
    `;
  }
};
function La(n) {
  const { backend: t, attrs: e } = n, { shape: s, value: o } = e;
  let { dtype: r } = e;
  if (r = r || gr(o), r === "string") {
    const i6 = oe(r, O(s));
    return i6.fill(o), t.makeTensorInfo(s, r, i6);
  } else {
    const i6 = new IZ(s, o), a = [[o]];
    return t.runWebGLProgram(i6, [], r, a);
  }
}
var CZ = {
  kernelName: ch,
  backendName: "webgl",
  kernelFunc: La
};
var vZ = class {
  constructor(t) {
    this.variableNames = ["Image"], this.outputShape = [];
    const e = t[2];
    this.outputShape = t, this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];

          int coordX = ${e} - x - 1;
          float outputValue;
          if(coordX >= 0 && coordX < ${e}) {
            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);
          } else {
            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);
          }
          setOutput(outputValue);
        }
    `;
  }
};
var SZ = {
  kernelName: uh,
  backendName: "webgl",
  kernelFunc: ({ inputs: n, backend: t }) => {
    const { image: e } = n, s = t, o = new vZ(e.shape);
    return s.runWebGLProgram(o, [e], e.dtype);
  }
};
var xg = "return floor(x);";
var kZ = Nt({ opSnippet: xg, packedOpSnippet: xg, cpuKernelImpl: QX });
var TZ = {
  kernelName: Ri,
  backendName: "webgl",
  kernelFunc: kZ
};
var NZ = `
  float s = sign(a) * sign(b);
  int ia = round(a);
  int ib = round(b);
  if (ib != 0) {
    // Windows (D3D) wants guaranteed non-zero int division at compile-time.
    return float(idiv(ia, ib, s));
  } else {
    return NAN;
  }
`;
var RZ = `
  ivec4 ia = round(a);
  ivec4 ib = round(b);
  bvec4 cond = notEqual(ib, ivec4(0));
  ivec4 result = ivec4(0);
  vec4 s = sign(a) * sign(b);

  // Windows (D3D) wants guaranteed non-zero int division at compile-time.
  if (cond[0]) {
    result[0] = idiv(ia[0], ib[0], s[0]);
  }
  if (cond[1]) {
    result[1] = idiv(ia[1], ib[1], s[1]);
  }
  if (cond[2]) {
    result[2] = idiv(ia[2], ib[2], s[2]);
  }
  if (cond[3]) {
    result[3] = idiv(ia[3], ib[3], s[3]);
  }
  return vec4(result);
`;
var $Z = Ne({ opSnippet: NZ, packedOpSnippet: RZ, dtype: "int32" });
var GZ = {
  kernelName: $i,
  backendName: "webgl",
  kernelFunc: $Z
};
var EZ = class {
  constructor(t) {
    this.variableNames = ["A"];
    const e = ze(), [s, o] = t;
    this.outputShape = t, this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${o}.0, ${s}.0);

        vec4 values = ${e.texture2D}(A, uv);
        float value;
        if (depth == 0) {
          value = values.r;
        } else if (depth == 1) {
          value = values.g;
        } else if (depth == 2) {
          value = values.b;
        } else if (depth == 3) {
          value = values.a;
        }

        setOutput(floor(value * 255.0 + 0.5));
      }
    `;
  }
};
var LZ = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true;
    const e = ze(), [s, o] = t;
    this.outputShape = t, this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];

        vec4 result = vec4(0.);

        for(int row=0; row<=1; row++) {
          for(int col=0; col<=1; col++) {
            texC = coords[1] + row;
            depth = coords[2] + col;

            vec2 uv = (vec2(texC, texR) + halfCR) /
                       vec2(${o}.0, ${s}.0);
            vec4 values = ${e.texture2D}(A, uv);
            float value;
            if (depth == 0) {
              value = values.r;
            } else if (depth == 1) {
              value = values.g;
            } else if (depth == 2) {
              value = values.b;
            } else if (depth == 3) {
              value = values.a;
            }

            result[row * 2 + col] = floor(value * 255.0 + 0.5);
          }
        }

        ${e.output} = result;
      }
    `;
  }
};
var MZ = {
  kernelName: sd,
  backendName: "webgl",
  kernelFunc: WZ
};
var Bo;
var Du = F().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
function WZ(n) {
  const { inputs: t, backend: e, attrs: s } = n;
  let { pixels: o } = t;
  const { numChannels: r } = s, i6 = typeof HTMLVideoElement < "u" && o instanceof HTMLVideoElement, a = typeof HTMLImageElement < "u" && o instanceof HTMLImageElement, [l, c] = i6 ? [
    o.videoWidth,
    o.videoHeight
  ] : [o.width, o.height], u = [c, l], d = [c, l, r];
  if (a || i6) {
    const m = F().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
    (Bo == null || m !== Du) && (Du = m, Bo = document.createElement("canvas").getContext("2d", { willReadFrequently: Du })), Bo.canvas.width = l, Bo.canvas.height = c, Bo.drawImage(o, 0, 0, l, c), o = Bo.canvas;
  }
  const h6 = e.makeTensorInfo(u, "int32");
  e.texData.get(h6.dataId).usage = ln.PIXELS, e.gpgpu.uploadPixelDataToTexture(e.getTexture(h6.dataId), o);
  const p6 = F().getBool("WEBGL_PACK") ? new LZ(d) : new EZ(d), f = e.runWebGLProgram(p6, [h6], "int32");
  return e.disposeData(h6.dataId), f;
}
function DZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r, bias: i6, preluActivationWeights: a } = t, { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h6, activation: p6, leakyreluAlpha: f } = s, m = ys(u), g6 = ke(o.shape, r.shape, l, d, c, h6, false, m);
  let b6;
  const x6 = [], w6 = i6 != null, y6 = a != null, I = p6 === "leakyrelu", C6 = () => {
    const S = [o, r], N = (R, M6) => {
      if (M6 === "NCHW" && R.shape.length === 1 && R.shape[0] !== 1) {
        const V = st({
          inputs: { x: R },
          backend: e,
          attrs: { shape: [R.shape[0], 1, 1] }
        });
        return x6.push(V), V;
      }
      return R;
    };
    if (w6 && S.push(N(i6, u)), y6 && S.push(N(a, u)), I) {
      const R = e.makeTensorInfo([], "float32", bs(f, "float32"));
      S.push(R), x6.push(R);
    }
    return S;
  };
  if (g6.filterHeight === 1 && g6.filterWidth === 1 && g6.dilationHeight === 1 && g6.dilationWidth === 1 && g6.strideHeight === 1 && g6.strideWidth === 1 && (g6.padInfo.type === "SAME" || g6.padInfo.type === "VALID"))
    b6 = Jw({
      x: o,
      filter: r,
      convInfo: g6,
      backend: e,
      bias: i6,
      activation: p6,
      preluActivationWeights: a,
      leakyreluAlpha: f
    });
  else if (g6.strideWidth <= 2 && m === "channelsLast" && F().getBool("WEBGL_EXP_CONV")) {
    const S = p6 ? ai(p6, true) : null, N = new Qw(g6, w6, S, y6, I), R = [
      [g6.padInfo.top, g6.padInfo.left],
      [g6.strideHeight, g6.strideWidth],
      [g6.dilationHeight, g6.dilationWidth],
      [g6.inHeight, g6.inWidth]
    ], M6 = C6();
    b6 = e.runWebGLProgram(N, M6, "float32", R);
  } else if (F().getBool("WEBGL_CONV_IM2COL"))
    b6 = jw({
      x: o,
      filter: r,
      convInfo: g6,
      backend: e,
      bias: i6,
      activation: p6,
      preluActivationWeights: a,
      leakyreluAlpha: f
    });
  else {
    const S = p6 ? ai(p6, false) : null, N = new Yw(g6, w6, S, y6, I), R = C6();
    b6 = e.runWebGLProgram(N, R, "float32");
  }
  const k7 = st({ inputs: { x: b6 }, backend: e, attrs: { shape: g6.outShape } });
  return x6.push(b6), x6.forEach((S) => e.disposeIntermediateTensorInfo(S)), k7;
}
var FZ = {
  kernelName: rl,
  backendName: "webgl",
  kernelFunc: DZ
};
function VZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r, bias: i6, preluActivationWeights: a } = t, { strides: l, pad: c, dilations: u, dimRoundingMode: d, activation: h6, leakyreluAlpha: p6 } = s, f = [];
  let m = u;
  m == null && (m = [1, 1]), v2(Ee(l, m), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${l} and dilations '${m}'`);
  const g6 = ke(
    o.shape,
    r.shape,
    l,
    m,
    c,
    d,
    true
    /* depthwise */
  ), b6 = F().getBool("WEBGL_PACK_DEPTHWISECONV") && g6.strideWidth <= 2 && g6.outChannels / g6.inChannels === 1, x6 = h6 ? ai(h6, b6) : null, w6 = [o, r], y6 = i6 != null, I = a != null, C6 = h6 === "leakyrelu";
  if (y6 && w6.push(i6), I && w6.push(a), C6) {
    const R = e.makeTensorInfo([], "float32", bs(p6, "float32"));
    w6.push(R), f.push(R);
  }
  let k7;
  b6 ? k7 = new eI(g6, y6, x6, I, C6) : k7 = new tI(g6, y6, x6, I, C6);
  const S = [
    [g6.padInfo.top, g6.padInfo.left],
    [g6.strideHeight, g6.strideWidth],
    [g6.dilationHeight, g6.dilationWidth],
    [g6.inHeight, g6.inWidth]
  ], N = e.runWebGLProgram(k7, w6, "float32", S);
  return f.forEach((R) => e.disposeIntermediateTensorInfo(R)), N;
}
var zZ = {
  kernelName: nb,
  backendName: "webgl",
  kernelFunc: VZ
};
var XZ = class {
  constructor(t, e, s, o) {
    this.sliceDim = t, this.strides = e, this.paramsShape = o, this.variableNames = ["x", "indices"], this.outputShape = s;
    const r = Kt(s.length);
    let i6 = `
    int index;`;
    for (let a = 0; a < this.sliceDim; a++)
      i6 += `
          index = round(getIndices(coords[0], ${a}));
          out_of_bounds = out_of_bounds || index < 0;
          out_of_bounds = out_of_bounds || index >= ${this.paramsShape[a]};
          flattenIndex += index * ${this.strides[a]};`;
    this.userCode = `
         void main() {
          ${r} coords = getOutputCoords();
          int flattenIndex = 0;
          bool out_of_bounds = false;

          ${i6}

          setOutput(out_of_bounds ? 0.0 : getX(flattenIndex, coords[1]));
        }
      `;
  }
};
function PZ(n) {
  const { inputs: t, backend: e } = n, { params: s, indices: o } = t, r = o.shape, i6 = r[r.length - 1], a = O(s.shape), [l, c, u, d] = Bc(s, o), h6 = st({ inputs: { x: o }, backend: e, attrs: { shape: [c, i6] } }), p6 = st({
    inputs: { x: s },
    backend: e,
    attrs: { shape: [O(s.shape) / u, u] }
  });
  if (e.shouldExecuteOnCPU([s, o]) || s.dtype === "string") {
    const b6 = e.readSync(o.dataId), x6 = e.bufferSync(s), w6 = JX(b6, x6, s.dtype, c, i6, u, d, s.shape, a);
    return e.makeTensorInfo(l, s.dtype, w6.values);
  }
  const f = new XZ(i6, d, [c, u], s.shape), m = e.runWebGLProgram(f, [p6, h6], p6.dtype), g6 = st({ inputs: { x: m }, backend: e, attrs: { shape: l } });
  return e.disposeIntermediateTensorInfo(h6), e.disposeIntermediateTensorInfo(p6), e.disposeIntermediateTensorInfo(m), g6;
}
var AZ = {
  kernelName: Hg,
  backendName: "webgl",
  kernelFunc: PZ
};
var OZ = class {
  constructor(t, e) {
    this.variableNames = ["A", "indices"], this.outputShape = e, this.rank = e.length;
    const s = Kt(this.rank), o = KZ(t);
    this.userCode = `
      void main() {
        ${s} resRC = getOutputCoords();
        int index = int(getIndices(resRC.x, resRC.z));
        float inBounds = (index >= 0) && (index < ${t[2]}) ? 1.0 : 0.0;
        setOutput(inBounds * getA(${o}));
      }
    `;
  }
};
function KZ(n, t) {
  const e = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"], s = [];
  for (let o = 0; o < n.length; o++)
    o === 2 ? s.push("index") : s.push(`${e[o]}`);
  return s.join();
}
function oI(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, indices: r } = t, { axis: i6, batchDims: a } = s, l = Ct(i6, o.shape)[0];
  if (F().get("DEBUG")) {
    const x6 = e.readSync(r.dataId), w6 = o.shape[l];
    for (let y6 = 0; y6 < x6.length; ++y6) {
      const I = x6[y6];
      v2(I <= w6 - 1 && I >= 0, () => `GatherV2: the index value ${I} is not in [0, ${w6 - 1}]`);
    }
  }
  const c = ef(o, r, l, a), u = O(r.shape), d = [], h6 = st({
    inputs: { x: o },
    backend: e,
    attrs: {
      shape: [
        c.batchSize,
        c.outerSize,
        c.dimSize,
        c.sliceSize
      ]
    }
  }), p6 = st({
    inputs: { x: r },
    backend: e,
    attrs: { shape: [c.batchSize, u / c.batchSize] }
  });
  d.push(h6), d.push(p6);
  const f = [
    c.batchSize,
    c.outerSize,
    u / c.batchSize,
    c.sliceSize
  ];
  if (e.shouldExecuteOnCPU([o, r]) || o.dtype === "string") {
    const x6 = e.bufferSync(p6), w6 = e.bufferSync(h6), y6 = jX(w6, x6, f);
    return d.forEach((I) => e.disposeIntermediateTensorInfo(I)), e.makeTensorInfo(c.outputShape, y6.dtype, y6.values);
  }
  const m = new OZ(h6.shape, f), g6 = e.runWebGLProgram(m, [h6, p6], h6.dtype);
  d.push(g6);
  const b6 = st({ inputs: { x: g6 }, backend: e, attrs: { shape: c.outputShape } });
  return d.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), b6;
}
var ZZ = {
  kernelName: ec,
  backendName: "webgl",
  kernelFunc: oI
};
var BZ = "return float(a > b);";
var HZ = `
  return vec4(greaterThan(a, b));
`;
var _Z = Ne({
  opSnippet: BZ,
  packedOpSnippet: HZ,
  cpuKernelImpl: qX,
  dtype: "bool"
});
var UZ = {
  kernelName: nc,
  backendName: "webgl",
  kernelFunc: _Z
};
var YZ = "return float(a >= b);";
var QZ = `
  return vec4(greaterThanEqual(a, b));
`;
var JZ = Ne({
  opSnippet: YZ,
  packedOpSnippet: QZ,
  dtype: "bool",
  cpuKernelImpl: tP
});
var jZ = {
  kernelName: Gi,
  backendName: "webgl",
  kernelFunc: JZ
};
function qZ(n) {
  const { inputs: t, backend: e } = n, { input: s } = t;
  return sI(s, true, e);
}
var tB = {
  kernelName: dh,
  backendName: "webgl",
  kernelFunc: qZ
};
var eB = "return float(!isnan(x) && !isinf(x));";
var nB = Nt({ opSnippet: eB, dtype: "bool" });
var sB = {
  kernelName: Li,
  backendName: "webgl",
  kernelFunc: nB
};
var oB = "return float(isinf(x));";
var rB = Nt({ opSnippet: oB, dtype: "bool" });
var iB = {
  kernelName: Mi,
  backendName: "webgl",
  kernelFunc: rB
};
var aB = "return float(isnan(x));";
var lB = Nt({ opSnippet: aB, dtype: "bool" });
var cB = {
  kernelName: Wi,
  backendName: "webgl",
  kernelFunc: lB
};
var uB = "return float(a < b);";
var dB = `
  return vec4(lessThan(a, b));
`;
var hB = Ne({
  opSnippet: uB,
  packedOpSnippet: dB,
  cpuKernelImpl: eP,
  dtype: "bool"
});
var pB = {
  kernelName: oc,
  backendName: "webgl",
  kernelFunc: hB
};
var fB = "return float(a <= b);";
var mB = `
  return vec4(lessThanEqual(a, b));
`;
var gB = Ne({
  opSnippet: fB,
  packedOpSnippet: mB,
  cpuKernelImpl: nP,
  dtype: "bool"
});
var bB = {
  kernelName: rc,
  backendName: "webgl",
  kernelFunc: gB
};
function xB(n) {
  const { backend: t, attrs: e } = n, { start: s, stop: o, num: r } = e, i6 = sP(s, o, r);
  return t.makeTensorInfo([i6.length], "float32", i6);
}
var yB = {
  kernelName: _g,
  backendName: "webgl",
  kernelFunc: xB
};
var wB = Gr + `
  return x < 0.0 ? 0./0. : log(x);
`;
var IB = `
  vec4 result = log(x);
  bvec4 isNaN = isnan(x);
  result.r = isNaN.r ? x.r : (x.r < 0.0 ? 0./0. : result.r);
  result.g = isNaN.g ? x.g : (x.g < 0.0 ? 0./0. : result.g);
  result.b = isNaN.b ? x.b : (x.b < 0.0 ? 0./0. : result.b);
  result.a = isNaN.a ? x.a : (x.a < 0.0 ? 0./0. : result.a);
  return result;
`;
var CB = Nt({ opSnippet: wB, packedOpSnippet: IB, cpuKernelImpl: oP });
var vB = {
  kernelName: Di,
  backendName: "webgl",
  kernelFunc: CB
};
var SB = Gr + `
  return log(1.0 + x);
`;
var kB = Nt({ opSnippet: SB });
var TB = {
  kernelName: Fi,
  backendName: "webgl",
  kernelFunc: kB
};
var NB = "return float(a >= 1.0 && b >= 1.0);";
var RB = `
  return vec4(
    vec4(greaterThanEqual(a, vec4(1.0))) *
    vec4(greaterThanEqual(b, vec4(1.0))));
`;
var $B = Ne({
  opSnippet: NB,
  packedOpSnippet: RB,
  dtype: "bool"
});
var GB = {
  kernelName: ic,
  backendName: "webgl",
  kernelFunc: $B
};
var EB = "return float(!(x >= 1.0));";
var LB = Nt({ opSnippet: EB });
var MB = {
  kernelName: ac,
  backendName: "webgl",
  kernelFunc: LB
};
var WB = "return float(a >= 1.0 || b >= 1.0);";
var DB = `
  return min(
    vec4(greaterThanEqual(a, vec4(1.0))) +
    vec4(greaterThanEqual(b, vec4(1.0))),
    vec4(1.0));
`;
var FB = Ne({ opSnippet: WB, packedOpSnippet: DB, dtype: "bool" });
var VB = {
  kernelName: lc,
  backendName: "webgl",
  kernelFunc: FB
};
var zB = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["x"], this.outputShape = [];
    const i6 = e, a = t[3] - 1;
    this.outputShape = t;
    let l;
    const c = `float(${s}) + float(${o}) * sum`;
    r === 0.5 ? l = `inversesqrt(${c})` : r === 1 ? l = `1.0/(${c})` : l = `exp(log(${c}) * float(-${r}));`, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];
        int d = coords[3];
        float x = getX(b, r, c, d);
        float sum = 0.0;
        for (int j = -${i6}; j <= ${i6}; j++) {
          int idx = d + j;
          if (idx >= 0 && idx <=  ${a}) {
            float z = getX(b, r, c, idx);
            sum += z * z;
          }
        }
        float val = x * ${l};
        setOutput(val);
      }
    `;
  }
};
var XB = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["x"], this.outputShape = [], this.packedInputs = true, this.packedOutput = true;
    const i6 = e, a = t[3] - 1;
    this.outputShape = t;
    let l;
    const c = `float(${s}) + float(${o}) * sum`;
    r === 0.5 ? l = `inversesqrt(${c})` : r === 1 ? l = `1.0/(${c})` : l = `exp(log(${c}) * float(-${r}));`, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords.x;
        int r = coords.y;
        int c = coords.z;
        int d = coords.w;

        bool hasNextCol = d < ${this.outputShape[3]};
        bool hasNextRow = c < ${this.outputShape[2]};

        vec4 sum = vec4(0.);
        vec4 xFragAtOutputCoords = getX(b, r, c, d);

        vec4 xAtOutputCoords = vec4(
          getChannel(xFragAtOutputCoords, vec2(c, d)),
          hasNextCol ?
            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,
          hasNextRow ?
            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,
          (hasNextRow && hasNextCol) ?
            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0
        );

        int firstChannel = d - ${i6};
        vec2 cache = vec2(0.);
        if(firstChannel >= 0){
          vec4 firstChannelFrag = getX(b, r, c, firstChannel);
          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));
            if(hasNextRow){
              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));
            }
        }

        ivec2 depth = ivec2(d, d + 1);
        for (int j = - ${i6}; j <= ${i6}; j++) {
          ivec2 idx = depth + j;
          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));
          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${a}));

          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;
          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;

          if(depthInRange || depthPlusOneInRange){
            vec4 z = vec4(0.);
            vec4 xFragAtCurrentDepth;
            z.xz = cache.xy;
            if(depthPlusOneInRange && hasNextCol){
              xFragAtCurrentDepth = idx.y != d ?
                getX(b, r, c, idx.y) : xFragAtOutputCoords;
              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));
              if(hasNextRow){
                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));
              }
            }
            cache.xy = z.yw;
            sum += z * z;
          }
        }
        vec4 result = xAtOutputCoords * ${l};
        setOutput(result);
      }
    `;
  }
};
var PB = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { depthRadius: r, bias: i6, alpha: a, beta: l } = s, c = F().getBool("WEBGL_PACK_NORMALIZATION") ? new XB(o.shape, r, i6, a, l) : new zB(o.shape, r, i6, a, l);
  return e.runWebGLProgram(c, [o], o.dtype);
};
var AB = {
  kernelName: cc,
  backendName: "webgl",
  kernelFunc: PB
};
var OB = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["inputImage", "outputImage", "dy"], this.outputShape = [], this.outputShape = t, this.depth = t[3], this.depthRadius = e, this.bias = s, this.alpha = o, this.beta = r, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];

        float result = 0.0;
        for (int d = 0; d < ${this.depth}; ++d) {
          int depthBegin = int(max(0.0, float(d - ${e})));
          int depthEnd = int(min(float(${this.depth}),
              float(d + ${e} + 1)));

          const int MIN_DEPTH_BEGIN = 0;
          const int MAX_DEPTH_END = ${this.depth};

          float norm = 0.0;
          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd) {
              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);
            }
            else {
              break;
            }
          }

          norm = float(${o}) * norm + float(${s});

          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd){
              float dyi = -2.0 * float(${o})
                * float(${r})
                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d)
                / norm;
              if (k == d) {
                dyi += pow(norm, -1.0 * ${r});
              }
              if (k == coords[3]) {
                dyi *= getDy(b, r, c, d);
                result += dyi;
              }
            }
            else {
              break;
            }
          }
      }
      setOutput(result);
      }
    `;
  }
};
var KB = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, y: r, dy: i6 } = t, { depthRadius: a, bias: l, alpha: c, beta: u } = s, d = new OB(o.shape, a, l, c, u);
  return e.runWebGLProgram(d, [o, r, i6], o.dtype);
};
var ZB = {
  kernelName: ph,
  backendName: "webgl",
  kernelFunc: KB
};
function BB(n, t, e, s) {
  const o = O(t), i6 = O(n.shape) / o, a = st({ inputs: { x: n }, attrs: { shape: [i6, o] }, backend: s }), l = Oo(a, n.dtype, "max", s), c = st({ inputs: { x: l }, attrs: { shape: e }, backend: s });
  return s.disposeIntermediateTensorInfo(a), s.disposeIntermediateTensorInfo(l), c;
}
function rI(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { reductionIndices: r, keepDims: i6 } = s, a = o.shape.length, l = Ct(r, o.shape);
  let c = l;
  const u = qt(c, a), d = u != null, h6 = e.shouldExecuteOnCPU([o]);
  let p6 = o;
  if (d) {
    if (h6) {
      const w6 = e.texData.get(p6.dataId).values, y6 = new Array(a);
      for (let k7 = 0; k7 < y6.length; k7++)
        y6[k7] = o.shape[u[k7]];
      const I = Pf(w6, o.shape, o.dtype, u, y6);
      p6 = e.makeTensorInfo(y6, o.dtype);
      const C6 = e.texData.get(p6.dataId);
      C6.values = I;
    } else
      p6 = pu(o, u, e);
    c = ie(c.length, a);
  }
  Te("max", c, a);
  const [f, m] = ye(p6.shape, c);
  let g6 = f;
  i6 && (g6 = re(f, l));
  let b6;
  if (h6) {
    const w6 = e.texData.get(p6.dataId).values, y6 = rP(w6, O(m), g6, o.dtype);
    b6 = e.makeTensorInfo(g6, o.dtype);
    const I = e.texData.get(b6.dataId);
    I.values = y6;
  } else
    b6 = BB(p6, m, g6, e);
  return d && e.disposeIntermediateTensorInfo(p6), b6;
}
var HB = {
  kernelName: uc,
  backendName: "webgl",
  kernelFunc: rI
};
var _B = Af + `
  return max(a, b);
`;
var UB = `
  vec4 result = vec4(max(a, b));
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + $a + `
  return result;
`;
var YB = Ne({
  opSnippet: _B,
  packedOpSnippet: UB,
  cpuKernelImpl: iP
});
var QB = {
  kernelName: Vi,
  backendName: "webgl",
  kernelFunc: YB
};
function JB(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  Na(o, "maxPool");
  const { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = s, c = 1;
  v2(Ee(i6, c), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${i6} and dilations '${c}'`);
  const u = $n(o.shape, r, i6, c, a, l);
  if (u.filterWidth === 1 && u.filterHeight === 1 && Rt(u.inShape, u.outShape))
    return tn({ inputs: { x: o }, backend: e });
  const d = new li(u, "max", false);
  return e.runWebGLProgram(d, [o], o.dtype);
}
var jB = {
  kernelName: dc,
  backendName: "webgl",
  kernelFunc: JB
};
function qB(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { filterSize: r, strides: i6, pad: a, dataFormat: l, dimRoundingMode: c } = s, u = [1, 1, 1], d = xs(o.shape, r, i6, u, a, c, l), h6 = new Kf(d, "max", false);
  return e.runWebGLProgram(h6, [o], o.dtype);
}
var tH = {
  kernelName: hc,
  backendName: "webgl",
  kernelFunc: qB
};
var eH = class {
  constructor(t) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = t.inShape;
    const e = t.strideHeight, s = t.strideWidth, o = t.dilationHeight, r = t.effectiveFilterHeight, i6 = t.effectiveFilterWidth, a = r - 1 - t.padInfo.top, l = i6 - 1 - t.padInfo.left, c = r * i6 - 1;
    this.userCode = `
      const ivec2 pads = ivec2(${a}, ${l});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${r};
          wR += ${o}) {
          float dyR = float(dyRCorner + wR) / ${e}.0;

          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${i6}; wC++) {
            float dyC = float(dyCCorner + wC) / ${s}.0;

            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);
            int maxPosValue = ${c} - int(getMaxPos(b, idyR, idyC, d));

            // Get the current value, check it against the value from the
            // position matrix.
            int curPosValue = wR * ${i6} + wC;
            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

            dotProd += dyValue * mask;
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var nH = class {
  constructor(t) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = t.inShape;
    const e = t.strideDepth, s = t.strideHeight, o = t.strideWidth, r = t.dilationDepth, i6 = t.dilationHeight, a = t.dilationWidth, l = t.effectiveFilterDepth, c = t.effectiveFilterHeight, u = t.effectiveFilterWidth, d = l - 1 - t.padInfo.front, h6 = c - 1 - t.padInfo.top, p6 = u - 1 - t.padInfo.left, f = l * c * u - 1;
    this.userCode = `
      const ivec3 pads = ivec3(${d}, ${h6}, ${p6});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${l};
           wD += ${r}) {
          float dyD = float(dyDCorner + wD) / ${e}.0;

          if (dyD < 0.0 || dyD >= ${t.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${c};
              wR += ${i6}) {
            float dyR = float(dyRCorner + wR) / ${s}.0;

            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${u};
                wC += ${a}) {
              float dyC = float(dyCCorner + wC) / ${o}.0;

              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);
              int maxPosValue = ${f} -
                  int(getMaxPos(batch, idyD, idyR, idyC, ch));

              // Get the current value, check it against the value from the
              // position matrix.
              int curPosValue =
                  wD * ${c} * ${u} +
                  wR * ${u} + wC;
              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

              dotProd += dyValue * mask;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
function sH(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, i6 = r, { filterSize: a, strides: l, pad: c, dimRoundingMode: u } = s, d = [1, 1, 1], h6 = xs(i6.shape, a, l, d, c, u), p6 = new Kf(
    h6,
    "max",
    true
    /* get positions */
  ), f = e.runWebGLProgram(p6, [i6], i6.dtype), m = new nH(h6), g6 = e.runWebGLProgram(m, [o, f], i6.dtype);
  return e.disposeIntermediateTensorInfo(f), g6;
}
var oH = {
  kernelName: mh,
  backendName: "webgl",
  kernelFunc: sH
};
function rH(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r, output: i6 } = t, a = r;
  Na([r, i6], "maxPoolGrad");
  const { filterSize: l, strides: c, pad: u, dimRoundingMode: d } = s, h6 = $n(a.shape, l, c, 1, u, d), p6 = true, f = new li(h6, "max", p6), m = e.runWebGLProgram(f, [a], a.dtype), g6 = new eH(h6), b6 = e.runWebGLProgram(g6, [o, m], a.dtype);
  return e.disposeIntermediateTensorInfo(m), b6;
}
var iH = {
  kernelName: fh,
  backendName: "webgl",
  kernelFunc: rH
};
function aH(n, t, e, s) {
  let o = new li(e, "max", false);
  const r = s.runWebGLProgram(o, [n], "float32");
  o = new li(e, "max", true, true, t);
  const i6 = s.runWebGLProgram(o, [n], "float32");
  return [r, i6];
}
var lH = {
  kernelName: Ug,
  backendName: "webgl",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { x: s } = n, { filterSize: o, strides: r, pad: i6, includeBatchInIndex: a } = t, l = e;
    v2(s.shape.length === 4, () => `Error in maxPool: input must be rank 4 but got rank ${s.shape.length}.`);
    const c = [1, 1];
    v2(Ee(r, c), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${r} and dilations '${c}'`);
    const u = $n(s.shape, o, r, c, i6), [d, h6] = aH(s, a, u, l);
    return [d, h6];
  }
};
function cH(n, t, e, s) {
  const o = O(t), i6 = O(n.shape) / o, a = st({ inputs: { x: n }, attrs: { shape: [i6, o] }, backend: s }), l = Oo(a, "float32", "mean", s), c = st({ inputs: { x: l }, attrs: { shape: e }, backend: s });
  return s.disposeIntermediateTensorInfo(a), s.disposeIntermediateTensorInfo(l), c;
}
var uH = {
  kernelName: pc,
  backendName: "webgl",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { x: s } = n, { keepDims: o, axis: r } = t, i6 = e, a = s.shape.length, l = Ct(r, s.shape);
    let c = l;
    const u = qt(c, a), d = u != null, h6 = i6.shouldExecuteOnCPU([s]), p6 = [];
    let f = s;
    if (d) {
      if (h6) {
        const y6 = i6.texData.get(f.dataId).values, I = new Array(a);
        for (let S = 0; S < I.length; S++)
          I[S] = s.shape[u[S]];
        const C6 = Pf(y6, s.shape, s.dtype, u, I);
        f = i6.makeTensorInfo(I, s.dtype);
        const k7 = i6.texData.get(f.dataId);
        k7.values = C6;
      } else
        f = pu(s, u, i6);
      p6.push(f), c = ie(c.length, a);
    }
    Te("sum", c, a);
    const [m, g6] = ye(f.shape, c);
    let b6 = m;
    o && (b6 = re(m, l));
    const x6 = cH(f, g6, b6, i6);
    for (const w6 of p6)
      i6.disposeIntermediateTensorInfo(w6);
    return x6;
  }
};
function dH(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = o.shape.length, l = Ct(r, o.shape);
  let c = l;
  const u = qt(c, a);
  let d = o;
  u != null && (d = Fe({ inputs: { x: o }, backend: e, attrs: { perm: u } }), c = ie(c.length, o.shape.length)), Te("min", c, a);
  const [h6, p6] = ye(d.shape, c), f = O(p6), m = st({ inputs: { x: d }, backend: e, attrs: { shape: [-1, f] } }), g6 = Oo(m, m.dtype, "min", e);
  let b6;
  if (i6) {
    const x6 = re(h6, l);
    b6 = st({ inputs: { x: g6 }, backend: e, attrs: { shape: x6 } });
  } else
    b6 = st({ inputs: { x: g6 }, backend: e, attrs: { shape: h6 } });
  return e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(g6), u != null && e.disposeIntermediateTensorInfo(d), b6;
}
var hH = {
  kernelName: fc,
  backendName: "webgl",
  kernelFunc: dH
};
var pH = Af + `
  return min(a, b);
`;
var fH = `
  vec4 result = vec4(min(a, b));
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + $a + `
  return result;
`;
var mH = Ne({
  opSnippet: pH,
  packedOpSnippet: fH,
  cpuKernelImpl: aP
});
var gH = {
  kernelName: zi,
  backendName: "webgl",
  kernelFunc: mH
};
var bH = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.outputShape = e.map(
      (u, d) => u[0] + t[d] + u[1]
      /* afterPad */
    );
    const o = t.length, r = Kt(o), i6 = e.map((u) => u[0]).join(","), a = e.map((u, d) => u[0] + t[d]).join(","), l = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, o), c = s === "reflect" ? 0 : 1;
    if (o === 1) {
      this.userCode = `
        int start = ${i6};
        int end = ${a};

        void main() {
          int outC = getOutputCoords();
          if (outC < start) {
            outC = start * 2 - outC - ${c};
          } else if(outC >= end) {
            outC = (end - 1) * 2 - outC + ${c};
          }
          setOutput(getX(outC - start));
        }
      `;
      return;
    }
    this.userCode = `
      ${r} start = ${r}(${i6});
      ${r} end = ${r}(${a});

      void main() {
        ${r} outC = getOutputCoords();
        for (int i = 0; i < ${o}; i++) {
          if (outC[i] < start[i]) {
            outC[i] = start[i] * 2 - outC[i] - ${c};
          } else if(outC[i] >= end[i]) {
            outC[i] = (end[i] - 1) * 2 - outC[i] + ${c};
          }
        }
        ${r} coords = outC - start;
        setOutput(getX(${l}));
      }
    `;
  }
};
var xH = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true, this.outputShape = e.map(
      (f, m) => f[0] + t[m] + f[1]
      /* afterPad */
    );
    const o = t.length, r = Kt(o), i6 = e.map((f) => f[0]).join(","), a = e.map((f, m) => f[0] + t[m]).join(","), l = We("rc", o), c = We("source", o), u = `${l[o - 1]} < ${this.outputShape[o - 1]}`, d = o === 1 ? "source" : `vec2(${c.slice(-2).join()})`, h6 = s === "reflect" ? 0 : 1;
    let p6 = "";
    if (o === 1) {
      const f = `
        ${r} source = rc;
        if (source < start) {
          source = start * 2 - source - ${h6};
        } else if (source >= end) {
          source = (end - 1) * 2 - source + ${h6};
        }
        source -= start;
      `;
      p6 = `
        ${r} rc = outputLoc;
        ${f}
        result[0] = getChannel(getX(${c.join()}), ${d});
        ${l[o - 1]} += 1;
        if(${u}) {
          ${f}
          result[1] = getChannel(getX(${c.join()}), ${d});
        }
      `;
    } else {
      const f = `
        ${r} source = rc;
        ${r} lt = ${r}(lessThan(source, start));
        ${r} gte = ${r}(greaterThanEqual(source, end));
        ${r} orig = 1 - (lt + gte);
        source = orig * source +
                lt * (start * 2 - source - ${h6}) +
                gte * ((end - 1) * 2 - source + ${h6});
        source -= start;
      `;
      p6 = `
        ${r} rc = outputLoc;
        ${f}
        result[0] = getChannel(getX(${c.join()}), ${d});
        ${l[o - 1]} += 1;
        if(${u}) {
          ${f}
          result[1] = getChannel(getX(${c.join()}), ${d});
        }
        rc = outputLoc;
        ${l[o - 2]} += 1;
        if(${l[o - 2]} < ${this.outputShape[o - 2]}) {
          ${f}
          result[2] = getChannel(getX(${c.join()}), ${d});
          ${l[o - 1]} += 1;
          if(${u}) {
            ${f}
            result[3] = getChannel(getX(${c.join()}), ${d});
          }
        }
      `;
    }
    this.userCode = `
      const ${r} start = ${r}(${i6});
      const ${r} end = ${r}(${a});

      void main() {
        ${r} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${p6}
        setOutput(result);
      }
    `;
  }
};
var yH = ({ inputs: n, backend: t, attrs: e }) => {
  const { x: s } = n, { paddings: o, mode: r } = e, i6 = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new xH(s.shape, o, r) : new bH(s.shape, o, r);
  return t.runWebGLProgram(i6, [s], s.dtype);
};
var wH = {
  kernelName: mc,
  backendName: "webgl",
  kernelFunc: yH
};
var IH = `if (b == 0.0) return NAN;
  return mod(a, b);`;
var CH = `
  vec4 result = mod(a, b);
  bvec4 isNaN = equal(b, vec4(0.0));
  ` + $a + `
  return result;
`;
var vH = Ne({
  opSnippet: IH,
  packedOpSnippet: CH
});
var SH = {
  kernelName: Xi,
  backendName: "webgl",
  kernelFunc: vH
};
var kH = class {
  constructor(t, e, s) {
    this.variableNames = ["probs"], this.customUniforms = [{ name: "seed", type: "float" }], this.outputShape = [t, s], this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];

        float r = random(seed);
        float cdf = 0.0;

        for (int i = 0; i < ${e - 1}; i++) {
          cdf += getProbs(batch, i);

          if (r < cdf) {
            setOutput(float(i));
            return;
          }
        }

        // If no other event happened, last event happened.
        setOutput(float(${e - 1}));
      }
    `;
  }
};
var TH = `
if (a == b) {
  return 1.0;
};
return a / b;`;
var NH = `
  // vec4 one = vec4(equal(a, b));
  // return one + (vec4(1.0) - one) * a / b;
  vec4 result = a / b;
  if(a.x == b.x) {
    result.x = 1.;
  }
  if(a.y == b.y) {
    result.y = 1.;
  }
  if(a.z == b.z) {
    result.z = 1.;
  }
  if(a.w == b.w) {
    result.w = 1.;
  }

  return result;
`;
var iI = Ne({ opSnippet: TH, packedOpSnippet: NH, checkOutOfBounds: true });
var RH = {
  kernelName: vi,
  backendName: "webgl",
  kernelFunc: iI
};
var yg = "return a - b;";
var aI = Ne({
  opSnippet: yg,
  packedOpSnippet: yg,
  supportsComplex: true,
  cpuKernelImpl: NP
});
var $H = {
  kernelName: ea,
  backendName: "webgl",
  kernelFunc: aI
};
function lI(n) {
  const { inputs: t, backend: e, attrs: s } = n, { logits: o } = t, { dim: r } = s, i6 = Ct([r], o.shape), a = rI({
    inputs: { x: o },
    backend: e,
    attrs: { reductionIndices: i6, keepDims: false }
  }), l = re(a.shape, i6), c = st({ inputs: { x: a }, backend: e, attrs: { shape: l } }), u = aI({ inputs: { a: o, b: c }, backend: e }), d = nI({ inputs: { x: u }, backend: e }), h6 = fu({ inputs: { x: d }, backend: e, attrs: { axis: i6, keepDims: false } }), p6 = st({ inputs: { x: h6 }, backend: e, attrs: { shape: l } }), f = iI({ inputs: { a: d, b: p6 }, backend: e });
  return e.disposeIntermediateTensorInfo(a), e.disposeIntermediateTensorInfo(c), e.disposeIntermediateTensorInfo(u), e.disposeIntermediateTensorInfo(d), e.disposeIntermediateTensorInfo(h6), e.disposeIntermediateTensorInfo(p6), f;
}
var GH = {
  kernelName: Mc,
  backendName: "webgl",
  kernelFunc: lI
};
function EH(n) {
  const { inputs: t, backend: e, attrs: s } = n, { logits: o } = t, { numSamples: r, seed: i6, normalized: a } = s, l = a ? o : lI({ inputs: { logits: o }, backend: e, attrs: { dim: o.shape.length - 1 } }), c = l.shape[0], u = l.shape[1], d = new kH(c, u, r), h6 = [[i6]], p6 = e.runWebGLProgram(d, [l], "int32", h6);
  return a || e.disposeIntermediateTensorInfo(l), p6;
}
var LH = {
  kernelName: Yg,
  backendName: "webgl",
  kernelFunc: EH
};
var MH = En + `
  return -x;
`;
var WH = `
  vec4 result = -x;
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
function DH(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (e.shouldExecuteOnCPU([s])) {
    const r = e.texData.get(s.dataId), [i6, a] = cP(r.values, s.shape, s.dtype);
    return e.makeTensorInfo(a, s.dtype, i6);
  }
  let o;
  return F().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? o = new Ls(s.shape, WH) : o = new qn(s.shape, MH), e.runWebGLProgram(o, [s], s.dtype);
}
var FH = {
  kernelName: gc,
  backendName: "webgl",
  kernelFunc: DH
};
var VH = Tp;
function zH(n) {
  rn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l } = s, c = e.readSync(o.dataId), u = e.readSync(r.dataId), { selectedIndices: d } = VH(c, u, i6, a, l);
  return e.makeTensorInfo([d.length], "int32", new Int32Array(d));
}
var XH = {
  kernelName: gh,
  backendName: "webgl",
  kernelFunc: zH
};
var PH = Np;
function AH(n) {
  rn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l, padToMaxOutputSize: c } = s, u = e.readSync(o.dataId), d = e.readSync(r.dataId), { selectedIndices: h6, validOutputs: p6 } = PH(u, d, i6, a, l, c);
  return [
    e.makeTensorInfo([h6.length], "int32", new Int32Array(h6)),
    e.makeTensorInfo([], "int32", new Int32Array([p6]))
  ];
}
var OH = {
  kernelName: bh,
  backendName: "webgl",
  kernelFunc: AH
};
var KH = Rp;
function ZH(n) {
  rn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l, softNmsSigma: c } = s, u = e.readSync(o.dataId), d = e.readSync(r.dataId), h6 = i6, p6 = a, f = l, m = c, { selectedIndices: g6, selectedScores: b6 } = KH(u, d, h6, p6, f, m);
  return [
    e.makeTensorInfo([g6.length], "int32", new Int32Array(g6)),
    e.makeTensorInfo([b6.length], "float32", new Float32Array(b6))
  ];
}
var BH = {
  kernelName: xh,
  backendName: "webgl",
  kernelFunc: ZH
};
var HH = class {
  constructor(t, e, s, o) {
    this.variableNames = ["indices"], this.outputShape = [t, e], this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int index = round(getIndices(coords.x));
        setOutput(mix(float(${o}), float(${s}),
                      float(index == coords.y)));
      }
    `;
  }
};
var _H = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { indices: o } = t, { dtype: r, depth: i6, onValue: a, offValue: l } = s, c = O(o.shape), u = new HH(c, i6, a, l), d = st({ inputs: { x: o }, backend: e, attrs: { shape: [c] } }), h6 = e.runWebGLProgram(u, [d], r);
  e.disposeIntermediateTensorInfo(d);
  const p6 = [...o.shape, i6], f = st({ inputs: { x: h6 }, backend: e, attrs: { shape: p6 } });
  return e.disposeIntermediateTensorInfo(h6), f;
};
var UH = {
  kernelName: yc,
  backendName: "webgl",
  kernelFunc: _H
};
function Ll(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (s.dtype === "complex64") {
    const o = Ea({ inputs: { input: s }, backend: e }), r = Ll({ inputs: { x: o }, backend: e }), i6 = mu({ inputs: { input: s }, backend: e }), a = Ll({ inputs: { x: i6 }, backend: e }), l = js({ inputs: { real: r, imag: a }, backend: e });
    return e.disposeIntermediateTensorInfo(o), e.disposeIntermediateTensorInfo(r), e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(a), l;
  } else
    return La({
      attrs: {
        shape: s.shape,
        dtype: s.dtype,
        value: s.dtype === "string" ? "" : 0
      },
      backend: e
    });
}
var YH = {
  kernelName: Fc,
  backendName: "webgl",
  kernelFunc: Ll
};
function cI(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (s.dtype === "string")
    throw new Error("onesLike is not supported under string dtype");
  if (s.dtype === "complex64") {
    const o = Ea({ inputs: { input: s }, backend: e }), r = cI({ inputs: { x: o }, backend: e }), i6 = mu({ inputs: { input: s }, backend: e }), a = Ll({ inputs: { x: i6 }, backend: e }), l = js({ inputs: { real: r, imag: a }, backend: e });
    return e.disposeIntermediateTensorInfo(o), e.disposeIntermediateTensorInfo(r), e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(a), l;
  } else
    return La({ attrs: { shape: s.shape, dtype: s.dtype, value: 1 }, backend: e });
}
var QH = {
  kernelName: xc,
  backendName: "webgl",
  kernelFunc: cI
};
function JH(n) {
  const { inputs: t, backend: e, attrs: s } = n, { axis: o } = s;
  if (t.length === 1)
    return Fd({ inputs: { input: t[0] }, backend: e, attrs: { dim: o } });
  const r = t[0].shape, i6 = t[0].dtype;
  t.forEach((u) => {
    Ve(r, u.shape, "All tensors passed to stack must have matching shapes"), v2(i6 === u.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const a = [], l = t.map((u) => {
    const d = Fd({ inputs: { input: u }, backend: e, attrs: { dim: o } });
    return a.push(d), d;
  }), c = Uw({ inputs: l, backend: e, attrs: { axis: o } });
  return a.forEach((u) => e.disposeIntermediateTensorInfo(u)), c;
}
var jH = {
  kernelName: wc,
  backendName: "webgl",
  kernelFunc: JH
};
var qH = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.customUniforms = [{ name: "value", type: "float" }], this.outputShape = e.map(
      (c, u) => c[0] + t[u] + c[1]
      /* afterPad */
    );
    const o = t.length, r = Kt(o), i6 = e.map((c) => c[0]).join(","), a = e.map((c, u) => c[0] + t[u]).join(","), l = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, o);
    if (o === 1) {
      this.userCode = `
        int start = ${i6};
        int end = ${a};

        void main() {
          int outC = getOutputCoords();
          if (outC < start || outC >= end) {
            setOutput(value);
          } else {
            setOutput(getX(outC - start));
          }
        }
      `;
      return;
    }
    this.userCode = `
      ${r} start = ${r}(${i6});
      ${r} end = ${r}(${a});

      void main() {
        ${r} outC = getOutputCoords();
        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {
          setOutput(value);
        } else {
          ${r} coords = outC - start;
          setOutput(getX(${l}));
        }
      }
    `;
  }
};
var t9 = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "value", type: "float" }], this.outputShape = e.map(
      (m, g6) => m[0] + t[g6] + m[1]
      /* afterPad */
    );
    const o = t.length, r = Kt(o), i6 = e.map((m) => m[0]).join(","), a = e.map((m, g6) => m[0] + t[g6]).join(","), l = We("rc", o), c = We("source", o), u = `${l[o - 1]} < ${this.outputShape[o - 1]}`, d = o === 1 ? "source" : `vec2(${c.slice(-2).join()})`, h6 = [
      `${r} rc = outputLoc;`,
      `${l[o - 1]} += 1;
       if(${u}) {
      `,
      o === 1 ? "" : `}
       rc = outputLoc;
       ${l[o - 2]} += 1;
       if(${l[o - 2]} < ${this.outputShape[o - 2]}) {`,
      o === 1 ? "" : `  ${l[o - 1]} += 1;
         if(${u}) {`
    ], p6 = o === 1 ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
    let f = "";
    for (let m = 0, g6 = o === 1 ? 2 : 4; m < g6; m++)
      f += `
        ${h6[m]}
        if (${p6}) {
          result[${m}] = float(value);
        } else {
          ${r} source = rc - start;
          result[${m}] = getChannel(getX(${c.join()}), ${d});
        }
      `;
    f += o === 1 ? "} " : "}}", this.userCode = `
      const ${r} start = ${r}(${i6});
      const ${r} end = ${r}(${a});

      void main() {
        ${r} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${f}
        setOutput(result);
      }
    `;
  }
};
var uI = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { paddings: r, constantValue: i6 } = s;
  if (O(o.shape) === 0) {
    const c = r.map(
      (u, d) => u[0] + o.shape[d] + u[1]
      /* afterPad */
    );
    return La({
      backend: e,
      attrs: { shape: c, value: i6, dtype: o.dtype }
    });
  }
  const a = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new t9(o.shape, r, i6) : new qH(o.shape, r, i6), l = [[i6]];
  return e.runWebGLProgram(a, [o], o.dtype, l);
};
var e9 = {
  kernelName: Ic,
  backendName: "webgl",
  kernelFunc: uI
};
var n9 = `
  if(a < 0.0 && floor(b) < b){
    return NAN;
  }
  if (b == 0.0) {
    return 1.0;
  }
  return (round(mod(b, 2.0)) != 1) ?
      pow(abs(a), b) : sign(a) * pow(abs(a), b);
`;
var s9 = `
  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.
  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));
  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);
  vec4 result = multiplier * pow(abs(a), b);

  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS
  bvec4 isExpZero = equal(b, vec4(0.0));
  result.r = isExpZero.r ? 1.0 : result.r;
  result.g = isExpZero.g ? 1.0 : result.g;
  result.b = isExpZero.b ? 1.0 : result.b;
  result.a = isExpZero.a ? 1.0 : result.a;

  bvec4 isNaN1 = lessThan(a, vec4(0.0));
  bvec4 isNaN2 = lessThan(floor(b), b);
  bvec4 isNaN = bvec4(isNaN1.x && isNaN2.x, isNaN1.y && isNaN2.y, isNaN1.z && isNaN2.z, isNaN1.w && isNaN2.w);
  ` + $a + `
  return result;
`;
var o9 = Ne({ opSnippet: n9, packedOpSnippet: s9 });
var r9 = {
  kernelName: Ai,
  backendName: "webgl",
  kernelFunc: o9
};
function i9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = o.shape.length, l = [], c = Ct(r, o.shape);
  let u = c;
  const d = qt(u, a);
  let h6 = o;
  d != null && (h6 = Fe({ inputs: { x: o }, backend: e, attrs: { perm: d } }), u = ie(u.length, a), l.push(h6)), Te("prod", u, a);
  let p6;
  if (e.shouldExecuteOnCPU([h6])) {
    const f = e.texData.get(h6.dataId).values, { outVals: m, outShape: g6, outDtype: b6 } = dP(h6.shape, h6.dtype, f, u);
    p6 = e.makeTensorInfo(g6, b6, m);
  } else {
    const [f, m] = ye(h6.shape, u), g6 = O(m), b6 = st({ inputs: { x: h6 }, backend: e, attrs: { shape: [-1, g6] } }), x6 = zh(o.dtype), w6 = Oo(b6, x6, "prod", e);
    p6 = st({ inputs: { x: w6 }, backend: e, attrs: { shape: f } }), l.push(b6), l.push(w6);
  }
  if (i6) {
    l.push(p6);
    const f = re(p6.shape, c);
    p6 = st({ inputs: { x: p6 }, backend: e, attrs: { shape: f } });
  }
  return l.forEach((f) => e.disposeIntermediateTensorInfo(f)), p6;
}
var a9 = {
  kernelName: vc,
  backendName: "webgl",
  kernelFunc: i9
};
function l9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { paramsNestedSplits: o, paramsDenseValues: r, indices: i6 } = t, { outputRaggedRank: a } = s, l = o.map((b6) => e.readSync(b6.dataId)), c = o.map((b6) => b6.shape), u = e.readSync(r.dataId), d = e.readSync(i6.dataId), [h6, p6, f] = hP(l, c, u, r.shape, r.dtype, d, i6.shape, a), m = h6.map((b6) => e.makeTensorInfo([b6.length], "int32", b6)), g6 = e.makeTensorInfo(f, r.dtype, p6);
  return m.concat([g6]);
}
var c9 = {
  kernelName: Qg,
  backendName: "webgl",
  kernelFunc: l9
};
function u9(n) {
  const { inputs: t, backend: e } = n, { starts: s, limits: o, deltas: r } = t, i6 = e.readSync(s.dataId), a = e.readSync(o.dataId), l = e.readSync(r.dataId), [c, u] = pP(i6, s.shape, s.dtype, a, o.shape, l, r.shape), d = e.makeTensorInfo([c.length], "int32", c), h6 = e.makeTensorInfo([u.length], s.dtype, u);
  return [d, h6];
}
var d9 = {
  kernelName: Jg,
  backendName: "webgl",
  kernelFunc: u9
};
function h9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { shape: o, values: r, defaultValue: i6, rowPartitionTensors: a } = t, { rowPartitionTypes: l } = s, c = e.readSync(o.dataId), u = e.readSync(r.dataId), d = e.readSync(i6.dataId), h6 = a.map((g6) => e.readSync(g6.dataId)), p6 = a.map((g6) => g6.shape), [f, m] = fP(c, o.shape, u, r.shape, r.dtype, d, i6.shape, h6, p6, l);
  return e.makeTensorInfo(f, r.dtype, m);
}
var p9 = {
  kernelName: jg,
  backendName: "webgl",
  kernelFunc: h9
};
var dI = (n) => {
  const { backend: t, attrs: e } = n, { start: s, stop: o, step: r, dtype: i6 } = e, a = mP(s, o, r, i6);
  return t.makeTensorInfo([a.length], i6, a);
};
var f9 = {
  kernelName: yh,
  backendName: "webgl",
  kernelFunc: dI
};
var m9 = "return 1.0 / x;";
var g9 = Nt({ opSnippet: m9 });
var b9 = {
  kernelName: Oi,
  backendName: "webgl",
  kernelFunc: g9
};
var x9 = En + `
  return (x < 0.0) ? 0.0 : x;
`;
var y9 = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var w9 = Nt({ opSnippet: x9, packedOpSnippet: y9 });
var I9 = {
  kernelName: Ki,
  backendName: "webgl",
  kernelFunc: w9
};
var C9 = En + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
var v9 = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var S9 = Nt({ opSnippet: C9, packedOpSnippet: v9 });
var k9 = {
  kernelName: Zi,
  backendName: "webgl",
  kernelFunc: S9
};
var T9 = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["A"], this.outputShape = [];
    const [i6, a, l, c] = t;
    this.outputShape = [i6, e, s, c];
    const u = [
      o && e > 1 ? a - 1 : a,
      o && s > 1 ? l - 1 : l
    ], d = [
      o && e > 1 ? e - 1 : e,
      o && s > 1 ? s - 1 : s
    ];
    let h6;
    r ? h6 = "(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)" : h6 = "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${u[0] / d[0]},
          ${u[1] / d[1]});
      const vec2 inputShapeRC = vec2(${a}.0, ${l}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${h6};

        // Compute the four integer indices.
        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));
        ivec2 sourceCeilRC = ivec2(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);
        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);
        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);
        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);

        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);

        float top = topLeft + (topRight - topLeft) * fracRC.y;
        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;
        float newValue = top + (bottom - top) * fracRC.x;

        setOutput(newValue);
      }
    `;
  }
};
var N9 = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = [];
    const [i6, a, l, c] = t;
    this.outputShape = [i6, e, s, c];
    const u = [
      o && e > 1 ? a - 1 : a,
      o && s > 1 ? l - 1 : l
    ], d = [
      o && e > 1 ? e - 1 : e,
      o && s > 1 ? s - 1 : s
    ];
    let h6;
    r ? h6 = "(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)" : h6 = "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${u[0] / d[0]},
          ${u[1] / d[1]},
          ${u[1] / d[1]});
      const vec3 inputShapeRC = vec3(${a}.0, ${l}.0,
                                     ${l}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${h6};

        // Compute the four integer indices.
        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));
        ivec3 sourceCeilRC = ivec3(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${c - 1};
        bool hasNextRow = coords.z < ${s - 1};

        // In parallel, construct four corners for all four components in
        // packed 2x2 cell.
        vec4 topLeft = vec4(
          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 bottomLeft = vec4(
          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 topRight = vec4(
          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec4 bottomRight = vec4(
          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);

        vec4 top = mix(topLeft, topRight, fracRC.yyzz);
        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);
        vec4 newValue = mix(top, bottom, fracRC.x);

        setOutput(newValue);
      }
    `;
  }
};
function R9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o } = t, { alignCorners: r, halfPixelCenters: i6, size: a } = s, [l, c] = a, u = F().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new N9(o.shape, l, c, r, i6) : new T9(o.shape, l, c, r, i6);
  return e.runWebGLProgram(u, [o], "float32");
}
var $9 = {
  kernelName: Tc,
  backendName: "webgl",
  kernelFunc: R9
};
var G9 = class {
  constructor(t, e, s) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = e;
    const [, o, r] = e, [, i6, a] = t, l = [
      s && i6 > 1 ? o - 1 : o,
      s && a > 1 ? r - 1 : r
    ], c = [
      s && i6 > 1 ? i6 - 1 : i6,
      s && a > 1 ? a - 1 : a
    ], u = l[0] / c[0], d = l[1] / c[1], h6 = 1 / u, p6 = 1 / d, f = Math.ceil(h6) * 2 + 2, m = Math.ceil(p6) * 2 + 2;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${u});
        const float widthScale = float(${d});

        const float invHeightScale = float(${h6});
        const float invWidthScale = float(${p6});

        const int winHeight = int(${f});
        const int winWidth = int(${m});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(startRLerp - float(winHeight / 2));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(startCLerp - float(winWidth / 2));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${i6}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${a}) {
              continue;
            }

            float dxR = float(dyR) * heightScale;
            int topDxRIndex = int(floor(dxR));
            int bottomDxRIndex = int(min(ceil(dxR), ${o - 1}.0));
            float dxRLerp = dxR - float(topDxRIndex);
            float inverseDxRLerp = 1.0 - dxRLerp;

            float dxC = float(dyC) * widthScale;
            int leftDxCIndex = int(floor(dxC));
            int rightDxCIndex = int(min(ceil(dxC), ${r - 1}.0));
            float dxCLerp = dxC - float(leftDxCIndex);
            float inverseDxCLerp = 1.0 - dxCLerp;

            if (r == topDxRIndex && c == leftDxCIndex) {
              // topLeft
              accumulator +=
                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;
            }

            if (r == topDxRIndex && c == rightDxCIndex) {
              // topRight
              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;
            }

            if (r == bottomDxRIndex && c == leftDxCIndex) {
              // bottomLeft
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;
            }

            if (r == bottomDxRIndex && c == rightDxCIndex) {
              // bottomRight
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
  }
};
function E9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o, dy: r } = t, { alignCorners: i6 } = s, a = new G9(r.shape, o.shape, i6);
  return e.runWebGLProgram(a, [r], r.dtype);
}
var L9 = {
  kernelName: Ch,
  backendName: "webgl",
  kernelFunc: E9
};
var M9 = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["A"], this.outputShape = [];
    const [i6, a, l, c] = t;
    this.outputShape = [i6, e, s, c];
    const u = [
      o && e > 1 ? a - 1 : a,
      o && s > 1 ? l - 1 : l
    ], d = [
      o && e > 1 ? e - 1 : e,
      o && s > 1 ? s - 1 : s
    ], h6 = o ? "0.5" : "0.0";
    let p6;
    r ? p6 = "max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))" : p6 = "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${u[0] / d[0]},
          ${u[1] / d[1]});
      const vec2 inputShapeRC = vec2(${a}.0, ${l}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${p6};

        // Compute the coordinators of nearest neighbor point.
        ivec2 sourceNearestRC = ivec2(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${h6})));
        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);

        setOutput(newValue);
      }
    `;
  }
};
var W9 = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = [];
    const [i6, a, l, c] = t;
    this.outputShape = [i6, e, s, c];
    const u = [
      o && e > 1 ? a - 1 : a,
      o && s > 1 ? l - 1 : l
    ], d = [
      o && e > 1 ? e - 1 : e,
      o && s > 1 ? s - 1 : s
    ], h6 = o ? "0.5" : "0.0";
    let p6;
    r ? p6 = "max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))" : p6 = "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${u[0] / d[0]},
          ${u[1] / d[1]},
          ${u[1] / d[1]});
      const vec3 inputShapeRC = vec3(${a}.0, ${l}.0,
                                     ${l}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${p6};

        // Compute the coordinators of nearest neighbor point.
        ivec3 sourceNearestRC = ivec3(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${h6})));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${c - 1};
        bool hasNextRow = coords.z < ${s - 1};

        vec4 newValue = vec4(
          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),
          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);

        setOutput(newValue);
      }
    `;
  }
};
function D9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o } = t, { alignCorners: r, halfPixelCenters: i6, size: a } = s, [l, c] = a, u = F().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new W9(o.shape, l, c, r, i6) : new M9(o.shape, l, c, r, i6);
  return e.runWebGLProgram(u, [o], o.dtype);
}
var F9 = {
  kernelName: kc,
  backendName: "webgl",
  kernelFunc: D9
};
var V9 = class {
  constructor(t, e, s) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = e;
    const [, o, r] = e, [, i6, a] = t, l = [
      s && i6 > 1 ? o - 1 : o,
      s && a > 1 ? r - 1 : r
    ], c = [
      s && i6 > 1 ? i6 - 1 : i6,
      s && a > 1 ? a - 1 : a
    ], u = l[0] / c[0], d = l[1] / c[1], h6 = 1 / u, p6 = 1 / d, f = Math.ceil(h6) * 2 + 2, m = Math.ceil(p6) * 2 + 2;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${u});
        const float widthScale = float(${d});

        const float invHeightScale = float(${h6});
        const float invWidthScale = float(${p6});

        const int winHeight = int(${f});
        const int winWidth = int(${m});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(floor(startRLerp - float(winHeight / 2)));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(floor(startCLerp - float(winWidth / 2)));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${i6}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${a}) {
              continue;
            }

            float sourceFracRow =
              float(${l[0]}) *
                (float(dyR) / float(${c[0]}));

            float sourceFracCol =
                float(${l[1]}) *
                  (float(dyC) / float(${c[1]}));

            int sourceNearestRow = int(min(
                float(int(${o}) - 1),
                ${s} ? float(round(sourceFracRow)) :
                                  float(floor(sourceFracRow))));

            int sourceNearestCol = int(min(
                float(int(${r}) - 1),
                ${s} ? float(round(sourceFracCol)) :
                                  float(floor(sourceFracCol))));

            if (r == sourceNearestRow && c == sourceNearestCol) {
              accumulator += getDy(b, dyR, dyC, d);
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
  }
};
function z9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o, dy: r } = t, { alignCorners: i6 } = s, a = new V9(r.shape, o.shape, i6);
  return e.runWebGLProgram(a, [r], r.dtype);
}
var X9 = {
  kernelName: Ih,
  backendName: "webgl",
  kernelFunc: z9
};
var P9 = class {
  constructor(t, e) {
    this.variableNames = ["x"];
    const s = t.length;
    if (s > 4)
      throw new Error(`WebGL backend: Reverse of rank-${s} tensor is not yet supported`);
    if (this.outputShape = t, s === 1) {
      this.userCode = `
        void main() {
          int coord = getOutputCoords();
          setOutput(getX(${t[0]} - coord - 1));
        }
      `;
      return;
    }
    const o = (a) => e.indexOf(a) !== -1 && t[a] !== 1 ? `${t[a]} - coords[${a}] - 1` : `coords[${a}]`, r = t.map((a, l) => o(l)).join(","), i6 = Kt(s);
    this.userCode = `
      void main() {
        ${i6} coords = getOutputCoords();
        setOutput(getX(${r}));
      }
    `;
  }
};
var A9 = class {
  constructor(t, e) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true;
    const s = t.length;
    if (s > 4)
      throw new Error(`WebGL backend: Reverse of rank-${s} tensor is not yet supported`);
    this.outputShape = t;
    const o = We("rc", s), r = `${o[s - 1]} + 1 < ${this.outputShape[s - 1]}`, i6 = `${o[s - 2]} + 1 < ${this.outputShape[s - 2]}`, a = Kt(s);
    s === 1 ? this.userCode = `
        void main(){
          int rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = getChannel(getX(${t[0]} - rc - 1),
            ${t[0]} - rc - 1);
          if(${r}){
              result.g = getChannel(getX(${t[0]} - (rc  + 1) - 1),
                ${t[0]} - (rc  + 1) - 1);
          }
          setOutput(result);
        }
      ` : this.userCode = `
        void main() {
          ${a} rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = ${l(o.slice())};
          if(${r}){
            result.g = ${c(o.slice())};
          }
          if(${i6}) {
            result.b = ${u(o.slice())};
            if(${r}) {
              result.a = ${d(o.slice())};
            }
          }
          setOutput(result);
        }
    `;
    function l(f) {
      return h6(f);
    }
    function c(f) {
      return f[s - 1] = "(" + f[s - 1] + " + 1)", h6(f);
    }
    function u(f) {
      return f[s - 2] = "(" + f[s - 2] + " + 1)", h6(f);
    }
    function d(f) {
      return f[s - 1] = "(" + f[s - 1] + " + 1)", f[s - 2] = "(" + f[s - 2] + " + 1)", h6(f);
    }
    function h6(f) {
      const m = t.map((x6, w6) => p6(w6, f)), g6 = m.join(","), b6 = m.slice(-2).join(",");
      return `getChannel(getX(${g6}), vec2(${b6}))`;
    }
    function p6(f, m) {
      return e.indexOf(f) !== -1 && t[f] !== 1 ? `${t[f]} - ${m[f]} - 1` : `${m[f]}`;
    }
  }
};
function O9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { dims: r } = s, i6 = o.shape.length, a = Ct(r, o.shape);
  if (i6 === 0)
    return tn({ inputs: { x: o }, backend: e });
  const l = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new A9(o.shape, a) : new P9(o.shape, a);
  return e.runWebGLProgram(l, [o], o.dtype);
}
var K9 = {
  kernelName: Nc,
  backendName: "webgl",
  kernelFunc: O9
};
var Z9 = class {
  constructor(t, e) {
    this.variableNames = ["Image"], this.outputShape = [], this.customUniforms = [{ name: "params", type: "vec4" }];
    const s = t[1], o = t[2];
    this.outputShape = t;
    let r = "";
    typeof e == "number" ? r = `float outputValue = ${e.toFixed(2)};` : r = `
        vec3 fill = vec3(${e.join(",")});
        float outputValue = fill[coords[3]];`, this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];
          int y = coords[1];
          float coordXFloat = (float(x) - params[0]) * params[3] -
            (float(y) - params[1]) * params[2];
          float coordYFloat = (float(x) - params[0]) * params[2] +
            (float(y) - params[1]) * params[3];
          int coordX = int(round(coordXFloat + params[0]));
          int coordY = int(round(coordYFloat + params[1]));
          ${r}
          if(coordX >= 0 && coordX < ${o} && coordY >= 0 && coordY < ${s}) {
            outputValue = getImage(coords[0], coordY, coordX, coords[3]);
          }
          setOutput(outputValue);
        }
    `;
  }
};
var B9 = {
  kernelName: Dh,
  backendName: "webgl",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { image: s } = n, { radians: o, fillValue: r, center: i6 } = t, a = e, l = new Z9(s.shape, r), [c, u] = Xp(i6, s.shape[1], s.shape[2]), d = [[c, u, Math.sin(o), Math.cos(o)]];
    return a.runWebGLProgram(l, [s], s.dtype, d);
  }
};
var H9 = `
  // OpenGL ES does not support round function.
  // The algorithm is based on banker's rounding.
  float base = floor(x);
  if ((x - base) < 0.5) {
    return floor(x);
  } else if ((x - base) > 0.5) {
    return ceil(x);
  } else {
    if (mod(base, 2.0) == 0.0) {
      return base;
    } else {
      return base + 1.0;
    }
  }
`;
var _9 = Nt({ opSnippet: H9 });
var U9 = {
  kernelName: Bi,
  backendName: "webgl",
  kernelFunc: _9
};
var Y9 = "return inversesqrt(x);";
var Q9 = Nt({ opSnippet: Y9, cpuKernelImpl: gP });
var J9 = {
  kernelName: Hi,
  backendName: "webgl",
  kernelFunc: Q9
};
var hI = class {
  constructor(t, e, s, o, r, i6, a = true) {
    this.variableNames = ["updates", "indices", "defaultValue"], this.outputShape = i6;
    const l = Kt(r.length), c = Kt(i6.length);
    let u = "";
    s === 1 ? u = "i" : s === 2 && (u = "i, j");
    const d = `getIndices(${u})`;
    let h6 = "";
    o === 1 ? h6 = "i" : o === 2 && (h6 = "i, coords[1]");
    const p6 = `getUpdates(${h6})`, f = e > 1 ? "strides[j]" : "strides";
    this.userCode = `
        ${l} strides = ${l}(${r});

        void main() {
          ${c} coords = getOutputCoords();
          float sum = 0.0;
          bool found = false;
          for (int i = 0; i < ${t}; i++) {
            int flattenedIndex = 0;
            for (int j = 0; j < ${e}; j++) {
              int index = round(${d});
              flattenedIndex += index * ${f};
            }
            if (flattenedIndex == coords[0]) {
              sum += ${p6};
              found = true;
            }
          }
          setOutput(mix(getDefaultValue(), sum, float(found)));
        }
      `;
  }
};
function j9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { indices: o, updates: r } = t, { shape: i6 } = s, { sliceRank: a, numUpdates: l, sliceSize: c, strides: u, outputSize: d } = Ir(r, o, i6), h6 = [d / c, c];
  if (d === 0)
    return e.makeTensorInfo(i6, o.dtype);
  const p6 = st({ inputs: { x: o }, backend: e, attrs: { shape: [l, a] } }), f = st({ inputs: { x: r }, backend: e, attrs: { shape: [l, c] } }), m = e.makeTensorInfo([], "float32", new Float32Array([0])), g6 = new hI(l, a, p6.shape.length, f.shape.length, u, h6), b6 = e.runWebGLProgram(g6, [f, p6, m], f.dtype), x6 = st({ inputs: { x: b6 }, backend: e, attrs: { shape: i6 } });
  return e.disposeIntermediateTensorInfo(p6), e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(b6), e.disposeIntermediateTensorInfo(m), x6;
}
var q9 = {
  kernelName: qg,
  backendName: "webgl",
  kernelFunc: j9
};
var t_ = class {
  constructor(t, e, s, o) {
    this.variableNames = ["sortedSequence", "values"], this.customUniforms = [{ name: "numInputs", type: "int" }], this.outputShape = [t, s];
    const r = "while (left < right) {", i6 = `for (int i = 0; i < ${Math.ceil(Math.log2(e + 1))}; ++i) { if (left >= right) break;`, a = F().getNumber("WEBGL_VERSION") === 2 ? r : i6, l = o === "left" ? "<" : "<=";
    this.userCode = `
       int findBound(int batch, float value) {
         int left = 0;
         int right = numInputs;
         int mid;
         ${a}
           mid = (left + right) / 2;
           if (getSortedSequence(batch, mid) ${l} value) {
             left = mid + 1;
           } else {
             right = mid;
           }
         }
         return right;
       }

       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int valueIndex = coords[1];

         float value = getValues(batch, valueIndex);

         setOutput(float(findBound(batch, value)));
       }
     `;
  }
};
function e_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { sortedSequence: o, values: r } = t, { side: i6 } = s, a = new t_(o.shape[0], o.shape[1], r.shape[1], i6), l = [[o.shape[1]]];
  return e.runWebGLProgram(a, [o, r], "int32", l);
}
var n_ = {
  kernelName: tb,
  backendName: "webgl",
  kernelFunc: e_
};
var s_ = class {
  constructor(t, e, s) {
    this.variableNames = ["c", "a", "b"], this.outputShape = e;
    let o, r;
    if (s > 4)
      throw Error(`Where for rank ${s} is not yet supported`);
    if (s === 1)
      r = "resRC", o = "resRC";
    else {
      const a = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"], l = [], c = [];
      for (let u = 0; u < e.length; u++)
        c.push(`${a[u]}`), u < t && l.push(`${a[u]}`);
      o = l.join(), r = c.join();
    }
    const i6 = Kt(s);
    this.userCode = `
      void main() {
        ${i6} resRC = getOutputCoords();
        float cVal = getC(${o});
        if (cVal >= 1.0) {
          setOutput(getA(${r}));
        } else {
          setOutput(getB(${r}));
        }
      }
    `;
  }
};
function o_(n) {
  const { inputs: t, backend: e } = n, { condition: s, t: o, e: r } = t, i6 = new s_(s.shape.length, o.shape, o.shape.length);
  return e.runWebGLProgram(i6, [s, o, r], je(o.dtype, r.dtype));
}
var r_ = {
  kernelName: Rc,
  backendName: "webgl",
  kernelFunc: o_
};
var i_ = `
  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.
  // see: https://arxiv.org/abs/1706.02515
  float scaleAlpha = ${Yc};
  float scale = ${Qc};
  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);
`;
var a_ = Nt({ opSnippet: i_ });
var l_ = {
  kernelName: _i,
  backendName: "webgl",
  kernelFunc: a_
};
var c_ = Gr + `
  return 1.0 / (1.0 + exp(-1.0 * x));
`;
var u_ = `
  vec4 result = 1.0 / (1.0 + exp(-1.0 * x));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var d_ = Nt({
  opSnippet: c_,
  packedOpSnippet: u_,
  cpuKernelImpl: xP
});
var h_ = {
  kernelName: Ji,
  backendName: "webgl",
  kernelFunc: d_
};
var p_ = `
  if (isnan(x)) { return 0.0; }
  return sign(x);
`;
var f_ = Nt({ opSnippet: p_ });
var m_ = {
  kernelName: Qi,
  backendName: "webgl",
  kernelFunc: f_
};
var g_ = Gr + `
  return sin(x);
`;
var b_ = Nt({ opSnippet: g_ });
var x_ = {
  kernelName: Ui,
  backendName: "webgl",
  kernelFunc: b_
};
var y_ = `
  float e2x = exp(x);
  return (e2x - 1.0 / e2x) / 2.0;
`;
var w_ = Nt({ opSnippet: y_ });
var I_ = {
  kernelName: Yi,
  backendName: "webgl",
  kernelFunc: w_
};
var C_ = `
  float epsilon = 1.1920928955078125e-7;
  float threshold = log(epsilon) + 2.0;

  bool too_large = x > -threshold;
  bool too_small = x < threshold;

  float result;
  float exp_x = exp(x);

  if (too_large){
    result = x;
  }
  else if (too_small){
    result = exp_x;
  }
  else{
    result = log(exp_x + 1.0);
  }
  return result;
`;
var v_ = Nt({ opSnippet: C_ });
var S_ = {
  kernelName: ji,
  backendName: "webgl",
  kernelFunc: v_
};
var k_ = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockShape: r, paddings: i6 } = s;
  v2(o.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");
  const a = r.reduce((b6, x6) => b6 * x6), l = [[0, 0]];
  l.push(...i6);
  for (let b6 = 1 + r.length; b6 < o.shape.length; ++b6)
    l.push([0, 0]);
  const c = [], u = uI({
    inputs: { x: o },
    backend: e,
    attrs: { paddings: l, constantValue: 0 }
  }), d = fa(u.shape, r, a, false), h6 = ma(d.length, r.length, false), p6 = ga(u.shape, r, a, false), f = st({ inputs: { x: u }, backend: e, attrs: { shape: d } }), m = Fe({
    inputs: { x: f },
    backend: e,
    attrs: { perm: h6 }
  }), g6 = st({ inputs: { x: m }, backend: e, attrs: { shape: p6 } });
  return c.push(u), c.push(f), c.push(m), c.forEach((b6) => e.disposeIntermediateTensorInfo(b6)), g6;
};
var T_ = {
  kernelName: Ec,
  backendName: "webgl",
  kernelFunc: k_
};
function N_(n) {
  const { inputs: t, backend: e } = n, { indices: s, values: o, denseShape: r, defaultValue: i6 } = t;
  if (r.shape.length !== 1)
    throw new Error(`Dense shape must be a vector, saw:
         ${r.shape}`);
  if (s.shape.length !== 2)
    throw new Error(`Indices must be a matrix, saw:
         ${s.shape}`);
  if (o.shape.length !== 1)
    throw new Error(`Values must be a vector, saw:
         ${o.shape}`);
  if (i6.shape.length !== 0)
    throw new Error(`Default value must be a scalar, saw:
        ${i6.shape}`);
  const a = e.readSync(s.dataId), l = e.readSync(o.dataId), c = e.readSync(r.dataId), u = e.readSync(i6.dataId)[0], [d, h6, p6, f, m] = wP(a, s.shape, s.dtype, l, o.dtype, c, u);
  return [
    e.makeTensorInfo(h6, s.dtype, d),
    e.makeTensorInfo([h6[0]], o.dtype, p6),
    e.makeTensorInfo([f.length], "bool", new Uint8Array(f.map((g6) => Number(g6)))),
    e.makeTensorInfo([m.length], s.dtype, new Int32Array(m))
  ];
}
var R_ = {
  kernelName: vh,
  backendName: "webgl",
  kernelFunc: N_
};
function $_(n) {
  const { inputs: t, backend: e } = n, { inputIndices: s, inputShape: o, newShape: r } = t;
  if (s.shape.length !== 2)
    throw new Error(`Input indices should be a matrix but received shape ${s.shape}`);
  if (o.shape.length !== 1)
    throw new Error(`Input shape should be a vector but received shape ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Target shape should be a vector but received shape ${r.shape}`);
  const i6 = Array.from(e.readSync(o.dataId)), a = e.readSync(s.dataId), l = Array.from(e.readSync(r.dataId)), [c, u, d] = IP(a, s.shape, s.dtype, i6, l);
  return [
    e.makeTensorInfo(u, s.dtype, c),
    e.makeTensorInfo([d.length], r.dtype, new Int32Array(d))
  ];
}
var G_ = {
  kernelName: Sh,
  backendName: "webgl",
  kernelFunc: $_
};
function E_(n) {
  const { inputs: t, backend: e } = n, { data: s, indices: o, segmentIds: r } = t;
  if (s.shape.length < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.shape.length !== 1)
    throw new Error(`Indices should be a vector but received shape
              ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Segment ids should be a vector but received shape
              ${r.shape}`);
  const i6 = e.readSync(s.dataId), a = e.readSync(o.dataId), l = e.readSync(r.dataId), [c, u] = Dw(i6, s.shape, s.dtype, a, l, true);
  return e.makeTensorInfo(u, s.dtype, c);
}
var L_ = {
  kernelName: kh,
  backendName: "webgl",
  kernelFunc: E_
};
function M_(n) {
  const { inputs: t, backend: e } = n, { data: s, indices: o, segmentIds: r } = t;
  if (s.shape.length < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.shape.length !== 1)
    throw new Error(`Indices should be a vector but received shape
             ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Segment ids should be a vector but received shape
             ${r.shape}`);
  const i6 = e.readSync(s.dataId), a = e.readSync(o.dataId), l = e.readSync(r.dataId), [c, u] = Dw(i6, s.shape, s.dtype, a, l);
  return e.makeTensorInfo(u, s.dtype, c);
}
var W_ = {
  kernelName: Th,
  backendName: "webgl",
  kernelFunc: M_
};
function D_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { sparseIndices: o, sparseValues: r, defaultValue: i6 } = t, { outputShape: a } = s, { sliceRank: l, numUpdates: c, sliceSize: u, strides: d, outputSize: h6 } = Ir(r, o, a), p6 = false;
  if (r.dtype === "string") {
    const b6 = e.bufferSync(o), x6 = e.bufferSync(r), w6 = ps(e.readSync(i6.dataId)[0]), y6 = bP(b6, x6, a, h6, u, c, l, d, w6, p6);
    return e.makeTensorInfo(a, y6.dtype, y6.values);
  }
  const f = new hI(c, l, o.shape.length, r.shape.length, d, [h6, 1], p6), m = e.runWebGLProgram(f, [r, o, i6], r.dtype), g6 = st({ inputs: { x: m }, backend: e, attrs: { shape: a } });
  return e.disposeIntermediateTensorInfo(m), g6;
}
var F_ = {
  kernelName: eb,
  backendName: "webgl",
  kernelFunc: D_
};
function V_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { numOrSizeSplits: r, axis: i6 } = s, a = Ct(i6, o.shape)[0], l = tf(o, r, a), c = o.shape.length, u = new Array(c).fill(0), d = o.shape.slice();
  return l.map((h6) => {
    const p6 = [...d];
    p6[a] = h6;
    const f = Er({ inputs: { x: o }, backend: e, attrs: { begin: u, size: p6 } });
    return u[a] += h6, f;
  });
}
var z_ = {
  kernelName: Lc,
  backendName: "webgl",
  kernelFunc: V_
};
var wg = "return sqrt(x);";
var X_ = Nt({ opSnippet: wg, packedOpSnippet: wg, cpuKernelImpl: CP });
var P_ = {
  kernelName: qi,
  backendName: "webgl",
  kernelFunc: X_
};
var A_ = "return x * x;";
var O_ = Nt({ opSnippet: A_ });
var K_ = {
  kernelName: Nh,
  backendName: "webgl",
  kernelFunc: O_
};
var Ig = "return (a - b) * (a - b);";
var Z_ = Ne({ opSnippet: Ig, packedOpSnippet: Ig });
var B_ = {
  kernelName: ta,
  backendName: "webgl",
  kernelFunc: Z_
};
function H_({ inputs: n, attrs: t, backend: e }) {
  const { x: s } = n, o = En + `
    return x > 0.0 ? 1.0 : float(${t.alpha});
  `, r = new qn(s.shape, o);
  return e.runWebGLProgram(r, [s], s.dtype);
}
var __ = {
  kernelName: ra,
  backendName: "webgl",
  kernelFunc: H_
};
var U_ = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.outputShape = s;
    const o = s.length, r = Kt(s.length), i6 = Kt(s.length);
    let a = "";
    if (o === 1)
      a = "coords * strides + begin";
    else {
      let l = 0;
      a = s.map((c, u) => (l++, s.length === 1 ? `coords * strides[${u}] + begin[${u}]` : `coords[${l - 1}] * strides[${u}] + begin[${u}]`)).join(",");
    }
    this.userCode = `
      ${r} begin = ${r}(${t});
      ${r} strides = ${r}(${e});

      void main() {
        ${i6} coords = getOutputCoords();
        setOutput(getX(${a}));
      }
    `;
  }
};
function Y_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { begin: r, end: i6, strides: a, beginMask: l, endMask: c, ellipsisMask: u, newAxisMask: d, shrinkAxisMask: h6 } = s, { finalShapeSparse: p6, finalShape: f, isIdentity: m, sliceDim0: g6, isSimpleSlice: b6, begin: x6, end: w6, strides: y6 } = Fp(o.shape, r, i6, a, l, c, u, d, h6);
  let I;
  if (m)
    I = st({ inputs: { x: o }, backend: e, attrs: { shape: f } });
  else if (g6 || b6) {
    v2(o.shape.length >= 1, () => `Input must have rank at least 1, got: ${o.shape.length}`);
    const k7 = Mp(x6, w6, y6), S = Er({ inputs: { x: o }, backend: e, attrs: { begin: x6, size: k7 } });
    I = st({ inputs: { x: S }, backend: e, attrs: { shape: f } }), e.disposeIntermediateTensorInfo(S);
  } else if (e.shouldExecuteOnCPU([o])) {
    const S = e.readSync(o.dataId), N = vt(o.shape, o.dtype, S), R = vP(p6, N, y6, x6);
    I = e.makeTensorInfo(f, o.dtype, R.values);
  } else {
    const S = new U_(x6, y6, p6);
    I = e.runWebGLProgram(S, [o], o.dtype);
  }
  const C6 = st({ inputs: { x: I }, backend: e, attrs: { shape: f } });
  return e.disposeIntermediateTensorInfo(I), C6;
}
var Q_ = {
  kernelName: Rh,
  backendName: "webgl",
  kernelFunc: Y_
};
function J_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { separator: o, nGramWidths: r, leftPad: i6, rightPad: a, padWidth: l, preserveShortSequences: c } = s, { data: u, dataSplits: d } = t, h6 = e.readSync(u.dataId), p6 = e.readSync(d.dataId), [f, m] = SP(h6, p6, o, r, i6, a, l, c);
  return [
    e.makeTensorInfo([f.length], "string", f),
    e.makeTensorInfo(d.shape, "int32", m)
  ];
}
var j_ = {
  kernelName: $h,
  backendName: "webgl",
  kernelFunc: J_
};
function q_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { skipEmpty: o } = s, { input: r, delimiter: i6 } = t;
  if (r.dtype !== "string")
    throw new Error("Input must be of datatype string");
  if (r.shape.length !== 1)
    throw new Error(`Input must be a vector, got shape: ${r.shape}`);
  if (i6.shape.length !== 0)
    throw new Error(`Delimiter must be a scalar, got shape: ${i6.shape}`);
  const a = e.readSync(r.dataId), l = e.readSync(i6.dataId)[0], [c, u, d] = kP(a, l, o), h6 = u.length;
  return [
    e.makeTensorInfo([h6, 2], "int32", c),
    e.makeTensorInfo([h6], "string", u),
    e.makeTensorInfo([2], "int32", new Int32Array(d))
  ];
}
var tU = {
  kernelName: Gh,
  backendName: "webgl",
  kernelFunc: q_
};
function eU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { numBuckets: o } = s, { input: r } = t;
  if (r.dtype !== "string")
    throw new Error("Input must be of datatype string");
  if (o <= 0)
    throw new Error("Number of buckets must be at least 1");
  const i6 = e.readSync(r.dataId), a = TP(i6, o);
  return e.makeTensorInfo(r.shape, "int32", a);
}
var nU = {
  kernelName: Eh,
  backendName: "webgl",
  kernelFunc: eU
};
var sU = "return tan(x);";
var oU = Nt({ opSnippet: sU });
var rU = {
  kernelName: na,
  backendName: "webgl",
  kernelFunc: oU
};
var iU = `
  float e2x = exp(-2.0 * abs(x));
  return sign(x) * (1.0 - e2x) / (1.0 + e2x);
`;
var aU = Nt({ opSnippet: iU });
var lU = {
  kernelName: sa,
  backendName: "webgl",
  kernelFunc: aU
};
var cU = class {
  constructor(t, e) {
    this.variableNames = ["A"];
    const s = new Array(t.length);
    for (let i6 = 0; i6 < s.length; i6++)
      s[i6] = t[i6] * e[i6];
    this.outputShape = s, this.rank = s.length;
    const o = Kt(this.rank), r = uU(t);
    this.userCode = `
      void main() {
        ${o} resRC = getOutputCoords();
        setOutput(getA(${r}));
      }
    `;
  }
};
function uU(n) {
  const t = n.length;
  if (t > 5)
    throw Error(`Tile for rank ${t} is not yet supported`);
  if (t === 1)
    return `imod(resRC, ${n[0]})`;
  const e = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"], s = [];
  for (let o = 0; o < n.length; o++)
    s.push(`imod(${e[o]}, ${n[o]})`);
  return s.join();
}
function pI(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { reps: r } = s;
  if (o.dtype === "string" || o.shape.length > 5) {
    const l = e.readSync(o.dataId), c = o.dtype === "string" ? l.map((h6) => ps(h6)) : l, u = vt(o.shape, o.dtype, c), d = RP(u, r);
    return e.makeTensorInfo(d.shape, d.dtype, d.values);
  }
  const i6 = new cU(o.shape, r);
  return e.runWebGLProgram(i6, [o], o.dtype);
}
var dU = {
  kernelName: oa,
  backendName: "webgl",
  kernelFunc: pI
};
var hU = class {
  /**
   * @param shape desired output shape (can be larger than input shape, output
   *                                    will be padded with -Infinity)
   */
  constructor(t) {
    this.variableNames = ["x", "indices"], this.customUniforms = [
      { name: "n", type: "int" },
      { name: "firstPass", type: "int" },
      { name: "negativeInf", type: "float" },
      { name: "dir", type: "int" },
      { name: "inc", type: "int" }
    ], this.outputShape = t, this.userCode = `
       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // We compare elements pair-wise within a group of size 2 * inc.
         // The comparing rule for each group alternates between ascending
         // and descending. Within each group, we compare each pair at
         // positions i and i+inc. To decide whether an element at position i
         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than
         // inc, it is in the first half of the group, we denote it as x0,
         // otherwise we denote it as x1.
         // For example, as shown in the Bitonic top K paper referenced above,
         // Figure5(a) shows that element[1] is in the
         // second half of the group when group size is 2, but it is in the
         // first half of the group when group size is 4.

         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;
         int i = isFirstInPair ? elemIdx : elemIdx - inc;

         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));
         float x0 = i0 < n ? getX(batch, i0) : negativeInf;
         float x1 = i1 < n ? getX(batch, i1) : negativeInf;

         // Denotes which direction indices are in (ascending or descending).
         bool reverse = imod(elemIdx, 2 * dir) >= dir;
         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);
         if (reverse == isGreater) { // Elements in opposite order of direction
           int iTemp = i0;
           i0 = i1;
           i1 = iTemp;
         }
         if (isFirstInPair) {
            setOutput(float(i0));
         } else {
            setOutput(float(i1));
         }
       }
     `;
  }
};
var pU = class {
  /**
   * @param shape desired output shape (must be half of the input size)
   */
  constructor(t) {
    this.variableNames = ["x", "indices"], this.customUniforms = [
      { name: "n", type: "int" },
      { name: "firstPass", type: "int" },
      { name: "k", type: "int" }
    ], this.outputShape = t, this.userCode = `
    void main() {
         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // The output size is half of the previous size.
         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),
         // we only need to output the indices at positions |, the indices at
         // positions _ can be thrown away, see Figure5(b) After Phase 2
         // (Merge phase) in the Bitonic Top K paper referenced above.
         // For example, the paper shows we only need to output the orange bars.
         // The output sequence should look like this | | | | | | | |.
         // Because the sequence is halved, to map the output index back
         // to the previous sequence to find the corresponding value,
         // we need to double the index. When we double the index,
         // we basically interpolate a position, so 2i looks like
         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position
         // of each 2k positions by - elemIdx % k. E.g. for output at
         // index 4,5,6,7, we want to get the corresponding element at
         // original index 8,9,10,11, for output at index 8,9,10,11,
         // we want to get the corresponding element at original index
         // 16,17,18,19, so on and so forth.

         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));
         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));

         float x0 = getX(batch, i0);
         float x1 = i1 < n ? getX(batch, i1) : x0;

         setOutput(x0 >= x1 ? float(i0) : float(i1));
       }
     `;
  }
};
function no(n, t) {
  t !== null && n.disposeIntermediateTensorInfo(t);
}
function Cg(n) {
  let t = 1;
  for (; t < n; )
    t *= 2;
  return t;
}
function fU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { k: r, sorted: i6 } = s, a = F().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"), l = F().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"), c = o.shape, u = c[c.length - 1];
  if (e.shouldExecuteOnCPU([o]) || u < a || r > l) {
    const R = e.readSync(o.dataId), [M6, V] = $P(R, c, o.dtype, r, i6);
    return [
      e.makeTensorInfo(M6.shape, M6.dtype, M6.values),
      e.makeTensorInfo(V.shape, V.dtype, V.values)
    ];
  }
  if (r === 0)
    return c[c.length - 1] = 0, [
      e.makeTensorInfo(c, o.dtype, []),
      e.makeTensorInfo(c, "int32", [])
    ];
  if (u === 1)
    return [
      o,
      La({ attrs: { shape: c, dtype: "int32", value: 0 }, backend: e })
    ];
  const d = e.texData.get(o.dataId), h6 = d !== null && d.isPacked, p6 = h6 ? e.unpackTensor(o) : o, m = O(c) / u, g6 = st({ inputs: { x: p6 }, attrs: { shape: [m, u] }, backend: e });
  h6 && no(e, p6);
  const b6 = Cg(r), x6 = Cg(u);
  let w6 = null;
  const y6 = () => w6 === null ? [g6, g6] : [g6, w6], I = (R, M6, V) => {
    const z = y6(), X = new hU(V), A6 = [[u], [w6 === null ? 1 : 0], [Number.NEGATIVE_INFINITY], [R], [M6]], B6 = w6;
    w6 = e.runWebGLProgram(X, z, "int32", A6), no(e, B6);
  };
  for (let R = 1; R < b6; R *= 2) {
    const M6 = R * 2;
    for (let V = R; V >= 1; V /= 2)
      I(M6, V, [m, x6]);
  }
  for (let R = x6; R > b6; R /= 2) {
    const M6 = y6(), V = new pU([m, R / 2]), X = [[u], [w6 === null ? 1 : 0], [b6]], P6 = w6;
    w6 = e.runWebGLProgram(V, M6, "int32", X), no(e, P6);
    const A6 = b6 / 2, B6 = A6 * 2;
    for (let Z = A6; Z >= 1; Z /= 2)
      I(B6, Z, w6.shape);
  }
  let C6 = w6;
  w6 = Er({ inputs: { x: w6 }, backend: e, attrs: { begin: 0, size: [m, r] } }), no(e, C6);
  let k7 = oI({ inputs: { x: g6, indices: w6 }, backend: e, attrs: { axis: 1, batchDims: 1 } });
  no(e, g6);
  const S = c.slice(0, -1);
  S.push(r), C6 = w6, w6 = st({ inputs: { x: w6 }, attrs: { shape: S }, backend: e }), no(e, C6);
  const N = k7;
  return k7 = st({ inputs: { x: k7 }, attrs: { shape: S }, backend: e }), no(e, N), [k7, w6];
}
var mU = {
  kernelName: Lh,
  backendName: "webgl",
  kernelFunc: fU
};
var gU = class {
  constructor(t, e, s, o, r, i6) {
    this.variableNames = ["Image", "Transforms"], this.outputShape = i6;
    const a = s === "nearest" ? 1 : 2;
    let l;
    switch (o) {
      case "constant":
        l = 1;
        break;
      case "reflect":
        l = 2;
        break;
      case "wrap":
        l = 3;
        break;
      case "nearest":
        l = 4;
        break;
      default:
        l = 1;
        break;
    }
    this.userCode = `
            float mapCoord(float outCoord, float len) {
              float inCoord = outCoord;
              if(${l} == 2) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    if (inCoord < sz2) {
                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +
                      inCoord;
                    }
                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    inCoord -= sz2 * float(int(float(inCoord / sz2)));
                    if (inCoord >= len) {
                      inCoord = sz2 - inCoord - 1.0;
                    }
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${l} == 3) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord -= len * float(int(float(inCoord / sz)));
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${l} == 4) {
                return clamp(outCoord, 0.0, len - 1.0);
              } else {
                return outCoord;
              }
            }

            float readWithFillValue(int batch, int coordY, int coordX,
              int channel) {
              float outputValue;
              if (0 <= coordY && coordY < ${t} && 0 <= coordX && coordX < ${e}) {
                  outputValue = getImage(batch, coordY, coordX, channel);
              } else {
                outputValue = float(${r});
              }
              return outputValue;
            }

            void main() {
              ivec4 coords = getOutputCoords();
              float outputValue;
              int batch = coords[0];
              int x = coords[2];
              int y = coords[1];
              int channel = coords[3];
              float xf = float(x);
              float yf = float(y);
              float a1 = getTransforms(batch, 0);
              float a2 = getTransforms(batch, 1);
              float a3 = getTransforms(batch, 2);
              float b1 = getTransforms(batch, 3);
              float b2 = getTransforms(batch, 4);
              float b3 = getTransforms(batch, 5);
              float c1 = getTransforms(batch, 6);
              float c2 = getTransforms(batch, 7);
              float projection = c1 * xf + c2 * yf + 1.0;
              if (projection == 0.0) {
                outputValue = float(${r});
              } else {
                float inX = (a1 * xf + a2 * yf + a3) / projection;
                float inY = (b1 * xf + b2 * yf + b3) / projection;
                float mapX = mapCoord(inX, float(${e}));
                float mapY = mapCoord(inY, float(${t}));

                if (${a} == 1) {
                  int coordY = int(round(mapY));
                  int coordX = int(round(mapX));
                  outputValue = readWithFillValue(batch, coordY, coordX,
                    channel);
                } else {
                  float yFloor = floor(mapY);
                  float xFloor = floor(mapX);
                  float yCeil = yFloor + 1.0;
                  float xCeil = xFloor + 1.0;
                  float valueYFloor = (xCeil - mapX) *
                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);
                  float valueYCeil = (xCeil - mapX) *
                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);
                  outputValue = (yCeil - mapY) * valueYFloor +
                  (mapY - yFloor) * valueYCeil;
                }
              }
              setOutput(outputValue);
            }
        `;
  }
};
function bU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { image: o, transforms: r } = t, { interpolation: i6, fillMode: a, fillValue: l, outputShape: c } = s, [u, d, h6, p6] = o.shape, [f, m] = c ?? [d, h6], g6 = [
    u,
    f,
    m,
    p6
  ], b6 = new gU(d, h6, i6, a, l, g6);
  return e.runWebGLProgram(b6, [o, r], "float32");
}
var xU = {
  kernelName: Mh,
  backendName: "webgl",
  kernelFunc: bU
};
function yU(n) {
  const { inputs: t, attrs: e, backend: s } = n, { axis: o } = e, { x: r } = t;
  Na(r, "unique"), console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
  const i6 = s.readSync(r.dataId), { outputValues: a, outputShape: l, indices: c } = GP(i6, o, r.shape, r.dtype);
  return [
    s.makeTensorInfo(l, r.dtype, a),
    s.makeTensorInfo([c.length], "int32", c)
  ];
}
var wU = {
  kernelName: Wh,
  backendName: "webgl",
  kernelFunc: yU
};
function IU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { value: o } = t;
  let { axis: r } = s;
  r < 0 && (r += o.shape.length);
  const i6 = o, a = i6.shape.length, l = o.shape[r], c = new Array(a - 1);
  let u = 0;
  for (let m = 0; m < a; m++)
    m !== r && (c[u++] = i6.shape[m]);
  const d = [], h6 = new Array(a).fill(0), p6 = i6.shape.slice();
  p6[r] = 1;
  const f = new Array(l);
  for (let m = 0; m < f.length; m++) {
    h6[r] = m;
    const g6 = Er({ inputs: { x: i6 }, backend: e, attrs: { begin: h6, size: p6 } }), b6 = st({ inputs: { x: g6 }, backend: e, attrs: { shape: c } });
    f[m] = b6, d.push(g6);
  }
  return d.forEach((m) => e.disposeIntermediateTensorInfo(m)), f;
}
var CU = {
  kernelName: Wc,
  backendName: "webgl",
  kernelFunc: IU
};
var vU = class {
  constructor(t, e) {
    this.variableNames = ["x", "segmentIds"];
    const s = t.windowSize, o = t.batchSize, r = t.inSize, i6 = t.numSegments, a = i6 * Math.ceil(r / s);
    this.outputShape = [o, a];
    const l = "0.0", c = "sumValue", u = Math.floor(s / 4) * 4, d = s % 4, h6 = `
        sumValue += dot(values, segFilter);
    `;
    let p6 = "";
    r % s > 0 && (p6 = `
        if (inIdx < 0 || inIdx >= ${r}) {
          return initializationValue;
        }
      `);
    let f = "";
    r % s > 0 && (f = `
        if (inIdx < 0 || inIdx >= ${r}) {
          return -1.0;
        }
      `), this.userCode = `
      const float initializationValue = ${l};

      float getValue(int batch, int inIdx) {
        ${p6}
        return getX(batch, inIdx);
      }

      float getSegmentIdAtIndex(int inIdx) {
        ${f}
        return getSegmentIds(inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = int(floor(float(outIdx) / float(
          ${i6})) * float(${s}));
        int currentSeg = int(mod(float(outIdx), float(${i6})));

        float sumValue = 0.0;

        for (int i = 0; i < ${u}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0
          );

          ${h6}
        }

        int inIdx = inOffset + ${u};
        if (${d === 1}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            0,
            0,
            0
          );

          ${h6}
        } else if (${d === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
              0,
              0
          );

          ${h6}
        } else if (${d === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            0
          );

          ${h6}
        }
        setOutput(${c});
      }
    `;
  }
};
function SU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, segmentIds: r } = t, { numSegments: i6 } = s, a = o.shape.length, l = [];
  let c = 0;
  const u = qt([c], a);
  let d = o;
  u != null && (d = Fe({ inputs: { x: o }, backend: e, attrs: { perm: u } }), l.push(d), c = ie(1, a)[0]);
  const h6 = U0(d.shape, c, i6), p6 = O([d.shape[c]]), f = st({ inputs: { x: d }, backend: e, attrs: { shape: [-1, p6] } });
  l.push(f);
  const m = zh(o.dtype), g6 = (y6, I, C6, k7, S) => {
    const N = y6.shape[0], R = y6.shape[1], M6 = _0(R, S), V = { windowSize: M6, inSize: R, batchSize: N, numSegments: S }, z = new vU(V, I), X = e.compileAndRun(z, [y6, C6], k7);
    if (l.push(X), X.shape[1] === S)
      return X;
    const P6 = dI({
      backend: e,
      attrs: { start: 0, stop: S, step: 1, dtype: "float32" }
    }), A6 = pI({
      inputs: { x: P6 },
      backend: e,
      attrs: { reps: [R / M6] }
    });
    return l.push(P6), l.push(A6), g6(X, I, A6, k7, S);
  }, b6 = g6(f, "unsortedSegmentSum", r, m, i6), x6 = st({ inputs: { x: b6 }, backend: e, attrs: { shape: h6 } });
  let w6 = x6;
  if (u != null) {
    l.push(x6);
    const y6 = Hs(u);
    w6 = Fe({ inputs: { x: w6 }, backend: e, attrs: { perm: y6 } });
  }
  return l.forEach((y6) => e.disposeIntermediateTensorInfo(y6)), w6;
}
var kU = {
  kernelName: Dc,
  backendName: "webgl",
  kernelFunc: SU
};
var TU = [
  IA,
  vA,
  TA,
  $A,
  EA,
  WA,
  FA,
  zA,
  OA,
  ZA,
  _A,
  QA,
  qA,
  sO,
  iO,
  lO,
  uO,
  fO,
  gO,
  xO,
  CO,
  $O,
  EO,
  MO,
  XO,
  AO,
  BO,
  oA,
  UO,
  qO,
  sK,
  cK,
  dK,
  pK,
  mK,
  bK,
  wK,
  vK,
  TK,
  RK,
  GK,
  LK,
  DK,
  VK,
  AK,
  KK,
  HK,
  YK,
  JK,
  eZ,
  rZ,
  cZ,
  hZ,
  mZ,
  gZ,
  xZ,
  wZ,
  CZ,
  SZ,
  TZ,
  GZ,
  MZ,
  FZ,
  zZ,
  AZ,
  ZZ,
  UZ,
  jZ,
  sA,
  tB,
  JO,
  sB,
  iB,
  cB,
  iA,
  pB,
  bB,
  yB,
  vB,
  TB,
  GB,
  MB,
  VB,
  AB,
  ZB,
  HB,
  QB,
  jB,
  tH,
  oH,
  iH,
  lH,
  uH,
  hH,
  gH,
  wH,
  SH,
  LH,
  cA,
  FH,
  XH,
  OH,
  BH,
  DO,
  UH,
  QH,
  jH,
  e9,
  r9,
  lA,
  a9,
  c9,
  d9,
  p9,
  f9,
  FO,
  RH,
  b9,
  I9,
  k9,
  dA,
  $9,
  L9,
  F9,
  X9,
  K9,
  B9,
  U9,
  J9,
  q9,
  n_,
  r_,
  l_,
  h_,
  m_,
  x_,
  I_,
  NO,
  GH,
  S_,
  T_,
  R_,
  G_,
  L_,
  W_,
  F_,
  z_,
  P_,
  K_,
  B_,
  __,
  Q_,
  j_,
  tU,
  nU,
  $H,
  xA,
  rU,
  lU,
  dU,
  mU,
  xU,
  yA,
  wU,
  CU,
  kU,
  YH
];
for (const n of TU)
  en(n);
var fI = "(function(){"use strict";class Wt{constructor(n=[],e=Qt){if(this.data=n,this.length=this.data.length,this.compare=e,this.length>0)for(let t=(this.length>>1)-1;t>=0;t--)this._down(t)}push(n){this.data.push(n),this.length++,this._up(this.length-1)}pop(){if(this.length===0)return;const n=this.data[0],e=this.data.pop();return this.length--,this.length>0&&(this.data[0]=e,this._down(0)),n}peek(){return this.data[0]}_up(n){const{data:e,compare:t}=this,s=e[n];for(;n>0;){const r=n-1>>1,i=e[r];if(t(s,i)>=0)break;e[n]=i,n=r}e[n]=s}_down(n){const{data:e,compare:t}=this,s=this.length>>1,r=e[n];for(;n<s;){let i=(n<<1)+1,h=e[i];const l=i+1;if(l<this.length&&t(e[l],h)<0&&(i=l,h=e[l]),t(h,r)>=0)break;e[n]=h,n=i}e[n]=r}}function Qt(o,n){return o<n?-1:o>n?1:0}const yt=o=>{const{v1:n,v2:e}=o;let t=0;for(let s=0;s<n.length;s++){let r=(n[s]^e[s])>>>0;t+=Zt(r)}return t},Zt=o=>{var n=o-(o>>1&1431655765);return n=(n>>2&858993459)+(n&858993459),n=(n>>4)+n&252645135,n=(n>>8)+n&16711935,n=(n>>16)+n&65535,n},ct=1,vt=o=>{const{keywidth:n,keyheight:e,querywidth:t,queryheight:s,matches:r}=o,i=t*1.2,h=-i,l=s*1.2,u=-l,f=12,g=10,a=-1,j=1,y=1/Math.log(10),m=Math.max(n,e),M=Math.floor(n/2),T=Math.floor(e/2),E=[];for(let N=0;N<r.length;N++){const $=r[N].querypoint.scale,K=r[N].keypoint.scale;K==0&&console.log("ERROR divide zero");const v=$/K;E.push(v*m)}E.sort((N,$)=>N-$);const R=.25*E[Math.floor(E.length/2)-(E.length%2==0?1:0)-1],q=Math.max(5,Math.ceil((i-h)/R)),I=Math.max(5,Math.ceil((l-u)/R)),z=q*I,B=z*f,c=[],p=[],S={};for(let N=0;N<r.length;N++){const $=r[N].querypoint,K=r[N].keypoint,{x:v,y:V,scale:L,angle:C}=xt({querypoint:$,keypoint:K,keycenterX:M,keycenterY:T,scaleOneOverLogK:y});if(v<h||v>=i||V<u||V>=l||C<=-Math.PI||C>Math.PI||L<a||L>=j){c[N]=!1;continue}let X=q*(v-h)/(i-h),wt=I*(V-u)/(l-u),pt=f*(C+Math.PI)/(2*Math.PI),dt=g*(L-a)/(j-a);p[N]={binX:X,binY:wt,binAngle:pt,binScale:dt};let it=Math.floor(X-.5),lt=Math.floor(wt-.5),ht=Math.floor(dt-.5),jt=(Math.floor(pt-.5)+f)%f;if(it<0||it+1>=q||lt<0||lt+1>=I||ht<0||ht+1>=g){c[N]=!1;continue}for(let ut=0;ut<2;ut++){let kt=it+ut;for(let bt=0;bt<2;bt++){let un=lt+bt;for(let It=0;It<2;It++){let cn=(jt+It)%f;for(let Rt=0;Rt<2;Rt++){let fn=ht+Rt;const Nt=kt+un*q+cn*z+fn*B;S[Nt]===void 0&&(S[Nt]=0),S[Nt]+=1}}}}c[N]=!0}let d=0,D=-1;if(Object.keys(S).forEach(N=>{S[N]>d&&(d=S[N],D=N)}),d<3)return[];const U=Math.floor(D%B%z%q),F=Math.floor((D-U)%B%z/q),P=Math.floor((D-U-F*q)%B/z),Y=Math.floor((D-U-F*q-P*z)/B),G=[];for(let N=0;N<r.length;N++){if(!c[N])continue;const $=p[N];if(Math.abs($.binX-(U+.5))>=ct||Math.abs($.binY-(F+.5))>=ct||Math.abs($.binScale-(Y+.5))>=ct)continue;const L=Math.abs($.binAngle-(P+.5));Math.min(L,f-L)>=ct||G.push(r[N])}return G},xt=({querypoint:o,keypoint:n,keycenterX:e,keycenterY:t,scaleOneOverLogK:s})=>{let r=o.angle-n.angle;r<=-Math.PI?r+=2*Math.PI:r>Math.PI&&(r-=2*Math.PI);const i=o.scale/n.scale,h=i*Math.cos(r),l=i*Math.sin(r),u=[h,-l,l,h],f=[u[0]*n.x+u[1]*n.y,u[2]*n.x+u[3]*n.y],g=o.x-f[0],a=o.y-f[1];return{x:u[0]*e+u[1]*t+g,y:u[2]*e+u[3]*t+a,angle:r,scale:Math.log(i)*s}},At=Object.prototype.toString;function W(o){return At.call(o).endsWith("Array]")}function te(o){var n=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(!W(o))throw new TypeError("input must be an array");if(o.length===0)throw new TypeError("input must not be empty");var e=n.fromIndex,t=e===void 0?0:e,s=n.toIndex,r=s===void 0?o.length:s;if(t<0||t>=o.length||!Number.isInteger(t))throw new Error("fromIndex must be a positive integer smaller than length");if(r<=t||r>o.length||!Number.isInteger(r))throw new Error("toIndex must be an integer greater than fromIndex and at most equal to length");for(var i=o[t],h=t+1;h<r;h++)o[h]>i&&(i=o[h]);return i}function ee(o){var n=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(!W(o))throw new TypeError("input must be an array");if(o.length===0)throw new TypeError("input must not be empty");var e=n.fromIndex,t=e===void 0?0:e,s=n.toIndex,r=s===void 0?o.length:s;if(t<0||t>=o.length||!Number.isInteger(t))throw new Error("fromIndex must be a positive integer smaller than length");if(r<=t||r>o.length||!Number.isInteger(r))throw new Error("toIndex must be an integer greater than fromIndex and at most equal to length");for(var i=o[t],h=t+1;h<r;h++)o[h]<i&&(i=o[h]);return i}function qt(o){var n=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(W(o)){if(o.length===0)throw new TypeError("input must not be empty")}else throw new TypeError("input must be an array");var e;if(n.output!==void 0){if(!W(n.output))throw new TypeError("output option must be an array if specified");e=n.output}else e=new Array(o.length);var t=ee(o),s=te(o);if(t===s)throw new RangeError("minimum and maximum input values are equal. Cannot rescale a constant array");var r=n.min,i=r===void 0?n.autoMinMax?t:0:r,h=n.max,l=h===void 0?n.autoMinMax?s:1:h;if(i>=l)throw new RangeError("min option must be smaller than max option");for(var u=(l-i)/(s-t),f=0;f<o.length;f++)e[f]=(o[f]-t)*u+i;return e}const ft=" ".repeat(2),_t=" ".repeat(4);function ne(){return Tt(this)}function Tt(o,n={}){const{maxRows:e=15,maxColumns:t=10,maxNumSize:s=8,padMinus:r="auto"}=n;return`${o.constructor.name} {
${ft}[
${_t}${se(o,e,t,s,r)}
${ft}]
${ft}rows: ${o.rows}
${ft}columns: ${o.columns}
}`}function se(o,n,e,t,s){const{rows:r,columns:i}=o,h=Math.min(r,n),l=Math.min(i,e),u=[];if(s==="auto"){s=!1;t:for(let f=0;f<h;f++)for(let g=0;g<l;g++)if(o.get(f,g)<0){s=!0;break t}}for(let f=0;f<h;f++){let g=[];for(let a=0;a<l;a++)g.push(oe(o.get(f,a),t,s));u.push(`${g.join(" ")}`)}return l!==i&&(u[u.length-1]+=` ... ${i-e} more columns`),h!==r&&u.push(`... ${r-n} more rows`),u.join(`
${_t}`)}function oe(o,n,e){return(o>=0&&e?` ${zt(o,n-1)}`:zt(o,n)).padEnd(n)}function zt(o,n){let e=o.toString();if(e.length<=n)return e;let t=o.toFixed(n);if(t.length>n&&(t=o.toFixed(Math.max(0,n-(t.length-n)))),t.length<=n&&!t.startsWith("0.000")&&!t.startsWith("-0.000"))return t;let s=o.toExponential(n);return s.length>n&&(s=o.toExponential(Math.max(0,n-(s.length-n)))),s.slice(0)}function re(o,n){o.prototype.add=function(t){return typeof t=="number"?this.addS(t):this.addM(t)},o.prototype.addS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)+t);return this},o.prototype.addM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)+t.get(s,r));return this},o.add=function(t,s){return new n(t).add(s)},o.prototype.sub=function(t){return typeof t=="number"?this.subS(t):this.subM(t)},o.prototype.subS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)-t);return this},o.prototype.subM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)-t.get(s,r));return this},o.sub=function(t,s){return new n(t).sub(s)},o.prototype.subtract=o.prototype.sub,o.prototype.subtractS=o.prototype.subS,o.prototype.subtractM=o.prototype.subM,o.subtract=o.sub,o.prototype.mul=function(t){return typeof t=="number"?this.mulS(t):this.mulM(t)},o.prototype.mulS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)*t);return this},o.prototype.mulM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)*t.get(s,r));return this},o.mul=function(t,s){return new n(t).mul(s)},o.prototype.multiply=o.prototype.mul,o.prototype.multiplyS=o.prototype.mulS,o.prototype.multiplyM=o.prototype.mulM,o.multiply=o.mul,o.prototype.div=function(t){return typeof t=="number"?this.divS(t):this.divM(t)},o.prototype.divS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)/t);return this},o.prototype.divM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)/t.get(s,r));return this},o.div=function(t,s){return new n(t).div(s)},o.prototype.divide=o.prototype.div,o.prototype.divideS=o.prototype.divS,o.prototype.divideM=o.prototype.divM,o.divide=o.div,o.prototype.mod=function(t){return typeof t=="number"?this.modS(t):this.modM(t)},o.prototype.modS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)%t);return this},o.prototype.modM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)%t.get(s,r));return this},o.mod=function(t,s){return new n(t).mod(s)},o.prototype.modulus=o.prototype.mod,o.prototype.modulusS=o.prototype.modS,o.prototype.modulusM=o.prototype.modM,o.modulus=o.mod,o.prototype.and=function(t){return typeof t=="number"?this.andS(t):this.andM(t)},o.prototype.andS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)&t);return this},o.prototype.andM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)&t.get(s,r));return this},o.and=function(t,s){return new n(t).and(s)},o.prototype.or=function(t){return typeof t=="number"?this.orS(t):this.orM(t)},o.prototype.orS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)|t);return this},o.prototype.orM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)|t.get(s,r));return this},o.or=function(t,s){return new n(t).or(s)},o.prototype.xor=function(t){return typeof t=="number"?this.xorS(t):this.xorM(t)},o.prototype.xorS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)^t);return this},o.prototype.xorM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)^t.get(s,r));return this},o.xor=function(t,s){return new n(t).xor(s)},o.prototype.leftShift=function(t){return typeof t=="number"?this.leftShiftS(t):this.leftShiftM(t)},o.prototype.leftShiftS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)<<t);return this},o.prototype.leftShiftM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)<<t.get(s,r));return this},o.leftShift=function(t,s){return new n(t).leftShift(s)},o.prototype.signPropagatingRightShift=function(t){return typeof t=="number"?this.signPropagatingRightShiftS(t):this.signPropagatingRightShiftM(t)},o.prototype.signPropagatingRightShiftS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)>>t);return this},o.prototype.signPropagatingRightShiftM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)>>t.get(s,r));return this},o.signPropagatingRightShift=function(t,s){return new n(t).signPropagatingRightShift(s)},o.prototype.rightShift=function(t){return typeof t=="number"?this.rightShiftS(t):this.rightShiftM(t)},o.prototype.rightShiftS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)>>>t);return this},o.prototype.rightShiftM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)>>>t.get(s,r));return this},o.rightShift=function(t,s){return new n(t).rightShift(s)},o.prototype.zeroFillRightShift=o.prototype.rightShift,o.prototype.zeroFillRightShiftS=o.prototype.rightShiftS,o.prototype.zeroFillRightShiftM=o.prototype.rightShiftM,o.zeroFillRightShift=o.rightShift,o.prototype.not=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,~this.get(t,s));return this},o.not=function(t){return new n(t).not()},o.prototype.abs=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.abs(this.get(t,s)));return this},o.abs=function(t){return new n(t).abs()},o.prototype.acos=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.acos(this.get(t,s)));return this},o.acos=function(t){return new n(t).acos()},o.prototype.acosh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.acosh(this.get(t,s)));return this},o.acosh=function(t){return new n(t).acosh()},o.prototype.asin=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.asin(this.get(t,s)));return this},o.asin=function(t){return new n(t).asin()},o.prototype.asinh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.asinh(this.get(t,s)));return this},o.asinh=function(t){return new n(t).asinh()},o.prototype.atan=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.atan(this.get(t,s)));return this},o.atan=function(t){return new n(t).atan()},o.prototype.atanh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.atanh(this.get(t,s)));return this},o.atanh=function(t){return new n(t).atanh()},o.prototype.cbrt=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.cbrt(this.get(t,s)));return this},o.cbrt=function(t){return new n(t).cbrt()},o.prototype.ceil=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.ceil(this.get(t,s)));return this},o.ceil=function(t){return new n(t).ceil()},o.prototype.clz32=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.clz32(this.get(t,s)));return this},o.clz32=function(t){return new n(t).clz32()},o.prototype.cos=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.cos(this.get(t,s)));return this},o.cos=function(t){return new n(t).cos()},o.prototype.cosh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.cosh(this.get(t,s)));return this},o.cosh=function(t){return new n(t).cosh()},o.prototype.exp=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.exp(this.get(t,s)));return this},o.exp=function(t){return new n(t).exp()},o.prototype.expm1=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.expm1(this.get(t,s)));return this},o.expm1=function(t){return new n(t).expm1()},o.prototype.floor=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.floor(this.get(t,s)));return this},o.floor=function(t){return new n(t).floor()},o.prototype.fround=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.fround(this.get(t,s)));return this},o.fround=function(t){return new n(t).fround()},o.prototype.log=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.log(this.get(t,s)));return this},o.log=function(t){return new n(t).log()},o.prototype.log1p=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.log1p(this.get(t,s)));return this},o.log1p=function(t){return new n(t).log1p()},o.prototype.log10=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.log10(this.get(t,s)));return this},o.log10=function(t){return new n(t).log10()},o.prototype.log2=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.log2(this.get(t,s)));return this},o.log2=function(t){return new n(t).log2()},o.prototype.round=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.round(this.get(t,s)));return this},o.round=function(t){return new n(t).round()},o.prototype.sign=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.sign(this.get(t,s)));return this},o.sign=function(t){return new n(t).sign()},o.prototype.sin=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.sin(this.get(t,s)));return this},o.sin=function(t){return new n(t).sin()},o.prototype.sinh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.sinh(this.get(t,s)));return this},o.sinh=function(t){return new n(t).sinh()},o.prototype.sqrt=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.sqrt(this.get(t,s)));return this},o.sqrt=function(t){return new n(t).sqrt()},o.prototype.tan=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.tan(this.get(t,s)));return this},o.tan=function(t){return new n(t).tan()},o.prototype.tanh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.tanh(this.get(t,s)));return this},o.tanh=function(t){return new n(t).tanh()},o.prototype.trunc=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.trunc(this.get(t,s)));return this},o.trunc=function(t){return new n(t).trunc()},o.pow=function(t,s){return new n(t).pow(s)},o.prototype.pow=function(t){return typeof t=="number"?this.powS(t):this.powM(t)},o.prototype.powS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,Math.pow(this.get(s,r),t));return this},o.prototype.powM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,Math.pow(this.get(s,r),t.get(s,r)));return this}}function Q(o,n,e){let t=e?o.rows:o.rows-1;if(n<0||n>t)throw new RangeError("Row index out of range")}function Z(o,n,e){let t=e?o.columns:o.columns-1;if(n<0||n>t)throw new RangeError("Column index out of range")}function tt(o,n){if(n.to1DArray&&(n=n.to1DArray()),n.length!==o.columns)throw new RangeError("vector size must be the same as the number of columns");return n}function et(o,n){if(n.to1DArray&&(n=n.to1DArray()),n.length!==o.rows)throw new RangeError("vector size must be the same as the number of rows");return n}function ie(o,n){if(!W(n))throw new TypeError("row indices must be an array");for(let e=0;e<n.length;e++)if(n[e]<0||n[e]>=o.rows)throw new RangeError("row indices are out of range")}function le(o,n){if(!W(n))throw new TypeError("column indices must be an array");for(let e=0;e<n.length;e++)if(n[e]<0||n[e]>=o.columns)throw new RangeError("column indices are out of range")}function Ft(o,n,e,t,s){if(arguments.length!==5)throw new RangeError("expected 4 arguments");if(at("startRow",n),at("endRow",e),at("startColumn",t),at("endColumn",s),n>e||t>s||n<0||n>=o.rows||e<0||e>=o.rows||t<0||t>=o.columns||s<0||s>=o.columns)throw new RangeError("Submatrix indices are out of range")}function gt(o,n=0){let e=[];for(let t=0;t<o;t++)e.push(n);return e}function at(o,n){if(typeof n!="number")throw new TypeError(`${o} must be a number`)}function nt(o){if(o.isEmpty())throw new Error("Empty matrix has no elements to index")}function he(o){let n=gt(o.rows);for(let e=0;e<o.rows;++e)for(let t=0;t<o.columns;++t)n[e]+=o.get(e,t);return n}function ue(o){let n=gt(o.columns);for(let e=0;e<o.rows;++e)for(let t=0;t<o.columns;++t)n[t]+=o.get(e,t);return n}function ce(o){let n=0;for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)n+=o.get(e,t);return n}function fe(o){let n=gt(o.rows,1);for(let e=0;e<o.rows;++e)for(let t=0;t<o.columns;++t)n[e]*=o.get(e,t);return n}function ge(o){let n=gt(o.columns,1);for(let e=0;e<o.rows;++e)for(let t=0;t<o.columns;++t)n[t]*=o.get(e,t);return n}function ae(o){let n=1;for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)n*=o.get(e,t);return n}function me(o,n,e){const t=o.rows,s=o.columns,r=[];for(let i=0;i<t;i++){let h=0,l=0,u=0;for(let f=0;f<s;f++)u=o.get(i,f)-e[i],h+=u,l+=u*u;n?r.push((l-h*h/s)/(s-1)):r.push((l-h*h/s)/s)}return r}function we(o,n,e){const t=o.rows,s=o.columns,r=[];for(let i=0;i<s;i++){let h=0,l=0,u=0;for(let f=0;f<t;f++)u=o.get(f,i)-e[i],h+=u,l+=u*u;n?r.push((l-h*h/t)/(t-1)):r.push((l-h*h/t)/t)}return r}function pe(o,n,e){const t=o.rows,s=o.columns,r=t*s;let i=0,h=0,l=0;for(let u=0;u<t;u++)for(let f=0;f<s;f++)l=o.get(u,f)-e,i+=l,h+=l*l;return n?(h-i*i/r)/(r-1):(h-i*i/r)/r}function de(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)-n[e])}function ye(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)-n[t])}function Me(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)-n)}function Ee(o){const n=[];for(let e=0;e<o.rows;e++){let t=0;for(let s=0;s<o.columns;s++)t+=Math.pow(o.get(e,s),2)/(o.columns-1);n.push(Math.sqrt(t))}return n}function Se(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)/n[e])}function je(o){const n=[];for(let e=0;e<o.columns;e++){let t=0;for(let s=0;s<o.rows;s++)t+=Math.pow(o.get(s,e),2)/(o.rows-1);n.push(Math.sqrt(t))}return n}function ke(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)/n[t])}function be(o){const n=o.size-1;let e=0;for(let t=0;t<o.columns;t++)for(let s=0;s<o.rows;s++)e+=Math.pow(o.get(s,t),2)/n;return Math.sqrt(e)}function Ie(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)/n)}class _{static from1DArray(n,e,t){if(n*e!==t.length)throw new RangeError("data length does not match given dimensions");let r=new b(n,e);for(let i=0;i<n;i++)for(let h=0;h<e;h++)r.set(i,h,t[i*e+h]);return r}static rowVector(n){let e=new b(1,n.length);for(let t=0;t<n.length;t++)e.set(0,t,n[t]);return e}static columnVector(n){let e=new b(n.length,1);for(let t=0;t<n.length;t++)e.set(t,0,n[t]);return e}static zeros(n,e){return new b(n,e)}static ones(n,e){return new b(n,e).fill(1)}static rand(n,e,t={}){if(typeof t!="object")throw new TypeError("options must be an object");const{random:s=Math.random}=t;let r=new b(n,e);for(let i=0;i<n;i++)for(let h=0;h<e;h++)r.set(i,h,s());return r}static randInt(n,e,t={}){if(typeof t!="object")throw new TypeError("options must be an object");const{min:s=0,max:r=1e3,random:i=Math.random}=t;if(!Number.isInteger(s))throw new TypeError("min must be an integer");if(!Number.isInteger(r))throw new TypeError("max must be an integer");if(s>=r)throw new RangeError("min must be smaller than max");let h=r-s,l=new b(n,e);for(let u=0;u<n;u++)for(let f=0;f<e;f++){let g=s+Math.round(i()*h);l.set(u,f,g)}return l}static eye(n,e,t){e===void 0&&(e=n),t===void 0&&(t=1);let s=Math.min(n,e),r=this.zeros(n,e);for(let i=0;i<s;i++)r.set(i,i,t);return r}static diag(n,e,t){let s=n.length;e===void 0&&(e=s),t===void 0&&(t=e);let r=Math.min(s,e,t),i=this.zeros(e,t);for(let h=0;h<r;h++)i.set(h,h,n[h]);return i}static min(n,e){n=this.checkMatrix(n),e=this.checkMatrix(e);let t=n.rows,s=n.columns,r=new b(t,s);for(let i=0;i<t;i++)for(let h=0;h<s;h++)r.set(i,h,Math.min(n.get(i,h),e.get(i,h)));return r}static max(n,e){n=this.checkMatrix(n),e=this.checkMatrix(e);let t=n.rows,s=n.columns,r=new this(t,s);for(let i=0;i<t;i++)for(let h=0;h<s;h++)r.set(i,h,Math.max(n.get(i,h),e.get(i,h)));return r}static checkMatrix(n){return _.isMatrix(n)?n:new b(n)}static isMatrix(n){return n!=null&&n.klass==="Matrix"}get size(){return this.rows*this.columns}apply(n){if(typeof n!="function")throw new TypeError("callback must be a function");for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n.call(this,e,t);return this}to1DArray(){let n=[];for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n.push(this.get(e,t));return n}to2DArray(){let n=[];for(let e=0;e<this.rows;e++){n.push([]);for(let t=0;t<this.columns;t++)n[e].push(this.get(e,t))}return n}toJSON(){return this.to2DArray()}isRowVector(){return this.rows===1}isColumnVector(){return this.columns===1}isVector(){return this.rows===1||this.columns===1}isSquare(){return this.rows===this.columns}isEmpty(){return this.rows===0||this.columns===0}isSymmetric(){if(this.isSquare()){for(let n=0;n<this.rows;n++)for(let e=0;e<=n;e++)if(this.get(n,e)!==this.get(e,n))return!1;return!0}return!1}isEchelonForm(){let n=0,e=0,t=-1,s=!0,r=!1;for(;n<this.rows&&s;){for(e=0,r=!1;e<this.columns&&r===!1;)this.get(n,e)===0?e++:this.get(n,e)===1&&e>t?(r=!0,t=e):(s=!1,r=!0);n++}return s}isReducedEchelonForm(){let n=0,e=0,t=-1,s=!0,r=!1;for(;n<this.rows&&s;){for(e=0,r=!1;e<this.columns&&r===!1;)this.get(n,e)===0?e++:this.get(n,e)===1&&e>t?(r=!0,t=e):(s=!1,r=!0);for(let i=e+1;i<this.rows;i++)this.get(n,i)!==0&&(s=!1);n++}return s}echelonForm(){let n=this.clone(),e=0,t=0;for(;e<n.rows&&t<n.columns;){let s=e;for(let r=e;r<n.rows;r++)n.get(r,t)>n.get(s,t)&&(s=r);if(n.get(s,t)===0)t++;else{n.swapRows(e,s);let r=n.get(e,t);for(let i=t;i<n.columns;i++)n.set(e,i,n.get(e,i)/r);for(let i=e+1;i<n.rows;i++){let h=n.get(i,t)/n.get(e,t);n.set(i,t,0);for(let l=t+1;l<n.columns;l++)n.set(i,l,n.get(i,l)-n.get(e,l)*h)}e++,t++}}return n}reducedEchelonForm(){let n=this.echelonForm(),e=n.columns,t=n.rows,s=t-1;for(;s>=0;)if(n.maxRow(s)===0)s--;else{let r=0,i=!1;for(;r<t&&i===!1;)n.get(s,r)===1?i=!0:r++;for(let h=0;h<s;h++){let l=n.get(h,r);for(let u=r;u<e;u++){let f=n.get(h,u)-l*n.get(s,u);n.set(h,u,f)}}s--}return n}set(){throw new Error("set method is unimplemented")}get(){throw new Error("get method is unimplemented")}repeat(n={}){if(typeof n!="object")throw new TypeError("options must be an object");const{rows:e=1,columns:t=1}=n;if(!Number.isInteger(e)||e<=0)throw new TypeError("rows must be a positive integer");if(!Number.isInteger(t)||t<=0)throw new TypeError("columns must be a positive integer");let s=new b(this.rows*e,this.columns*t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)s.setSubMatrix(this,this.rows*r,this.columns*i);return s}fill(n){for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,n);return this}neg(){return this.mulS(-1)}getRow(n){Q(this,n);let e=[];for(let t=0;t<this.columns;t++)e.push(this.get(n,t));return e}getRowVector(n){return b.rowVector(this.getRow(n))}setRow(n,e){Q(this,n),e=tt(this,e);for(let t=0;t<this.columns;t++)this.set(n,t,e[t]);return this}swapRows(n,e){Q(this,n),Q(this,e);for(let t=0;t<this.columns;t++){let s=this.get(n,t);this.set(n,t,this.get(e,t)),this.set(e,t,s)}return this}getColumn(n){Z(this,n);let e=[];for(let t=0;t<this.rows;t++)e.push(this.get(t,n));return e}getColumnVector(n){return b.columnVector(this.getColumn(n))}setColumn(n,e){Z(this,n),e=et(this,e);for(let t=0;t<this.rows;t++)this.set(t,n,e[t]);return this}swapColumns(n,e){Z(this,n),Z(this,e);for(let t=0;t<this.rows;t++){let s=this.get(t,n);this.set(t,n,this.get(t,e)),this.set(t,e,s)}return this}addRowVector(n){n=tt(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)+n[t]);return this}subRowVector(n){n=tt(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)-n[t]);return this}mulRowVector(n){n=tt(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)*n[t]);return this}divRowVector(n){n=tt(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)/n[t]);return this}addColumnVector(n){n=et(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)+n[e]);return this}subColumnVector(n){n=et(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)-n[e]);return this}mulColumnVector(n){n=et(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)*n[e]);return this}divColumnVector(n){n=et(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)/n[e]);return this}mulRow(n,e){Q(this,n);for(let t=0;t<this.columns;t++)this.set(n,t,this.get(n,t)*e);return this}mulColumn(n,e){Z(this,n);for(let t=0;t<this.rows;t++)this.set(t,n,this.get(t,n)*e);return this}max(n){if(this.isEmpty())return NaN;switch(n){case"row":{const e=new Array(this.rows).fill(Number.NEGATIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)>e[t]&&(e[t]=this.get(t,s));return e}case"column":{const e=new Array(this.columns).fill(Number.NEGATIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)>e[s]&&(e[s]=this.get(t,s));return e}case void 0:{let e=this.get(0,0);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)>e&&(e=this.get(t,s));return e}default:throw new Error(`invalid option: ${n}`)}}maxIndex(){nt(this);let n=this.get(0,0),e=[0,0];for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)>n&&(n=this.get(t,s),e[0]=t,e[1]=s);return e}min(n){if(this.isEmpty())return NaN;switch(n){case"row":{const e=new Array(this.rows).fill(Number.POSITIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)<e[t]&&(e[t]=this.get(t,s));return e}case"column":{const e=new Array(this.columns).fill(Number.POSITIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)<e[s]&&(e[s]=this.get(t,s));return e}case void 0:{let e=this.get(0,0);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)<e&&(e=this.get(t,s));return e}default:throw new Error(`invalid option: ${n}`)}}minIndex(){nt(this);let n=this.get(0,0),e=[0,0];for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)<n&&(n=this.get(t,s),e[0]=t,e[1]=s);return e}maxRow(n){if(Q(this,n),this.isEmpty())return NaN;let e=this.get(n,0);for(let t=1;t<this.columns;t++)this.get(n,t)>e&&(e=this.get(n,t));return e}maxRowIndex(n){Q(this,n),nt(this);let e=this.get(n,0),t=[n,0];for(let s=1;s<this.columns;s++)this.get(n,s)>e&&(e=this.get(n,s),t[1]=s);return t}minRow(n){if(Q(this,n),this.isEmpty())return NaN;let e=this.get(n,0);for(let t=1;t<this.columns;t++)this.get(n,t)<e&&(e=this.get(n,t));return e}minRowIndex(n){Q(this,n),nt(this);let e=this.get(n,0),t=[n,0];for(let s=1;s<this.columns;s++)this.get(n,s)<e&&(e=this.get(n,s),t[1]=s);return t}maxColumn(n){if(Z(this,n),this.isEmpty())return NaN;let e=this.get(0,n);for(let t=1;t<this.rows;t++)this.get(t,n)>e&&(e=this.get(t,n));return e}maxColumnIndex(n){Z(this,n),nt(this);let e=this.get(0,n),t=[0,n];for(let s=1;s<this.rows;s++)this.get(s,n)>e&&(e=this.get(s,n),t[0]=s);return t}minColumn(n){if(Z(this,n),this.isEmpty())return NaN;let e=this.get(0,n);for(let t=1;t<this.rows;t++)this.get(t,n)<e&&(e=this.get(t,n));return e}minColumnIndex(n){Z(this,n),nt(this);let e=this.get(0,n),t=[0,n];for(let s=1;s<this.rows;s++)this.get(s,n)<e&&(e=this.get(s,n),t[0]=s);return t}diag(){let n=Math.min(this.rows,this.columns),e=[];for(let t=0;t<n;t++)e.push(this.get(t,t));return e}norm(n="frobenius"){let e=0;if(n==="max")return this.max();if(n==="frobenius"){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)e=e+this.get(t,s)*this.get(t,s);return Math.sqrt(e)}else throw new RangeError(`unknown norm type: ${n}`)}cumulativeSum(){let n=0;for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n+=this.get(e,t),this.set(e,t,n);return this}dot(n){_.isMatrix(n)&&(n=n.to1DArray());let e=this.to1DArray();if(e.length!==n.length)throw new RangeError("vectors do not have the same size");let t=0;for(let s=0;s<e.length;s++)t+=e[s]*n[s];return t}mmul(n){n=b.checkMatrix(n);let e=this.rows,t=this.columns,s=n.columns,r=new b(e,s),i=new Float64Array(t);for(let h=0;h<s;h++){for(let l=0;l<t;l++)i[l]=n.get(l,h);for(let l=0;l<e;l++){let u=0;for(let f=0;f<t;f++)u+=this.get(l,f)*i[f];r.set(l,h,u)}}return r}strassen2x2(n){n=b.checkMatrix(n);let e=new b(2,2);const t=this.get(0,0),s=n.get(0,0),r=this.get(0,1),i=n.get(0,1),h=this.get(1,0),l=n.get(1,0),u=this.get(1,1),f=n.get(1,1),g=(t+u)*(s+f),a=(h+u)*s,j=t*(i-f),w=u*(l-s),y=(t+r)*f,m=(h-t)*(s+i),M=(r-u)*(l+f),T=g+w-y+M,E=j+y,k=a+w,R=g-a+j+m;return e.set(0,0,T),e.set(0,1,E),e.set(1,0,k),e.set(1,1,R),e}strassen3x3(n){n=b.checkMatrix(n);let e=new b(3,3);const t=this.get(0,0),s=this.get(0,1),r=this.get(0,2),i=this.get(1,0),h=this.get(1,1),l=this.get(1,2),u=this.get(2,0),f=this.get(2,1),g=this.get(2,2),a=n.get(0,0),j=n.get(0,1),w=n.get(0,2),y=n.get(1,0),m=n.get(1,1),M=n.get(1,2),T=n.get(2,0),E=n.get(2,1),k=n.get(2,2),R=(t+s+r-i-h-f-g)*m,q=(t-i)*(-j+m),I=h*(-a+j+y-m-M-T+k),z=(-t+i+h)*(a-j+m),B=(i+h)*(-a+j),c=t*a,p=(-t+u+f)*(a-w+M),S=(-t+u)*(w-M),d=(u+f)*(-a+w),D=(t+s+r-h-l-u-f)*M,U=f*(-a+w+y-m-M-T+E),F=(-r+f+g)*(m+T-E),P=(r-g)*(m-E),Y=r*T,G=(f+g)*(-T+E),N=(-r+h+l)*(M+T-k),$=(r-l)*(M-k),K=(h+l)*(-T+k),v=s*y,V=l*E,L=i*w,C=u*j,X=g*k,wt=c+Y+v,pt=R+z+B+c+F+Y+G,dt=c+p+d+D+Y+N+K,it=q+I+z+c+Y+N+$,lt=q+z+B+c+V,ht=Y+N+$+K+L,jt=c+p+S+U+F+P+Y,ut=F+P+Y+G+C,kt=c+p+S+d+X;return e.set(0,0,wt),e.set(0,1,pt),e.set(0,2,dt),e.set(1,0,it),e.set(1,1,lt),e.set(1,2,ht),e.set(2,0,jt),e.set(2,1,ut),e.set(2,2,kt),e}mmulStrassen(n){n=b.checkMatrix(n);let e=this.clone(),t=e.rows,s=e.columns,r=n.rows,i=n.columns;s!==r&&console.warn(`Multiplying ${t} x ${s} and ${r} x ${i} matrix: dimensions do not match.`);function h(g,a,j){let w=g.rows,y=g.columns;if(w===a&&y===j)return g;{let m=_.zeros(a,j);return m=m.setSubMatrix(g,0,0),m}}let l=Math.max(t,r),u=Math.max(s,i);e=h(e,l,u),n=h(n,l,u);function f(g,a,j,w){if(j<=512||w<=512)return g.mmul(a);j%2===1&&w%2===1?(g=h(g,j+1,w+1),a=h(a,j+1,w+1)):j%2===1?(g=h(g,j+1,w),a=h(a,j+1,w)):w%2===1&&(g=h(g,j,w+1),a=h(a,j,w+1));let y=parseInt(g.rows/2,10),m=parseInt(g.columns/2,10),M=g.subMatrix(0,y-1,0,m-1),T=a.subMatrix(0,y-1,0,m-1),E=g.subMatrix(0,y-1,m,g.columns-1),k=a.subMatrix(0,y-1,m,a.columns-1),R=g.subMatrix(y,g.rows-1,0,m-1),q=a.subMatrix(y,a.rows-1,0,m-1),I=g.subMatrix(y,g.rows-1,m,g.columns-1),z=a.subMatrix(y,a.rows-1,m,a.columns-1),B=f(_.add(M,I),_.add(T,z),y,m),c=f(_.add(R,I),T,y,m),p=f(M,_.sub(k,z),y,m),S=f(I,_.sub(q,T),y,m),d=f(_.add(M,E),z,y,m),D=f(_.sub(R,M),_.add(T,k),y,m),U=f(_.sub(E,I),_.add(q,z),y,m),F=_.add(B,S);F.sub(d),F.add(U);let P=_.add(p,d),Y=_.add(c,S),G=_.sub(B,c);G.add(p),G.add(D);let N=_.zeros(2*F.rows,2*F.columns);return N=N.setSubMatrix(F,0,0),N=N.setSubMatrix(P,F.rows,0),N=N.setSubMatrix(Y,0,F.columns),N=N.setSubMatrix(G,F.rows,F.columns),N.subMatrix(0,j-1,0,w-1)}return f(e,n,l,u)}scaleRows(n={}){if(typeof n!="object")throw new TypeError("options must be an object");const{min:e=0,max:t=1}=n;if(!Number.isFinite(e))throw new TypeError("min must be a number");if(!Number.isFinite(t))throw new TypeError("max must be a number");if(e>=t)throw new RangeError("min must be smaller than max");let s=new b(this.rows,this.columns);for(let r=0;r<this.rows;r++){const i=this.getRow(r);i.length>0&&qt(i,{min:e,max:t,output:i}),s.setRow(r,i)}return s}scaleColumns(n={}){if(typeof n!="object")throw new TypeError("options must be an object");const{min:e=0,max:t=1}=n;if(!Number.isFinite(e))throw new TypeError("min must be a number");if(!Number.isFinite(t))throw new TypeError("max must be a number");if(e>=t)throw new RangeError("min must be smaller than max");let s=new b(this.rows,this.columns);for(let r=0;r<this.columns;r++){const i=this.getColumn(r);i.length&&qt(i,{min:e,max:t,output:i}),s.setColumn(r,i)}return s}flipRows(){const n=Math.ceil(this.columns/2);for(let e=0;e<this.rows;e++)for(let t=0;t<n;t++){let s=this.get(e,t),r=this.get(e,this.columns-1-t);this.set(e,t,r),this.set(e,this.columns-1-t,s)}return this}flipColumns(){const n=Math.ceil(this.rows/2);for(let e=0;e<this.columns;e++)for(let t=0;t<n;t++){let s=this.get(t,e),r=this.get(this.rows-1-t,e);this.set(t,e,r),this.set(this.rows-1-t,e,s)}return this}kroneckerProduct(n){n=b.checkMatrix(n);let e=this.rows,t=this.columns,s=n.rows,r=n.columns,i=new b(e*s,t*r);for(let h=0;h<e;h++)for(let l=0;l<t;l++)for(let u=0;u<s;u++)for(let f=0;f<r;f++)i.set(s*h+u,r*l+f,this.get(h,l)*n.get(u,f));return i}kroneckerSum(n){if(n=b.checkMatrix(n),!this.isSquare()||!n.isSquare())throw new Error("Kronecker Sum needs two Square Matrices");let e=this.rows,t=n.rows,s=this.kroneckerProduct(b.eye(t,t)),r=b.eye(e,e).kroneckerProduct(n);return s.add(r)}transpose(){let n=new b(this.columns,this.rows);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n.set(t,e,this.get(e,t));return n}sortRows(n=Pt){for(let e=0;e<this.rows;e++)this.setRow(e,this.getRow(e).sort(n));return this}sortColumns(n=Pt){for(let e=0;e<this.columns;e++)this.setColumn(e,this.getColumn(e).sort(n));return this}subMatrix(n,e,t,s){Ft(this,n,e,t,s);let r=new b(e-n+1,s-t+1);for(let i=n;i<=e;i++)for(let h=t;h<=s;h++)r.set(i-n,h-t,this.get(i,h));return r}subMatrixRow(n,e,t){if(e===void 0&&(e=0),t===void 0&&(t=this.columns-1),e>t||e<0||e>=this.columns||t<0||t>=this.columns)throw new RangeError("Argument out of range");let s=new b(n.length,t-e+1);for(let r=0;r<n.length;r++)for(let i=e;i<=t;i++){if(n[r]<0||n[r]>=this.rows)throw new RangeError(`Row index out of range: ${n[r]}`);s.set(r,i-e,this.get(n[r],i))}return s}subMatrixColumn(n,e,t){if(e===void 0&&(e=0),t===void 0&&(t=this.rows-1),e>t||e<0||e>=this.rows||t<0||t>=this.rows)throw new RangeError("Argument out of range");let s=new b(t-e+1,n.length);for(let r=0;r<n.length;r++)for(let i=e;i<=t;i++){if(n[r]<0||n[r]>=this.columns)throw new RangeError(`Column index out of range: ${n[r]}`);s.set(i-e,r,this.get(i,n[r]))}return s}setSubMatrix(n,e,t){if(n=b.checkMatrix(n),n.isEmpty())return this;let s=e+n.rows-1,r=t+n.columns-1;Ft(this,e,s,t,r);for(let i=0;i<n.rows;i++)for(let h=0;h<n.columns;h++)this.set(e+i,t+h,n.get(i,h));return this}selection(n,e){ie(this,n),le(this,e);let t=new b(n.length,e.length);for(let s=0;s<n.length;s++){let r=n[s];for(let i=0;i<e.length;i++){let h=e[i];t.set(s,i,this.get(r,h))}}return t}trace(){let n=Math.min(this.rows,this.columns),e=0;for(let t=0;t<n;t++)e+=this.get(t,t);return e}clone(){let n=new b(this.rows,this.columns);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n.set(e,t,this.get(e,t));return n}sum(n){switch(n){case"row":return he(this);case"column":return ue(this);case void 0:return ce(this);default:throw new Error(`invalid option: ${n}`)}}product(n){switch(n){case"row":return fe(this);case"column":return ge(this);case void 0:return ae(this);default:throw new Error(`invalid option: ${n}`)}}mean(n){const e=this.sum(n);switch(n){case"row":{for(let t=0;t<this.rows;t++)e[t]/=this.columns;return e}case"column":{for(let t=0;t<this.columns;t++)e[t]/=this.rows;return e}case void 0:return e/this.size;default:throw new Error(`invalid option: ${n}`)}}variance(n,e={}){if(typeof n=="object"&&(e=n,n=void 0),typeof e!="object")throw new TypeError("options must be an object");const{unbiased:t=!0,mean:s=this.mean(n)}=e;if(typeof t!="boolean")throw new TypeError("unbiased must be a boolean");switch(n){case"row":{if(!W(s))throw new TypeError("mean must be an array");return me(this,t,s)}case"column":{if(!W(s))throw new TypeError("mean must be an array");return we(this,t,s)}case void 0:{if(typeof s!="number")throw new TypeError("mean must be a number");return pe(this,t,s)}default:throw new Error(`invalid option: ${n}`)}}standardDeviation(n,e){typeof n=="object"&&(e=n,n=void 0);const t=this.variance(n,e);if(n===void 0)return Math.sqrt(t);for(let s=0;s<t.length;s++)t[s]=Math.sqrt(t[s]);return t}center(n,e={}){if(typeof n=="object"&&(e=n,n=void 0),typeof e!="object")throw new TypeError("options must be an object");const{center:t=this.mean(n)}=e;switch(n){case"row":{if(!W(t))throw new TypeError("center must be an array");return de(this,t),this}case"column":{if(!W(t))throw new TypeError("center must be an array");return ye(this,t),this}case void 0:{if(typeof t!="number")throw new TypeError("center must be a number");return Me(this,t),this}default:throw new Error(`invalid option: ${n}`)}}scale(n,e={}){if(typeof n=="object"&&(e=n,n=void 0),typeof e!="object")throw new TypeError("options must be an object");let t=e.scale;switch(n){case"row":{if(t===void 0)t=Ee(this);else if(!W(t))throw new TypeError("scale must be an array");return Se(this,t),this}case"column":{if(t===void 0)t=je(this);else if(!W(t))throw new TypeError("scale must be an array");return ke(this,t),this}case void 0:{if(t===void 0)t=be(this);else if(typeof t!="number")throw new TypeError("scale must be a number");return Ie(this,t),this}default:throw new Error(`invalid option: ${n}`)}}toString(n){return Tt(this,n)}}_.prototype.klass="Matrix",typeof Symbol<"u"&&(_.prototype[Symbol.for("nodejs.util.inspect.custom")]=ne);function Pt(o,n){return o-n}function Re(o){return o.every(n=>typeof n=="number")}_.random=_.rand,_.randomInt=_.randInt,_.diagonal=_.diag,_.prototype.diagonal=_.prototype.diag,_.identity=_.eye,_.prototype.negate=_.prototype.neg,_.prototype.tensorProduct=_.prototype.kroneckerProduct;class b extends _{constructor(n,e){if(super(),b.isMatrix(n))return n.clone();if(Number.isInteger(n)&&n>=0)if(this.data=[],Number.isInteger(e)&&e>=0)for(let t=0;t<n;t++)this.data.push(new Float64Array(e));else throw new TypeError("nColumns must be a positive integer");else if(W(n)){const t=n;if(n=t.length,e=n?t[0].length:0,typeof e!="number")throw new TypeError("Data must be a 2D array with at least one element");this.data=[];for(let s=0;s<n;s++){if(t[s].length!==e)throw new RangeError("Inconsistent array dimensions");if(!Re(t[s]))throw new TypeError("Input data contains non-numeric values");this.data.push(Float64Array.from(t[s]))}}else throw new TypeError("First argument must be a positive number or an array");this.rows=n,this.columns=e}set(n,e,t){return this.data[n][e]=t,this}get(n,e){return this.data[n][e]}removeRow(n){return Q(this,n),this.data.splice(n,1),this.rows-=1,this}addRow(n,e){return e===void 0&&(e=n,n=this.rows),Q(this,n,!0),e=Float64Array.from(tt(this,e)),this.data.splice(n,0,e),this.rows+=1,this}removeColumn(n){Z(this,n);for(let e=0;e<this.rows;e++){const t=new Float64Array(this.columns-1);for(let s=0;s<n;s++)t[s]=this.data[e][s];for(let s=n+1;s<this.columns;s++)t[s-1]=this.data[e][s];this.data[e]=t}return this.columns-=1,this}addColumn(n,e){typeof e>"u"&&(e=n,n=this.columns),Z(this,n,!0),e=et(this,e);for(let t=0;t<this.rows;t++){const s=new Float64Array(this.columns+1);let r=0;for(;r<n;r++)s[r]=this.data[t][r];for(s[r++]=e[t];r<this.columns+1;r++)s[r]=this.data[t][r-1];this.data[t]=s}return this.columns+=1,this}}re(_,b);class st extends _{constructor(n){super(),this.data=n,this.rows=n.length,this.columns=n[0].length}set(n,e,t){return this.data[n][e]=t,this}get(n,e){return this.data[n][e]}}class Ne{constructor(n){n=st.checkMatrix(n);let e=n.clone(),t=e.rows,s=e.columns,r=new Float64Array(t),i=1,h,l,u,f,g,a,j,w,y;for(h=0;h<t;h++)r[h]=h;for(w=new Float64Array(t),l=0;l<s;l++){for(h=0;h<t;h++)w[h]=e.get(h,l);for(h=0;h<t;h++){for(y=Math.min(h,l),g=0,u=0;u<y;u++)g+=e.get(h,u)*w[u];w[h]-=g,e.set(h,l,w[h])}for(f=l,h=l+1;h<t;h++)Math.abs(w[h])>Math.abs(w[f])&&(f=h);if(f!==l){for(u=0;u<s;u++)a=e.get(f,u),e.set(f,u,e.get(l,u)),e.set(l,u,a);j=r[f],r[f]=r[l],r[l]=j,i=-i}if(l<t&&e.get(l,l)!==0)for(h=l+1;h<t;h++)e.set(h,l,e.get(h,l)/e.get(l,l))}this.LU=e,this.pivotVector=r,this.pivotSign=i}isSingular(){let n=this.LU,e=n.columns;for(let t=0;t<e;t++)if(n.get(t,t)===0)return!0;return!1}solve(n){n=b.checkMatrix(n);let e=this.LU;if(e.rows!==n.rows)throw new Error("Invalid matrix dimensions");if(this.isSingular())throw new Error("LU matrix is singular");let s=n.columns,r=n.subMatrixRow(this.pivotVector,0,s-1),i=e.columns,h,l,u;for(u=0;u<i;u++)for(h=u+1;h<i;h++)for(l=0;l<s;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u));for(u=i-1;u>=0;u--){for(l=0;l<s;l++)r.set(u,l,r.get(u,l)/e.get(u,u));for(h=0;h<u;h++)for(l=0;l<s;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u))}return r}get determinant(){let n=this.LU;if(!n.isSquare())throw new Error("Matrix must be square");let e=this.pivotSign,t=n.columns;for(let s=0;s<t;s++)e*=n.get(s,s);return e}get lowerTriangularMatrix(){let n=this.LU,e=n.rows,t=n.columns,s=new b(e,t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)r>i?s.set(r,i,n.get(r,i)):r===i?s.set(r,i,1):s.set(r,i,0);return s}get upperTriangularMatrix(){let n=this.LU,e=n.rows,t=n.columns,s=new b(e,t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)r<=i?s.set(r,i,n.get(r,i)):s.set(r,i,0);return s}get pivotPermutationVector(){return Array.from(this.pivotVector)}}function x(o,n){let e=0;return Math.abs(o)>Math.abs(n)?(e=n/o,Math.abs(o)*Math.sqrt(1+e*e)):n!==0?(e=o/n,Math.abs(n)*Math.sqrt(1+e*e)):0}class ve{constructor(n){n=st.checkMatrix(n);let e=n.clone(),t=n.rows,s=n.columns,r=new Float64Array(s),i,h,l,u;for(l=0;l<s;l++){let f=0;for(i=l;i<t;i++)f=x(f,e.get(i,l));if(f!==0){for(e.get(l,l)<0&&(f=-f),i=l;i<t;i++)e.set(i,l,e.get(i,l)/f);for(e.set(l,l,e.get(l,l)+1),h=l+1;h<s;h++){for(u=0,i=l;i<t;i++)u+=e.get(i,l)*e.get(i,h);for(u=-u/e.get(l,l),i=l;i<t;i++)e.set(i,h,e.get(i,h)+u*e.get(i,l))}}r[l]=-f}this.QR=e,this.Rdiag=r}solve(n){n=b.checkMatrix(n);let e=this.QR,t=e.rows;if(n.rows!==t)throw new Error("Matrix row dimensions must agree");if(!this.isFullRank())throw new Error("Matrix is rank deficient");let s=n.columns,r=n.clone(),i=e.columns,h,l,u,f;for(u=0;u<i;u++)for(l=0;l<s;l++){for(f=0,h=u;h<t;h++)f+=e.get(h,u)*r.get(h,l);for(f=-f/e.get(u,u),h=u;h<t;h++)r.set(h,l,r.get(h,l)+f*e.get(h,u))}for(u=i-1;u>=0;u--){for(l=0;l<s;l++)r.set(u,l,r.get(u,l)/this.Rdiag[u]);for(h=0;h<u;h++)for(l=0;l<s;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u))}return r.subMatrix(0,i-1,0,s-1)}isFullRank(){let n=this.QR.columns;for(let e=0;e<n;e++)if(this.Rdiag[e]===0)return!1;return!0}get upperTriangularMatrix(){let n=this.QR,e=n.columns,t=new b(e,e),s,r;for(s=0;s<e;s++)for(r=0;r<e;r++)s<r?t.set(s,r,n.get(s,r)):s===r?t.set(s,r,this.Rdiag[s]):t.set(s,r,0);return t}get orthogonalMatrix(){let n=this.QR,e=n.rows,t=n.columns,s=new b(e,t),r,i,h,l;for(h=t-1;h>=0;h--){for(r=0;r<e;r++)s.set(r,h,0);for(s.set(h,h,1),i=h;i<t;i++)if(n.get(h,h)!==0){for(l=0,r=h;r<e;r++)l+=n.get(r,h)*s.get(r,i);for(l=-l/n.get(h,h),r=h;r<e;r++)s.set(r,i,s.get(r,i)+l*n.get(r,h))}}return s}}class Dt{constructor(n,e={}){if(n=st.checkMatrix(n),n.isEmpty())throw new Error("Matrix must be non-empty");let t=n.rows,s=n.columns;const{computeLeftSingularVectors:r=!0,computeRightSingularVectors:i=!0,autoTranspose:h=!1}=e;let l=!!r,u=!!i,f=!1,g;if(t<s)if(!h)g=n.clone(),console.warn("Computing SVD on a matrix with more columns than rows. Consider enabling autoTranspose");else{g=n.transpose(),t=g.rows,s=g.columns,f=!0;let c=l;l=u,u=c}else g=n.clone();let a=Math.min(t,s),j=Math.min(t+1,s),w=new Float64Array(j),y=new b(t,a),m=new b(s,s),M=new Float64Array(s),T=new Float64Array(t),E=new Float64Array(j);for(let c=0;c<j;c++)E[c]=c;let k=Math.min(t-1,s),R=Math.max(0,Math.min(s-2,t)),q=Math.max(k,R);for(let c=0;c<q;c++){if(c<k){w[c]=0;for(let p=c;p<t;p++)w[c]=x(w[c],g.get(p,c));if(w[c]!==0){g.get(c,c)<0&&(w[c]=-w[c]);for(let p=c;p<t;p++)g.set(p,c,g.get(p,c)/w[c]);g.set(c,c,g.get(c,c)+1)}w[c]=-w[c]}for(let p=c+1;p<s;p++){if(c<k&&w[c]!==0){let S=0;for(let d=c;d<t;d++)S+=g.get(d,c)*g.get(d,p);S=-S/g.get(c,c);for(let d=c;d<t;d++)g.set(d,p,g.get(d,p)+S*g.get(d,c))}M[p]=g.get(c,p)}if(l&&c<k)for(let p=c;p<t;p++)y.set(p,c,g.get(p,c));if(c<R){M[c]=0;for(let p=c+1;p<s;p++)M[c]=x(M[c],M[p]);if(M[c]!==0){M[c+1]<0&&(M[c]=0-M[c]);for(let p=c+1;p<s;p++)M[p]/=M[c];M[c+1]+=1}if(M[c]=-M[c],c+1<t&&M[c]!==0){for(let p=c+1;p<t;p++)T[p]=0;for(let p=c+1;p<t;p++)for(let S=c+1;S<s;S++)T[p]+=M[S]*g.get(p,S);for(let p=c+1;p<s;p++){let S=-M[p]/M[c+1];for(let d=c+1;d<t;d++)g.set(d,p,g.get(d,p)+S*T[d])}}if(u)for(let p=c+1;p<s;p++)m.set(p,c,M[p])}}let I=Math.min(s,t+1);if(k<s&&(w[k]=g.get(k,k)),t<I&&(w[I-1]=0),R+1<I&&(M[R]=g.get(R,I-1)),M[I-1]=0,l){for(let c=k;c<a;c++){for(let p=0;p<t;p++)y.set(p,c,0);y.set(c,c,1)}for(let c=k-1;c>=0;c--)if(w[c]!==0){for(let p=c+1;p<a;p++){let S=0;for(let d=c;d<t;d++)S+=y.get(d,c)*y.get(d,p);S=-S/y.get(c,c);for(let d=c;d<t;d++)y.set(d,p,y.get(d,p)+S*y.get(d,c))}for(let p=c;p<t;p++)y.set(p,c,-y.get(p,c));y.set(c,c,1+y.get(c,c));for(let p=0;p<c-1;p++)y.set(p,c,0)}else{for(let p=0;p<t;p++)y.set(p,c,0);y.set(c,c,1)}}if(u)for(let c=s-1;c>=0;c--){if(c<R&&M[c]!==0)for(let p=c+1;p<s;p++){let S=0;for(let d=c+1;d<s;d++)S+=m.get(d,c)*m.get(d,p);S=-S/m.get(c+1,c);for(let d=c+1;d<s;d++)m.set(d,p,m.get(d,p)+S*m.get(d,c))}for(let p=0;p<s;p++)m.set(p,c,0);m.set(c,c,1)}let z=I-1,B=Number.EPSILON;for(;I>0;){let c,p;for(c=I-2;c>=-1&&c!==-1;c--){const S=Number.MIN_VALUE+B*Math.abs(w[c]+Math.abs(w[c+1]));if(Math.abs(M[c])<=S||Number.isNaN(M[c])){M[c]=0;break}}if(c===I-2)p=4;else{let S;for(S=I-1;S>=c&&S!==c;S--){let d=(S!==I?Math.abs(M[S]):0)+(S!==c+1?Math.abs(M[S-1]):0);if(Math.abs(w[S])<=B*d){w[S]=0;break}}S===c?p=3:S===I-1?p=1:(p=2,c=S)}switch(c++,p){case 1:{let S=M[I-2];M[I-2]=0;for(let d=I-2;d>=c;d--){let D=x(w[d],S),U=w[d]/D,F=S/D;if(w[d]=D,d!==c&&(S=-F*M[d-1],M[d-1]=U*M[d-1]),u)for(let P=0;P<s;P++)D=U*m.get(P,d)+F*m.get(P,I-1),m.set(P,I-1,-F*m.get(P,d)+U*m.get(P,I-1)),m.set(P,d,D)}break}case 2:{let S=M[c-1];M[c-1]=0;for(let d=c;d<I;d++){let D=x(w[d],S),U=w[d]/D,F=S/D;if(w[d]=D,S=-F*M[d],M[d]=U*M[d],l)for(let P=0;P<t;P++)D=U*y.get(P,d)+F*y.get(P,c-1),y.set(P,c-1,-F*y.get(P,d)+U*y.get(P,c-1)),y.set(P,d,D)}break}case 3:{const S=Math.max(Math.abs(w[I-1]),Math.abs(w[I-2]),Math.abs(M[I-2]),Math.abs(w[c]),Math.abs(M[c])),d=w[I-1]/S,D=w[I-2]/S,U=M[I-2]/S,F=w[c]/S,P=M[c]/S,Y=((D+d)*(D-d)+U*U)/2,G=d*U*(d*U);let N=0;(Y!==0||G!==0)&&(Y<0?N=0-Math.sqrt(Y*Y+G):N=Math.sqrt(Y*Y+G),N=G/(Y+N));let $=(F+d)*(F-d)+N,K=F*P;for(let v=c;v<I-1;v++){let V=x($,K);V===0&&(V=Number.MIN_VALUE);let L=$/V,C=K/V;if(v!==c&&(M[v-1]=V),$=L*w[v]+C*M[v],M[v]=L*M[v]-C*w[v],K=C*w[v+1],w[v+1]=L*w[v+1],u)for(let X=0;X<s;X++)V=L*m.get(X,v)+C*m.get(X,v+1),m.set(X,v+1,-C*m.get(X,v)+L*m.get(X,v+1)),m.set(X,v,V);if(V=x($,K),V===0&&(V=Number.MIN_VALUE),L=$/V,C=K/V,w[v]=V,$=L*M[v]+C*w[v+1],w[v+1]=-C*M[v]+L*w[v+1],K=C*M[v+1],M[v+1]=L*M[v+1],l&&v<t-1)for(let X=0;X<t;X++)V=L*y.get(X,v)+C*y.get(X,v+1),y.set(X,v+1,-C*y.get(X,v)+L*y.get(X,v+1)),y.set(X,v,V)}M[I-2]=$;break}case 4:{if(w[c]<=0&&(w[c]=w[c]<0?-w[c]:0,u))for(let S=0;S<=z;S++)m.set(S,c,-m.get(S,c));for(;c<z&&!(w[c]>=w[c+1]);){let S=w[c];if(w[c]=w[c+1],w[c+1]=S,u&&c<s-1)for(let d=0;d<s;d++)S=m.get(d,c+1),m.set(d,c+1,m.get(d,c)),m.set(d,c,S);if(l&&c<t-1)for(let d=0;d<t;d++)S=y.get(d,c+1),y.set(d,c+1,y.get(d,c)),y.set(d,c,S);c++}I--;break}}}if(f){let c=m;m=y,y=c}this.m=t,this.n=s,this.s=w,this.U=y,this.V=m}solve(n){let e=n,t=this.threshold,s=this.s.length,r=b.zeros(s,s);for(let a=0;a<s;a++)Math.abs(this.s[a])<=t?r.set(a,a,0):r.set(a,a,1/this.s[a]);let i=this.U,h=this.rightSingularVectors,l=h.mmul(r),u=h.rows,f=i.rows,g=b.zeros(u,f);for(let a=0;a<u;a++)for(let j=0;j<f;j++){let w=0;for(let y=0;y<s;y++)w+=l.get(a,y)*i.get(j,y);g.set(a,j,w)}return g.mmul(e)}solveForDiagonal(n){return this.solve(b.diag(n))}inverse(){let n=this.V,e=this.threshold,t=n.rows,s=n.columns,r=new b(t,this.s.length);for(let f=0;f<t;f++)for(let g=0;g<s;g++)Math.abs(this.s[g])>e&&r.set(f,g,n.get(f,g)/this.s[g]);let i=this.U,h=i.rows,l=i.columns,u=new b(t,h);for(let f=0;f<t;f++)for(let g=0;g<h;g++){let a=0;for(let j=0;j<l;j++)a+=r.get(f,j)*i.get(g,j);u.set(f,g,a)}return u}get condition(){return this.s[0]/this.s[Math.min(this.m,this.n)-1]}get norm2(){return this.s[0]}get rank(){let n=Math.max(this.m,this.n)*this.s[0]*Number.EPSILON,e=0,t=this.s;for(let s=0,r=t.length;s<r;s++)t[s]>n&&e++;return e}get diagonal(){return Array.from(this.s)}get threshold(){return Number.EPSILON/2*Math.max(this.m,this.n)*this.s[0]}get leftSingularVectors(){return this.U}get rightSingularVectors(){return this.V}get diagonalMatrix(){return b.diag(this.s)}}function Mt(o,n=!1){return o=st.checkMatrix(o),n?new Dt(o).inverse():qe(o,b.eye(o.rows))}function qe(o,n,e=!1){return o=st.checkMatrix(o),n=st.checkMatrix(n),e?new Dt(o).solve(n):o.isSquare()?new Ne(o).solve(n):new ve(o).solve(n)}const _e=1234,Te=()=>({seed:_e,arrayShuffle(n){const{arr:e,sampleSize:t}=n;for(let s=0;s<t;s++){this.seed=(214013*this.seed+2531011)%-2147483648;let r=this.seed>>16&32767;r=r%e.length;let i=e[s];e[s]=e[r],e[r]=i}},nextInt(n){this.seed=(214013*this.seed+2531011)%-2147483648;let e=this.seed>>16&32767;return e=e%n,e}}),J=(o,n,e)=>(n[0]-o[0])*(e[1]-o[1])-(n[1]-o[1])*(e[0]-o[0]),ze=(o,n,e,t,s,r,i,h)=>!(J(o,n,e)>0!=J(s,r,i)>0||J(n,e,t)>0!=J(r,i,h)>0||J(e,t,o)>0!=J(i,h,s)>0||J(t,o,n)>0!=J(h,s,r)>0),Fe=(o,n,e,t,s,r)=>J(o,n,e)>0==J(t,s,r)>0,Pe=o=>{const n=o[4]*o[8]-o[5]*o[7],e=o[3]*o[8]-o[5]*o[6],t=o[3]*o[7]-o[4]*o[6];return o[0]*n-o[1]*e+o[2]*t},Bt=(o,n)=>{const e=Pe(o);if(Math.abs(e)<=n)return null;const t=1/e;return[(o[4]*o[8]-o[5]*o[7])*t,(o[2]*o[7]-o[1]*o[8])*t,(o[1]*o[5]-o[2]*o[4])*t,(o[5]*o[6]-o[3]*o[8])*t,(o[0]*o[8]-o[2]*o[6])*t,(o[2]*o[3]-o[0]*o[5])*t,(o[3]*o[7]-o[4]*o[6])*t,(o[1]*o[6]-o[0]*o[7])*t,(o[0]*o[4]-o[1]*o[3])*t]},ot=(o,n)=>{const e=n[6]*o[0]+n[7]*o[1]+n[8],t=[];return t[0]=(n[0]*o[0]+n[1]*o[1]+n[2])/e,t[1]=(n[3]*o[0]+n[4]*o[1]+n[5])/e,t},De=(o,n,e,t)=>{const s=rt(n,o),r=rt(e,o),i=rt(t,o),h=rt(n,e),l=rt(t,e),u=mt(s,r),f=mt(r,i),g=mt(s,i),a=mt(h,l);return Math.min(Math.min(Math.min(u,f),g),a)},Be=(o,n,e,t)=>{const s=J(o,n,e)<=0;return!(J(n,e,t)<=0!==s||J(e,t,o)<=0!==s||J(t,o,n)<=0!==s)},rt=(o,n)=>[o[0]-n[0],o[1]-n[1]],mt=(o,n)=>{const e=o[0]*n[1]-o[1]*n[0];return Math.abs(e)*.5},Vt=(o,n)=>{const{normPoints:e,param:t}=Xt(o),{normPoints:s,param:r}=Xt(n),i=s.length,h=[],l=[];for(let u=0;u<i;u++){const f=[e[u][0],e[u][1],1,0,0,0,-(e[u][0]*s[u][0]),-(e[u][1]*s[u][0])],g=[0,0,0,e[u][0],e[u][1],1,-(e[u][0]*s[u][1]),-(e[u][1]*s[u][1])];h.push(f),h.push(g),l.push([s[u][0]]),l.push([s[u][1]])}try{const u=new b(h),f=new b(l),g=u.transpose(),a=g.mmul(u),j=g.mmul(f),y=Mt(a).mmul(j).to1DArray();return Ve(y,t,r)}catch{return null}},Xt=o=>{let n=0,e=0;for(let l=0;l<o.length;l++)n+=o[l][0],e+=o[l][1];let t=n/o.length,s=e/o.length,r=0;for(let l=0;l<o.length;l++){const u=o[l][0]-t,f=o[l][1]-s;r+=Math.sqrt(u*u+f*f)}let i=Math.sqrt(2)*o.length/r;const h=[];for(let l=0;l<o.length;l++)h.push([(o[l][0]-t)*i,(o[l][1]-s)*i]);return{normPoints:h,param:{meanX:t,meanY:s,s:i}}},Ve=(o,n,e)=>{const t=e.s*e.meanX,s=e.s*e.meanY,r=[o[0]+t*o[6],o[1]+t*o[7],(o[0]+t*o[6])*-n.meanX+(o[1]+t*o[7])*-n.meanY+(o[2]+t)/n.s,o[3]+s*o[6],o[4]+s*o[7],(o[3]+s*o[6])*-n.meanX+(o[4]+s*o[7])*-n.meanY+(o[5]+s)/n.s,e.s*o[6],e.s*o[7],e.s*o[6]*-n.meanX+e.s*o[7]*-n.meanY+e.s/n.s];for(let i=0;i<9;i++)r[i]=r[i]/r[8];return r},Xe=.01,Ue=10,$e=20,Le=10,Ut=o=>{const{srcPoints:n,dstPoints:e,keyframe:t,quickMode:s}=o,r=[[0,0],[t.width,0],[t.width,t.height],[0,t.height]],i=4;if(n.length<i)return null;const h=Xe,l=1/(h*h),u=Math.min(Ue,n.length),f=Te(),g=[];for(let E=0;E<n.length;E++)g[E]=E;f.arrayShuffle({arr:g,sampleSize:g.length});const a=s?Le:$e,j=a*2;let w=0;const y=[];for(;w<j&&y.length<a;){if(w+=1,f.arrayShuffle({arr:g,sampleSize:i}),!ze(n[g[0]],n[g[1]],n[g[2]],n[g[3]],e[g[0]],e[g[1]],e[g[2]],e[g[3]]))continue;const E=Vt([n[g[0]],n[g[1]],n[g[2]],n[g[3]]],[e[g[0]],e[g[1]],e[g[2]],e[g[3]]]);E!==null&&He({H:E,testPoints:r})&&y.push(E)}if(y.length===0)return null;const m=[];for(let E=0;E<y.length;E++)m.push({H:y[E],cost:0});let M=u;for(let E=0;E<n.length&&m.length>2;E+=M){M=Math.min(u,n.length-E);let k=E+M;for(let R=0;R<m.length;R++)for(let q=E;q<k;q++){const I=Ce({H:m[R].H,srcPoint:n[q],dstPoint:e[q],oneOverScale2:l});m[R].cost+=I}m.sort((R,q)=>R.cost-q.cost),m.splice(-Math.floor((m.length+1)/2))}let T=null;for(let E=0;E<m.length;E++){const k=Ye({inH:m[E].H});if(Oe({H:k,testPoints:r,keyframe:t})){T=k;break}}return T},Oe=({H:o,testPoints:n,keyframe:e})=>{const t=Bt(o,1e-5);if(t===null)return!1;const s=[];for(let i=0;i<n.length;i++)s.push(ot(n[i],t));return!(De(s[0],s[1],s[2],s[3])<e.width*e.height*1e-4||!Be(s[0],s[1],s[2],s[3]))},Ye=({inH:o})=>{const n=1/o[8],e=[];for(let t=0;t<8;t++)e[t]=o[t]*n;return e[8]=1,e},Ce=({H:o,srcPoint:n,dstPoint:e,oneOverScale2:t})=>{const s=ot(n,o),r=[s[0]-e[0],s[1]-e[1]];return Math.log(1+(r[0]*r[0]+r[1]*r[1])*t)},He=({H:o,testPoints:n})=>{const e=[];for(let t=0;t<n.length;t++)e[t]=ot(n[t],o);for(let t=0;t<n.length;t++){const s=t,r=(t+1)%n.length,i=(t+2)%n.length;if(!Fe(n[s],n[r],n[i],e[s],e[r],e[i]))return!1}return!0},$t=3,Lt=6,Ke=8,Ot=.7,Je=({keyframe:o,querypoints:n,querywidth:e,queryheight:t,debugMode:s})=>{let r={};const i=[];for(let m=0;m<n.length;m++){const M=n[m],T=M.maxima?o.maximaPoints:o.minimaPoints;if(T.length===0)continue;const E=M.maxima?o.maximaPointsCluster.rootNode:o.minimaPointsCluster.rootNode,k=[],R=new Wt([],(B,c)=>B.d-c.d);Et({node:E,keypoints:T,querypoint:M,queue:R,keypointIndexes:k,numPop:0});let q=-1,I=Number.MAX_SAFE_INTEGER,z=Number.MAX_SAFE_INTEGER;for(let B=0;B<k.length;B++){const c=T[k[B]],p=yt({v1:c.descriptors,v2:M.descriptors});p<I?(z=I,I=p,q=k[B]):p<z&&(z=p)}q!==-1&&(z===Number.MAX_SAFE_INTEGER||1*I/z<Ot)&&i.push({querypoint:M,keypoint:T[q]})}if(s&&(r.matches=i),i.length<Lt)return{debugExtra:r};const h=vt({keywidth:o.width,keyheight:o.height,querywidth:e,queryheight:t,matches:i});s&&(r.houghMatches=h);const l=Ut({srcPoints:h.map(m=>[m.keypoint.x,m.keypoint.y]),dstPoints:h.map(m=>[m.querypoint.x,m.querypoint.y]),keyframe:o});if(l===null)return{debugExtra:r};const u=Yt({H:l,matches:h,threshold:$t});if(s&&(r.inlierMatches=u),u.length<Lt)return{debugExtra:r};const f=Bt(l,1e-5),g=10*10,a=[];for(let m=0;m<n.length;m++){const M=n[m],T=ot([M.x,M.y],f);let E=-1,k=Number.MAX_SAFE_INTEGER,R=Number.MAX_SAFE_INTEGER;const q=M.maxima?o.maximaPoints:o.minimaPoints;for(let I=0;I<q.length;I++){const z=q[I];if((z.x-T[0])*(z.x-T[0])+(z.y-T[1])*(z.y-T[1])>g)continue;const c=yt({v1:z.descriptors,v2:M.descriptors});c<k?(R=k,k=c,E=I):c<R&&(R=c)}E!==-1&&(R===Number.MAX_SAFE_INTEGER||1*k/R<Ot)&&a.push({querypoint:M,keypoint:q[E]})}s&&(r.matches2=a);const j=vt({keywidth:o.width,keyheight:o.height,querywidth:e,queryheight:t,matches:a});s&&(r.houghMatches2=j);const w=Ut({srcPoints:j.map(m=>[m.keypoint.x,m.keypoint.y]),dstPoints:j.map(m=>[m.querypoint.x,m.querypoint.y]),keyframe:o});if(w===null)return{debugExtra:r};const y=Yt({H:w,matches:j,threshold:$t});return s&&(r.inlierMatches2=y),{H:w,matches:y,debugExtra:r}},Et=({node:o,keypoints:n,querypoint:e,queue:t,keypointIndexes:s,numPop:r})=>{if(o.leaf){for(let l=0;l<o.pointIndexes.length;l++)s.push(o.pointIndexes[l]);return}const i=[];for(let l=0;l<o.children.length;l++){const f=o.children[l].centerPointIndex,g=yt({v1:n[f].descriptors,v2:e.descriptors});i.push(g)}let h=Number.MAX_SAFE_INTEGER;for(let l=0;l<o.children.length;l++)h=Math.min(h,i[l]);for(let l=0;l<o.children.length;l++)i[l]!==h&&t.push({node:o.children[l],d:i[l]});for(let l=0;l<o.children.length;l++)i[l]===h&&Et({node:o.children[l],keypoints:n,querypoint:e,queue:t,keypointIndexes:s,numPop:r});if(r<Ke&&t.length>0){const{node:l,d:u}=t.pop();r+=1,Et({node:l,keypoints:n,querypoint:e,queue:t,keypointIndexes:s,numPop:r})}},Yt=o=>{const{H:n,matches:e,threshold:t}=o,s=t*t,r=[];for(let i=0;i<e.length;i++){const h=e[i].querypoint,l=e[i].keypoint,u=ot([l.x,l.y],n);(u[0]-h.x)*(u[0]-h.x)+(u[1]-h.y)*(u[1]-h.y)<=s&&r.push(e[i])}return r};class Ge{constructor(n,e,t=!1){this.queryWidth=n,this.queryHeight=e,this.debugMode=t}matchDetection(n,e){let t={frames:[]},s=null;for(let l=0;l<n.length;l++){const{H:u,matches:f,debugExtra:g}=Je({keyframe:n[l],querypoints:e,querywidth:this.queryWidth,queryheight:this.queryHeight,debugMode:this.debugMode});t.frames.push(g),u&&(s===null||s.matches.length<f.length)&&(s={keyframeIndex:l,H:u,matches:f})}if(s===null)return{keyframeIndex:-1,debugExtra:t};const r=[],i=[],h=n[s.keyframeIndex];for(let l=0;l<s.matches.length;l++){const u=s.matches[l].querypoint,f=s.matches[l].keypoint;r.push({x:u.x,y:u.y}),i.push({x:(f.x+.5)/h.scale,y:(f.y+.5)/h.scale,z:0})}return{screenCoords:r,worldCoords:i,keyframeIndex:s.keyframeIndex,debugExtra:t}}}const We=({screenCoords:o,worldCoords:n,projectionTransform:e})=>{const t=Vt(n.map(m=>[m.x,m.y]),o.map(m=>[m.x,m.y])),s=new b([[t[0],t[1],t[2]],[t[3],t[4],t[5]],[t[6],t[7],t[8]]]),r=new b(e),l=Mt(r).mmul(s).to1DArray(),u=Math.sqrt(l[0]*l[0]+l[3]*l[3]+l[6]*l[6]),f=Math.sqrt(l[1]*l[1]+l[4]*l[4]+l[7]*l[7]),g=(u+f)/2,a=[];a[0]=l[0]/u,a[3]=l[3]/u,a[6]=l[6]/u,a[1]=l[1]/f,a[4]=l[4]/f,a[7]=l[7]/f,a[2]=a[3]*a[7]-a[6]*a[4],a[5]=a[6]*a[1]-a[0]*a[7],a[8]=a[0]*a[4]-a[1]*a[3];const j=Math.sqrt(a[2]*a[2]+a[5]*a[5]+a[8]*a[8]);a[2]/=j,a[5]/=j,a[8]/=j;const w=[];return w[0]=l[2]/g,w[1]=l[5]/g,w[2]=l[8]/g,[[a[0],a[1],a[2],w[0]],[a[3],a[4],a[5],w[1]],[a[6],a[7],a[8],w[2]]]},Qe=(o,n)=>[[o[0][0]*n[0][0]+o[0][2]*n[2][0],o[0][0]*n[0][1]+o[0][2]*n[2][1],o[0][0]*n[0][2]+o[0][2]*n[2][2],o[0][0]*n[0][3]+o[0][2]*n[2][3]],[o[1][1]*n[1][0]+o[1][2]*n[2][0],o[1][1]*n[1][1]+o[1][2]*n[2][1],o[1][1]*n[1][2]+o[1][2]*n[2][2],o[1][1]*n[1][3]+o[1][2]*n[2][3]],[n[2][0],n[2][1],n[2][2],n[2][3]]],Ct=(o,n,e,t)=>{const s=o[0][0]*n+o[0][1]*e+o[0][3],r=o[1][0]*n+o[1][1]*e+o[1][3],i=o[2][0]*n+o[2][1]*e+o[2][3];return{x:s,y:r,z:i}},Ze=(o,n,e,t)=>{const{x:s,y:r,z:i}=Ct(o,n,e);return{x:s/i,y:r/i}},xe=5,Ae=4,Ht=10,tn=.1,en=.99;let H=[[],[],[]],A=[[],[]],O=[[],[],[]];const nn=({initialModelViewTransform:o,projectionTransform:n,worldCoords:e,screenCoords:t})=>{let s=0,r=0;for(let g=0;g<e.length;g++)s+=e[g].x,r+=e[g].y;s/=e.length,r/=e.length;const i=[];for(let g=0;g<e.length;g++)i.push({x:e[g].x-s,y:e[g].y-r,z:e[g].z});const h=[[],[],[]];for(let g=0;g<3;g++)for(let a=0;a<3;a++)h[g][a]=o[g][a];h[0][3]=o[0][0]*s+o[0][1]*r+o[0][3],h[1][3]=o[1][0]*s+o[1][1]*r+o[1][3],h[2][3]=o[2][0]*s+o[2][1]*r+o[2][3];const l=[1,.8,.6,.4,0];let u=h,f=null;for(let g=0;g<l.length;g++){const a=sn({initialModelViewTransform:u,projectionTransform:n,worldCoords:i,screenCoords:t,inlierProb:l[g]});if(u=a.modelViewTransform,a.err<xe){f=u;break}}return f===null?null:(f[0][3]=f[0][3]-f[0][0]*s-f[0][1]*r,f[1][3]=f[1][3]-f[1][0]*s-f[1][1]*r,f[2][3]=f[2][3]-f[2][0]*s-f[2][1]*r,f)},sn=({initialModelViewTransform:o,projectionTransform:n,worldCoords:e,screenCoords:t,inlierProb:s})=>{const r=s<1;let i=o,h=0,l=0,u=new Array(e.length),f=new Array(e.length),g=new Array(e.length),a=new Array(e.length);for(let j=0;j<=Ht;j++){const w=Qe(n,i);for(let E=0;E<e.length;E++){const k=Ze(w,e[E].x,e[E].y,e[E].z),R=t[E].x-k.x,q=t[E].y-k.y;g[E]=R,a[E]=q,u[E]=R*R+q*q}let y;if(l=0,r){const E=Math.max(3,Math.floor(e.length*s)-1);for(let k=0;k<e.length;k++)f[k]=u[k];f.sort((k,R)=>k-R),y=Math.max(f[E]*Ae,16);for(let k=0;k<e.length;k++)f[k]>y?l+=y/6:l+=y/6*(1-(1-f[k]/y)*(1-f[k]/y)*(1-f[k]/y))}else for(let E=0;E<e.length;E++)l+=u[E];if(l/=e.length,l<tn||j>0&&l/h>en||j===Ht)break;h=l;const m=[],M=[];for(let E=0;E<e.length;E++){if(r&&u[E]>y)continue;const k=ln({modelViewProjectionTransform:w,modelViewTransform:i,projectionTransform:n,worldCoord:e[E]});if(r){const R=(1-u[E]/y)*(1-u[E]/y);for(let q=0;q<2;q++)for(let I=0;I<6;I++)k[q][I]*=R;m.push([g[E]*R]),m.push([a[E]*R])}else m.push([g[E]]),m.push([a[E]]);for(let R=0;R<k.length;R++)M.push(k[R])}const T=rn({dU:m,J_U_S:M});if(T===null)break;i=on({modelViewTransform:i,dS:T})}return{modelViewTransform:i,err:l}},on=({modelViewTransform:o,dS:n})=>{let e=n[0]*n[0]+n[1]*n[1]+n[2]*n[2],t,s,r;e<1e-6?(t=1,s=0,r=0,e=0):(e=Math.sqrt(e),t=n[0]/e,s=n[1]/e,r=n[2]/e);const i=Math.cos(e),h=Math.sin(e),l=1-i;H[0][0]=t*t*l+i,H[0][1]=t*s*l-r*h,H[0][2]=t*r*l+s*h,H[0][3]=n[3],H[1][0]=s*t*l+r*h,H[1][1]=s*s*l+i,H[1][2]=s*r*l-t*h,H[1][3]=n[4],H[2][0]=r*t*l-s*h,H[2][1]=r*s*l+t*h,H[2][2]=r*r*l+i,H[2][3]=n[5];const u=[[],[],[]];for(let f=0;f<3;f++){for(let g=0;g<4;g++)u[f][g]=o[f][0]*H[0][g]+o[f][1]*H[1][g]+o[f][2]*H[2][g];u[f][3]+=o[f][3]}return u},rn=({dU:o,J_U_S:n})=>{const e=new b(n),t=new b(o),s=e.transpose(),r=s.mmul(e),i=s.mmul(t);let h;try{h=Mt(r)}catch{return null}return h.mmul(i).to1DArray()},ln=({modelViewProjectionTransform:o,modelViewTransform:n,projectionTransform:e,worldCoord:t})=>{const s=n,{x:r,y:i,z:h}=t,l=Ct(o,r,i),u=l.z*l.z;A[0][0]=e[0][0]*l.z/u,A[0][1]=e[0][1]*l.z/u,A[0][2]=(e[0][2]*l.z-e[2][2]*l.x)/u,A[1][0]=e[1][0]*l.z/u,A[1][1]=e[1][1]*l.z/u,A[1][2]=(e[1][2]*l.z-e[2][2]*l.y)/u,O[0][0]=s[0][2]*i,O[0][1]=-s[0][2]*r,O[0][2]=s[0][1]*r-s[0][0]*i,O[0][3]=s[0][0],O[0][4]=s[0][1],O[0][5]=s[0][2],O[1][0]=s[1][2]*i,O[1][1]=-s[1][2]*r,O[1][2]=s[1][1]*r-s[1][0]*i,O[1][3]=s[1][0],O[1][4]=s[1][1],O[1][5]=s[1][2],O[2][0]=s[2][2]*i,O[2][1]=-s[2][2]*r,O[2][2]=s[2][1]*r-s[2][0]*i,O[2][3]=s[2][0],O[2][4]=s[2][1],O[2][5]=s[2][2];const f=[[],[]];for(let g=0;g<2;g++)for(let a=0;a<6;a++){f[g][a]=0;for(let j=0;j<3;j++)f[g][a]+=A[g][j]*O[j][a]}return f};class hn{constructor(n){this.projectionTransform=n}estimate({screenCoords:n,worldCoords:e}){return We({screenCoords:n,worldCoords:e,projectionTransform:this.projectionTransform})}refineEstimate({initialModelViewTransform:n,worldCoords:e,screenCoords:t}){return nn({initialModelViewTransform:n,worldCoords:e,screenCoords:t,projectionTransform:this.projectionTransform})}}let Kt=null,Jt=!1,Gt=null,St=null;onmessage=o=>{const{data:n}=o;switch(n.type){case"setup":n.projectionTransform,Kt=n.matchingDataList,Jt=n.debugMode,Gt=new Ge(n.inputWidth,n.inputHeight,Jt),St=new hn(n.projectionTransform);break;case"match":const e=n.targetIndexes;let t=-1,s=null,r=null;for(let f=0;f<e.length;f++){const g=e[f],{keyframeIndex:a,screenCoords:j,worldCoords:w,debugExtra:y}=Gt.matchDetection(Kt[g],n.featurePoints);if(r=y,a!==-1){const m=St.estimate({screenCoords:j,worldCoords:w});m&&(t=g,s=m);break}}postMessage({type:"matchDone",targetIndex:t,modelViewTransform:s,debugExtra:r});break;case"trackUpdate":const{modelViewTransform:i,worldCoords:h,screenCoords:l}=n,u=St.refineEstimate({initialModelViewTransform:i,worldCoords:h,screenCoords:l});postMessage({type:"trackUpdateDone",modelViewTransform:u});break;case"dispose":close();break;default:throw new Error(`Invalid message type '${n.type}'`)}}})();
";
var vg = typeof window < "u" && window.Blob && new Blob([atob(fI)], { type: "text/javascript;charset=utf-8" });
function NU() {
  let n;
  try {
    if (n = vg && (window.URL || window.webkitURL).createObjectURL(vg), !n)
      throw "";
    return new Worker(n);
  } catch {
    return new Worker("data:application/javascript;base64," + fI);
  } finally {
    n && (window.URL || window.webkitURL).revokeObjectURL(n);
  }
}
var RU = (n, t) => [
  [
    n[0][0] * t[0][0] + n[0][2] * t[2][0],
    n[0][0] * t[0][1] + n[0][2] * t[2][1],
    n[0][0] * t[0][2] + n[0][2] * t[2][2],
    n[0][0] * t[0][3] + n[0][2] * t[2][3]
  ],
  [
    n[1][1] * t[1][0] + n[1][2] * t[2][0],
    n[1][1] * t[1][1] + n[1][2] * t[2][1],
    n[1][1] * t[1][2] + n[1][2] * t[2][2],
    n[1][1] * t[1][3] + n[1][2] * t[2][3]
  ],
  [
    t[2][0],
    t[2][1],
    t[2][2],
    t[2][3]
  ]
];
var $U = (n, t, e, s) => {
  const o = n[0][0] * t + n[0][1] * e + n[0][3], r = n[1][0] * t + n[1][1] * e + n[1][3], i6 = n[2][0] * t + n[2][1] * e + n[2][3];
  return { x: o, y: r, z: i6 };
};
var GU = (n, t, e, s) => {
  const { x: o, y: r, z: i6 } = $U(n, t, e);
  return { x: o / i6, y: r / i6 };
};
var EU = 6;
var LU = 1;
var MU = 10;
var WU = 1;
var DU = 0.8;
var FU = 1;
var _n = 1e3;
var VU = class {
  constructor(t, e, s, o, r, i6 = false) {
    this.markerDimensions = t, this.trackingDataList = e, this.projectionTransform = s, this.debugMode = i6, this.trackingKeyframeList = [];
    for (let l = 0; l < e.length; l++)
      this.trackingKeyframeList.push(e[l][FU]);
    let a = 0;
    for (let l = 0; l < this.trackingKeyframeList.length; l++)
      a = Math.max(a, this.trackingKeyframeList[l].points.length);
    this.featurePointsListT = [], this.imagePixelsListT = [], this.imagePropertiesListT = [];
    for (let l = 0; l < this.trackingKeyframeList.length; l++) {
      const { featurePoints: c, imagePixels: u, imageProperties: d } = this._prebuild(this.trackingKeyframeList[l], a);
      this.featurePointsListT[l] = c, this.imagePixelsListT[l] = u, this.imagePropertiesListT[l] = d;
    }
    this.kernelCaches = {};
  }
  dummyRun(t) {
    let e = [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]];
    for (let s = 0; s < this.featurePointsListT.length; s++)
      this.track(t, e, s);
  }
  track(t, e, s) {
    let o = {};
    const r = RU(this.projectionTransform, e), i6 = this._buildAdjustedModelViewTransform(r);
    this.markerDimensions[s][0], this.markerDimensions[s][1], this.trackingKeyframeList[s].width, this.trackingKeyframeList[s].height;
    const a = this.featurePointsListT[s], l = this.imagePixelsListT[s], c = this.imagePropertiesListT[s], u = this._computeProjection(i6, t, s), { matchingPointsT: d, simT: h6 } = this._computeMatching(a, l, c, u), p6 = d.arraySync(), f = h6.arraySync(), m = this.trackingKeyframeList[s], g6 = [], b6 = [], x6 = [];
    for (let w6 = 0; w6 < p6.length; w6++)
      if (f[w6] > DU && w6 < m.points.length) {
        x6.push(w6);
        const y6 = GU(r, p6[w6][0], p6[w6][1]);
        b6.push(y6), g6.push({ x: m.points[w6].x / m.scale, y: m.points[w6].y / m.scale, z: 0 });
      }
    return this.debugMode && (o = {
      projectedImage: u.arraySync(),
      matchingPoints: d.arraySync(),
      goodTrack: x6,
      trackedPoints: b6
    }), i6.dispose(), u.dispose(), d.dispose(), h6.dispose(), { worldCoords: g6, screenCoords: b6, debugExtra: o };
  }
  _computeMatching(t, e, s, o) {
    const r = EU, i6 = r * 2 + 1, l = MU * LU, c = WU, u = l * 2 + 1, d = o.shape[0], h6 = o.shape[1], p6 = t.shape[0];
    if (!this.kernelCaches.computeMatching) {
      const f = {
        variableNames: ["features", "markerPixels", "markerProperties", "targetPixels"],
        outputShape: [p6, u * u],
        userCode: `
	  void main() {
	    ivec2 coords = getOutputCoords();

	    int featureIndex = coords[0];
	    int searchOffsetIndex = coords[1];

	    int markerWidth = int(getMarkerProperties(0));
	    int markerHeight = int(getMarkerProperties(1));
	    float markerScale = getMarkerProperties(2);

	    int searchOffsetX = imod(searchOffsetIndex, ${u}) * ${c};
	    int searchOffsetY = searchOffsetIndex / ${u} * ${c};

	    int sCenterX = int(getFeatures(featureIndex, 0) * markerScale);
	    int sCenterY = int(getFeatures(featureIndex, 1) * markerScale);

	    int sx = sCenterX + searchOffsetX - ${l};
	    int sy = sCenterY + searchOffsetY - ${l};

	    if (sx < ${r} || sx >= (${h6} - ${r}) || sy < ${r} || sy >= (${d} - ${r})) {
	      setOutput(-2.);
	    } 
	    else {
	      float sumPoint = 0.;
	      float sumPointSquare = 0.;
	      float sumTemplate = 0.;
	      float sumTemplateSquare = 0.;
	      float sumPointTemplate = 0.;

	      for (int templateOffsetY = 0; templateOffsetY < ${i6}; templateOffsetY++) {
		for (int templateOffsetX = 0; templateOffsetX < ${i6}; templateOffsetX++) {
		  int fx2 = sCenterX + templateOffsetX - ${r};
		  int fy2 = sCenterY + templateOffsetY - ${r};

		  int sx2 = sx + templateOffsetX - ${r};
		  int sy2 = sy + templateOffsetY - ${r};

		  int markerPixelIndex = fy2 * markerWidth + fx2;
		  float markerPixel = getMarkerPixels(markerPixelIndex);
		  float targetPixel = getTargetPixels(sy2, sx2);

		  sumTemplate += markerPixel;
		  sumTemplateSquare += markerPixel * markerPixel;
		  sumPoint += targetPixel;
		  sumPointSquare += targetPixel * targetPixel;
		  sumPointTemplate += targetPixel * markerPixel;
		}
	      }

	      // Normalized cross-correlation
	      // !important divide first avoid overflow (e.g. sumPoint / count * sumPoint)
	      float count = float(${i6} * ${i6});
	      float pointVariance = sqrt(sumPointSquare - sumPoint / count * sumPoint);
	      float templateVariance = sqrt(sumTemplateSquare - sumTemplate / count * sumTemplate);

	      if (pointVariance < 0.0000001) {
		setOutput(-3.);
	      } else if (templateVariance < 0.0000001) {
		//setOutput(sumTemplate);
		setOutput(-4.);
	      } else {
		sumPointTemplate -= sumPoint / count * sumTemplate;
		float sim = sumPointTemplate / pointVariance / templateVariance;  
		setOutput(sim);
	      }
	    }
	  }
	`
      }, m = {
        variableNames: ["featurePoints", "markerProperties", "maxIndex"],
        outputShape: [p6, 2],
        // [x, y]
        userCode: `
	  void main() {
	    ivec2 coords = getOutputCoords();

	    float markerScale = getMarkerProperties(2);

	    int featureIndex = coords[0];

	    int maxIndex = int(getMaxIndex(featureIndex));
	    int searchLocationIndex = maxIndex / ${u * u};
	    int searchOffsetIndex = imod(maxIndex, ${u * u});

	    if (coords[1] == 0) {
	      int searchOffsetX = imod(searchOffsetIndex, ${u}) * ${c};
	      setOutput(getFeaturePoints(featureIndex, 0) + float(searchOffsetX - ${l}) / markerScale);
	    }
	    else if (coords[1] == 1) {
	      int searchOffsetY = searchOffsetIndex / ${u} * ${c};
	      setOutput(getFeaturePoints(featureIndex, 1) + float(searchOffsetY - ${l}) / markerScale);
	    }
	  }
	`
      }, g6 = {
        variableNames: ["sims", "maxIndex"],
        outputShape: [p6],
        userCode: `
	  void main() {
	    int featureIndex = getOutputCoords();
	    int maxIndex = int(getMaxIndex(featureIndex));
	    setOutput(getSims(featureIndex, maxIndex));
	  }
	`
      };
      this.kernelCaches.computeMatching = [f, m, g6];
    }
    return D(() => {
      const f = this.kernelCaches.computeMatching, m = this._compileAndRun(f[0], [t, e, s, o]), g6 = m.argMax(1), b6 = this._compileAndRun(f[1], [t, s, g6]), x6 = this._compileAndRun(f[2], [m, g6]);
      return { matchingPointsT: b6, simT: x6 };
    });
  }
  _computeProjection(t, e, s) {
    const o = this.trackingKeyframeList[s].width, r = this.trackingKeyframeList[s].height, i6 = this.trackingKeyframeList[s].scale, a = o + "-" + r + "-" + i6;
    if (this.kernelCaches.computeProjection || (this.kernelCaches.computeProjection = {}), !this.kernelCaches.computeProjection[a]) {
      const l = {
        variableNames: ["M", "pixel"],
        outputShape: [r, o],
        userCode: `
	  void main() {
	      ivec2 coords = getOutputCoords();

	      float m00 = getM(0, 0) * ${_n}.;
	      float m01 = getM(0, 1) * ${_n}.;
	      float m03 = getM(0, 3) * ${_n}.;
	      float m10 = getM(1, 0) * ${_n}.;
	      float m11 = getM(1, 1) * ${_n}.;
	      float m13 = getM(1, 3) * ${_n}.;
	      float m20 = getM(2, 0) * ${_n}.;
	      float m21 = getM(2, 1) * ${_n}.;
	      float m23 = getM(2, 3) * ${_n}.;

	      float y = float(coords[0]) / float(${i6});
	      float x = float(coords[1]) / float(${i6});
	      float uz = (x * m20) + (y * m21) + m23;
	      float oneOverUz = 1. / uz;

	      float ux = (x * m00) + (y * m01) + m03;
	      float uy = (x * m10) + (y * m11) + m13;

	      ux = floor(ux * oneOverUz + 0.5);
	      uy = floor(uy * oneOverUz + 0.5);
	      setOutput(getPixel(int(uy), int(ux)));
	    }
	`
      };
      this.kernelCaches.computeProjection[a] = l;
    }
    return D(() => {
      const l = this.kernelCaches.computeProjection[a];
      return this._compileAndRun(l, [t, e]);
    });
  }
  _buildAdjustedModelViewTransform(t) {
    return D(() => {
      let e = [];
      for (let o = 0; o < t.length; o++) {
        e.push([]);
        for (let r = 0; r < t[o].length; r++)
          e[o].push(t[o][r] / _n);
      }
      return Re(e, [3, 4]);
    });
  }
  _prebuild(t, e) {
    return D(() => {
      const s = t.scale, o = [];
      for (let l = 0; l < e; l++)
        l < t.points.length ? o.push([t.points[l].x / s, t.points[l].y / s]) : o.push([-1, -1]);
      const r = Re(t.data, [t.width * t.height]), i6 = Re([t.width, t.height, t.scale], [3]);
      return {
        featurePoints: Re(o, [o.length, 2], "float32"),
        imagePixels: r,
        imageProperties: i6
      };
    });
  }
  _compileAndRun(t, e) {
    const s = $s().compileAndRun(t, e);
    return Xt().makeTensorFromDataId(s.dataId, s.shape, s.dtype);
  }
};
var _a = [
  // ring 5
  {
    sigma: 0.55,
    points: [
      [-1, 0],
      [-0.5, -0.866025],
      [0.5, -0.866025],
      [1, -0],
      [0.5, 0.866025],
      [-0.5, 0.866025]
    ]
  },
  // ring 4
  {
    sigma: 0.475,
    points: [
      [0, 0.930969],
      [-0.806243, 0.465485],
      [-0.806243, -0.465485],
      [-0, -0.930969],
      [0.806243, -0.465485],
      [0.806243, 0.465485]
    ]
  },
  // ring 3
  {
    sigma: 0.4,
    points: [
      [0.847306, -0],
      [0.423653, 0.733789],
      [-0.423653, 0.733789],
      [-0.847306, 0],
      [-0.423653, -0.733789],
      [0.423653, -0.733789]
    ]
  },
  // ring 2
  {
    sigma: 0.325,
    points: [
      [-0, -0.741094],
      [0.641806, -0.370547],
      [0.641806, 0.370547],
      [0, 0.741094],
      [-0.641806, 0.370547],
      [-0.641806, -0.370547]
    ]
  },
  // ring 1
  {
    sigma: 0.25,
    points: [
      [-0.595502, 0],
      [-0.297751, -0.51572],
      [0.297751, -0.51572],
      [0.595502, -0],
      [0.297751, 0.51572],
      [-0.297751, 0.51572]
    ]
  },
  // ring 0
  {
    sigma: 0.175,
    points: [
      [0, 0.362783],
      [-0.314179, 0.181391],
      [-0.314179, -0.181391],
      [-0, -0.362783],
      [0.314179, -0.181391],
      [0.314179, 0.181391]
    ]
  },
  // center
  {
    sigma: 0.1,
    points: [
      [0, 0]
    ]
  }
];
var Eo = [];
for (let n = 0; n < _a.length; n++) {
  const t = _a[n].sigma;
  for (let e = 0; e < _a[n].points.length; e++) {
    const s = _a[n].points[e];
    Eo.push([t, s[0], s[1]]);
  }
}
var Fu = {};
function zU(n) {
  const t = n.shape[1], e = n.shape[0], s = "w" + t + "h" + e;
  if (!Fu.hasOwnProperty(s)) {
    const o = {
      variableNames: ["p"],
      outputShape: [e, t],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();

          float sum = getP(coords[0], coords[1]-2);
          sum += getP(coords[0], coords[1]-1) * 4.;
          sum += getP(coords[0], coords[1]) * 6.;
          sum += getP(coords[0], coords[1]+1) * 4.;
          sum += getP(coords[0], coords[1]+2);
          setOutput(sum);
        }
      `
    }, r = {
      variableNames: ["p"],
      outputShape: [e, t],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();

          float sum = getP(coords[0]-2, coords[1]);
          sum += getP(coords[0]-1, coords[1]) * 4.;
          sum += getP(coords[0], coords[1]) * 6.;
          sum += getP(coords[0]+1, coords[1]) * 4.;
          sum += getP(coords[0]+2, coords[1]);
          sum /= 256.;
          setOutput(sum);
        }
      `
    };
    Fu[s] = [o, r];
  }
  return Fu[s];
}
var XU = (n) => {
  const t = n.inputs.image, e = n.backend, [s, o] = zU(t), r = e.runWebGLProgram(s, [t], t.dtype), i6 = e.runWebGLProgram(o, [r], t.dtype);
  return e.disposeIntermediateTensorInfo(r), i6;
};
var PU = {
  //: KernelConfig
  kernelName: "BinomialFilter",
  backendName: "webgl",
  kernelFunc: XU
  // as {} as KernelFunc,
};
var Ua = 7;
var Sg = 3;
var AU = Sg * Sg;
var Vu = 4;
var OU = (Vu + 1) * (Vu + 1) / Vu;
var zu = {};
function KU(n) {
  const t = n.shape[1], e = n.shape[0], s = "w" + t + "h" + e;
  if (!zu.hasOwnProperty(s)) {
    const o = {
      variableNames: ["image0", "image1", "image2"],
      outputShape: [e, t],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();
    
          int y = coords[0];
          int x = coords[1];
    
          float value = getImage1(y, x);
    
          // Step 1: find local maxima/minima
          if (value * value < ${AU}.) {
            setOutput(0.);
            return;
          }
          if (y < ${Ua} || y > ${e - 1 - Ua}) {
            setOutput(0.);
            return;
          }
          if (x < ${Ua} || x > ${t - 1 - Ua}) {
            setOutput(0.);
            return;
          }
    
          bool isMax = true;
          bool isMin = true;
          for (int dy = -1; dy <= 1; dy++) {
            for (int dx = -1; dx <= 1; dx++) {
              float value0 = getImage0(y+dy, x+dx);
              float value1 = getImage1(y+dy, x+dx);
              float value2 = getImage2(y+dy, x+dx);
    
        if (value < value0 || value < value1 || value < value2) {
          isMax = false;
        }
        if (value > value0 || value > value1 || value > value2) {
          isMin = false;
        }
            }
          }
    
          if (!isMax && !isMin) {
            setOutput(0.);
            return;
          }
    
          // compute edge score and reject based on threshold
          float dxx = getImage1(y, x+1) + getImage1(y, x-1) - 2. * getImage1(y, x);
          float dyy = getImage1(y+1, x) + getImage1(y-1, x) - 2. * getImage1(y, x);
          float dxy = 0.25 * (getImage1(y-1,x-1) + getImage1(y+1,x+1) - getImage1(y-1,x+1) - getImage1(y+1,x-1));
    
          float det = (dxx * dyy) - (dxy * dxy);
    
          if (abs(det) < 0.0001) { // determinant undefined. no solution
            setOutput(0.);
            return;
          }
    
          float edgeScore = (dxx + dyy) * (dxx + dyy) / det;
    
          if (abs(edgeScore) >= ${OU} ) {
            setOutput(0.);
            return;
          }
          setOutput(getImage1(y,x));
        }
      `
    };
    zu[s] = o;
  }
  return zu[s];
}
var ZU = (n) => {
  let { image0: t, image1: e, image2: s } = n.inputs;
  const o = n.backend, r = KU(e);
  return t = Xt().runKernel("DownsampleBilinear", { image: t }), s = Xt().runKernel("UpsampleBilinear", { image: s, targetImage: e }), o.runWebGLProgram(r, [t, e, s], e.dtype);
};
var BU = {
  //: KernelConfig
  kernelName: "BuildExtremas",
  backendName: "webgl",
  kernelFunc: ZU
  // as {} as KernelFunc,
};
var Fr = 36;
var Xu = {};
function HU(n) {
  const t = n.shape[0];
  if (!Xu.hasOwnProperty(t)) {
    const e = {
      variableNames: ["histogram"],
      outputShape: [n.shape[0]],
      userCode: `
            void main() {
                int featureIndex = getOutputCoords();

                int maxIndex = 0;
                for (int i = 1; i < ${Fr}; i++) {
                    if (getHistogram(featureIndex, i) > getHistogram(featureIndex, maxIndex)) {
                        maxIndex = i;
                    }
                }

                int prev = imod(maxIndex - 1 + ${Fr}, ${Fr});
                int next = imod(maxIndex + 1, ${Fr});

                /**
                 * Fit a quatratic to 3 points. The system of equations is:
                 *
                 * y0 = A*x0^2 + B*x0 + C
                 * y1 = A*x1^2 + B*x1 + C
                 * y2 = A*x2^2 + B*x2 + C
                 *
                 * This system of equations is solved for A,B,C.
                 */
                float p10 = float(maxIndex - 1);
                float p11 = getHistogram(featureIndex, prev); 
                float p20 = float(maxIndex);
                float p21 = getHistogram(featureIndex, maxIndex); 
                float p30 = float(maxIndex + 1);
                float p31 = getHistogram(featureIndex, next); 

                float d1 = (p30-p20)*(p30-p10);
                float d2 = (p10-p20)*(p30-p10);
                float d3 = p10-p20;

                // If any of the denominators are zero then, just use maxIndex.
                    float fbin = float(maxIndex);
                if ( abs(d1) > 0.00001 && abs(d2) > 0.00001 && abs(d3) > 0.00001) {
                float a = p10*p10;
                float b = p20*p20;

                // Solve for the coefficients A,B,C
                float A = ((p31-p21)/d1)-((p11-p21)/d2);
                float B = ((p11-p21)+(A*(b-a)))/d3;
                float C = p11-(A*a)-(B*p10);
                fbin = -B / (2. * A);
                }

                float an = 2.0 *${Math.PI} * (fbin + 0.5) / ${Fr}. - ${Math.PI};
                setOutput(an);
            }
            `
    };
    Xu[t] = e;
  }
  return Xu[t];
}
var _U = (n) => {
  const { histograms: t } = n.inputs, e = n.backend, s = HU(t);
  return e.runWebGLProgram(s, [t], t.dtype);
};
var UU = {
  //: KernelConfig
  kernelName: "ComputeExtremaAngles",
  backendName: "webgl",
  kernelFunc: _U
  // as {} as KernelFunc,
};
var kg = 7;
var Pu = {};
function YU(n, t) {
  const e = `${n}|${t.shape[0]}`;
  if (!Pu.hasOwnProperty(e)) {
    const s = [];
    for (let i6 = 1; i6 < n; i6++)
      s.push("image" + i6);
    let o = "float getPixel(int octave, int y, int x) {";
    for (let i6 = 1; i6 < n; i6++)
      o += `
  if (octave == ${i6}) {
	return getImage${i6}(y, x);
  }
`;
    o += "}";
    const r = {
      variableNames: [...s, "extrema", "angles", "freakPoints"],
      outputShape: [t.shape[0], Eo.length],
      userCode: `
  ${o}
  void main() {
	ivec2 coords = getOutputCoords();
	int featureIndex = coords[0];
	int freakIndex = coords[1];

	float freakSigma = getFreakPoints(freakIndex, 0);
	float freakX = getFreakPoints(freakIndex, 1);
	float freakY = getFreakPoints(freakIndex, 2);

	int octave = int(getExtrema(featureIndex, 1));
	float inputY = getExtrema(featureIndex, 2);
	float inputX = getExtrema(featureIndex, 3);
	float inputAngle = getAngles(featureIndex);
	float cos = ${kg}. * cos(inputAngle);
	float sin = ${kg}. * sin(inputAngle);

	float yp = inputY + freakX * sin + freakY * cos;
	float xp = inputX + freakX * cos + freakY * -sin;

	int x0 = int(floor(xp));
	int x1 = x0 + 1;
	int y0 = int(floor(yp));
	int y1 = y0 + 1;

	float f1 = getPixel(octave, y0, x0);
	float f2 = getPixel(octave, y0, x1);
	float f3 = getPixel(octave, y1, x0);
	float f4 = getPixel(octave, y1, x1);

	float x1f = float(x1);
	float y1f = float(y1);
	float x0f = float(x0);
	float y0f = float(y0);

	// ratio for interpolation between four neighbouring points
	float value = (x1f - xp) * (y1f - yp) * f1
		+ (xp - x0f) * (y1f - yp) * f2
		+ (x1f - xp) * (yp - y0f) * f3
		+ (xp - x0f) * (yp - y0f) * f4;

	setOutput(value);
  }
`
    };
    Pu[e] = r;
  }
  return Pu[e];
}
var QU = (n) => {
  const { gaussianImagesT: t, prunedExtremas: e, prunedExtremasAngles: s, freakPointsT: o, pyramidImagesLength: r } = n.inputs, i6 = n.backend, a = YU(r, e);
  return i6.runWebGLProgram(a, [...t, e, s, o], "float32");
};
var JU = {
  //: KernelConfig
  kernelName: "ComputeExtremaFreak",
  backendName: "webgl",
  kernelFunc: QU
  // as {} as KernelFunc,
};
var mI = (Eo.length - 1) * Eo.length / 2;
var jU = Math.ceil(mI / 8);
var Au = {};
function qU(n) {
  const t = `${n.shape[0]}`;
  if (!Au.hasOwnProperty(t)) {
    const e = {
      variableNames: ["freak", "p"],
      outputShape: [n.shape[0], jU],
      userCode: `
  void main() {
    ivec2 coords = getOutputCoords();
    int featureIndex = coords[0];
    int descIndex = coords[1] * 8;

    int sum = 0;
    for (int i = 0; i < 8; i++) {
      if (descIndex + i >= ${mI}) {
        continue;
      }

      int p1 = int(getP(descIndex + i, 0));
      int p2 = int(getP(descIndex + i, 1));

      float v1 = getFreak(featureIndex, p1);
      float v2 = getFreak(featureIndex, p2);

      if (v1 < v2 + 0.01) {
        sum += int(pow(2.0, float(7 - i)));
      }
    }
    setOutput(float(sum));
  }
`
    };
    Au[t] = e;
  }
  return Au[t];
}
var t5 = (n) => {
  const { extremaFreaks: t, positionT: e } = n.inputs, { backend: s } = n, o = qU(t);
  return s.runWebGLProgram(o, [t, e], "int32");
};
var e5 = {
  //: KernelConfig
  kernelName: "ComputeFreakDescriptors",
  backendName: "webgl",
  kernelFunc: t5
  // as {} as KernelFunc,
};
var Ou = {};
function n5(n, t) {
  const e = `${n}|${t}`;
  if (!Ou.hasOwnProperty(e)) {
    const s = [];
    let o = "float getPixel(int octave, int y, int x) {";
    for (let r = 1; r < n; r++)
      s.push("image" + r), o += `
				if (octave == ${r}) {
					return getImage${r}(y, x);
				}
			`;
    o += "}", Ou[e] = {
      variableNames: [...s, "extrema"],
      outputShape: [t, 3, 3],
      // 3x3 pixels around the extrema
      userCode: `
			${o}
		
			void main() {
				ivec3 coords = getOutputCoords();
				int featureIndex = coords[0];
				float score = getExtrema(featureIndex, 0);
				if (score == 0.0) {
					return;
				}
		
				int dy = coords[1]-1;
				int dx = coords[2]-1;
				int octave = int(getExtrema(featureIndex, 1));
				int y = int(getExtrema(featureIndex, 2));
				int x = int(getExtrema(featureIndex, 3));
				setOutput(getPixel(octave, y+dy, x+dx));
			}
			`
    };
  }
  return Ou[e];
}
var s5 = (n) => {
  const { prunedExtremasList: t, dogPyramidImagesT: e } = n.inputs, s = n.backend, o = n5(e.length, t.length), r = Re(t, [t.length, t[0].length], "int32");
  return s.runWebGLProgram(o, [...e.slice(1), r], e[0].dtype);
};
var o5 = {
  //: KernelConfig
  kernelName: "ComputeLocalization",
  backendName: "webgl",
  kernelFunc: s5
  // as {} as KernelFunc,
};
var r5 = 0.159154943091895;
var Ho = 36;
var Ku = {};
function i5(n, t, e) {
  const s = `${e}|${n.shape[0]}|${t.shape[0]}`;
  if (!Ku.hasOwnProperty(s)) {
    const o = [];
    for (let l = 1; l < e; l++)
      o.push("image" + l);
    let r = "float getPixel(int octave, int y, int x) {";
    for (let l = 1; l < e; l++)
      r += `
            if (octave == ${l}) {
                return getImage${l}(y, x);
            }
            `;
    r += "}";
    const i6 = {
      variableNames: [...o, "extrema", "radial"],
      outputShape: [n.shape[0], t.shape[0], 2],
      // last dimension: [fbin, magnitude]
      userCode: `
                ${r}

                void main() {
                    ivec3 coords = getOutputCoords();
                    int featureIndex = coords[0];
                    int radialIndex = coords[1];
                    int propertyIndex = coords[2];

                    int radialY = int(getRadial(radialIndex, 0));
                    int radialX = int(getRadial(radialIndex, 1));
                    float radialW = getRadial(radialIndex, 2);

                    int octave = int(getExtrema(featureIndex, 1));
                    int y = int(getExtrema(featureIndex, 2));
                    int x = int(getExtrema(featureIndex, 3));

                    int xp = x + radialX;
                    int yp = y + radialY;

                    float dy = getPixel(octave, yp+1, xp) - getPixel(octave, yp-1, xp);
                    float dx = getPixel(octave, yp, xp+1) - getPixel(octave, yp, xp-1);

                    if (propertyIndex == 0) {
                    // be careful that atan(0, 0) gives 1.57 instead of 0 (different from js), but doesn't matter here, coz magnitude is 0
                    
                    float angle = atan(dy, dx) + ${Math.PI};
                    float fbin = angle * ${Ho}. * ${r5};
                    setOutput(fbin);
                    return;
                    }

                    if (propertyIndex == 1) {
                        float mag = sqrt(dx * dx + dy * dy);
                        float magnitude = radialW * mag;
                        setOutput(magnitude);
                        return;
                    }
                }

                `
    }, a = {
      variableNames: ["fbinMag"],
      outputShape: [n.shape[0], Ho],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();
                int featureIndex = coords[0];
                int binIndex = coords[1];

                float sum = 0.;
                for (int i = 0; i < ${t.shape[0]}; i++) {
                    float fbin = getFbinMag(featureIndex, i, 0);
                    int bin = int(floor(fbin - 0.5));
                    int b1 = imod(bin + ${Ho}, ${Ho});
                    int b2 = imod(bin + 1 + ${Ho}, ${Ho});

                    if (b1 == binIndex || b2 == binIndex) {
                        float magnitude = getFbinMag(featureIndex, i, 1);
                        float w2 = fbin - float(bin) - 0.5;
                        float w1 = w2 * -1. + 1.;

                        if (b1 == binIndex) {
                            sum += w1 * magnitude;
                        }
                        if (b2 == binIndex) {
                            sum += w2 * magnitude;
                        }
                    }
                }
                setOutput(sum);
            }
            `
    };
    Ku[s] = [i6, a];
  }
  return Ku[s];
}
var a5 = (n) => {
  const { gaussianImagesT: t, prunedExtremasT: e, radialPropertiesT: s, pyramidImagesLength: o } = n.inputs, r = n.backend, [i6, a] = i5(e, s, o), l = r.runWebGLProgram(i6, [...t, e, s], s.dtype), c = r.runWebGLProgram(a, [l], s.dtype);
  return r.disposeIntermediateTensorInfo(l), c;
};
var l5 = {
  kernelName: "ComputeOrientationHistograms",
  backendName: "webgl",
  kernelFunc: a5
  // as {} as KernelFunc,
};
var Zu = {};
function c5(n) {
  const t = n.shape[1], e = n.shape[0], s = "w" + t + "h" + e;
  if (!Zu.hasOwnProperty(s)) {
    const o = {
      variableNames: ["p"],
      outputShape: [Math.floor(e / 2), Math.floor(t / 2)],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();
                int y = coords[0] * 2;
                int x = coords[1] * 2;
        
                float sum = getP(y, x) * 0.25;
                sum += getP(y+1,x) * 0.25; 
                sum += getP(y, x+1) * 0.25; 
                sum += getP(y+1,x+1) * 0.25;
                setOutput(sum);
            }
            `
    };
    Zu[s] = o;
  }
  return Zu[s];
}
var u5 = (n) => {
  const t = n.inputs.image, e = n.backend, s = c5(t);
  return e.runWebGLProgram(s, [t], t.dtype);
};
var d5 = {
  //: KernelConfig
  kernelName: "DownsampleBilinear",
  backendName: "webgl",
  kernelFunc: u5
  // as {} as KernelFunc,
};
var h5 = (n) => {
  const { extremasResultT: t } = n.inputs, e = n.backend, s = t.shape[0], o = t.shape[1], r = {
    variableNames: ["extrema"],
    outputShape: [Math.floor(s / 2), Math.floor(o / 2)],
    userCode: `
		  void main() {
			ivec2 coords = getOutputCoords();
			int y = coords[0] * 2;
			int x = coords[1] * 2;
  
			float location = 0.0;
			float values = getExtrema(y, x);
  
			if (getExtrema(y+1, x) != 0.0) {
			  location = 1.0;
		  values = getExtrema(y+1, x);
			}
			else if (getExtrema(y, x+1) != 0.0) {
			  location = 2.0;
		  values = getExtrema(y, x+1);
			}
			else if (getExtrema(y+1, x+1) != 0.0) {
			  location = 3.0;
		  values = getExtrema(y+1, x+1);
			}
  
			if (values < 0.0) {
			  setOutput(location * -1000.0 + values);
			} else {
			  setOutput(location * 1000.0 + values);
			}
		  }
		`
  };
  return e.runWebGLProgram(r, [t], t.dtype);
};
var p5 = {
  //: KernelConfig
  kernelName: "ExtremaReduction",
  backendName: "webgl",
  kernelFunc: h5
  // as {} as KernelFunc,
};
var Ya = 36;
var f5 = 5;
var Bu = {};
function m5(n) {
  const t = `h${n.shape[0]}`;
  if (!Bu.hasOwnProperty(t)) {
    const e = {
      variableNames: ["histogram"],
      outputShape: [n.shape[0], Ya],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();

                int featureIndex = coords[0];
                int binIndex = coords[1];

                int prevBin = imod(binIndex - 1 + ${Ya}, ${Ya});
                int nextBin = imod(binIndex + 1, ${Ya});
                float result = 0.274068619061197 * getHistogram(featureIndex, prevBin) + 0.451862761877606 * getHistogram(featureIndex, binIndex) + 0.274068619061197 * getHistogram(featureIndex, nextBin);

                setOutput(result);
            }
            `
    };
    Bu[t] = e;
  }
  return Bu[t];
}
var g5 = (n) => {
  let { histograms: t } = n.inputs;
  const e = n.backend, s = m5(t);
  for (let o = 0; o < f5; o++) {
    const r = t;
    t = e.runWebGLProgram(s, [t], t.dtype), o > 0 && e.disposeIntermediateTensorInfo(r);
  }
  return t;
};
var b5 = {
  //: KernelConfig
  kernelName: "SmoothHistograms",
  backendName: "webgl",
  kernelFunc: g5
  // as {} as KernelFunc,
};
var Hu = {};
function x5(n, t) {
  const e = t.shape[1], s = t.shape[0], o = "w" + e + "h" + s;
  if (!Hu.hasOwnProperty(o)) {
    const r = {
      variableNames: ["p"],
      outputShape: [s, e],
      userCode: `
              void main() {
                ivec2 coords = getOutputCoords();
                int j = coords[0];
                int i = coords[1];
        
                float sj = 0.5 * float(j) - 0.25; 
                float si = 0.5 * float(i) - 0.25;
        
                float sj0 = floor(sj);
                float sj1 = ceil(sj);
                float si0 = floor(si);
                float si1 = ceil(si);
        
                int sj0I = int(sj0);
                int sj1I = int(sj1);
                int si0I = int(si0);
                int si1I = int(si1);
        
                float sum = 0.0;
                sum += getP(sj0I, si0I) * (si1 - si) * (sj1 - sj);
                sum += getP(sj1I, si0I) * (si1 - si) * (sj - sj0);
                sum += getP(sj0I, si1I) * (si - si0) * (sj1 - sj);
                sum += getP(sj1I, si1I) * (si - si0) * (sj - sj0);
                setOutput(sum);
              }
            `
    };
    Hu[o] = r;
  }
  return Hu[o];
}
var y5 = (n) => {
  const { image: t, targetImage: e } = n.inputs, s = n.backend, o = x5(t, e);
  return s.runWebGLProgram(o, [t], t.dtype);
};
var w5 = {
  //: KernelConfig
  kernelName: "UpsampleBilinear",
  backendName: "webgl",
  kernelFunc: y5
  // as {} as KernelFunc,
};
en(PU);
en(BU);
en(UU);
en(JU);
en(e5);
en(o5);
en(l5);
en(d5);
en(p5);
en(b5);
en(w5);
var Tg = 8;
var I5 = 5;
var Vr = 10;
var C5 = 5;
var _u = 3;
var v5 = 1.5;
(Eo.length - 1) * Eo.length / 2;
var gI = class {
  constructor(t, e, s = false) {
    this.debugMode = s, this.width = t, this.height = e;
    let o = 0;
    for (; t >= Tg && e >= Tg && (t /= 2, e /= 2, o++, o !== I5); )
      ;
    this.numOctaves = o, this.tensorCaches = {}, this.kernelCaches = {};
  }
  // used in compiler
  detectImageData(t) {
    const e = new Uint8ClampedArray(4 * t.length);
    for (let o = 0; o < t.length; o++)
      e[4 * o] = t[o], e[4 * o + 1] = t[o], e[4 * o + 2] = t[o], e[4 * o + 3] = 255;
    const s = new ImageData(e, this.width, this.height);
    return this.detect(s);
  }
  /**
   * 
   * @param {tf.Tensor<tf.Rank>} inputImageT 
   * @returns 
   */
  detect(t) {
    let e = null;
    const s = [];
    for (let b6 = 0; b6 < this.numOctaves; b6++) {
      let x6, w6;
      b6 === 0 ? x6 = this._applyFilter(t) : x6 = this._downsampleBilinear(s[b6 - 1][s[b6 - 1].length - 1]), w6 = this._applyFilter(x6), s.push([x6, w6]);
    }
    const o = [];
    for (let b6 = 0; b6 < this.numOctaves; b6++) {
      let x6 = this._differenceImageBinomial(s[b6][0], s[b6][1]);
      o.push(x6);
    }
    const r = [];
    for (let b6 = 1; b6 < this.numOctaves - 1; b6++) {
      const x6 = this._buildExtremas(o[b6 - 1], o[b6], o[b6 + 1]);
      r.push(x6);
    }
    const i6 = this._applyPrune(r), a = this._computeLocalization(i6, o), l = this._computeOrientationHistograms(a, s), c = this._smoothHistograms(l), u = this._computeExtremaAngles(c), d = this._computeExtremaFreak(s, a, u), h6 = this._computeFreakDescriptors(d), p6 = a.arraySync(), f = u.arraySync(), m = h6.arraySync();
    this.debugMode && (e = {
      pyramidImages: s.map((b6) => b6.map((x6) => x6.arraySync())),
      dogPyramidImages: o.map((b6) => b6 ? b6.arraySync() : null),
      extremasResults: r.map((b6) => b6.arraySync()),
      extremaAngles: u.arraySync(),
      prunedExtremas: i6,
      localizedExtremas: a.arraySync()
    }), s.forEach((b6) => b6.forEach((x6) => x6.dispose())), o.forEach((b6) => b6 && b6.dispose()), r.forEach((b6) => b6.dispose()), a.dispose(), l.dispose(), c.dispose(), u.dispose(), d.dispose(), h6.dispose();
    const g6 = [];
    for (let b6 = 0; b6 < p6.length; b6++) {
      if (p6[b6][0] == 0)
        continue;
      const x6 = [];
      for (let N = 0; N < m[b6].length; N += 4) {
        const R = m[b6][N], M6 = m[b6][N + 1], V = m[b6][N + 2], z = m[b6][N + 3];
        let X = R * 16777216 + M6 * 65536 + V * 256 + z;
        x6.push(X);
      }
      const w6 = p6[b6][1], y6 = p6[b6][2], C6 = p6[b6][3] * Math.pow(2, w6) + Math.pow(2, w6 - 1) - 0.5, k7 = y6 * Math.pow(2, w6) + Math.pow(2, w6 - 1) - 0.5, S = Math.pow(2, w6);
      g6.push({
        maxima: p6[b6][0] > 0,
        x: C6,
        y: k7,
        scale: S,
        angle: f[b6],
        descriptors: x6
      });
    }
    return { featurePoints: g6, debugExtra: e };
  }
  _computeFreakDescriptors(t) {
    if (!this.tensorCaches.computeFreakDescriptors) {
      const s = [], o = [];
      for (let a = 0; a < t.shape[1]; a++)
        for (let l = a + 1; l < t.shape[1]; l++)
          s.push(a), o.push(l);
      const r = Re(s, [s.length]).cast("int32"), i6 = Re(o, [o.length]).cast("int32");
      this.tensorCaches.computeFreakDescriptors = {
        positionT: cn(os([r, i6], 1))
      };
    }
    const { positionT: e } = this.tensorCaches.computeFreakDescriptors;
    return D(() => Xt().runKernel("ComputeFreakDescriptors", { extremaFreaks: t, positionT: e }));
  }
  _computeExtremaFreak(t, e, s) {
    this.tensorCaches._computeExtremaFreak || D(() => {
      const i6 = Re(Eo);
      this.tensorCaches._computeExtremaFreak = {
        freakPointsT: cn(i6)
      };
    });
    const { freakPointsT: o } = this.tensorCaches._computeExtremaFreak, r = [];
    for (let i6 = 1; i6 < t.length; i6++)
      r.push(t[i6][1]);
    return D(() => Xt().runKernel("ComputeExtremaFreak", { gaussianImagesT: r, prunedExtremas: e, prunedExtremasAngles: s, freakPointsT: o, pyramidImagesLength: t.length }));
  }
  /**
   * 
   * @param {tf.Tensor<tf.Rank>} histograms 
   * @returns 
   */
  _computeExtremaAngles(t) {
    return D(() => Xt().runKernel("ComputeExtremaAngles", { histograms: t }));
  }
  // TODO: maybe can try just using average momentum, instead of histogram method. histogram might be overcomplicated
  /**
   * 
   * @param {tf.Tensor<tf.Rank>} prunedExtremasT 
   * @param {tf.Tensor<tf.Rank>[]} pyramidImagesT 
   * @returns 
   */
  _computeOrientationHistograms(t, e) {
    const s = [];
    for (let r = 1; r < e.length; r++)
      s.push(e[r][1]);
    this.tensorCaches.orientationHistograms || D(() => {
      const r = -1 / (2 * _u * _u), i6 = _u * v5, a = Math.ceil(i6), l = [];
      for (let c = -a; c <= a; c++)
        for (let u = -a; u <= a; u++) {
          const d = u * u + c * c;
          if (d <= i6 * i6) {
            const h6 = d * r;
            let p6 = (720 + h6 * (720 + h6 * (360 + h6 * (120 + h6 * (30 + h6 * (6 + h6)))))) * 0.0013888888;
            l.push([c, u, p6]);
          }
        }
      this.tensorCaches.orientationHistograms = {
        radialPropertiesT: cn(Re(l, [l.length, 3]))
      };
    });
    const { radialPropertiesT: o } = this.tensorCaches.orientationHistograms;
    return D(() => Xt().runKernel("ComputeOrientationHistograms", { gaussianImagesT: s, prunedExtremasT: t, radialPropertiesT: o, pyramidImagesLength: e.length }));
  }
  // The histogram is smoothed with a Gaussian, with sigma = 1
  _smoothHistograms(t) {
    return D(() => Xt().runKernel("SmoothHistograms", { histograms: t }));
  }
  /**
   * 
   * @param {number[][]} prunedExtremasList 
   * @param {tf.Tensor<tf.Rank>[]} dogPyramidImagesT 
   * @returns 
   */
  _computeLocalization(t, e) {
    return D(() => {
      const o = Xt().runKernel("ComputeLocalization", { prunedExtremasList: t, dogPyramidImagesT: e }).arraySync(), r = [];
      for (let a = 0; a < o.length; a++) {
        r.push([]);
        for (let l = 0; l < o[a].length; l++)
          r[a].push([]);
      }
      const i6 = [];
      for (let a = 0; a < t.length; a++)
        i6[a] = [
          t[a][0],
          t[a][1],
          t[a][2],
          t[a][3]
        ];
      for (let a = 0; a < i6.length; a++) {
        if (i6[a][0] === 0)
          continue;
        const l = o[a], c = 0.5 * (l[1][2] - l[1][0]), u = 0.5 * (l[2][1] - l[0][1]), d = l[1][2] + l[1][0] - 2 * l[1][1], h6 = l[2][1] + l[0][1] - 2 * l[1][1], p6 = 0.25 * (l[0][0] + l[2][2] - l[0][2] - l[2][0]), f = d * h6 - p6 * p6, m = (h6 * -c + -p6 * -u) / f, g6 = (-p6 * -c + d * -u) / f, b6 = i6[a][2] + g6, x6 = i6[a][3] + m;
        Math.abs(f) < 1e-4 || (i6[a][2] = b6, i6[a][3] = x6);
      }
      return Re(i6, [i6.length, i6[0].length], "float32");
    });
  }
  // faster to do it in CPU
  // if we do in gpu, we probably need to use tf.topk(), which seems to be run in CPU anyway (no gpu operation for that)
  //  TODO: research adapative maximum supression method
  /**
   * 
   * @param {tf.Tensor<tf.Rank>[]} extremasResultsT 
   * @returns 
   */
  _applyPrune(t) {
    const e = Vr * Vr, s = C5, o = [], r = [];
    for (let a = 0; a < e; a++) {
      r.push([]), o.push([]);
      for (let l = 0; l < s; l++)
        r[a].push([0, 0, 0, 0]), o[a].push(0);
    }
    D(() => {
      for (let a = 0; a < t.length; a++) {
        const l = Xt().runKernel("ExtremaReduction", { extremasResultT: t[a] }), c = a + 1, u = l.arraySync(), d = l.shape[0], h6 = l.shape[1], p6 = h6 * 2 / Vr, f = d * 2 / Vr;
        for (let m = 0; m < d; m++)
          for (let g6 = 0; g6 < h6; g6++) {
            const b6 = u[m][g6];
            if (b6 == 0)
              continue;
            const x6 = b6 % 1e3, w6 = Math.floor(Math.abs(b6) / 1e3), y6 = g6 * 2 + (w6 === 2 || w6 === 3 ? 1 : 0), I = m * 2 + (w6 === 1 || w6 === 3 ? 1 : 0), C6 = Math.floor(y6 / p6), S = Math.floor(I / f) * Vr + C6, N = Math.abs(x6);
            let R = s;
            for (; R >= 1 && N > o[S][R - 1]; )
              R -= 1;
            if (R < s) {
              for (let M6 = s - 1; M6 >= R + 1; M6--)
                o[S][M6] = o[S][M6 - 1], r[S][M6][0] = r[S][M6 - 1][0], r[S][M6][1] = r[S][M6 - 1][1], r[S][M6][2] = r[S][M6 - 1][2], r[S][M6][3] = r[S][M6 - 1][3];
              o[S][R] = N, r[S][R][0] = x6, r[S][R][1] = c, r[S][R][2] = I, r[S][R][3] = y6;
            }
          }
      }
    });
    const i6 = [];
    for (let a = 0; a < e; a++)
      for (let l = 0; l < s; l++)
        i6.push(r[a][l]);
    return i6;
  }
  _buildExtremas(t, e, s) {
    return D(() => Xt().runKernel("BuildExtremas", { image0: t, image1: e, image2: s }));
  }
  /**
   * 
   * @param {tf.Tensor<tf.Rank>} image1 
   * @param {tf.Tensor<tf.Rank>} image2 
   * @returns 
   */
  _differenceImageBinomial(t, e) {
    return D(() => t.sub(e));
  }
  // 4th order binomail filter [1,4,6,4,1] X [1,4,6,4,1]
  _applyFilter(t) {
    return D(() => Xt().runKernel("BinomialFilter", { image: t }));
  }
  /* _upsampleBilinear(image, targetImage) {
  		const imageHeight = image.shape[0];
  		const imageWidth = image.shape[1];
  
  		const kernelKey = 'w' + imageWidth;
  		if (!this.kernelCaches.upsampleBilinear) {
  			this.kernelCaches.upsampleBilinear = {};
  		}
  
  		if (!this.kernelCaches.upsampleBilinear[kernelKey]) {
  			const kernel = {
  				variableNames: ['p'],
  				outputShape: [targetImage.shape[0], targetImage.shape[1]],
  				userCode: `
  	  void main() {
  		ivec2 coords = getOutputCoords();
  		int j = coords[0];
  		int i = coords[1];
  
  		float sj = 0.5 * float(j) - 0.25; 
  		float si = 0.5 * float(i) - 0.25;
  
  		float sj0 = floor(sj);
  		float sj1 = ceil(sj);
  		float si0 = floor(si);
  		float si1 = ceil(si);
  
  		int sj0I = int(sj0);
  		int sj1I = int(sj1);
  		int si0I = int(si0);
  		int si1I = int(si1);
  
  		float sum = 0.0;
  		sum += getP(sj0I, si0I) * (si1 - si) * (sj1 - sj);
  		sum += getP(sj1I, si0I) * (si1 - si) * (sj - sj0);
  		sum += getP(sj0I, si1I) * (si - si0) * (sj1 - sj);
  		sum += getP(sj1I, si1I) * (si - si0) * (sj - sj0);
  		setOutput(sum);
  	  }
  	`
  			};
  			this.kernelCaches.upsampleBilinear[kernelKey] = kernel;
  		}
  
  		return tf.tidy(() => {
  			const program = this.kernelCaches.upsampleBilinear[kernelKey];
  			return tf.engine().runKernel("UpsampleBilinear", { x: image, width: image.shape[1], height: image.shape[0] });//this._compileAndRun(program, [image]);
  		});
  	} */
  _downsampleBilinear(t) {
    return D(() => Xt().runKernel("DownsampleBilinear", { image: t }));
  }
  /**
   * 
   * @param {tf.MathBackendWebGL.GPGPUProgram} program 
   * @param {*} inputs 
   * @returns 
   */
  _compileAndRun(t, e) {
    const s = $s().compileAndRun(t, e);
    return Xt().makeTensorFromDataId(s.dataId, s.shape, s.dtype);
  }
  _runWebGLProgram(t, e, s) {
    const o = $s().runWebGLProgram(t, e, s);
    return Xt().makeTensorFromDataId(o.dataId, o.shape, o.dtype);
  }
};
var S5 = class {
  constructor(t, e, s = false) {
    this.debugMode = s, this.width = t, this.height = e;
    let o = Math.min(t, e) / 2, r = Math.pow(2, Math.round(Math.log(o) / Math.log(2)));
    this.cropSize = r, this.detector = new gI(r, r, s), this.kernelCaches = {}, this.lastRandomIndex = 4;
  }
  detect(t) {
    const e = Math.floor(this.height / 2 - this.cropSize / 2), s = Math.floor(this.width / 2 - this.cropSize / 2), o = this._detect(t, s, e);
    return this.debugMode && (o.debugExtra.crop = { startX: s, startY: e, cropSize: this.cropSize }), o;
  }
  detectMoving(t) {
    const e = this.lastRandomIndex % 3, s = Math.floor(this.lastRandomIndex / 3);
    let o = Math.floor(this.height / 2 - this.cropSize + s * this.cropSize / 2), r = Math.floor(this.width / 2 - this.cropSize + e * this.cropSize / 2);
    return r < 0 && (r = 0), o < 0 && (o = 0), r >= this.width - this.cropSize && (r = this.width - this.cropSize - 1), o >= this.height - this.cropSize && (o = this.height - this.cropSize - 1), this.lastRandomIndex = (this.lastRandomIndex + 1) % 9, this._detect(t, r, o);
  }
  _detect(t, e, s) {
    const o = t.slice([s, e], [this.cropSize, this.cropSize]), { featurePoints: r, debugExtra: i6 } = this.detector.detect(o);
    return r.forEach((a) => {
      a.x += e, a.y += s;
    }), this.debugMode && (i6.projectedImage = o.arraySync()), o.dispose(), { featurePoints: r, debugExtra: i6 };
  }
};
var bI = ({ image: n, ratio: t }) => {
  const e = Math.round(n.width * t), s = Math.round(n.height * t), o = new Uint8Array(e * s);
  for (let r = 0; r < e; r++) {
    let i6 = Math.round(1 * r / t), a = Math.round(1 * (r + 1) / t) - 1;
    a >= n.width && (a = n.width - 1);
    for (let l = 0; l < s; l++) {
      let c = Math.round(1 * l / t), u = Math.round(1 * (l + 1) / t) - 1;
      u >= n.height && (u = n.height - 1);
      let d = 0, h6 = 0;
      for (let p6 = i6; p6 <= a; p6++)
        for (let f = c; f <= u; f++)
          d += 1 * n.data[f * n.width + p6], h6 += 1;
      o[l * e + r] = Math.floor(d / h6);
    }
  }
  return { data: o, width: e, height: s };
};
var k5 = 100;
var T5 = (n) => {
  const t = k5 / Math.min(n.width, n.height), e = [];
  let s = t;
  for (; ; )
    if (e.push(s), s *= Math.pow(2, 1 / 3), s >= 0.95) {
      s = 1;
      break;
    }
  e.push(s), e.reverse();
  const o = [];
  for (let r = 0; r < e.length; r++)
    n.width * e[r], n.height * e[r], o.push(Object.assign(bI({ image: n, ratio: e[r] }), { scale: e[r] }));
  return o;
};
var N5 = (n) => {
  const t = Math.min(n.width, n.height), e = [], s = [];
  e.push(256 / t), e.push(128 / t);
  for (let o = 0; o < e.length; o++)
    s.push(Object.assign(bI({ image: n, ratio: e[o] }), { scale: e[o] }));
  return s;
};
var R5 = (n) => {
  const { v1: t, v2: e } = n;
  let s = 0;
  for (let o = 0; o < t.length; o++) {
    let r = (t[o] ^ e[o]) >>> 0;
    s += $5(r);
  }
  return s;
};
var $5 = (n) => {
  var t = n - (n >> 1 & 1431655765);
  return t = (t >> 2 & 858993459) + (t & 858993459), t = (t >> 4) + t & 252645135, t = (t >> 8) + t & 16711935, t = (t >> 16) + t & 65535, t;
};
var G5 = 1234;
var E5 = () => ({
  seed: G5,
  arrayShuffle(t) {
    const { arr: e, sampleSize: s } = t;
    for (let o = 0; o < s; o++) {
      this.seed = (214013 * this.seed + 2531011) % -2147483648;
      let r = this.seed >> 16 & 32767;
      r = r % e.length;
      let i6 = e[o];
      e[o] = e[r], e[r] = i6;
    }
  },
  nextInt(t) {
    this.seed = (214013 * this.seed + 2531011) % -2147483648;
    let e = this.seed >> 16 & 32767;
    return e = e % t, e;
  }
});
var L5 = 16;
var M5 = 128;
var Vd = 8;
var W5 = (n) => {
  const { points: t, pointIndexes: e, randomizer: s } = n, o = [];
  for (let l = 0; l < e.length; l++)
    o.push(l);
  let r = Number.MAX_SAFE_INTEGER, i6 = -1;
  const a = [];
  for (let l = 0; l < M5; l++) {
    s.arrayShuffle({ arr: o, sampleSize: Vd });
    let c = 0;
    const u = [];
    for (let d = 0; d < e.length; d++) {
      let h6 = Number.MAX_SAFE_INTEGER;
      for (let p6 = 0; p6 < Vd; p6++) {
        const f = e[o[p6]], m = R5({ v1: t[e[d]].descriptors, v2: t[f].descriptors });
        m < h6 && (u[d] = o[p6], h6 = m);
      }
      c += h6;
    }
    a.push(u), c < r && (r = c, i6 = l);
  }
  return a[i6];
};
var Ng = ({ points: n }) => {
  const t = [];
  for (let o = 0; o < n.length; o++)
    t.push(o);
  const e = E5();
  return { rootNode: xI({ points: n, pointIndexes: t, centerPointIndex: null, randomizer: e }) };
};
var xI = (n) => {
  const { points: t, pointIndexes: e, centerPointIndex: s, randomizer: o } = n;
  let r = false;
  (e.length <= Vd || e.length <= L5) && (r = true);
  const i6 = {};
  if (!r) {
    const l = W5({ points: t, pointIndexes: e, randomizer: o });
    for (let c = 0; c < l.length; c++)
      i6[e[l[c]]] === void 0 && (i6[e[l[c]]] = []), i6[e[l[c]]].push(e[c]);
  }
  Object.keys(i6).length === 1 && (r = true);
  const a = {
    centerPointIndex: s
  };
  if (r) {
    a.leaf = true, a.pointIndexes = [];
    for (let l = 0; l < e.length; l++)
      a.pointIndexes.push(e[l]);
    return a;
  }
  return a.leaf = false, a.children = [], Object.keys(i6).forEach((l) => {
    a.children.push(xI({ points: t, pointIndexes: i6[l], centerPointIndex: l, randomizer: o }));
  }), a;
};
var ao = 4294967295;
function D5(n, t, e) {
  var s = e / 4294967296, o = e;
  n.setUint32(t, s), n.setUint32(t + 4, o);
}
function yI(n, t, e) {
  var s = Math.floor(e / 4294967296), o = e;
  n.setUint32(t, s), n.setUint32(t + 4, o);
}
function wI(n, t) {
  var e = n.getInt32(t), s = n.getUint32(t + 4);
  return e * 4294967296 + s;
}
function F5(n, t) {
  var e = n.getUint32(t), s = n.getUint32(t + 4);
  return e * 4294967296 + s;
}
var Uu;
var Yu;
var Qu;
var gu = (typeof process > "u" || ((Uu = process == null ? void 0 : process.env) === null || Uu === void 0 ? void 0 : Uu.TEXT_ENCODING) !== "never") && typeof TextEncoder < "u" && typeof TextDecoder < "u";
function Rg(n) {
  for (var t = n.length, e = 0, s = 0; s < t; ) {
    var o = n.charCodeAt(s++);
    if (o & 4294967168)
      if (!(o & 4294965248))
        e += 2;
      else {
        if (o >= 55296 && o <= 56319 && s < t) {
          var r = n.charCodeAt(s);
          (r & 64512) === 56320 && (++s, o = ((o & 1023) << 10) + (r & 1023) + 65536);
        }
        o & 4294901760 ? e += 4 : e += 3;
      }
    else {
      e++;
      continue;
    }
  }
  return e;
}
function V5(n, t, e) {
  for (var s = n.length, o = e, r = 0; r < s; ) {
    var i6 = n.charCodeAt(r++);
    if (i6 & 4294967168)
      if (!(i6 & 4294965248))
        t[o++] = i6 >> 6 & 31 | 192;
      else {
        if (i6 >= 55296 && i6 <= 56319 && r < s) {
          var a = n.charCodeAt(r);
          (a & 64512) === 56320 && (++r, i6 = ((i6 & 1023) << 10) + (a & 1023) + 65536);
        }
        i6 & 4294901760 ? (t[o++] = i6 >> 18 & 7 | 240, t[o++] = i6 >> 12 & 63 | 128, t[o++] = i6 >> 6 & 63 | 128) : (t[o++] = i6 >> 12 & 15 | 224, t[o++] = i6 >> 6 & 63 | 128);
      }
    else {
      t[o++] = i6;
      continue;
    }
    t[o++] = i6 & 63 | 128;
  }
}
var _r = gu ? new TextEncoder() : void 0;
var z5 = gu ? typeof process < "u" && ((Yu = process == null ? void 0 : process.env) === null || Yu === void 0 ? void 0 : Yu.TEXT_ENCODING) !== "force" ? 200 : 0 : ao;
function X5(n, t, e) {
  t.set(_r.encode(n), e);
}
function P5(n, t, e) {
  _r.encodeInto(n, t.subarray(e));
}
var A5 = _r != null && _r.encodeInto ? P5 : X5;
var O5 = 4096;
function II(n, t, e) {
  for (var s = t, o = s + e, r = [], i6 = ""; s < o; ) {
    var a = n[s++];
    if (!(a & 128))
      r.push(a);
    else if ((a & 224) === 192) {
      var l = n[s++] & 63;
      r.push((a & 31) << 6 | l);
    } else if ((a & 240) === 224) {
      var l = n[s++] & 63, c = n[s++] & 63;
      r.push((a & 31) << 12 | l << 6 | c);
    } else if ((a & 248) === 240) {
      var l = n[s++] & 63, c = n[s++] & 63, u = n[s++] & 63, d = (a & 7) << 18 | l << 12 | c << 6 | u;
      d > 65535 && (d -= 65536, r.push(d >>> 10 & 1023 | 55296), d = 56320 | d & 1023), r.push(d);
    } else
      r.push(a);
    r.length >= O5 && (i6 += String.fromCharCode.apply(String, r), r.length = 0);
  }
  return r.length > 0 && (i6 += String.fromCharCode.apply(String, r)), i6;
}
var K5 = gu ? new TextDecoder() : null;
var Z5 = gu ? typeof process < "u" && ((Qu = process == null ? void 0 : process.env) === null || Qu === void 0 ? void 0 : Qu.TEXT_DECODER) !== "force" ? 200 : 0 : ao;
function B5(n, t, e) {
  var s = n.subarray(t, t + e);
  return K5.decode(s);
}
var Qa = (
  /** @class */
  function() {
    function n(t, e) {
      this.type = t, this.data = e;
    }
    return n;
  }()
);
var H5 = globalThis && globalThis.__extends || function() {
  var n = function(t, e) {
    return n = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(s, o) {
      s.__proto__ = o;
    } || function(s, o) {
      for (var r in o)
        Object.prototype.hasOwnProperty.call(o, r) && (s[r] = o[r]);
    }, n(t, e);
  };
  return function(t, e) {
    if (typeof e != "function" && e !== null)
      throw new TypeError("Class extends value " + String(e) + " is not a constructor or null");
    n(t, e);
    function s() {
      this.constructor = t;
    }
    t.prototype = e === null ? Object.create(e) : (s.prototype = e.prototype, new s());
  };
}();
var Un = (
  /** @class */
  function(n) {
    H5(t, n);
    function t(e) {
      var s = n.call(this, e) || this, o = Object.create(t.prototype);
      return Object.setPrototypeOf(s, o), Object.defineProperty(s, "name", {
        configurable: true,
        enumerable: false,
        value: t.name
      }), s;
    }
    return t;
  }(Error)
);
var _5 = -1;
var U5 = 4294967296 - 1;
var Y5 = 17179869184 - 1;
function Q5(n) {
  var t = n.sec, e = n.nsec;
  if (t >= 0 && e >= 0 && t <= Y5)
    if (e === 0 && t <= U5) {
      var s = new Uint8Array(4), o = new DataView(s.buffer);
      return o.setUint32(0, t), s;
    } else {
      var r = t / 4294967296, i6 = t & 4294967295, s = new Uint8Array(8), o = new DataView(s.buffer);
      return o.setUint32(0, e << 2 | r & 3), o.setUint32(4, i6), s;
    }
  else {
    var s = new Uint8Array(12), o = new DataView(s.buffer);
    return o.setUint32(0, e), yI(o, 4, t), s;
  }
}
function J5(n) {
  var t = n.getTime(), e = Math.floor(t / 1e3), s = (t - e * 1e3) * 1e6, o = Math.floor(s / 1e9);
  return {
    sec: e + o,
    nsec: s - o * 1e9
  };
}
function j5(n) {
  if (n instanceof Date) {
    var t = J5(n);
    return Q5(t);
  } else
    return null;
}
function q5(n) {
  var t = new DataView(n.buffer, n.byteOffset, n.byteLength);
  switch (n.byteLength) {
    case 4: {
      var e = t.getUint32(0), s = 0;
      return { sec: e, nsec: s };
    }
    case 8: {
      var o = t.getUint32(0), r = t.getUint32(4), e = (o & 3) * 4294967296 + r, s = o >>> 2;
      return { sec: e, nsec: s };
    }
    case 12: {
      var e = wI(t, 4), s = t.getUint32(0);
      return { sec: e, nsec: s };
    }
    default:
      throw new Un("Unrecognized data size for timestamp (expected 4, 8, or 12): ".concat(n.length));
  }
}
function t4(n) {
  var t = q5(n);
  return new Date(t.sec * 1e3 + t.nsec / 1e6);
}
var e4 = {
  type: _5,
  encode: j5,
  decode: t4
};
var CI = (
  /** @class */
  function() {
    function n() {
      this.builtInEncoders = [], this.builtInDecoders = [], this.encoders = [], this.decoders = [], this.register(e4);
    }
    return n.prototype.register = function(t) {
      var e = t.type, s = t.encode, o = t.decode;
      if (e >= 0)
        this.encoders[e] = s, this.decoders[e] = o;
      else {
        var r = 1 + e;
        this.builtInEncoders[r] = s, this.builtInDecoders[r] = o;
      }
    }, n.prototype.tryToEncode = function(t, e) {
      for (var s = 0; s < this.builtInEncoders.length; s++) {
        var o = this.builtInEncoders[s];
        if (o != null) {
          var r = o(t, e);
          if (r != null) {
            var i6 = -1 - s;
            return new Qa(i6, r);
          }
        }
      }
      for (var s = 0; s < this.encoders.length; s++) {
        var o = this.encoders[s];
        if (o != null) {
          var r = o(t, e);
          if (r != null) {
            var i6 = s;
            return new Qa(i6, r);
          }
        }
      }
      return t instanceof Qa ? t : null;
    }, n.prototype.decode = function(t, e, s) {
      var o = e < 0 ? this.builtInDecoders[-1 - e] : this.decoders[e];
      return o ? o(t, e, s) : new Qa(e, t);
    }, n.defaultCodec = new n(), n;
  }()
);
function Ml(n) {
  return n instanceof Uint8Array ? n : ArrayBuffer.isView(n) ? new Uint8Array(n.buffer, n.byteOffset, n.byteLength) : n instanceof ArrayBuffer ? new Uint8Array(n) : Uint8Array.from(n);
}
function n4(n) {
  if (n instanceof ArrayBuffer)
    return new DataView(n);
  var t = Ml(n);
  return new DataView(t.buffer, t.byteOffset, t.byteLength);
}
var s4 = 100;
var o4 = 2048;
var r4 = (
  /** @class */
  function() {
    function n(t, e, s, o, r, i6, a, l) {
      t === void 0 && (t = CI.defaultCodec), e === void 0 && (e = void 0), s === void 0 && (s = s4), o === void 0 && (o = o4), r === void 0 && (r = false), i6 === void 0 && (i6 = false), a === void 0 && (a = false), l === void 0 && (l = false), this.extensionCodec = t, this.context = e, this.maxDepth = s, this.initialBufferSize = o, this.sortKeys = r, this.forceFloat32 = i6, this.ignoreUndefined = a, this.forceIntegerToFloat = l, this.pos = 0, this.view = new DataView(new ArrayBuffer(this.initialBufferSize)), this.bytes = new Uint8Array(this.view.buffer);
    }
    return n.prototype.reinitializeState = function() {
      this.pos = 0;
    }, n.prototype.encodeSharedRef = function(t) {
      return this.reinitializeState(), this.doEncode(t, 1), this.bytes.subarray(0, this.pos);
    }, n.prototype.encode = function(t) {
      return this.reinitializeState(), this.doEncode(t, 1), this.bytes.slice(0, this.pos);
    }, n.prototype.doEncode = function(t, e) {
      if (e > this.maxDepth)
        throw new Error("Too deep objects in depth ".concat(e));
      t == null ? this.encodeNil() : typeof t == "boolean" ? this.encodeBoolean(t) : typeof t == "number" ? this.encodeNumber(t) : typeof t == "string" ? this.encodeString(t) : this.encodeObject(t, e);
    }, n.prototype.ensureBufferSizeToWrite = function(t) {
      var e = this.pos + t;
      this.view.byteLength < e && this.resizeBuffer(e * 2);
    }, n.prototype.resizeBuffer = function(t) {
      var e = new ArrayBuffer(t), s = new Uint8Array(e), o = new DataView(e);
      s.set(this.bytes), this.view = o, this.bytes = s;
    }, n.prototype.encodeNil = function() {
      this.writeU8(192);
    }, n.prototype.encodeBoolean = function(t) {
      t === false ? this.writeU8(194) : this.writeU8(195);
    }, n.prototype.encodeNumber = function(t) {
      Number.isSafeInteger(t) && !this.forceIntegerToFloat ? t >= 0 ? t < 128 ? this.writeU8(t) : t < 256 ? (this.writeU8(204), this.writeU8(t)) : t < 65536 ? (this.writeU8(205), this.writeU16(t)) : t < 4294967296 ? (this.writeU8(206), this.writeU32(t)) : (this.writeU8(207), this.writeU64(t)) : t >= -32 ? this.writeU8(224 | t + 32) : t >= -128 ? (this.writeU8(208), this.writeI8(t)) : t >= -32768 ? (this.writeU8(209), this.writeI16(t)) : t >= -2147483648 ? (this.writeU8(210), this.writeI32(t)) : (this.writeU8(211), this.writeI64(t)) : this.forceFloat32 ? (this.writeU8(202), this.writeF32(t)) : (this.writeU8(203), this.writeF64(t));
    }, n.prototype.writeStringHeader = function(t) {
      if (t < 32)
        this.writeU8(160 + t);
      else if (t < 256)
        this.writeU8(217), this.writeU8(t);
      else if (t < 65536)
        this.writeU8(218), this.writeU16(t);
      else if (t < 4294967296)
        this.writeU8(219), this.writeU32(t);
      else
        throw new Error("Too long string: ".concat(t, " bytes in UTF-8"));
    }, n.prototype.encodeString = function(t) {
      var e = 5, s = t.length;
      if (s > z5) {
        var o = Rg(t);
        this.ensureBufferSizeToWrite(e + o), this.writeStringHeader(o), A5(t, this.bytes, this.pos), this.pos += o;
      } else {
        var o = Rg(t);
        this.ensureBufferSizeToWrite(e + o), this.writeStringHeader(o), V5(t, this.bytes, this.pos), this.pos += o;
      }
    }, n.prototype.encodeObject = function(t, e) {
      var s = this.extensionCodec.tryToEncode(t, this.context);
      if (s != null)
        this.encodeExtension(s);
      else if (Array.isArray(t))
        this.encodeArray(t, e);
      else if (ArrayBuffer.isView(t))
        this.encodeBinary(t);
      else if (typeof t == "object")
        this.encodeMap(t, e);
      else
        throw new Error("Unrecognized object: ".concat(Object.prototype.toString.apply(t)));
    }, n.prototype.encodeBinary = function(t) {
      var e = t.byteLength;
      if (e < 256)
        this.writeU8(196), this.writeU8(e);
      else if (e < 65536)
        this.writeU8(197), this.writeU16(e);
      else if (e < 4294967296)
        this.writeU8(198), this.writeU32(e);
      else
        throw new Error("Too large binary: ".concat(e));
      var s = Ml(t);
      this.writeU8a(s);
    }, n.prototype.encodeArray = function(t, e) {
      var s = t.length;
      if (s < 16)
        this.writeU8(144 + s);
      else if (s < 65536)
        this.writeU8(220), this.writeU16(s);
      else if (s < 4294967296)
        this.writeU8(221), this.writeU32(s);
      else
        throw new Error("Too large array: ".concat(s));
      for (var o = 0, r = t; o < r.length; o++) {
        var i6 = r[o];
        this.doEncode(i6, e + 1);
      }
    }, n.prototype.countWithoutUndefined = function(t, e) {
      for (var s = 0, o = 0, r = e; o < r.length; o++) {
        var i6 = r[o];
        t[i6] !== void 0 && s++;
      }
      return s;
    }, n.prototype.encodeMap = function(t, e) {
      var s = Object.keys(t);
      this.sortKeys && s.sort();
      var o = this.ignoreUndefined ? this.countWithoutUndefined(t, s) : s.length;
      if (o < 16)
        this.writeU8(128 + o);
      else if (o < 65536)
        this.writeU8(222), this.writeU16(o);
      else if (o < 4294967296)
        this.writeU8(223), this.writeU32(o);
      else
        throw new Error("Too large map object: ".concat(o));
      for (var r = 0, i6 = s; r < i6.length; r++) {
        var a = i6[r], l = t[a];
        this.ignoreUndefined && l === void 0 || (this.encodeString(a), this.doEncode(l, e + 1));
      }
    }, n.prototype.encodeExtension = function(t) {
      var e = t.data.length;
      if (e === 1)
        this.writeU8(212);
      else if (e === 2)
        this.writeU8(213);
      else if (e === 4)
        this.writeU8(214);
      else if (e === 8)
        this.writeU8(215);
      else if (e === 16)
        this.writeU8(216);
      else if (e < 256)
        this.writeU8(199), this.writeU8(e);
      else if (e < 65536)
        this.writeU8(200), this.writeU16(e);
      else if (e < 4294967296)
        this.writeU8(201), this.writeU32(e);
      else
        throw new Error("Too large extension object: ".concat(e));
      this.writeI8(t.type), this.writeU8a(t.data);
    }, n.prototype.writeU8 = function(t) {
      this.ensureBufferSizeToWrite(1), this.view.setUint8(this.pos, t), this.pos++;
    }, n.prototype.writeU8a = function(t) {
      var e = t.length;
      this.ensureBufferSizeToWrite(e), this.bytes.set(t, this.pos), this.pos += e;
    }, n.prototype.writeI8 = function(t) {
      this.ensureBufferSizeToWrite(1), this.view.setInt8(this.pos, t), this.pos++;
    }, n.prototype.writeU16 = function(t) {
      this.ensureBufferSizeToWrite(2), this.view.setUint16(this.pos, t), this.pos += 2;
    }, n.prototype.writeI16 = function(t) {
      this.ensureBufferSizeToWrite(2), this.view.setInt16(this.pos, t), this.pos += 2;
    }, n.prototype.writeU32 = function(t) {
      this.ensureBufferSizeToWrite(4), this.view.setUint32(this.pos, t), this.pos += 4;
    }, n.prototype.writeI32 = function(t) {
      this.ensureBufferSizeToWrite(4), this.view.setInt32(this.pos, t), this.pos += 4;
    }, n.prototype.writeF32 = function(t) {
      this.ensureBufferSizeToWrite(4), this.view.setFloat32(this.pos, t), this.pos += 4;
    }, n.prototype.writeF64 = function(t) {
      this.ensureBufferSizeToWrite(8), this.view.setFloat64(this.pos, t), this.pos += 8;
    }, n.prototype.writeU64 = function(t) {
      this.ensureBufferSizeToWrite(8), D5(this.view, this.pos, t), this.pos += 8;
    }, n.prototype.writeI64 = function(t) {
      this.ensureBufferSizeToWrite(8), yI(this.view, this.pos, t), this.pos += 8;
    }, n;
  }()
);
var i4 = {};
function a4(n, t) {
  t === void 0 && (t = i4);
  var e = new r4(t.extensionCodec, t.context, t.maxDepth, t.initialBufferSize, t.sortKeys, t.forceFloat32, t.ignoreUndefined, t.forceIntegerToFloat);
  return e.encodeSharedRef(n);
}
function Ju(n) {
  return "".concat(n < 0 ? "-" : "", "0x").concat(Math.abs(n).toString(16).padStart(2, "0"));
}
var l4 = 16;
var c4 = 16;
var u4 = (
  /** @class */
  function() {
    function n(t, e) {
      t === void 0 && (t = l4), e === void 0 && (e = c4), this.maxKeyLength = t, this.maxLengthPerKey = e, this.hit = 0, this.miss = 0, this.caches = [];
      for (var s = 0; s < this.maxKeyLength; s++)
        this.caches.push([]);
    }
    return n.prototype.canBeCached = function(t) {
      return t > 0 && t <= this.maxKeyLength;
    }, n.prototype.find = function(t, e, s) {
      var o = this.caches[s - 1];
      t:
        for (var r = 0, i6 = o; r < i6.length; r++) {
          for (var a = i6[r], l = a.bytes, c = 0; c < s; c++)
            if (l[c] !== t[e + c])
              continue t;
          return a.str;
        }
      return null;
    }, n.prototype.store = function(t, e) {
      var s = this.caches[t.length - 1], o = { bytes: t, str: e };
      s.length >= this.maxLengthPerKey ? s[Math.random() * s.length | 0] = o : s.push(o);
    }, n.prototype.decode = function(t, e, s) {
      var o = this.find(t, e, s);
      if (o != null)
        return this.hit++, o;
      this.miss++;
      var r = II(t, e, s), i6 = Uint8Array.prototype.slice.call(t, e, e + s);
      return this.store(i6, r), r;
    }, n;
  }()
);
var d4 = globalThis && globalThis.__awaiter || function(n, t, e, s) {
  function o(r) {
    return r instanceof e ? r : new e(function(i6) {
      i6(r);
    });
  }
  return new (e || (e = Promise))(function(r, i6) {
    function a(u) {
      try {
        c(s.next(u));
      } catch (d) {
        i6(d);
      }
    }
    function l(u) {
      try {
        c(s.throw(u));
      } catch (d) {
        i6(d);
      }
    }
    function c(u) {
      u.done ? r(u.value) : o(u.value).then(a, l);
    }
    c((s = s.apply(n, t || [])).next());
  });
};
var ju = globalThis && globalThis.__generator || function(n, t) {
  var e = { label: 0, sent: function() {
    if (r[0] & 1)
      throw r[1];
    return r[1];
  }, trys: [], ops: [] }, s, o, r, i6;
  return i6 = { next: a(0), throw: a(1), return: a(2) }, typeof Symbol == "function" && (i6[Symbol.iterator] = function() {
    return this;
  }), i6;
  function a(c) {
    return function(u) {
      return l([c, u]);
    };
  }
  function l(c) {
    if (s)
      throw new TypeError("Generator is already executing.");
    for (; e; )
      try {
        if (s = 1, o && (r = c[0] & 2 ? o.return : c[0] ? o.throw || ((r = o.return) && r.call(o), 0) : o.next) && !(r = r.call(o, c[1])).done)
          return r;
        switch (o = 0, r && (c = [c[0] & 2, r.value]), c[0]) {
          case 0:
          case 1:
            r = c;
            break;
          case 4:
            return e.label++, { value: c[1], done: false };
          case 5:
            e.label++, o = c[1], c = [0];
            continue;
          case 7:
            c = e.ops.pop(), e.trys.pop();
            continue;
          default:
            if (r = e.trys, !(r = r.length > 0 && r[r.length - 1]) && (c[0] === 6 || c[0] === 2)) {
              e = 0;
              continue;
            }
            if (c[0] === 3 && (!r || c[1] > r[0] && c[1] < r[3])) {
              e.label = c[1];
              break;
            }
            if (c[0] === 6 && e.label < r[1]) {
              e.label = r[1], r = c;
              break;
            }
            if (r && e.label < r[2]) {
              e.label = r[2], e.ops.push(c);
              break;
            }
            r[2] && e.ops.pop(), e.trys.pop();
            continue;
        }
        c = t.call(n, e);
      } catch (u) {
        c = [6, u], o = 0;
      } finally {
        s = r = 0;
      }
    if (c[0] & 5)
      throw c[1];
    return { value: c[0] ? c[1] : void 0, done: true };
  }
};
var $g = globalThis && globalThis.__asyncValues || function(n) {
  if (!Symbol.asyncIterator)
    throw new TypeError("Symbol.asyncIterator is not defined.");
  var t = n[Symbol.asyncIterator], e;
  return t ? t.call(n) : (n = typeof __values == "function" ? __values(n) : n[Symbol.iterator](), e = {}, s("next"), s("throw"), s("return"), e[Symbol.asyncIterator] = function() {
    return this;
  }, e);
  function s(r) {
    e[r] = n[r] && function(i6) {
      return new Promise(function(a, l) {
        i6 = n[r](i6), o(a, l, i6.done, i6.value);
      });
    };
  }
  function o(r, i6, a, l) {
    Promise.resolve(l).then(function(c) {
      r({ value: c, done: a });
    }, i6);
  }
};
var nr = globalThis && globalThis.__await || function(n) {
  return this instanceof nr ? (this.v = n, this) : new nr(n);
};
var h4 = globalThis && globalThis.__asyncGenerator || function(n, t, e) {
  if (!Symbol.asyncIterator)
    throw new TypeError("Symbol.asyncIterator is not defined.");
  var s = e.apply(n, t || []), o, r = [];
  return o = {}, i6("next"), i6("throw"), i6("return"), o[Symbol.asyncIterator] = function() {
    return this;
  }, o;
  function i6(h6) {
    s[h6] && (o[h6] = function(p6) {
      return new Promise(function(f, m) {
        r.push([h6, p6, f, m]) > 1 || a(h6, p6);
      });
    });
  }
  function a(h6, p6) {
    try {
      l(s[h6](p6));
    } catch (f) {
      d(r[0][3], f);
    }
  }
  function l(h6) {
    h6.value instanceof nr ? Promise.resolve(h6.value.v).then(c, u) : d(r[0][2], h6);
  }
  function c(h6) {
    a("next", h6);
  }
  function u(h6) {
    a("throw", h6);
  }
  function d(h6, p6) {
    h6(p6), r.shift(), r.length && a(r[0][0], r[0][1]);
  }
};
var p4 = function(n) {
  var t = typeof n;
  return t === "string" || t === "number";
};
var zr = -1;
var Zf = new DataView(new ArrayBuffer(0));
var f4 = new Uint8Array(Zf.buffer);
var zd = function() {
  try {
    Zf.getInt8(0);
  } catch (n) {
    return n.constructor;
  }
  throw new Error("never reached");
}();
var Gg = new zd("Insufficient data");
var m4 = new u4();
var g4 = (
  /** @class */
  function() {
    function n(t, e, s, o, r, i6, a, l) {
      t === void 0 && (t = CI.defaultCodec), e === void 0 && (e = void 0), s === void 0 && (s = ao), o === void 0 && (o = ao), r === void 0 && (r = ao), i6 === void 0 && (i6 = ao), a === void 0 && (a = ao), l === void 0 && (l = m4), this.extensionCodec = t, this.context = e, this.maxStrLength = s, this.maxBinLength = o, this.maxArrayLength = r, this.maxMapLength = i6, this.maxExtLength = a, this.keyDecoder = l, this.totalPos = 0, this.pos = 0, this.view = Zf, this.bytes = f4, this.headByte = zr, this.stack = [];
    }
    return n.prototype.reinitializeState = function() {
      this.totalPos = 0, this.headByte = zr, this.stack.length = 0;
    }, n.prototype.setBuffer = function(t) {
      this.bytes = Ml(t), this.view = n4(this.bytes), this.pos = 0;
    }, n.prototype.appendBuffer = function(t) {
      if (this.headByte === zr && !this.hasRemaining(1))
        this.setBuffer(t);
      else {
        var e = this.bytes.subarray(this.pos), s = Ml(t), o = new Uint8Array(e.length + s.length);
        o.set(e), o.set(s, e.length), this.setBuffer(o);
      }
    }, n.prototype.hasRemaining = function(t) {
      return this.view.byteLength - this.pos >= t;
    }, n.prototype.createExtraByteError = function(t) {
      var e = this, s = e.view, o = e.pos;
      return new RangeError("Extra ".concat(s.byteLength - o, " of ").concat(s.byteLength, " byte(s) found at buffer[").concat(t, "]"));
    }, n.prototype.decode = function(t) {
      this.reinitializeState(), this.setBuffer(t);
      var e = this.doDecodeSync();
      if (this.hasRemaining(1))
        throw this.createExtraByteError(this.pos);
      return e;
    }, n.prototype.decodeMulti = function(t) {
      return ju(this, function(e) {
        switch (e.label) {
          case 0:
            this.reinitializeState(), this.setBuffer(t), e.label = 1;
          case 1:
            return this.hasRemaining(1) ? [4, this.doDecodeSync()] : [3, 3];
          case 2:
            return e.sent(), [3, 1];
          case 3:
            return [
              2
              /*return*/
            ];
        }
      });
    }, n.prototype.decodeAsync = function(t) {
      var e, s, o, r;
      return d4(this, void 0, void 0, function() {
        var i6, a, l, c, u, d, h6, p6;
        return ju(this, function(f) {
          switch (f.label) {
            case 0:
              i6 = false, f.label = 1;
            case 1:
              f.trys.push([1, 6, 7, 12]), e = $g(t), f.label = 2;
            case 2:
              return [4, e.next()];
            case 3:
              if (s = f.sent(), !!s.done)
                return [3, 5];
              if (l = s.value, i6)
                throw this.createExtraByteError(this.totalPos);
              this.appendBuffer(l);
              try {
                a = this.doDecodeSync(), i6 = true;
              } catch (m) {
                if (!(m instanceof zd))
                  throw m;
              }
              this.totalPos += this.pos, f.label = 4;
            case 4:
              return [3, 2];
            case 5:
              return [3, 12];
            case 6:
              return c = f.sent(), o = { error: c }, [3, 12];
            case 7:
              return f.trys.push([7, , 10, 11]), s && !s.done && (r = e.return) ? [4, r.call(e)] : [3, 9];
            case 8:
              f.sent(), f.label = 9;
            case 9:
              return [3, 11];
            case 10:
              if (o)
                throw o.error;
              return [
                7
                /*endfinally*/
              ];
            case 11:
              return [
                7
                /*endfinally*/
              ];
            case 12:
              if (i6) {
                if (this.hasRemaining(1))
                  throw this.createExtraByteError(this.totalPos);
                return [2, a];
              }
              throw u = this, d = u.headByte, h6 = u.pos, p6 = u.totalPos, new RangeError("Insufficient data in parsing ".concat(Ju(d), " at ").concat(p6, " (").concat(h6, " in the current buffer)"));
          }
        });
      });
    }, n.prototype.decodeArrayStream = function(t) {
      return this.decodeMultiAsync(t, true);
    }, n.prototype.decodeStream = function(t) {
      return this.decodeMultiAsync(t, false);
    }, n.prototype.decodeMultiAsync = function(t, e) {
      return h4(this, arguments, function() {
        var o, r, i6, a, l, c, u, d, h6;
        return ju(this, function(p6) {
          switch (p6.label) {
            case 0:
              o = e, r = -1, p6.label = 1;
            case 1:
              p6.trys.push([1, 13, 14, 19]), i6 = $g(t), p6.label = 2;
            case 2:
              return [4, nr(i6.next())];
            case 3:
              if (a = p6.sent(), !!a.done)
                return [3, 12];
              if (l = a.value, e && r === 0)
                throw this.createExtraByteError(this.totalPos);
              this.appendBuffer(l), o && (r = this.readArraySize(), o = false, this.complete()), p6.label = 4;
            case 4:
              p6.trys.push([4, 9, , 10]), p6.label = 5;
            case 5:
              return [4, nr(this.doDecodeSync())];
            case 6:
              return [4, p6.sent()];
            case 7:
              return p6.sent(), --r === 0 ? [3, 8] : [3, 5];
            case 8:
              return [3, 10];
            case 9:
              if (c = p6.sent(), !(c instanceof zd))
                throw c;
              return [3, 10];
            case 10:
              this.totalPos += this.pos, p6.label = 11;
            case 11:
              return [3, 2];
            case 12:
              return [3, 19];
            case 13:
              return u = p6.sent(), d = { error: u }, [3, 19];
            case 14:
              return p6.trys.push([14, , 17, 18]), a && !a.done && (h6 = i6.return) ? [4, nr(h6.call(i6))] : [3, 16];
            case 15:
              p6.sent(), p6.label = 16;
            case 16:
              return [3, 18];
            case 17:
              if (d)
                throw d.error;
              return [
                7
                /*endfinally*/
              ];
            case 18:
              return [
                7
                /*endfinally*/
              ];
            case 19:
              return [
                2
                /*return*/
              ];
          }
        });
      });
    }, n.prototype.doDecodeSync = function() {
      t:
        for (; ; ) {
          var t = this.readHeadByte(), e = void 0;
          if (t >= 224)
            e = t - 256;
          else if (t < 192)
            if (t < 128)
              e = t;
            else if (t < 144) {
              var s = t - 128;
              if (s !== 0) {
                this.pushMapState(s), this.complete();
                continue t;
              } else
                e = {};
            } else if (t < 160) {
              var s = t - 144;
              if (s !== 0) {
                this.pushArrayState(s), this.complete();
                continue t;
              } else
                e = [];
            } else {
              var o = t - 160;
              e = this.decodeUtf8String(o, 0);
            }
          else if (t === 192)
            e = null;
          else if (t === 194)
            e = false;
          else if (t === 195)
            e = true;
          else if (t === 202)
            e = this.readF32();
          else if (t === 203)
            e = this.readF64();
          else if (t === 204)
            e = this.readU8();
          else if (t === 205)
            e = this.readU16();
          else if (t === 206)
            e = this.readU32();
          else if (t === 207)
            e = this.readU64();
          else if (t === 208)
            e = this.readI8();
          else if (t === 209)
            e = this.readI16();
          else if (t === 210)
            e = this.readI32();
          else if (t === 211)
            e = this.readI64();
          else if (t === 217) {
            var o = this.lookU8();
            e = this.decodeUtf8String(o, 1);
          } else if (t === 218) {
            var o = this.lookU16();
            e = this.decodeUtf8String(o, 2);
          } else if (t === 219) {
            var o = this.lookU32();
            e = this.decodeUtf8String(o, 4);
          } else if (t === 220) {
            var s = this.readU16();
            if (s !== 0) {
              this.pushArrayState(s), this.complete();
              continue t;
            } else
              e = [];
          } else if (t === 221) {
            var s = this.readU32();
            if (s !== 0) {
              this.pushArrayState(s), this.complete();
              continue t;
            } else
              e = [];
          } else if (t === 222) {
            var s = this.readU16();
            if (s !== 0) {
              this.pushMapState(s), this.complete();
              continue t;
            } else
              e = {};
          } else if (t === 223) {
            var s = this.readU32();
            if (s !== 0) {
              this.pushMapState(s), this.complete();
              continue t;
            } else
              e = {};
          } else if (t === 196) {
            var s = this.lookU8();
            e = this.decodeBinary(s, 1);
          } else if (t === 197) {
            var s = this.lookU16();
            e = this.decodeBinary(s, 2);
          } else if (t === 198) {
            var s = this.lookU32();
            e = this.decodeBinary(s, 4);
          } else if (t === 212)
            e = this.decodeExtension(1, 0);
          else if (t === 213)
            e = this.decodeExtension(2, 0);
          else if (t === 214)
            e = this.decodeExtension(4, 0);
          else if (t === 215)
            e = this.decodeExtension(8, 0);
          else if (t === 216)
            e = this.decodeExtension(16, 0);
          else if (t === 199) {
            var s = this.lookU8();
            e = this.decodeExtension(s, 1);
          } else if (t === 200) {
            var s = this.lookU16();
            e = this.decodeExtension(s, 2);
          } else if (t === 201) {
            var s = this.lookU32();
            e = this.decodeExtension(s, 4);
          } else
            throw new Un("Unrecognized type byte: ".concat(Ju(t)));
          this.complete();
          for (var r = this.stack; r.length > 0; ) {
            var i6 = r[r.length - 1];
            if (i6.type === 0)
              if (i6.array[i6.position] = e, i6.position++, i6.position === i6.size)
                r.pop(), e = i6.array;
              else
                continue t;
            else if (i6.type === 1) {
              if (!p4(e))
                throw new Un("The type of key must be string or number but " + typeof e);
              if (e === "__proto__")
                throw new Un("The key __proto__ is not allowed");
              i6.key = e, i6.type = 2;
              continue t;
            } else if (i6.map[i6.key] = e, i6.readCount++, i6.readCount === i6.size)
              r.pop(), e = i6.map;
            else {
              i6.key = null, i6.type = 1;
              continue t;
            }
          }
          return e;
        }
    }, n.prototype.readHeadByte = function() {
      return this.headByte === zr && (this.headByte = this.readU8()), this.headByte;
    }, n.prototype.complete = function() {
      this.headByte = zr;
    }, n.prototype.readArraySize = function() {
      var t = this.readHeadByte();
      switch (t) {
        case 220:
          return this.readU16();
        case 221:
          return this.readU32();
        default: {
          if (t < 160)
            return t - 144;
          throw new Un("Unrecognized array type byte: ".concat(Ju(t)));
        }
      }
    }, n.prototype.pushMapState = function(t) {
      if (t > this.maxMapLength)
        throw new Un("Max length exceeded: map length (".concat(t, ") > maxMapLengthLength (").concat(this.maxMapLength, ")"));
      this.stack.push({
        type: 1,
        size: t,
        key: null,
        readCount: 0,
        map: {}
      });
    }, n.prototype.pushArrayState = function(t) {
      if (t > this.maxArrayLength)
        throw new Un("Max length exceeded: array length (".concat(t, ") > maxArrayLength (").concat(this.maxArrayLength, ")"));
      this.stack.push({
        type: 0,
        size: t,
        array: new Array(t),
        position: 0
      });
    }, n.prototype.decodeUtf8String = function(t, e) {
      var s;
      if (t > this.maxStrLength)
        throw new Un("Max length exceeded: UTF-8 byte length (".concat(t, ") > maxStrLength (").concat(this.maxStrLength, ")"));
      if (this.bytes.byteLength < this.pos + e + t)
        throw Gg;
      var o = this.pos + e, r;
      return this.stateIsMapKey() && (!((s = this.keyDecoder) === null || s === void 0) && s.canBeCached(t)) ? r = this.keyDecoder.decode(this.bytes, o, t) : t > Z5 ? r = B5(this.bytes, o, t) : r = II(this.bytes, o, t), this.pos += e + t, r;
    }, n.prototype.stateIsMapKey = function() {
      if (this.stack.length > 0) {
        var t = this.stack[this.stack.length - 1];
        return t.type === 1;
      }
      return false;
    }, n.prototype.decodeBinary = function(t, e) {
      if (t > this.maxBinLength)
        throw new Un("Max length exceeded: bin length (".concat(t, ") > maxBinLength (").concat(this.maxBinLength, ")"));
      if (!this.hasRemaining(t + e))
        throw Gg;
      var s = this.pos + e, o = this.bytes.subarray(s, s + t);
      return this.pos += e + t, o;
    }, n.prototype.decodeExtension = function(t, e) {
      if (t > this.maxExtLength)
        throw new Un("Max length exceeded: ext length (".concat(t, ") > maxExtLength (").concat(this.maxExtLength, ")"));
      var s = this.view.getInt8(this.pos + e), o = this.decodeBinary(
        t,
        e + 1
        /* extType */
      );
      return this.extensionCodec.decode(o, s, this.context);
    }, n.prototype.lookU8 = function() {
      return this.view.getUint8(this.pos);
    }, n.prototype.lookU16 = function() {
      return this.view.getUint16(this.pos);
    }, n.prototype.lookU32 = function() {
      return this.view.getUint32(this.pos);
    }, n.prototype.readU8 = function() {
      var t = this.view.getUint8(this.pos);
      return this.pos++, t;
    }, n.prototype.readI8 = function() {
      var t = this.view.getInt8(this.pos);
      return this.pos++, t;
    }, n.prototype.readU16 = function() {
      var t = this.view.getUint16(this.pos);
      return this.pos += 2, t;
    }, n.prototype.readI16 = function() {
      var t = this.view.getInt16(this.pos);
      return this.pos += 2, t;
    }, n.prototype.readU32 = function() {
      var t = this.view.getUint32(this.pos);
      return this.pos += 4, t;
    }, n.prototype.readI32 = function() {
      var t = this.view.getInt32(this.pos);
      return this.pos += 4, t;
    }, n.prototype.readU64 = function() {
      var t = F5(this.view, this.pos);
      return this.pos += 8, t;
    }, n.prototype.readI64 = function() {
      var t = wI(this.view, this.pos);
      return this.pos += 8, t;
    }, n.prototype.readF32 = function() {
      var t = this.view.getFloat32(this.pos);
      return this.pos += 4, t;
    }, n.prototype.readF64 = function() {
      var t = this.view.getFloat64(this.pos);
      return this.pos += 8, t;
    }, n;
  }()
);
var b4 = {};
function x4(n, t) {
  t === void 0 && (t = b4);
  var e = new g4(t.extensionCodec, t.context, t.maxStrLength, t.maxBinLength, t.maxArrayLength, t.maxMapLength, t.maxExtLength);
  return e.decode(n);
}
var Eg = 2;
var y4 = class {
  constructor() {
    this.data = null;
  }
  // input html Images
  compileImageTargets(t, e) {
    return new Promise(async (s, o) => {
      const r = [];
      for (let c = 0; c < t.length; c++) {
        const u = t[c], h6 = this.createProcessCanvas(u).getContext("2d");
        h6.drawImage(u, 0, 0, u.width, u.height);
        const p6 = h6.getImageData(0, 0, u.width, u.height), f = new Uint8Array(u.width * u.height);
        for (let g6 = 0; g6 < f.length; g6++) {
          const b6 = g6 * 4;
          f[g6] = Math.floor((p6.data[b6] + p6.data[b6 + 1] + p6.data[b6 + 2]) / 3);
        }
        const m = { data: f, height: u.height, width: u.width };
        r.push(m);
      }
      const i6 = 50 / r.length;
      let a = 0;
      this.data = [];
      for (let c = 0; c < r.length; c++) {
        const u = r[c], d = T5(u), h6 = i6 / d.length, p6 = await w4(d, () => {
          a += h6, e(a);
        });
        this.data.push({
          targetImage: u,
          imageList: d,
          matchingData: p6
        });
      }
      for (let c = 0; c < r.length; c++) {
        const u = N5(r[c]);
        this.data[c].trackingImageList = u;
      }
      const l = await this.compileTrack({ progressCallback: e, targetImages: r, basePercent: 50 });
      for (let c = 0; c < r.length; c++)
        this.data[c].trackingData = l[c];
      s(this.data);
    });
  }
  // not exporting imageList because too large. rebuild this using targetImage
  exportData() {
    const t = [];
    for (let s = 0; s < this.data.length; s++)
      t.push({
        //targetImage: this.data[i].targetImage,
        targetImage: {
          width: this.data[s].targetImage.width,
          height: this.data[s].targetImage.height
        },
        trackingData: this.data[s].trackingData,
        matchingData: this.data[s].matchingData
      });
    return a4({
      v: Eg,
      dataList: t
    });
  }
  importData(t) {
    const e = x4(new Uint8Array(t));
    if (!e.v || e.v !== Eg)
      return console.error("Your compiled .mind might be outdated. Please recompile"), [];
    const { dataList: s } = e;
    this.data = [];
    for (let o = 0; o < s.length; o++)
      this.data.push({
        targetImage: s[o].targetImage,
        trackingData: s[o].trackingData,
        matchingData: s[o].matchingData
      });
    return this.data;
  }
  createProcessCanvas(t) {
    console.warn("missing createProcessCanvas implementation");
  }
  compileTrack({ progressCallback: t, targetImages: e, basePercent: s }) {
    console.warn("missing compileTrack implementation");
  }
};
var w4 = async (n, t) => {
  const e = [];
  for (let s = 0; s < n.length; s++) {
    const o = n[s], r = new gI(o.width, o.height);
    await _c(), D(() => {
      const i6 = Re(o.data, [o.data.length], "float32").reshape([o.height, o.width]), { featurePoints: a } = r.detect(i6), l = a.filter((h6) => h6.maxima), c = a.filter((h6) => !h6.maxima), u = Ng({ points: l }), d = Ng({ points: c });
      e.push({
        maximaPoints: l,
        minimaPoints: c,
        maximaPointsCluster: u,
        minimaPointsCluster: d,
        width: o.width,
        height: o.height,
        scale: o.scale
      }), t(s);
    });
  }
  return e;
};
var vI = "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";
var Lg = typeof window < "u" && window.Blob && new Blob([atob(vI)], { type: "text/javascript;charset=utf-8" });
function I4() {
  let n;
  try {
    if (n = Lg && (window.URL || window.webkitURL).createObjectURL(Lg), !n)
      throw "";
    return new Worker(n);
  } catch {
    return new Worker("data:application/javascript;base64," + vI);
  } finally {
    n && (window.URL || window.webkitURL).revokeObjectURL(n);
  }
}
var C4 = class extends y4 {
  createProcessCanvas(t) {
    const e = document.createElement("canvas");
    return e.width = t.width, e.height = t.height, e;
  }
  compileTrack({ progressCallback: t, targetImages: e, basePercent: s }) {
    return new Promise((o, r) => {
      const i6 = new I4();
      i6.onmessage = (a) => {
        a.data.type === "progress" ? t(s + a.data.percent * s / 100) : a.data.type === "compileDone" && o(a.data.list);
      }, i6.postMessage({ type: "compile", targetImages: e });
    });
  }
};
var v4 = class {
  constructor(t, e) {
    this.width = t, this.height = e, this.texShape = [e, t];
    const s = document.createElement("canvas").getContext("2d");
    s.canvas.width = t, s.canvas.height = e, this.context = s, this.program = this.buildProgram(t, e);
    const o = $s();
    this.tempPixelHandle = o.makeTensorInfo(this.texShape, "float32"), o.texData.get(this.tempPixelHandle.dataId).usage = 2;
  }
  // old method
  _loadInput(t) {
    return D(() => {
      let e = b0(t);
      return e = e.mean(2), e;
    });
  }
  // input is instance of HTMLVideoElement or HTMLImageElement
  loadInput(t) {
    const e = this.context;
    if (e.clearRect(0, 0, this.context.canvas.width, this.context.canvas.height), t.width === this.height && t.height === this.width) {
      let i6 = this.context.canvas.width / 2, a = this.context.canvas.height / 2, l = 90;
      e.save(), e.translate(i6, a), e.rotate(l * Math.PI / 180), e.drawImage(t, -t.width / 2, -t.height / 2), e.restore();
    } else
      this.context.drawImage(t, 0, 0, t.width, t.height);
    const o = $s();
    return o.gpgpu.uploadPixelDataToTexture(o.getTexture(this.tempPixelHandle.dataId), this.context.canvas), this._compileAndRun(this.program, [this.tempPixelHandle]);
  }
  buildProgram(t, e) {
    const s = F().getNumber("WEBGL_VERSION") === 2 ? "texture" : "texture2D";
    return {
      variableNames: ["A"],
      outputShape: this.texShape,
      userCode: `
	void main() {
	  ivec2 coords = getOutputCoords();
	  int texR = coords[0];
	  int texC = coords[1];
	  vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${t}.0, ${e}.0);

	  vec4 values = ${s}(A, uv);
	  setOutput((0.299 * values.r + 0.587 * values.g + 0.114 * values.b) * 255.0);
	}
      `
    };
  }
  _compileAndRun(t, e) {
    const s = $s().compileAndRun(t, e);
    return Xt().makeTensorFromDataId(s.dataId, s.shape, s.dtype);
  }
  _runWebGLProgram(t, e, s) {
    const o = $s().runWebGLProgram(t, e, s);
    return Xt().makeTensorFromDataId(o.dataId, o.shape, o.dtype);
  }
};
var qu = { memory: cl, nextFrame: _c };
var S4 = 1e-3;
var k4 = 1e3;
var T4 = 5;
var N4 = 5;
var MY = class {
  constructor({
    inputWidth: t,
    inputHeight: e,
    onUpdate: s = null,
    debugMode: o = false,
    maxTrack: r = 1,
    warmupTolerance: i6 = null,
    missTolerance: a = null,
    filterMinCF: l = null,
    filterBeta: c = null
  }) {
    this.inputWidth = t, this.inputHeight = e, this.maxTrack = r, this.filterMinCF = l === null ? S4 : l, this.filterBeta = c === null ? k4 : c, this.warmupTolerance = i6 === null ? T4 : i6, this.missTolerance = a === null ? N4 : a, this.cropDetector = new S5(this.inputWidth, this.inputHeight, o), this.inputLoader = new v4(this.inputWidth, this.inputHeight), this.markerDimensions = null, this.onUpdate = s, this.debugMode = o, this.processingVideo = false, this.interestedTargetIndex = -1, this.trackingStates = [];
    const u = 10, d = 1e5, h6 = 45 * Math.PI / 180, p6 = this.inputHeight / 2 / Math.tan(h6 / 2);
    this.projectionTransform = [
      [p6, 0, this.inputWidth / 2],
      [0, p6, this.inputHeight / 2],
      [0, 0, 1]
    ], this.projectionMatrix = this._glProjectionMatrix({
      projectionTransform: this.projectionTransform,
      width: this.inputWidth,
      height: this.inputHeight,
      near: u,
      far: d
    }), this.worker = new NU(), this.workerMatchDone = null, this.workerTrackDone = null, this.worker.onmessage = (f) => {
      f.data.type === "matchDone" && this.workerMatchDone !== null && this.workerMatchDone(f.data), f.data.type === "trackUpdateDone" && this.workerTrackDone !== null && this.workerTrackDone(f.data);
    };
  }
  showTFStats() {
    console.log(qu.memory().numTensors), console.table(qu.memory());
  }
  addImageTargets(t) {
    return new Promise(async (e, s) => {
      const r = await (await fetch(t)).arrayBuffer(), i6 = this.addImageTargetsFromBuffer(r);
      e(i6);
    });
  }
  addImageTargetsFromBuffer(t) {
    const s = new C4().importData(t), o = [], r = [], i6 = [];
    for (let a = 0; a < s.length; a++)
      r.push(s[a].matchingData), o.push(s[a].trackingData), i6.push([s[a].targetImage.width, s[a].targetImage.height]);
    return this.tracker = new VU(i6, o, this.projectionTransform, this.inputWidth, this.inputHeight, this.debugMode), this.worker.postMessage({
      type: "setup",
      inputWidth: this.inputWidth,
      inputHeight: this.inputHeight,
      projectionTransform: this.projectionTransform,
      debugMode: this.debugMode,
      matchingDataList: r
    }), this.markerDimensions = i6, { dimensions: i6, matchingDataList: r, trackingDataList: o };
  }
  dispose() {
    this.stopProcessVideo(), this.worker.postMessage({
      type: "dispose"
    });
  }
  // warm up gpu - build kernels is slow
  dummyRun(t) {
    const e = this.inputLoader.loadInput(t);
    this.cropDetector.detect(e), this.tracker.dummyRun(e), e.dispose();
  }
  getProjectionMatrix() {
    return this.projectionMatrix;
  }
  getRotatedZ90Matrix(t) {
    return [
      -t[1],
      t[0],
      t[2],
      t[3],
      -t[5],
      t[4],
      t[6],
      t[7],
      -t[9],
      t[8],
      t[10],
      t[11],
      -t[13],
      t[12],
      t[14],
      t[15]
    ];
  }
  getWorldMatrix(t, e) {
    return this._glModelViewMatrix(t, e);
  }
  async _detectAndMatch(t, e) {
    const { featurePoints: s } = this.cropDetector.detectMoving(t), { targetIndex: o, modelViewTransform: r } = await this._workerMatch(s, e);
    return { targetIndex: o, modelViewTransform: r };
  }
  async _trackAndUpdate(t, e, s) {
    const { worldCoords: o, screenCoords: r } = this.tracker.track(t, e, s);
    return o.length < 4 ? null : await this._workerTrackUpdate(e, { worldCoords: o, screenCoords: r });
  }
  processVideo(t) {
    if (this.processingVideo)
      return;
    this.processingVideo = true, this.trackingStates = [];
    for (let s = 0; s < this.markerDimensions.length; s++)
      this.trackingStates.push({
        showing: false,
        isTracking: false,
        currentModelViewTransform: null,
        trackCount: 0,
        trackMiss: 0,
        filter: new P({ minCutOff: this.filterMinCF, beta: this.filterBeta })
      });
    (async () => {
      for (; this.processingVideo; ) {
        const s = this.inputLoader.loadInput(t);
        if (this.trackingStates.reduce((r, i6) => r + (i6.isTracking ? 1 : 0), 0) < this.maxTrack) {
          const r = [];
          for (let l = 0; l < this.trackingStates.length; l++)
            this.trackingStates[l].isTracking !== true && (this.interestedTargetIndex !== -1 && this.interestedTargetIndex !== l || r.push(l));
          const { targetIndex: i6, modelViewTransform: a } = await this._detectAndMatch(s, r);
          i6 !== -1 && (this.trackingStates[i6].isTracking = true, this.trackingStates[i6].currentModelViewTransform = a);
        }
        for (let r = 0; r < this.trackingStates.length; r++) {
          const i6 = this.trackingStates[r];
          if (i6.isTracking) {
            let a = await this._trackAndUpdate(s, i6.currentModelViewTransform, r);
            a === null ? i6.isTracking = false : i6.currentModelViewTransform = a;
          }
          if (i6.showing || i6.isTracking && (i6.trackMiss = 0, i6.trackCount += 1, i6.trackCount > this.warmupTolerance && (i6.showing = true, i6.trackingMatrix = null, i6.filter.reset())), i6.showing && (i6.isTracking ? i6.trackMiss = 0 : (i6.trackCount = 0, i6.trackMiss += 1, i6.trackMiss > this.missTolerance && (i6.showing = false, i6.trackingMatrix = null, this.onUpdate && this.onUpdate({ type: "updateMatrix", targetIndex: r, worldMatrix: null })))), i6.showing) {
            const a = this._glModelViewMatrix(i6.currentModelViewTransform, r);
            i6.trackingMatrix = i6.filter.filter(Date.now(), a);
            let l = [];
            for (let u = 0; u < i6.trackingMatrix.length; u++)
              l[u] = i6.trackingMatrix[u];
            t.width === this.inputHeight && t.height === this.inputWidth && (l = this.getRotatedZ90Matrix(l)), this.onUpdate && this.onUpdate({ type: "updateMatrix", targetIndex: r, worldMatrix: l });
          }
        }
        s.dispose(), this.onUpdate && this.onUpdate({ type: "processDone" }), await qu.nextFrame();
      }
    })();
  }
  stopProcessVideo() {
    this.processingVideo = false;
  }
  async detect(t) {
    const e = this.inputLoader.loadInput(t), { featurePoints: s, debugExtra: o } = await this.cropDetector.detect(e);
    return e.dispose(), { featurePoints: s, debugExtra: o };
  }
  async match(t, e) {
    const { modelViewTransform: s, debugExtra: o } = await this._workerMatch(t, [e]);
    return { modelViewTransform: s, debugExtra: o };
  }
  async track(t, e, s) {
    const o = this.inputLoader.loadInput(t), r = this.tracker.track(o, e, s);
    return o.dispose(), r;
  }
  async trackUpdate(t, e) {
    return e.worldCoords.length < 4 ? null : await this._workerTrackUpdate(t, e);
  }
  _workerMatch(t, e) {
    return new Promise(async (s, o) => {
      this.workerMatchDone = (r) => {
        s({ targetIndex: r.targetIndex, modelViewTransform: r.modelViewTransform, debugExtra: r.debugExtra });
      }, this.worker.postMessage({ type: "match", featurePoints: t, targetIndexes: e });
    });
  }
  _workerTrackUpdate(t, e) {
    return new Promise(async (s, o) => {
      this.workerTrackDone = (a) => {
        s(a.modelViewTransform);
      };
      const { worldCoords: r, screenCoords: i6 } = e;
      this.worker.postMessage({ type: "trackUpdate", modelViewTransform: t, worldCoords: r, screenCoords: i6 });
    });
  }
  _glModelViewMatrix(t, e) {
    const s = this.markerDimensions[e][1];
    return [
      t[0][0],
      -t[1][0],
      -t[2][0],
      0,
      -t[0][1],
      t[1][1],
      t[2][1],
      0,
      -t[0][2],
      t[1][2],
      t[2][2],
      0,
      t[0][1] * s + t[0][3],
      -(t[1][1] * s + t[1][3]),
      -(t[2][1] * s + t[2][3]),
      1
    ];
  }
  // build openGL projection matrix
  // ref: https://strawlab.org/2011/11/05/augmented-reality-with-OpenGL/
  _glProjectionMatrix({ projectionTransform: t, width: e, height: s, near: o, far: r }) {
    const i6 = [
      [2 * t[0][0] / e, 0, -(2 * t[0][2] / e - 1), 0],
      [0, 2 * t[1][1] / s, -(2 * t[1][2] / s - 1), 0],
      [0, 0, -(r + o) / (r - o), -2 * r * o / (r - o)],
      [0, 0, -1, 0]
    ], a = [];
    for (let l = 0; l < 4; l++)
      for (let c = 0; c < 4; c++)
        a.push(i6[c][l]);
    return a;
  }
};

// node_modules/three/examples/jsm/renderers/CSS3DRenderer.js
var _position = new Vector3();
var _quaternion = new Quaternion();
var _scale = new Vector3();
var _matrix = new Matrix4();
var _matrix2 = new Matrix4();
var CSS3DRenderer = class {
  constructor(parameters = {}) {
    const _this = this;
    let _width, _height;
    let _widthHalf, _heightHalf;
    const cache = {
      camera: { fov: 0, style: "" },
      objects: /* @__PURE__ */ new WeakMap()
    };
    const domElement = parameters.element !== void 0 ? parameters.element : document.createElement("div");
    domElement.style.overflow = "hidden";
    this.domElement = domElement;
    const viewElement = document.createElement("div");
    viewElement.style.transformOrigin = "0 0";
    viewElement.style.pointerEvents = "none";
    domElement.appendChild(viewElement);
    const cameraElement = document.createElement("div");
    cameraElement.style.transformStyle = "preserve-3d";
    viewElement.appendChild(cameraElement);
    this.getSize = function() {
      return {
        width: _width,
        height: _height
      };
    };
    this.render = function(scene, camera) {
      const fov = camera.projectionMatrix.elements[5] * _heightHalf;
      if (cache.camera.fov !== fov) {
        viewElement.style.perspective = camera.isPerspectiveCamera ? fov + "px" : "";
        cache.camera.fov = fov;
      }
      if (camera.view && camera.view.enabled) {
        viewElement.style.transform = `translate( ${-camera.view.offsetX * (_width / camera.view.width)}px, ${-camera.view.offsetY * (_height / camera.view.height)}px )`;
        viewElement.style.transform += `scale( ${camera.view.fullWidth / camera.view.width}, ${camera.view.fullHeight / camera.view.height} )`;
      } else {
        viewElement.style.transform = "";
      }
      if (scene.matrixWorldAutoUpdate === true)
        scene.updateMatrixWorld();
      if (camera.parent === null && camera.matrixWorldAutoUpdate === true)
        camera.updateMatrixWorld();
      let tx2, ty3;
      if (camera.isOrthographicCamera) {
        tx2 = -(camera.right + camera.left) / 2;
        ty3 = (camera.top + camera.bottom) / 2;
      }
      const scaleByViewOffset = camera.view && camera.view.enabled ? camera.view.height / camera.view.fullHeight : 1;
      const cameraCSSMatrix = camera.isOrthographicCamera ? `scale( ${scaleByViewOffset} )scale(` + fov + ")translate(" + epsilon(tx2) + "px," + epsilon(ty3) + "px)" + getCameraCSSMatrix(camera.matrixWorldInverse) : `scale( ${scaleByViewOffset} )translateZ(` + fov + "px)" + getCameraCSSMatrix(camera.matrixWorldInverse);
      const style = cameraCSSMatrix + "translate(" + _widthHalf + "px," + _heightHalf + "px)";
      if (cache.camera.style !== style) {
        cameraElement.style.transform = style;
        cache.camera.style = style;
      }
      renderObject(scene, scene, camera, cameraCSSMatrix);
    };
    this.setSize = function(width, height) {
      _width = width;
      _height = height;
      _widthHalf = _width / 2;
      _heightHalf = _height / 2;
      domElement.style.width = width + "px";
      domElement.style.height = height + "px";
      viewElement.style.width = width + "px";
      viewElement.style.height = height + "px";
      cameraElement.style.width = width + "px";
      cameraElement.style.height = height + "px";
    };
    function epsilon(value) {
      return Math.abs(value) < 1e-10 ? 0 : value;
    }
    function getCameraCSSMatrix(matrix) {
      const elements = matrix.elements;
      return "matrix3d(" + epsilon(elements[0]) + "," + epsilon(-elements[1]) + "," + epsilon(elements[2]) + "," + epsilon(elements[3]) + "," + epsilon(elements[4]) + "," + epsilon(-elements[5]) + "," + epsilon(elements[6]) + "," + epsilon(elements[7]) + "," + epsilon(elements[8]) + "," + epsilon(-elements[9]) + "," + epsilon(elements[10]) + "," + epsilon(elements[11]) + "," + epsilon(elements[12]) + "," + epsilon(-elements[13]) + "," + epsilon(elements[14]) + "," + epsilon(elements[15]) + ")";
    }
    function getObjectCSSMatrix(matrix) {
      const elements = matrix.elements;
      const matrix3d = "matrix3d(" + epsilon(elements[0]) + "," + epsilon(elements[1]) + "," + epsilon(elements[2]) + "," + epsilon(elements[3]) + "," + epsilon(-elements[4]) + "," + epsilon(-elements[5]) + "," + epsilon(-elements[6]) + "," + epsilon(-elements[7]) + "," + epsilon(elements[8]) + "," + epsilon(elements[9]) + "," + epsilon(elements[10]) + "," + epsilon(elements[11]) + "," + epsilon(elements[12]) + "," + epsilon(elements[13]) + "," + epsilon(elements[14]) + "," + epsilon(elements[15]) + ")";
      return "translate(-50%,-50%)" + matrix3d;
    }
    function renderObject(object, scene, camera, cameraCSSMatrix) {
      if (object.isCSS3DObject) {
        const visible = object.visible === true && object.layers.test(camera.layers) === true;
        object.element.style.display = visible === true ? "" : "none";
        if (visible === true) {
          object.onBeforeRender(_this, scene, camera);
          let style;
          if (object.isCSS3DSprite) {
            _matrix.copy(camera.matrixWorldInverse);
            _matrix.transpose();
            if (object.rotation2D !== 0)
              _matrix.multiply(_matrix2.makeRotationZ(object.rotation2D));
            object.matrixWorld.decompose(_position, _quaternion, _scale);
            _matrix.setPosition(_position);
            _matrix.scale(_scale);
            _matrix.elements[3] = 0;
            _matrix.elements[7] = 0;
            _matrix.elements[11] = 0;
            _matrix.elements[15] = 1;
            style = getObjectCSSMatrix(_matrix);
          } else {
            style = getObjectCSSMatrix(object.matrixWorld);
          }
          const element = object.element;
          const cachedObject = cache.objects.get(object);
          if (cachedObject === void 0 || cachedObject.style !== style) {
            element.style.transform = style;
            const objectData = { style };
            cache.objects.set(object, objectData);
          }
          if (element.parentNode !== cameraElement) {
            cameraElement.appendChild(element);
          }
          object.onAfterRender(_this, scene, camera);
        }
      }
      for (let i6 = 0, l = object.children.length; i6 < l; i6++) {
        renderObject(object.children[i6], scene, camera, cameraCSSMatrix);
      }
    }
  }
};

// node_modules/mind-ar/dist/mindar-image-three.prod.js
function hd2(s) {
  v2(Array.isArray(s), () => "The argument passed to tf.addN() must be a list of tensors"), v2(s.length >= 1, () => `Must pass at least one tensor to tf.addN(), but got ${s.length}`);
  const e = s.map((r, n) => T(r, `tensors${n}`, "addN")), t = e[0];
  e.forEach((r) => {
    if (r.dtype !== t.dtype)
      throw new Error("All tensors passed to tf.addN() must have the same dtype");
  }), e.forEach((r) => {
    if (!Rt(r.shape, t.shape))
      throw new Error("All tensors passed to tf.addN() must have the same shape");
  });
  const a = e;
  return $.runKernel(Bd, a);
}
var Yr2 = L({ addN_: hd2 });
function fd2(s, e, t, a, r, n) {
  const o = T(s, "forgetBias", "basicLSTMCell"), u = T(e, "lstmKernel", "basicLSTMCell"), l = T(t, "lstmBias", "basicLSTMCell"), p6 = T(a, "data", "basicLSTMCell"), m = T(r, "c", "basicLSTMCell"), c = T(n, "h", "basicLSTMCell"), d = Ge([p6, c], 1), h6 = Gt(d, u), b6 = U(h6, l), f = b6.shape[0], y6 = b6.shape[1] / 4, T6 = [f, y6], _6 = Dt(b6, [0, 0], T6), w6 = Dt(b6, [0, y6], T6), I = Dt(b6, [0, y6 * 2], T6), E6 = Dt(b6, [0, y6 * 3], T6), D6 = U(G(xr(_6), Hh(w6)), G(m, xr(U(o, I)))), V = G(Hh(D6), xr(E6));
  return [D6, V];
}
var Mr2 = L({ basicLSTMCell_: fd2 });
function yd2(s, e) {
  const t = T(s, "s0", "broadcastArgs", "int32"), a = T(e, "s1", "broadcastArgs", "int32");
  if (t.rank !== 1)
    throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${t.rank}`);
  if (a.rank !== 1)
    throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${a.rank}`);
  const r = { s0: t, s1: a };
  return $.runKernel(Kg, r);
}
var en2 = L({ broadcastArgs_: yd2 });
function gd2(s) {
  const t = { x: T(s, "x", "diag") };
  return $.runKernel(Zg, t);
}
var tn2 = L({ diag_: gd2 });
function bd2(s, ...e) {
  const t = e.map((r, n) => T(r, `tensors${n}`, "einsum")), a = { equation: s };
  return $.runKernel(Bg, t, a);
}
var sn2 = L({ einsum_: bd2 });
function an2(s, e, t) {
  if (t <= 0)
    throw new Error("The number of values should be positive.");
  const a = { start: s, stop: e, num: t };
  return $.runKernel(_g, {}, a);
}
var he2 = 2147483648;
function Nd2(s, e, t = "left") {
  const a = T(s, "sortedSequence", "searchSorted"), r = T(e, "values", "searchSorted"), n = a.shape[a.shape.length - 1], o = r.shape[r.shape.length - 1], u = W(a, [-1, n]), l = W(r, [-1, o]);
  if (u.rank < 2)
    throw new Error("Sorted input argument must be at least 2-dimensional");
  if (u.shape[0] !== l.shape[0])
    throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");
  if (O(l.shape) >= he2)
    throw new Error(`values tensor size must less than ${he2}`);
  if (u.shape[1] >= he2)
    throw new Error(`trailing dim_size must less than ${he2} for int32 output type, was ${u.shape[1]}`);
  const p6 = {
    sortedSequence: u,
    values: l
  }, m = { side: t };
  return $.runKernel(tb, p6, m);
}
var De2 = L({ searchSorted_: Nd2 });
function rn2(s, e) {
  return De2(s, e, "left");
}
function wd2(s, e, t, a, r = false) {
  const o = { x: T(s, "x", "maxPoolWithArgmax") }, u = { filterSize: e, strides: t, pad: a, includeBatchInIndex: r }, l = $.runKernel(Ug, o, u);
  return { result: l[0], indexes: l[1] };
}
var nn2 = L({ maxPoolWithArgmax_: wd2 });
function on(s, e, { indexing: t = "xy" } = {}) {
  if (t !== "xy" && t !== "ij")
    throw new TypeError(`${t} is not a valid third argument to meshgrid`);
  if (s === void 0)
    return [];
  let a = T(s, "x", "meshgrid", s instanceof Lt ? s.dtype : "float32");
  if (e === void 0)
    return [a];
  let r = T(e, "y", "meshgrid", e instanceof Lt ? e.dtype : "float32");
  const n = O(a.shape), o = O(r.shape);
  return t === "xy" ? (a = W(a, [1, -1]), r = W(r, [-1, 1]), [
    Gt(Us([o, 1], a.dtype), a),
    Gt(r, Us([1, n], r.dtype))
  ]) : (a = W(a, [-1, 1]), r = W(r, [1, -1]), [
    Gt(a, Us([1, o], a.dtype)),
    Gt(Us([n, 1], r.dtype), r)
  ]);
}
function Td2(s, e, t, a) {
  const r = T(e, "data", "multiRNNCell"), n = Ah(t, "c", "multiRNNCell"), o = Ah(a, "h", "multiRNNCell");
  let u = r;
  const l = [];
  for (let c = 0; c < s.length; c++) {
    const d = s[c](u, n[c], o[c]);
    l.push(d[0]), l.push(d[1]), u = d[1];
  }
  const p6 = [], m = [];
  for (let c = 0; c < l.length; c += 2)
    p6.push(l[c]), m.push(l[c + 1]);
  return [p6, m];
}
var un2 = L({ multiRNNCell_: Td2 });
function Sd2(s, e, t, a = false) {
  const r = T(s, "logits", "multinomial"), n = r.size, o = r.rank;
  if (n < 2)
    throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${n}.`);
  if (o > 2)
    throw new Error(`Rank of probabilities must be 1 or 2, but is ${o}`);
  t = t || Math.random();
  const l = { logits: o === 1 ? W(r, [1, -1]) : r }, p6 = { numSamples: e, seed: t, normalized: a }, m = $.runKernel(Yg, l, p6);
  return o === 1 ? W(m, [m.size]) : m;
}
var ln2 = L({ multinomial_: Sd2 });
function vd2(s, e) {
  const t = T(s, "v1", "outerProduct"), a = T(e, "v2", "outerProduct");
  v2(t.rank === 1 && a.rank === 1, () => `Error in outerProduct: inputs must be rank 1, but got ranks ${t.rank} and ${a.rank}.`);
  const r = W(t, [-1, 1]), n = W(a, [1, -1]);
  return Gt(r, n);
}
var pn2 = L({ outerProduct_: vd2 });
function Od2(s, e, t = 0) {
  return v2(e.length === 2, () => "Invalid number of paddings. Must be length of 2."), rp(s, [e], t);
}
var mn2 = L({ pad1d_: Od2 });
function _d2(s, e, t = 0) {
  return v2(e.length === 2 && e[0].length === 2 && e[1].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), rp(s, e, t);
}
var cn2 = L({ pad2d_: _d2 });
function Ad2(s, e, t = 0) {
  return v2(e.length === 3 && e[0].length === 2 && e[1].length === 2 && e[2].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), rp(s, e, t);
}
var dn2 = L({ pad3d_: Ad2 });
function Ed2(s, e, t = 0) {
  return v2(e.length === 4 && e[0].length === 2 && e[1].length === 2 && e[2].length === 2 && e[3].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), rp(s, e, t);
}
var hn2 = L({ pad4d_: Ed2 });
function kd2(s, e, t, a) {
  const r = s.map((m, c) => T(m, `tensors${c}`, "raggedGather", "int32")), n = T(e, "paramsDenseValues", "raggedGather"), o = T(t, "indices", "raggedGather", "int32"), u = {
    paramsNestedSplits: r,
    paramsDenseValues: n,
    indices: o
  }, l = { outputRaggedRank: a }, p6 = $.runKernel(Qg, u, l);
  return {
    outputNestedSplits: p6.slice(0, p6.length - 1),
    outputDenseValues: p6[p6.length - 1]
  };
}
var fn2 = L({ raggedGather_: kd2 });
function Id2(s, e, t) {
  const a = T(s, "starts", "raggedRange"), r = T(e, "limits", "raggedRange", a.dtype), n = T(t, "deltas", "raggedRange", a.dtype), o = {
    starts: a,
    limits: r,
    deltas: n
  }, u = $.runKernel(Jg, o);
  return {
    rtNestedSplits: u[0],
    rtDenseValues: u[1]
  };
}
var yn2 = L({ raggedRange_: Id2 });
function Dd2(s, e, t, a, r) {
  const n = T(s, "shape", "raggedTensorToTensor", "int32"), o = T(e, "values", "raggedTensorToTensor"), u = T(t, "defaultValue", "raggedTensorToTensor", o.dtype), l = a.map((c, d) => T(c, `tensors${d}`, "raggedTensorToTensor", "int32")), p6 = {
    shape: n,
    values: o,
    defaultValue: u,
    rowPartitionTensors: l
  }, m = { rowPartitionTypes: r };
  return $.runKernel(jg, p6, m);
}
var gn2 = L({ raggedTensorToTensor_: Dd2 });
function $d2(s, e, t) {
  is(s);
  const a = O(s);
  let r = null;
  if (t == null || t === "float32")
    r = new Float32Array(a);
  else if (t === "int32")
    r = new Int32Array(a);
  else if (t === "bool")
    r = new Uint8Array(a);
  else
    throw new Error(`Unknown data type ${t}`);
  for (let n = 0; n < a; n++)
    r[n] = e();
  return $.makeTensor(r, s, t);
}
var bn2 = L({ rand_: $d2 });
var Cd2 = 1e-3;
var Nn2 = 0.1;
function zd2(s, e, t) {
  return t == null && (t = ft()), Pe2(s, e, (a, r) => yt2(a, r, t));
}
function ft() {
  return $.backend.floatPrecision() === 32 ? Cd2 : Nn2;
}
function Pe2(s, e, t) {
  let a = true;
  if ((dn(s) || dn(e)) && (a = false), dn(s) && dn(e) && (a = true), a) {
    const o = s.constructor.name, u = e.constructor.name;
    if (o !== u)
      throw new Error(`Arrays are of different type. Actual: ${o}. Expected: ${u}`);
  }
  if (Array.isArray(s) && Array.isArray(e)) {
    const o = aa(s), u = aa(e);
    if (!Rt(o, u))
      throw new Error(`Arrays have different shapes. Actual: [${o}]. Expected: [${u}]`);
  }
  const r = dn(s) ? s : zs(s), n = dn(e) ? e : zs(e);
  if (r.length !== n.length)
    throw new Error(`Arrays have different lengths actual: ${r.length} vs expected: ${n.length}.
Actual:   ${r}.
Expected: ${n}.`);
  for (let o = 0; o < n.length; ++o) {
    const u = r[o], l = n[o];
    if (!t(u, l))
      throw new Error(`Arrays differ: actual[${o}] = ${u}, expected[${o}] = ${l}.
Actual:   ${r}.
Expected: ${n}.`);
  }
  typeof expect < "u" && expect().nothing();
}
function xd2(s, e) {
  s().then(() => e.fail(), () => e()), typeof expect < "u" && expect().nothing();
}
function Ld2(s, e) {
  const t = typeof e == "string" || typeof e == "number" || typeof e == "boolean" ? [e] : e;
  return mr(s) || mr(s[0]) || mr(e) || mr(e[0]) ? Pe2(s, t, (a, r) => a == r) : Pe2(s, e, (a, r) => yt2(a, r, 0));
}
function Vd2(s, e, t) {
  if (t == null && (t = ft()), !yt2(s, e, t))
    throw new Error(`Numbers differ: actual === ${s}, expected === ${e}`);
  typeof expect < "u" && expect().nothing();
}
function yt2(s, e, t) {
  return !isFinite(s) && !isFinite(e) ? true : !(isNaN(s) || isNaN(e) || Math.abs(s - e) > t);
}
function Fd2(s, e, t) {
  for (let a = 0; a < s.length; a++)
    if (s[a] < e || s[a] > t)
      throw new Error(`Value out of range:${s[a]} low: ${e}, high: ${t}`);
}
function Pd2(s, e) {
  const t = new Float32Array(s), a = new Float32Array(e);
  if (t.length !== a.length)
    throw new Error(`Expected ArrayBuffer to be of length ${a.length}, but it was ${t.length}`);
  for (let r = 0; r < a.length; r++)
    if (t[r] !== a[r])
      throw new Error(`Expected ArrayBuffer value at ${r} to be ${a[r]} but got ${t[r]} instead`);
}
function wn2(s) {
  for (let e = 0; e < s.length; e++) {
    const t = s[e];
    Array.isArray(t) ? wn2(t) : s[e] = hs(t);
  }
  return s;
}
function Rd2(s) {
  const e = document.createElement("video");
  return "playsInline" in e && (e.playsInline = true), e.muted = true, e.loop = true, e.style.position = "fixed", e.style.left = "0px", e.style.top = "0px", e.preload = "auto", e.appendChild(s), new Promise((t) => {
    e.addEventListener("loadeddata", (a) => t(e)), e.load();
  });
}
async function jd2(s) {
  await s.play(), "requestVideoFrameCallback" in s && await new Promise((e) => {
    s.requestVideoFrameCallback(e);
  });
}
var Bd2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  TEST_EPSILON_FLOAT16: Nn2,
  createVideoElement: Rd2,
  encodeStrings: wn2,
  expectArrayBuffersEqual: Pd2,
  expectArraysClose: zd2,
  expectArraysEqual: Ld2,
  expectNumbersClose: Vd2,
  expectPromiseToFail: xd2,
  expectValuesInRange: Fd2,
  play: jd2,
  testEpsilon: ft
}, Symbol.toStringTag, { value: "Module" }));
function Hd2(s, e, t = 1, a = "float32", r) {
  if (is(s), t == null && (t = 1), a == null && (a = "float32"), a !== "float32" && a !== "int32")
    throw new Error(`Unsupported data type ${a}`);
  const n = new dY(e, t, a, r), o = vt(s, a);
  for (let u = 0; u < o.values.length; u++)
    o.values[u] = n.nextValue();
  return o.toTensor();
}
var Tn2 = L({ randomGamma_: Hd2 });
function Wd2(s, e, t) {
  if (e != null && e === "bool")
    throw new Error(`Unsupported data type ${e}`);
  return hk(s, 0, 1, e, t);
}
var Sn2 = L({ randomStandardNormal_: Wd2 });
function qd2(s) {
  const e = T(s, "x", "reverse");
  return v2(e.rank === 1, () => `Error in reverse1D: x must be rank 1 but got rank ${e.rank}.`), ko(e, 0);
}
var vn2 = L({ reverse1d_: qd2 });
function Ud2(s, e) {
  const t = T(s, "x", "reverse");
  return v2(t.rank === 2, () => `Error in reverse2D: x must be rank 2 but got rank ${t.rank}.`), ko(t, e);
}
var On2 = L({ reverse2d_: Ud2 });
function Gd2(s, e) {
  const t = T(s, "x", "reverse");
  return v2(t.rank === 3, () => `Error in reverse3D: x must be rank 3 but got rank ${t.rank}.`), ko(t, e);
}
var _n2 = L({ reverse3d_: Gd2 });
function Kd2(s, e) {
  const t = T(s, "x", "reverse");
  return v2(t.rank === 4, () => `Error in reverse4D: x must be rank 4 but got rank ${t.rank}.`), ko(t, e);
}
var An2 = L({ reverse4d_: Kd2 });
async function Jd2(s, e) {
  const t = T(s, "x", "setdiff1d"), a = T(e, "y", "setdiff1d");
  v2(t.dtype === a.dtype, () => `x and y should have the same dtype, but got x (${t.dtype}) and y (${a.dtype}).`), v2(t.rank === 1, () => `x should be 1D tensor, but got x (${t.shape}).`), v2(a.rank === 1, () => `y should be 1D tensor, but got y (${a.shape}).`);
  const r = await t.data(), n = await a.data(), o = new Set(n);
  let u = 0;
  for (let m = 0; m < r.length; m++)
    o.has(r[m]) || u++;
  const l = new $e([u], t.dtype), p6 = new $e([u], "int32");
  for (let m = 0, c = 0; m < r.length; m++)
    o.has(r[m]) || (l.values[c] = r[m], p6.values[c] = m, c++);
  return [l.toTensor(), p6.toTensor()];
}
var En2 = Jd2;
function kn2(s, e, t) {
  if (Dl(s), e != null && e.length !== 4)
    throw new Error("tensor4d() requires shape to have four numbers");
  const a = aa(s, t);
  if (a.length !== 4 && a.length !== 1)
    throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
  if (a.length === 1 && e == null)
    throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
  return la(s, e, a, t);
}
function In2(s, e, t) {
  if (Dl(s), e != null && e.length !== 5)
    throw new Error("tensor5d() requires shape to have five numbers");
  const a = aa(s, t);
  if (a.length !== 5 && a.length !== 1)
    throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
  if (a.length === 1 && e == null)
    throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
  return la(s, e, a, t);
}
function Dn2(s, e, t) {
  if (Dl(s), e != null && e.length !== 6)
    throw new Error("tensor6d() requires shape to have six numbers");
  const a = aa(s, t);
  if (a.length !== 6 && a.length !== 1)
    throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
  if (a.length === 1 && e == null)
    throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
  return e = e || a, la(s, e, a, t);
}
function $n2(s, e) {
  return De2(s, e, "right");
}
async function Qd2(s) {
  const e = T(s, "condition", "whereAsync", "bool"), t = await e.data(), a = t0(e.shape, t);
  return s !== e && e.dispose(), a;
}
var gt2 = Qd2;
async function Xd2(s, e, t) {
  const a = T(s, "tensor", "boolMask"), r = T(e, "mask", "boolMask", "bool"), n = t ?? 0, o = r.rank, u = a.shape;
  v2(o > 0, () => "mask cannot be scalar"), Ve(u.slice(n, n + o), r.shape, "mask's shape must match the first K dimensions of tensor's shape,");
  let l = 1;
  for (let f = n; f < n + o; f++)
    l *= u[f];
  const p6 = u.slice(0, n).concat([l], u.slice(n + o)), m = W(a, p6), c = W(r, [-1]), d = await gt2(c), h6 = ha(d, [1]), b6 = jh(m, h6, n);
  return s !== a && a.dispose(), e !== r && r.dispose(), h6.dispose(), m.dispose(), c.dispose(), d.dispose(), b6;
}
var Cn2 = Xd2;
function Zd2(s, e, t, a, r = true) {
  const n = T(s, "v", "movingAverage"), o = T(e, "x", "movingAverage"), u = T(t, "decay", "movingAverage");
  pC(n, o), v2(Rt(n.shape, o.shape), () => "Shape mismatch in v and x");
  const l = gt(1), p6 = lt(l, u);
  let m = G(lt(o, n), p6);
  if (r) {
    v2(a != null, () => "When using zeroDebias: true, step is required.");
    const c = T(a, "step", "movingAverage");
    m = ut(m, lt(l, ir(u, c)));
  }
  return U(n, m);
}
var zn2 = L({ movingAverage_: Zd2 });
function Yd2(s, e, t) {
  is(t);
  const a = T(s, "indices", "scatterND", "int32"), r = T(e, "updates", "scatterND");
  e0(r, a, t);
  const n = { indices: a, updates: r }, o = { shape: t };
  return $.runKernel(qg, n, o);
}
var xn2 = L({ scatterND_: Yd2 });
function Md2(s, e, t, a) {
  if (s.dtype !== "int32")
    throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${s.dtype}.`);
  if (s.rank > 2)
    throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${s.shape}.`);
  const r = s.rank > 0 ? s.shape[0] : 1, n = s.rank > 1 ? s.shape[1] : 1;
  if (t.length !== n)
    throw new Error(`outputShape has incorrect number of elements:, ${t.length}, should be: ${n}.`);
  const o = e.size;
  if (!(e.rank === 0 || e.rank === 1 && o === r))
    throw new Error(`sparseValues has incorrect shape ${e.shape}, should be [] or [${r}]`);
  if (e.dtype !== a.dtype)
    throw new Error("sparseValues.dtype must match defaultValues.dtype");
}
function eh2(s, e, t, a = 0) {
  is(t);
  const r = T(s, "sparseIndices", "sparseToDense", "int32"), n = T(e, "sparseValues", "sparseToDense", "string_or_numeric"), o = T(a, "defaultValue", "sparseToDense", n.dtype);
  Md2(r, n, t, o);
  const u = {
    sparseIndices: r,
    sparseValues: n,
    defaultValue: o
  }, l = { outputShape: t };
  return $.runKernel(eb, u, l);
}
var Ln = L({ sparseToDense_: eh2 });
function th2(s, e) {
  const t = T(e, "indices", "gatherND", "int32"), r = { params: T(s, "x", "gatherND", "string_or_numeric"), indices: t };
  return $.runKernel(Hg, r);
}
var Vn2 = L({ gatherND_: th2 });
async function sh2(s, e, t = 1) {
  const a = T(s, "predictions", "inTopK"), r = T(e, "targets", "inTopK");
  v2(a.rank > 1, () => `inTopK() expects the predictions to be of rank 2 or higher, but got ${a.rank}`), v2(a.rank - 1 === r.rank, () => `predictions rank should be 1 larger than targets rank, but got predictions rank ${a.rank} and targets rank ${r.rank}`), Ve(a.shape.slice(0, a.shape.length - 1), r.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
  const n = a.shape[a.shape.length - 1];
  v2(t > 0 && t <= n, () => `'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${n}), but got ${t}`);
  const o = await a.data(), u = await r.data(), [l, p6] = [o.length / n, n], m = xe("bool", l);
  for (let c = 0; c < l; c++) {
    const d = c * p6, h6 = o.subarray(d, d + p6), b6 = [];
    for (let f = 0; f < h6.length; f++)
      b6.push({ value: h6[f], index: f });
    b6.sort((f, y6) => y6.value - f.value), m[c] = 0;
    for (let f = 0; f < t; f++)
      if (b6[f].index === u[c]) {
        m[c] = 1;
        break;
      }
  }
  return s !== a && a.dispose(), e !== r && r.dispose(), Re(m, r.shape, "bool");
}
var Fn2 = sh2;
function ah2({ x: s, filter: e, strides: t, pad: a, dataFormat: r = "NHWC", dilations: n = [1, 1], dimRoundingMode: o, bias: u, activation: l = "linear", preluActivationWeights: p6, leakyreluAlpha: m }) {
  if (kp($.state.gradientDepth, l) === false) {
    let E6 = Qh(s, e, t, a, r, n, o);
    return u != null && (E6 = U(E6, u)), Sp(E6, l, p6, m);
  }
  const c = T(s, "x", "depthwiseConv2d", "float32"), d = T(e, "filter", "depthwiseConv2d", "float32");
  let h6 = c, b6 = false;
  c.rank === 3 && (b6 = true, h6 = W(c, [1, c.shape[0], c.shape[1], c.shape[2]])), v2(h6.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${h6.rank}.`), v2(d.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${d.rank}.`), v2(h6.shape[3] === d.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${h6.shape[3]}) must match the inChannels dimension in filter ${d.shape[2]}.`), n == null && (n = [1, 1]), v2(Ee(t, n), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${t} and dilations '${n}'`), Be("fused depthwiseConv2d", a, o);
  const f = ke(
    h6.shape,
    d.shape,
    t,
    n,
    a,
    o,
    true
    /* depthwise */
  );
  let y6;
  u != null && (y6 = T(u, "bias", "fused conv2d"), [y6] = ne(y6, c), bt(f.outShape, y6.shape));
  let T6;
  p6 != null && (T6 = T(p6, "prelu weights", "fused depthwiseConv2d"));
  const _6 = (E6, D6) => {
    v2(wo(n), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${n}'`);
    const [V, Q, L6, j] = D6, $e2 = Cp(E6, L6, l), Et = hT(Q.shape, $e2, V, t, a, n, o), kt2 = uT(Q, $e2, V.shape, t, a, n, o);
    if (j != null) {
      const li2 = vp(y6, $e2);
      return [Et, kt2, li2];
    }
    return [Et, kt2];
  }, w6 = {
    x: h6,
    filter: d,
    bias: y6,
    preluActivationWeights: T6
  }, I = {
    strides: t,
    pad: a,
    dataFormat: r,
    dilations: n,
    dimRoundingMode: o,
    activation: l,
    leakyreluAlpha: m
  };
  return u == null ? So((D6, V, Q) => {
    let L6 = $.runKernel(nb, w6, I);
    return Q([V, D6, L6]), b6 && (L6 = W(L6, [L6.shape[1], L6.shape[2], L6.shape[3]])), { value: L6, gradFunc: _6 };
  })(h6, d) : So((D6, V, Q, L6) => {
    let j = $.runKernel(nb, w6, I);
    return L6([V, D6, j, Q]), b6 && (j = W(j, [j.shape[1], j.shape[2], j.shape[3]])), { value: j, gradFunc: _6 };
  })(h6, d, y6);
}
var rh2 = L({ fusedDepthwiseConv2d_: ah2 });
var Pn2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  conv2d: lT,
  depthwiseConv2d: rh2,
  matMul: im
}, Symbol.toStringTag, { value: "Module" }));
var nh2 = "model";
var ih2 = ".json";
var oh2 = ".weights.bin";
function xt2(s) {
  return new Promise((e) => setTimeout(e)).then(s);
}
var K6 = class {
  constructor(e) {
    if (!F().getBool("IS_BROWSER"))
      throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
    e.startsWith(K6.URL_SCHEME) && (e = e.slice(K6.URL_SCHEME.length)), (e == null || e.length === 0) && (e = nh2), this.modelJsonFileName = e + ih2, this.weightDataFileName = e + oh2;
  }
  async save(e) {
    if (typeof document > "u")
      throw new Error("Browser downloads are not supported in this environment since `document` is not present");
    const t = window.URL.createObjectURL(new Blob([e.weightData], { type: "application/octet-stream" }));
    if (e.modelTopology instanceof ArrayBuffer)
      throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
    {
      const a = [{
        paths: ["./" + this.weightDataFileName],
        weights: e.weightSpecs
      }], r = SC(e, a), n = window.URL.createObjectURL(new Blob([JSON.stringify(r)], { type: "application/json" })), o = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
      if (o.download = this.modelJsonFileName, o.href = n, await xt2(() => o.dispatchEvent(new MouseEvent("click"))), e.weightData != null) {
        const u = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
        u.download = this.weightDataFileName, u.href = t, await xt2(() => u.dispatchEvent(new MouseEvent("click")));
      }
      return { modelArtifactsInfo: Kh(e) };
    }
  }
};
K6.URL_SCHEME = "downloads://";
var uh2 = class {
  constructor(e) {
    if (e == null || e.length < 1)
      throw new Error(`When calling browserFiles, at least 1 file is required, but received ${e}`);
    this.jsonFile = e[0], this.weightsFiles = e.slice(1);
  }
  async load() {
    return new Promise((e, t) => {
      const a = new FileReader();
      a.onload = (r) => {
        const n = JSON.parse(r.target.result), o = n.modelTopology;
        if (o == null) {
          t(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));
          return;
        }
        if (n.weightsManifest == null) {
          t(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));
          return;
        }
        if (this.weightsFiles.length === 0) {
          e({ modelTopology: o });
          return;
        }
        const l = TC(n, (p6) => this.loadWeights(p6));
        e(l);
      }, a.onerror = (r) => t(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`), a.readAsText(this.jsonFile);
    });
  }
  loadWeights(e) {
    const t = [], a = [];
    for (const o of e)
      t.push(...o.weights), a.push(...o.paths);
    const r = this.checkManifestAndWeightFiles(e), n = a.map((o) => this.loadWeightsFile(o, r[o]));
    return Promise.all(n).then((o) => [t, bb(o)]);
  }
  loadWeightsFile(e, t) {
    return new Promise((a, r) => {
      const n = new FileReader();
      n.onload = (o) => {
        const u = o.target.result;
        a(u);
      }, n.onerror = (o) => r(`Failed to weights data from file of path '${e}'.`), n.readAsArrayBuffer(t);
    });
  }
  /**
   * Check the compatibility between weights manifest and weight files.
   */
  checkManifestAndWeightFiles(e) {
    const t = [], a = this.weightsFiles.map((n) => X4(n.name)), r = {};
    for (const n of e)
      n.paths.forEach((o) => {
        const u = X4(o);
        if (t.indexOf(u) !== -1)
          throw new Error(`Duplicate file basename found in weights manifest: '${u}'`);
        if (t.push(u), a.indexOf(u) === -1)
          throw new Error(`Weight file with basename '${u}' is not provided.`);
        r[o] = this.weightsFiles[a.indexOf(u)];
      });
    if (t.length !== this.weightsFiles.length)
      throw new Error(`Mismatch in the number of files in weights manifest (${t.length}) and the number of weight files provided (${this.weightsFiles.length}).`);
    return r;
  }
};
var lh2 = (s) => F().getBool("IS_BROWSER") && !Array.isArray(s) && s.startsWith(K6.URL_SCHEME) ? ph2(s.slice(K6.URL_SCHEME.length)) : null;
ee.registerSaveRouter(lh2);
function ph2(s = "model") {
  return new K6(s);
}
function mh2(s) {
  return new uh2(s);
}
var Ce2 = class {
  constructor(e) {
    this.modelArtifacts = e;
  }
  load() {
    return this.modelArtifacts;
  }
};
var Rn2 = class {
  constructor(e) {
    this.saveHandler = e;
  }
  save(e) {
    return this.saveHandler(e);
  }
};
var ch2 = class {
  constructor(e) {
    e.load && (this.load = () => Promise.resolve(e.load())), e.save && (this.save = (t) => Promise.resolve(e.save(t)));
  }
};
function dh2(s, e, t, a) {
  const r = arguments;
  return new ch2(_e2(...r));
}
function _e2(s, e, t, a) {
  return arguments.length === 1 ? s.modelTopology != null || s.weightSpecs != null ? new Ce2(s) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."), new Ce2({ modelTopology: s })) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."), new Ce2({
    modelTopology: s,
    weightSpecs: e,
    weightData: t,
    trainingConfig: a
  }));
}
function hh2(s) {
  return new Rn2(s);
}
function fh2(s) {
  return new Rn2(s);
}
var bt2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  browserFiles: mh2,
  browserHTTPRequest: HN,
  concatenateArrayBuffers: bb,
  copyModel: Z4,
  decodeWeights: gb,
  encodeWeights: sm,
  fromMemory: dh2,
  fromMemorySync: _e2,
  getLoadHandlers: MC,
  getModelArtifactsForJSON: TC,
  getModelArtifactsForJSONSync: kC,
  getModelArtifactsInfoForJSON: Kh,
  getSaveHandlers: LC,
  getWeightSpecs: NC,
  http: m0,
  isHTTPScheme: um,
  listModels: O4,
  loadWeights: AN,
  moveModel: B4,
  registerLoadRouter: A4,
  registerSaveRouter: P4,
  removeModel: K4,
  weightsLoaderFactory: ON,
  withSaveHandler: hh2,
  withSaveHandlerSync: fh2
}, Symbol.toStringTag, { value: "Module" }));
function yh2(s, e, t) {
  const a = T(s, "labels", "confusionMatrix"), r = T(e, "predictions", "confusionMatrix");
  v2(t == null || t > 0 && Number.isInteger(t), () => `If provided, numClasses must be a positive integer, but got ${t}`), v2(a.rank === 1, () => `Expected the rank of labels to be 1, but got ${a.rank}`), v2(r.rank === 1, () => `Expected the rank of predictions to be 1, but got ${r.rank}`), v2(a.shape[0] === r.shape[0], () => `Mismatch in the number of examples: ${a.shape[0]} vs. ${r.shape[0]}. Labels and predictions should have the same number of elements.`), v2(t > 0 && Number.isInteger(t), () => `numClasses is required to be a positive integer, but got ${t}`);
  const n = Pb(et(a, "int32"), t), o = Pb(et(r, "int32"), t), u = kt(n), l = Gt(u, o);
  return et(l, "int32");
}
var gh2 = L({ confusionMatrix_: yh2 });
var bh2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  confusionMatrix: gh2
}, Symbol.toStringTag, { value: "Module" }));
var jn2 = "4.2.0";
var Nh2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  nonMaxSuppressionV3Impl: Tp,
  nonMaxSuppressionV4Impl: Np,
  nonMaxSuppressionV5Impl: Rp,
  whereImpl: t0
}, Symbol.toStringTag, { value: "Module" }));
function wh2(s) {
  return new gx(s);
}
function Th2(s) {
  return new bx(s);
}
function Sh2() {
  return new xx();
}
function vh2(s) {
  return new yx(s);
}
var Oh2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  maxNorm: wh2,
  minMaxNorm: vh2,
  nonNeg: Sh2,
  unitNorm: Th2
}, Symbol.toStringTag, { value: "Module" }));
function _h2() {
  return new lx();
}
function Ah2() {
  return new af();
}
function Eh2(s) {
  return new cx(s);
}
function kh2(s) {
  return new ux(s);
}
function Ih2(s) {
  return new dx(s);
}
function Dh2(s) {
  return new hx(s);
}
function $h2(s) {
  return new px(s);
}
function Ch2(s) {
  return new qe(s);
}
function zh2(s) {
  return new lf(s);
}
function xh2(s) {
  return new cf(s);
}
function Lh2(s) {
  return new uf(s);
}
function Vh2(s) {
  return new df(s);
}
function Fh2(s) {
  return new hf(s);
}
function Ph2(s) {
  return new pf(s);
}
function Rh2(s) {
  return new fx(s);
}
var jh2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  constant: Eh2,
  glorotNormal: xh2,
  glorotUniform: zh2,
  heNormal: Lh2,
  heUniform: Vh2,
  identity: $h2,
  leCunNormal: Fh2,
  leCunUniform: Ph2,
  ones: Ah2,
  orthogonal: Rh2,
  randomNormal: Ih2,
  randomUniform: kh2,
  truncatedNormal: Dh2,
  varianceScaling: Ch2,
  zeros: _h2
}, Symbol.toStringTag, { value: "Module" }));
function Bh2(s) {
  return new tr(s);
}
function Hh2(s) {
  return new oi(s);
}
function Bn2(s) {
  return ZG(s);
}
function Wh2(s, e) {
  xn.registerCallbackConstructor(s, e);
}
function qh2(s) {
  return new Ia(s);
}
function Uh2(s) {
  return new qx(s);
}
function Gh2(s) {
  return new Qx(s);
}
function Kh2(s) {
  return new Jx(s);
}
function Jh2(s) {
  return new jx(s);
}
function Qh2(s) {
  return new ey(s);
}
function Xh2(s) {
  return new ty(s);
}
function Zh2(s) {
  return new ou(s);
}
function Yh2(s) {
  return new va(s);
}
function Mh2(s) {
  return new sy(s);
}
function ef2(s) {
  return new Sa(s);
}
function tf2(s) {
  return new oy(s);
}
function sf2(s) {
  return new iy(s);
}
function af2(s) {
  return new ay(s);
}
function rf2(s) {
  return new ly(s);
}
function nf2(s) {
  return new cy(s);
}
function of2(s) {
  return new wy(s);
}
function uf2(s) {
  return new xy(s);
}
function lf2(s) {
  return new kf(s);
}
function pf2(s) {
  return new by(s);
}
function mf2(s) {
  return new yy(s);
}
function cf2(s) {
  return new Iy(s);
}
function df2(s) {
  return new Cy(s);
}
function hf2(s) {
  return new vy(s);
}
function ff2(s) {
  return new ky(s);
}
function yf2(s) {
  return new Ty(s);
}
function gf2(s) {
  return new Ry(s);
}
function bf2(s) {
  return new Ey(s);
}
function Nf2(s) {
  return new $y(s);
}
function wf2(s) {
  return new Gy(s);
}
function Tf2(s) {
  return new Ny(s);
}
function Sf2(s) {
  return new Ly(s);
}
function vf2(s) {
  return new Fy(s);
}
function Of2(s) {
  return new Vy(s);
}
function _f2(s) {
  return new zy(s);
}
function Nt2(s) {
  return new Oy(s);
}
function Af2(s) {
  return Nt2(s);
}
function Ef2(s) {
  return Nt2(s);
}
function wt(s) {
  return new By(s);
}
function kf2(s) {
  return wt(s);
}
function If2(s) {
  return wt(s);
}
function Tt2(s) {
  return new Uy(s);
}
function Df2(s) {
  return Tt2(s);
}
function $f2(s) {
  return Tt2(s);
}
function Cf2(s) {
  return new Qy(s);
}
function zf2(s) {
  return new qy(s);
}
function Hn2(s) {
  return new Jy(s);
}
function Wn2(s) {
  return new t1(s);
}
function qn2(s) {
  return new Ay(s);
}
function Un2(s) {
  return new Zy(s);
}
function xf2(s) {
  return new _y(s);
}
function Lf2(s) {
  return new py(s);
}
function Vf2(s) {
  return new Cf(s);
}
function Ff2(s) {
  return new fy(s);
}
function Pf2(s) {
  return new iu(s);
}
function Rf2(s) {
  return new hy(s);
}
function jf2(s) {
  return new If(s);
}
function Bf2(s) {
  return new gy(s);
}
function Hf2(s) {
  return new Sf(s);
}
function Wf2(s) {
  return new Qs(s);
}
function qf2(s) {
  return new vf(s);
}
function Uf2(s) {
  return new s1(s);
}
function Gf2(s) {
  return new n1(s);
}
var Kf2 = Hn2;
var Jf2 = Wn2;
var Qf2 = qn2;
var Xf2 = Un2;
function Zf2(s) {
  return new My(s);
}
function Yf2(s) {
  return new Wy(s);
}
function Mf2(s) {
  return new Dy(s);
}
function ey2(s) {
  return new Sy(s);
}
function ty2(s) {
  return new o1(s);
}
function sy2(s) {
  return new r1(s);
}
function ay2(s) {
  return new a1(s);
}
function ry2(s) {
  return new i1(s);
}
var ny2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  Layer: St,
  RNN: Qs,
  RNNCell: ru,
  activation: of2,
  add: yf2,
  alphaDropout: Mf2,
  average: gf2,
  averagePooling1d: Nt2,
  averagePooling2d: wt,
  averagePooling3d: Tt2,
  avgPool1d: Af2,
  avgPool2d: kf2,
  avgPool3d: Df2,
  avgPooling1d: Ef2,
  avgPooling2d: If2,
  avgPooling3d: $f2,
  batchNormalization: vf2,
  bidirectional: Uf2,
  categoryEncoding: ry2,
  centerCrop: sy2,
  concatenate: bf2,
  conv1d: Zh2,
  conv2d: Yh2,
  conv2dTranspose: Mh2,
  conv3d: ef2,
  conv3dTranspose: tf2,
  convLstm2d: Bf2,
  convLstm2dCell: Hf2,
  cropping2D: af2,
  dense: uf2,
  depthwiseConv2d: nf2,
  dot: Sf2,
  dropout: lf2,
  elu: Uh2,
  embedding: ff2,
  flatten: mf2,
  gaussianDropout: Yf2,
  gaussianNoise: Zf2,
  globalAveragePooling1d: Cf2,
  globalAveragePooling2d: zf2,
  globalMaxPool1d: Kf2,
  globalMaxPool2d: Jf2,
  globalMaxPooling1d: Hn2,
  globalMaxPooling2d: Wn2,
  gru: Lf2,
  gruCell: Vf2,
  input: Bn2,
  inputLayer: qh2,
  layerNormalization: Of2,
  leakyReLU: Kh2,
  lstm: Ff2,
  lstmCell: Pf2,
  masking: ey2,
  maxPool1d: Qf2,
  maxPool2d: Xf2,
  maxPooling1d: qn2,
  maxPooling2d: Un2,
  maxPooling3d: xf2,
  maximum: Nf2,
  minimum: wf2,
  multiply: Tf2,
  permute: hf2,
  prelu: Jh2,
  reLU: Gh2,
  repeatVector: cf2,
  rescaling: ty2,
  reshape: df2,
  resizing: ay2,
  rnn: Wf2,
  separableConv2d: sf2,
  simpleRNN: Rf2,
  simpleRNNCell: jf2,
  softmax: Qh2,
  spatialDropout1d: pf2,
  stackedRNNCells: qf2,
  thresholdedReLU: Xh2,
  timeDistributed: Gf2,
  upSampling2d: rf2,
  zeroPadding2d: _f2
}, Symbol.toStringTag, { value: "Module" }));
function iy2(s, e) {
  return Sx(s, e);
}
function oy2(s, e) {
  return pE(s, e);
}
function uy2(s, e) {
  return fE(s, e);
}
function ly2(s, e) {
  return kx(s, e);
}
function py2(s, e) {
  return Nx(s, e);
}
function my2(s, e) {
  return hE(s, e);
}
function cy2(s, e) {
  return IY(s, e);
}
function dy2(s, e) {
  return vx(s, e);
}
function hy2(s, e) {
  return gf(s, e);
}
function fy2(s, e) {
  return bf(s, e);
}
function yy2(s, e) {
  return bf(s, e);
}
function gy2(s, e) {
  return bf(s, e);
}
function by2(s, e) {
  return tu(s, e);
}
function Ny2(s, e) {
  return tu(s, e);
}
function wy2(s, e) {
  return tu(s, e);
}
var Ty2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  MAPE: yy2,
  MSE: Ny2,
  binaryAccuracy: iy2,
  binaryCrossentropy: oy2,
  categoricalAccuracy: ly2,
  categoricalCrossentropy: py2,
  cosineProximity: dy2,
  mape: gy2,
  meanAbsoluteError: hy2,
  meanAbsolutePercentageError: fy2,
  meanSquaredError: by2,
  mse: wy2,
  precision: my2,
  recall: cy2,
  sparseCategoricalAccuracy: uy2
}, Symbol.toStringTag, { value: "Module" }));
var Sy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  modelFromJSON: CY
}, Symbol.toStringTag, { value: "Module" }));
function vy2(s) {
  return new nu(s);
}
function Oy2(s) {
  return TY(s);
}
function _y2(s) {
  return NY(s);
}
var Ay2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  l1: Oy2,
  l1l2: vy2,
  l2: _y2
}, Symbol.toStringTag, { value: "Module" }));
var Gn2 = class extends ei {
  constructor() {
    super(...arguments), this.model = null;
  }
  setModel(e) {
    if (!(e instanceof tr))
      throw new Error("model must be a LayersModel, not some other Container");
    this.model = e;
  }
};
function fe2(s, e) {
  return s < e;
}
function Lt2(s, e) {
  return s > e;
}
var Kn2 = class extends Gn2 {
  constructor(e) {
    if (super(), e == null && (e = {}), e.restoreBestWeights)
      throw new xt("restoreBestWeights = True is not implemented in EarlyStopping yet.");
    this.monitor = e.monitor || "val_loss", this.minDelta = Math.abs(e.minDelta || 0), this.patience = e.patience || 0, this.verbose = e.verbose || 0, this.mode = e.mode || "auto", this.baseline = e.baseline, ["auto", "min", "max"].indexOf(this.mode) === -1 && (console.warn(`EarlyStopping mode '${this.mode}' is invalid. Falling back to mode 'auto'.`), this.mode = "auto"), this.mode === "min" ? this.monitorFunc = fe2 : this.mode === "max" ? this.monitorFunc = Lt2 : this.monitor.indexOf("acc") !== -1 ? this.monitorFunc = Lt2 : this.monitorFunc = fe2, this.monitorFunc === fe2 && (this.minDelta *= -1);
  }
  async onTrainBegin(e) {
    this.wait = 0, this.stoppedEpoch = 0, this.baseline != null ? this.best = this.baseline : this.best = this.monitorFunc === fe2 ? 1 / 0 : -1 / 0;
  }
  async onEpochEnd(e, t) {
    await eo(t);
    const a = this.getMonitorValue(t);
    a != null && (this.monitorFunc(a - this.minDelta, this.best) ? (this.best = a, this.wait = 0) : (this.wait++, this.wait >= this.patience && (this.stoppedEpoch = e, this.model.stopTraining = true)));
  }
  async onTrainEnd(e) {
    this.stoppedEpoch > 0 && this.verbose && console.log(`Epoch ${this.stoppedEpoch}: early stopping.`);
  }
  getMonitorValue(e) {
    e == null && (e = {});
    const t = e[this.monitor];
    return t == null && console.warn(`Metric for EarlyStopping ${this.monitor} is not available. Available metrics are: ${Object.keys(e)}`), t;
  }
};
function Ey2(s) {
  return new Kn2(s);
}
var ky2 = { earlyStopping: Ey2 };
var St2 = {};
function Iy2(s, e) {
  const t = {
    tfOpName: s,
    category: "custom",
    inputs: [],
    attrs: [],
    customExecutor: e
  };
  St2[s] = t;
}
function Jn2(s) {
  return St2[s];
}
function Dy2(s) {
  delete St2[s];
}
function i(s, e, t, a, r) {
  const n = e.inputParams[s];
  if (n && n.inputIndexStart !== void 0) {
    const u = n.inputIndexStart, l = n.inputIndexEnd === 0 ? void 0 : n.inputIndexEnd === void 0 ? u + 1 : n.inputIndexEnd;
    if (n.type === "tensor")
      return k6(e.inputNames[n.inputIndexStart], t, a, r);
    if (n.type === "tensors")
      return e.inputNames.slice(u, l).map((d) => k6(d, t, a, r));
    const p6 = k6(e.inputNames.slice(u)[0], t, a, r), m = p6.dataSync();
    return n.type === "number" ? m[0] : Sn(p6.shape, m);
  }
  const o = e.attrParams[s];
  return o && o.value;
}
function k6(s, e, t, a) {
  const [r, n] = $6(s);
  if (a != null) {
    const u = a.getHashTableHandleByName(r);
    if (u != null)
      return u;
  }
  const o = t.currentContextIds.find((u) => !!e[Ae2(r, u)]);
  return o !== void 0 ? e[Ae2(r, o)][n] : void 0;
}
function $y2(s, e, t) {
  return e[Ae2(s, t.currentContextId)];
}
function B(s, e) {
  const [t, a, r] = $6(s);
  return [
    Ae2(t, e && e.currentContextId),
    a,
    r
  ];
}
function Ae2(s, e) {
  return e ? `${s}-${e}` : s;
}
function $6(s) {
  const e = s.split(":");
  if (e.length === 1)
    return [s, 0, void 0];
  const t = e[0], a = e.length === 3 ? e[1] : void 0, r = Number(e[e.length - 1]);
  return [t, r, a];
}
function be2(s, e, t) {
  let a = i("pad", s, e, t);
  if (a === "explicit") {
    a = i("explicitPaddings", s, e, t);
    const r = [[0, 0], [0, 0], [0, 0], [0, 0]];
    for (let n = 0; n < 4; n++)
      r[n][0] = a[n * 2], r[n][1] = a[n * 2 + 1];
    return r;
  }
  return a;
}
function H(s) {
  return s.kept ? s : po(s);
}
var Cy2 = [
  {
    tfOpName: "Add",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "AddV2",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "AddN",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "tensors",
        type: "tensors"
      }
    ]
  },
  {
    tfOpName: "BiasAdd",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sub",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "RealDiv",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Div",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "DivNoNan",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "FloorDiv",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Mul",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Maximum",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Minimum",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Pow",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "SquaredDifference",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Mod",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "FloorMod",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  }
];
var zy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Cy2
}, Symbol.toStringTag, { value: "Module" }));
var xy2 = [
  {
    tfOpName: "Abs",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Acos",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Asin",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Atan",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Atan2",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "y",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Ceil",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "ClipByValue",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "clipValueMin",
        type: "number"
      },
      {
        start: 2,
        name: "clipValueMax",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Complex",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "real",
        type: "tensor"
      },
      {
        start: 1,
        name: "imag",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "ComplexAbs",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Cos",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Cosh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Elu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Exp",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Floor",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Log",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Imag",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "outputType",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Neg",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Real",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "outputType",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Prelu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "alpha",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Relu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Relu6",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Selu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sigmoid",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sin",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sinh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sqrt",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Rsqrt",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Square",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Tan",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Tanh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sign",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Round",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Expm1",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Log1p",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Reciprocal",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Softplus",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Asinh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Acosh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Atanh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Erf",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Prod",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axes",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool",
        notSupported: true
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LeakyRelu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "alpha",
        name: "alpha",
        type: "number",
        defaultValue: 0.2
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "IsNan",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  }
];
var Ly2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: xy2
}, Symbol.toStringTag, { value: "Module" }));
var Vy2 = [
  {
    tfOpName: "EmptyTensorList",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "elementShape",
        type: "shape"
      },
      {
        start: 1,
        name: "maxNumElements",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "LoopCond",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "pred",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Switch",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "data",
        type: "tensor"
      },
      {
        start: 1,
        name: "pred",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Merge",
    category: "control",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "tensors",
        type: "tensors"
      }
    ]
  },
  {
    tfOpName: "Enter",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "frame_name",
        name: "frameName",
        type: "string"
      },
      {
        tfName: "is_constant",
        name: "isConstant",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Exit",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "NextIteration",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorArrayV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "size",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "element_shape",
        name: "elementShape",
        type: "shape"
      },
      {
        tfName: "dynamic_size",
        name: "dynamicSize",
        type: "bool"
      },
      {
        tfName: "clear_after_read",
        name: "clearAfterRead",
        type: "bool"
      },
      {
        tfName: "identical_element_shapes",
        name: "identicalElementShapes",
        type: "bool"
      },
      {
        tfName: "tensor_array_name",
        name: "name",
        type: "string"
      }
    ]
  },
  {
    tfOpName: "TensorArrayWriteV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "index",
        type: "number"
      },
      {
        start: 2,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 3,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorArrayReadV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "index",
        type: "number"
      },
      {
        start: 2,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorArrayGatherV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "element_shape",
        name: "elementShape",
        type: "shape"
      }
    ]
  },
  {
    tfOpName: "TensorArrayScatterV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 3,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorArrayConcatV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "element_shape_except0",
        name: "elementShapeExcept0",
        type: "shape",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorArraySplitV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 2,
        name: "lengths",
        type: "number[]"
      },
      {
        start: 3,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorArraySizeV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "flowIn",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "TensorArrayCloseV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "StatelessIf",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "cond",
        type: "tensor"
      },
      {
        start: 1,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "then_branch",
        name: "thenBranch",
        type: "func"
      },
      {
        tfName: "else_branch",
        name: "elseBranch",
        type: "func"
      }
    ]
  },
  {
    tfOpName: "If",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "cond",
        type: "tensor"
      },
      {
        start: 1,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "then_branch",
        name: "thenBranch",
        type: "func"
      },
      {
        tfName: "else_branch",
        name: "elseBranch",
        type: "func"
      }
    ]
  },
  {
    tfOpName: "StatelessWhile",
    category: "control",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "cond",
        name: "cond",
        type: "func"
      },
      {
        tfName: "body",
        name: "body",
        type: "func"
      }
    ]
  },
  {
    tfOpName: "While",
    category: "control",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "cond",
        name: "cond",
        type: "func"
      },
      {
        tfName: "body",
        name: "body",
        type: "func"
      }
    ]
  },
  {
    tfOpName: "TensorListScatter",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListScatterV2",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "elementShape",
        type: "shape"
      },
      {
        start: 3,
        name: "numElements",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListGather",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListGetItem",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "index",
        type: "number"
      },
      {
        start: 2,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListSetItem",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "index",
        type: "number"
      },
      {
        start: 2,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListReserve",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "elementShape",
        type: "shape"
      },
      {
        start: 1,
        name: "numElements",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListFromTensor",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListStack",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      },
      {
        tfName: "num_elements",
        name: "numElements",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListSplit",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "elementShape",
        type: "shape"
      },
      {
        start: 2,
        name: "lengths",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListConcat",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "element_shape",
        name: "elementShape",
        type: "shape"
      },
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListConcatV2",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "element_shape",
        name: "elementShape",
        type: "shape"
      },
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListPopBack",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListPushBack",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListLength",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "TensorListResize",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number"
      }
    ]
  }
];
var Fy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Vy2
}, Symbol.toStringTag, { value: "Module" }));
var Py2 = [
  {
    tfOpName: "AvgPool",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "MaxPool",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: [],
        notSupported: true
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "MaxPoolWithArgmax",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "include_batch_in_index",
        name: "includeBatchInIndex",
        type: "bool"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "AvgPool3D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "MaxPool3D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Conv1D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "stride",
        name: "stride",
        type: "number"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NWC"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "dilation",
        name: "dilation",
        type: "number",
        defaultValue: 1
      }
    ]
  },
  {
    tfOpName: "Conv2D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "useCudnnOnGpu",
        name: "useCudnnOnGpu",
        type: "bool"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "_FusedConv2D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      },
      {
        start: 2,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "num_args",
        name: "numArgs",
        type: "number"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "use_cudnn_on_gpu",
        name: "useCudnnOnGpu",
        type: "bool",
        defaultValue: true
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]",
        defaultValue: [
          1,
          1,
          1,
          1
        ]
      },
      {
        tfName: "fused_ops",
        name: "fusedOps",
        type: "string[]",
        defaultValue: []
      },
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-4
      },
      {
        tfName: "leakyrelu_alpha",
        name: "leakyreluAlpha",
        type: "number",
        defaultValue: 0.2
      }
    ]
  },
  {
    tfOpName: "Conv2DBackpropInput",
    category: "convolution",
    inputs: [
      {
        start: 2,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      },
      {
        start: 0,
        name: "outputShape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "DepthwiseConv2d",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "DepthwiseConv2dNative",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "FusedDepthwiseConv2dNative",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      },
      {
        start: 2,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "num_args",
        name: "numArgs",
        type: "number"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]",
        defaultValue: [
          1,
          1,
          1,
          1
        ]
      },
      {
        tfName: "fused_ops",
        name: "fusedOps",
        type: "string[]",
        defaultValue: []
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      }
    ]
  },
  {
    tfOpName: "Conv3D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "Dilation2D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "rates",
        name: "dilations",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      }
    ]
  }
];
var Ry2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Py2
}, Symbol.toStringTag, { value: "Module" }));
var jy2 = [
  {
    tfOpName: "Fill",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      },
      {
        start: 1,
        name: "value",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "LinSpace",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "start",
        type: "number"
      },
      {
        start: 1,
        name: "stop",
        type: "number"
      },
      {
        start: 2,
        name: "num",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "OneHot",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "indices",
        type: "tensor"
      },
      {
        start: 1,
        name: "depth",
        type: "number"
      },
      {
        start: 2,
        name: "onValue",
        type: "number",
        defaultValue: 1
      },
      {
        start: 3,
        name: "offValue",
        type: "number",
        defaultValue: 0
      }
    ],
    attrs: [
      {
        tfName: "axis",
        name: "axis",
        type: "number",
        notSupported: true
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "Ones",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "OnesLike",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "RandomStandardNormal",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "seed",
        name: "seed",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number",
        defaultValue: 0,
        notSupported: true
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "T",
        name: "T",
        type: "number",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "RandomUniform",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "minval",
        name: "minval",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "maxval",
        name: "maxval",
        type: "number",
        defaultValue: 1
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "seed",
        name: "seed",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number",
        defaultValue: 0,
        notSupported: true
      },
      {
        tfName: "T",
        name: "T",
        type: "number",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Range",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "start",
        type: "number"
      },
      {
        start: 1,
        name: "stop",
        type: "number"
      },
      {
        start: 2,
        name: "step",
        type: "number",
        defaultValue: 0
      }
    ],
    attrs: [
      {
        tfName: "Tidx",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TruncatedNormal",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "means",
        name: "mean",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "stddev",
        name: "stdDev",
        type: "number",
        defaultValue: 1
      },
      {
        tfName: "seed",
        name: "seed",
        type: "number"
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number",
        defaultValue: 0,
        notSupported: true
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "T",
        name: "T",
        type: "number",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Zeros",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "ZerosLike",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "Multinomial",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "logits",
        type: "tensor"
      },
      {
        start: 1,
        name: "numSamples",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "seed",
        name: "seed",
        type: "number"
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "output_dtype",
        name: "output_dtype",
        type: "dtype"
      }
    ]
  }
];
var By2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: jy2
}, Symbol.toStringTag, { value: "Module" }));
var Hy2 = [
  {
    tfOpName: "NonMaxSuppressionV2",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 1,
        name: "scores",
        type: "tensor"
      },
      {
        start: 2,
        name: "maxOutputSize",
        type: "number"
      },
      {
        start: 3,
        name: "iouThreshold",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "NonMaxSuppressionV3",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 1,
        name: "scores",
        type: "tensor"
      },
      {
        start: 2,
        name: "maxOutputSize",
        type: "number"
      },
      {
        start: 3,
        name: "iouThreshold",
        type: "number"
      },
      {
        start: 4,
        name: "scoreThreshold",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "NonMaxSuppressionV4",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 1,
        name: "scores",
        type: "tensor"
      },
      {
        start: 2,
        name: "maxOutputSize",
        type: "number"
      },
      {
        start: 3,
        name: "iouThreshold",
        type: "number"
      },
      {
        start: 4,
        name: "scoreThreshold",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "T_threshold",
        name: "threshold",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "pad_to_max_output_size",
        name: "padToMaxOutputSize",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "NonMaxSuppressionV5",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 1,
        name: "scores",
        type: "tensor"
      },
      {
        start: 2,
        name: "maxOutputSize",
        type: "number"
      },
      {
        start: 3,
        name: "iouThreshold",
        type: "number"
      },
      {
        start: 4,
        name: "scoreThreshold",
        type: "number"
      },
      {
        start: 5,
        name: "softNmsSigma",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "Where",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "condition",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "ListDiff",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "y",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  }
];
var Wy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Hy2
}, Symbol.toStringTag, { value: "Module" }));
var qy2 = [
  {
    tfOpName: "LowerBound",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "sortedSequence",
        type: "tensor"
      },
      {
        start: 1,
        name: "values",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "TopKV2",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "k",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "sorted",
        name: "sorted",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "UpperBound",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "sortedSequence",
        type: "tensor"
      },
      {
        start: 1,
        name: "values",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Unique",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "UniqueV2",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ]
  }
];
var Uy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: qy2
}, Symbol.toStringTag, { value: "Module" }));
var Gy2 = [
  {
    tfOpName: "PlaceholderWithDefault",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "default",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "shape",
        name: "shape",
        type: "shape"
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "Placeholder",
    category: "graph",
    attrs: [
      {
        tfName: "shape",
        name: "shape",
        type: "shape"
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "Const",
    category: "graph"
  },
  {
    tfOpName: "Identity",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "IdentityN",
    category: "graph",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "x",
        type: "tensors"
      }
    ]
  },
  {
    tfOpName: "Snapshot",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Rank",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Size",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Shape",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "ShapeN",
    category: "graph",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "x",
        type: "tensors"
      }
    ]
  },
  {
    tfOpName: "Print",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "data",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "message",
        name: "message",
        type: "string"
      },
      {
        tfName: "first_n",
        name: "firstN",
        type: "number",
        notSupported: true
      },
      {
        tfName: "summarize",
        name: "summarize",
        type: "number",
        defaultValue: 3
      }
    ]
  },
  {
    tfOpName: "NoOp",
    category: "graph",
    inputs: []
  },
  {
    tfOpName: "StopGradient",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "FakeQuantWithMinMaxVars",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "min",
        name: "min",
        type: "number"
      },
      {
        tfName: "max",
        name: "max",
        type: "number"
      }
    ]
  }
];
var Ky2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Gy2
}, Symbol.toStringTag, { value: "Module" }));
var Jy2 = [
  {
    tfOpName: "HashTable",
    category: "hash_table",
    inputs: [],
    attrs: [
      {
        tfName: "shared_name",
        name: "sharedName",
        type: "string"
      },
      {
        tfName: "use_node_name_sharing",
        name: "useNodeNameSharing",
        type: "bool"
      },
      {
        tfName: "key_dtype",
        name: "keyDType",
        type: "dtype"
      },
      {
        tfName: "value_dtype",
        name: "valueDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "HashTableV2",
    category: "hash_table",
    inputs: [],
    attrs: [
      {
        tfName: "shared_name",
        name: "sharedName",
        type: "string"
      },
      {
        tfName: "use_node_name_sharing",
        name: "useNodeNameSharing",
        type: "bool"
      },
      {
        tfName: "key_dtype",
        name: "keyDType",
        type: "dtype"
      },
      {
        tfName: "value_dtype",
        name: "valueDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "LookupTableImport",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "Tin",
        name: "tIn",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "tOut",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LookupTableImportV2",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "Tin",
        name: "tIn",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "tOut",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LookupTableFind",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "defaultValue",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "Tin",
        name: "tIn",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "tOut",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LookupTableFindV2",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "defaultValue",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "Tin",
        name: "tIn",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "tOut",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LookupTableSize",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "LookupTableSizeV2",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "InitializeTable",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "InitializeTableV2",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ]
  }
];
var Qy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Jy2
}, Symbol.toStringTag, { value: "Module" }));
var Xy2 = [
  {
    tfOpName: "ResizeBilinear",
    category: "image",
    inputs: [
      {
        start: 0,
        name: "images",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "align_corners",
        name: "alignCorners",
        type: "bool"
      },
      {
        tfName: "half_pixel_centers",
        name: "halfPixelCenters",
        type: "bool"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "ResizeNearestNeighbor",
    category: "image",
    inputs: [
      {
        start: 0,
        name: "images",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "align_corners",
        name: "alignCorners",
        type: "bool"
      },
      {
        tfName: "half_pixel_centers",
        name: "halfPixelCenters",
        type: "bool"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "CropAndResize",
    category: "image",
    inputs: [
      {
        start: 0,
        name: "image",
        type: "tensor"
      },
      {
        start: 1,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 2,
        name: "boxInd",
        type: "tensor"
      },
      {
        start: 3,
        name: "cropSize",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "method",
        name: "method",
        type: "string"
      },
      {
        tfName: "extrapolation_value",
        name: "extrapolationValue",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "ImageProjectiveTransformV3",
    category: "image",
    inputs: [
      {
        start: 0,
        name: "images",
        type: "tensor"
      },
      {
        start: 1,
        name: "transforms",
        type: "tensor"
      },
      {
        start: 2,
        name: "outputShape",
        type: "number[]"
      },
      {
        start: 3,
        name: "fillValue",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "interpolation",
        name: "interpolation",
        type: "string"
      },
      {
        tfName: "fill_mode",
        name: "fillMode",
        type: "string"
      }
    ]
  }
];
var Zy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Xy2
}, Symbol.toStringTag, { value: "Module" }));
var Yy2 = [
  {
    tfOpName: "Equal",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "NotEqual",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Greater",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "GreaterEqual",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Less",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LessEqual",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LogicalAnd",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LogicalNot",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LogicalOr",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Select",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "condition",
        type: "tensor"
      },
      {
        start: 1,
        name: "a",
        type: "tensor"
      },
      {
        start: 2,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "SelectV2",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "condition",
        type: "tensor"
      },
      {
        start: 1,
        name: "a",
        type: "tensor"
      },
      {
        start: 2,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  }
];
var My2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Yy2
}, Symbol.toStringTag, { value: "Module" }));
var eg2 = [
  {
    tfOpName: "_FusedMatMul",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      },
      {
        start: 2,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "num_args",
        name: "numArgs",
        type: "number"
      },
      {
        tfName: "fused_ops",
        name: "fusedOps",
        type: "string[]",
        defaultValue: []
      },
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-4
      },
      {
        tfName: "transpose_a",
        name: "transposeA",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "transpose_b",
        name: "transposeB",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "leakyrelu_alpha",
        name: "leakyreluAlpha",
        type: "number",
        defaultValue: 0.2
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "MatMul",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "transpose_a",
        name: "transposeA",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "transpose_b",
        name: "transposeB",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "BatchMatMul",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "adj_x",
        name: "transposeA",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "adj_y",
        name: "transposeB",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "BatchMatMulV2",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "adj_x",
        name: "transposeA",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "adj_y",
        name: "transposeB",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Transpose",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "perm",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Einsum",
    category: "matrices",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "tensors",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "equation",
        name: "equation",
        type: "string"
      },
      {
        tfName: "N",
        name: "n",
        type: "number",
        defaultValue: 2
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  }
];
var tg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: eg2
}, Symbol.toStringTag, { value: "Module" }));
var sg2 = [
  {
    tfOpName: "EuclideanNorm",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool",
        defaultValue: false
      }
    ]
  },
  {
    tfOpName: "FusedBatchNorm",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "scale",
        type: "tensor"
      },
      {
        start: 2,
        name: "offset",
        type: "tensor"
      },
      {
        start: 3,
        name: "mean",
        type: "tensor"
      },
      {
        start: 4,
        name: "variance",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-3
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "FusedBatchNormV2",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "scale",
        type: "tensor"
      },
      {
        start: 2,
        name: "offset",
        type: "tensor"
      },
      {
        start: 3,
        name: "mean",
        type: "tensor"
      },
      {
        start: 4,
        name: "variance",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-3
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "FusedBatchNormV3",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "scale",
        type: "tensor"
      },
      {
        start: 2,
        name: "offset",
        type: "tensor"
      },
      {
        start: 3,
        name: "mean",
        type: "tensor"
      },
      {
        start: 4,
        name: "variance",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-3
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LRN",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "depth_radius",
        name: "radius",
        type: "number",
        defaultValue: 5
      },
      {
        tfName: "bias",
        name: "bias",
        type: "number",
        defaultValue: 1
      },
      {
        tfName: "alpha",
        name: "alpha",
        type: "number",
        defaultValue: 1
      },
      {
        tfName: "beta",
        name: "beta",
        type: "number",
        defaultValue: 0.5
      }
    ]
  },
  {
    tfOpName: "Softmax",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "LogSoftmax",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "SparseToDense",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "sparseIndices",
        type: "tensor"
      },
      {
        start: 1,
        name: "outputShape",
        type: "number[]"
      },
      {
        start: 2,
        name: "sparseValues",
        type: "tensor"
      },
      {
        start: 3,
        name: "defaultValue",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "validate_indices",
        name: "validateIndices",
        type: "bool",
        defaultValue: true,
        notSupported: true
      }
    ]
  }
];
var ag2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: sg2
}, Symbol.toStringTag, { value: "Module" }));
var rg2 = [
  {
    tfOpName: "Bincount",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number"
      },
      {
        start: 2,
        name: "weights",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "DenseBincount",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number"
      },
      {
        start: 2,
        name: "weights",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "binary_output",
        name: "binaryOutput",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Max",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Mean",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Min",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Sum",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "All",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Any",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "ArgMax",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "ArgMin",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "Prod",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Cumprod",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "exclusive",
        name: "exclusive",
        type: "bool"
      },
      {
        tfName: "reverse",
        name: "reverse",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Cumsum",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "exclusive",
        name: "exclusive",
        type: "bool"
      },
      {
        tfName: "reverse",
        name: "reverse",
        type: "bool"
      }
    ]
  }
];
var ng2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: rg2
}, Symbol.toStringTag, { value: "Module" }));
var ig2 = [
  {
    tfOpName: "ConcatV2",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        end: -1,
        name: "tensors",
        type: "tensors"
      },
      {
        start: -1,
        name: "axis",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "N",
        name: "n",
        type: "number",
        defaultValue: 2
      }
    ]
  },
  {
    tfOpName: "Concat",
    category: "slice_join",
    inputs: [
      {
        start: 1,
        end: 0,
        name: "tensors",
        type: "tensors"
      },
      {
        start: 0,
        name: "axis",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "N",
        name: "n",
        type: "number",
        defaultValue: 2
      }
    ]
  },
  {
    tfOpName: "GatherV2",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      },
      {
        start: 2,
        name: "axis",
        type: "number",
        defaultValue: 0
      }
    ],
    attrs: [
      {
        tfName: "batch_dims",
        name: "batchDims",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "Gather",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "validate_indices",
        name: "validateIndices",
        type: "bool",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Reverse",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "dims",
        type: "bool[]"
      }
    ]
  },
  {
    tfOpName: "ReverseV2",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "Slice",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "begin",
        type: "number[]"
      },
      {
        start: 2,
        name: "size",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "StridedSlice",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "begin",
        type: "number[]"
      },
      {
        start: 2,
        name: "end",
        type: "number[]"
      },
      {
        start: 3,
        name: "strides",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "begin_mask",
        name: "beginMask",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "end_mask",
        name: "endMask",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "new_axis_mask",
        name: "newAxisMask",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "ellipsis_mask",
        name: "ellipsisMask",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "shrink_axis_mask",
        name: "shrinkAxisMask",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "Pack",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "tensors",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "axis",
        name: "axis",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "Unpack",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "axis",
        name: "axis",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "num",
        name: "num",
        type: "number",
        defaultValue: 0,
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Tile",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "reps",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "Split",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "axis",
        type: "number",
        defaultValue: 0
      },
      {
        start: 1,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "num_split",
        name: "numOrSizeSplits",
        type: "number",
        defaultValue: 1
      }
    ]
  },
  {
    tfOpName: "SplitV",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "numOrSizeSplits",
        type: "number[]"
      },
      {
        start: 2,
        name: "axis",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "ScatterNd",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "indices",
        type: "tensor"
      },
      {
        start: 1,
        name: "values",
        type: "tensor"
      },
      {
        start: 2,
        name: "shape",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "GatherNd",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "SparseToDense",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "sparseIndices",
        type: "tensor"
      },
      {
        start: 1,
        name: "outputShape",
        type: "number[]"
      },
      {
        start: 2,
        name: "sparseValues",
        type: "tensor"
      },
      {
        start: 3,
        name: "defaultValue",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "validate_indices",
        name: "validateIndices",
        type: "bool",
        defaultValue: false,
        notSupported: true
      }
    ]
  }
];
var og2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: ig2
}, Symbol.toStringTag, { value: "Module" }));
var ug2 = [
  {
    tfOpName: "SparseFillEmptyRows",
    category: "sparse",
    inputs: [
      {
        start: 0,
        name: "indices",
        type: "tensor"
      },
      {
        start: 1,
        name: "values",
        type: "tensor"
      },
      {
        start: 2,
        name: "denseShape",
        type: "tensor"
      },
      {
        start: 3,
        name: "defaultValue",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "SparseReshape",
    category: "sparse",
    inputs: [
      {
        start: 0,
        name: "inputIndices",
        type: "tensor"
      },
      {
        start: 1,
        name: "inputShape",
        type: "tensor"
      },
      {
        start: 2,
        name: "newShape",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "SparseSegmentMean",
    category: "sparse",
    inputs: [
      {
        start: 0,
        name: "data",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      },
      {
        start: 2,
        name: "segmentIds",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "SparseSegmentSum",
    category: "sparse",
    inputs: [
      {
        start: 0,
        name: "data",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      },
      {
        start: 2,
        name: "segmentIds",
        type: "tensor"
      }
    ]
  }
];
var lg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: ug2
}, Symbol.toStringTag, { value: "Module" }));
var pg2 = [
  {
    tfOpName: "FFT",
    category: "spectral",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "IFFT",
    category: "spectral",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "RFFT",
    category: "spectral",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "fft_length",
        type: "number",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "IRFFT",
    category: "spectral",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "fft_length",
        type: "number",
        notSupported: true
      }
    ]
  }
];
var mg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: pg2
}, Symbol.toStringTag, { value: "Module" }));
var cg2 = [
  {
    tfOpName: "StringNGrams",
    category: "string",
    inputs: [
      {
        start: 0,
        name: "data",
        type: "tensor"
      },
      {
        start: 1,
        name: "dataSplits",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "separator",
        name: "separator",
        type: "string"
      },
      {
        tfName: "ngram_widths",
        name: "nGramWidths",
        type: "number[]"
      },
      {
        tfName: "left_pad",
        name: "leftPad",
        type: "string"
      },
      {
        tfName: "right_pad",
        name: "rightPad",
        type: "string"
      },
      {
        tfName: "pad_width",
        name: "padWidth",
        type: "number"
      },
      {
        tfName: "preserve_short_sequences",
        name: "preserveShortSequences",
        type: "bool"
      }
    ],
    outputs: [
      "ngrams",
      "ngrams_splits"
    ]
  },
  {
    tfOpName: "StringSplit",
    category: "string",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      },
      {
        start: 1,
        name: "delimiter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "skip_empty",
        name: "skipEmpty",
        type: "bool"
      }
    ],
    outputs: [
      "indices",
      "values",
      "shape"
    ]
  },
  {
    tfOpName: "StringToHashBucketFast",
    category: "string",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "num_buckets",
        name: "numBuckets",
        type: "number"
      }
    ]
  }
];
var dg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: cg2
}, Symbol.toStringTag, { value: "Module" }));
var hg2 = [
  {
    tfOpName: "Cast",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "SrcT",
        name: "sdtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "DstT",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "ExpandDims",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "MirrorPad",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "padding",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "mode",
        name: "mode",
        type: "string"
      }
    ]
  },
  {
    tfOpName: "Pad",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "padding",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "constant_value",
        name: "constantValue",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "PadV2",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "padding",
        type: "number[]"
      },
      {
        start: 2,
        name: "constantValue",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "Reshape",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "shape",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "Squeeze",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "axis",
        tfDeprecatedName: "squeeze_dims",
        name: "axis",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "SpaceToBatchND",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "blockShape",
        type: "number[]"
      },
      {
        start: 2,
        name: "paddings",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "BatchToSpaceND",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "blockShape",
        type: "number[]"
      },
      {
        start: 2,
        name: "crops",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "DepthToSpace",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "block_size",
        name: "blockSize",
        type: "number"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string"
      }
    ]
  },
  {
    tfOpName: "BroadcastTo",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: []
  },
  {
    tfOpName: "BroadcastArgs",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "s0",
        type: "tensor"
      },
      {
        start: 1,
        name: "s1",
        type: "tensor"
      }
    ],
    attrs: []
  }
];
var fg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: hg2
}, Symbol.toStringTag, { value: "Module" }));
var Vt = class {
  // Loads the op mapping from the JSON file.
  constructor() {
    const e = [
      zy2,
      Ly2,
      Fy2,
      Ry2,
      By2,
      Wy2,
      Uy2,
      Ky2,
      Qy2,
      Zy2,
      My2,
      tg2,
      ag2,
      ng2,
      og2,
      lg2,
      mg2,
      dg2,
      fg2
    ], t = [].concat(...e.map((a) => a.json));
    this.opMappers = t.reduce((a, r) => (a[r.tfOpName] = r, a), {});
  }
  // Singleton instance for the mapper
  static get Instance() {
    return this._instance || (this._instance = new this());
  }
  // Converts the model inference graph from Tensorflow GraphDef to local
  // representation for TensorFlow.js API
  transformGraph(e, t = {}) {
    const a = e.node, r = [], n = [], o = [], u = a.reduce((f, y6) => (f[y6.name] = this.mapNode(y6), y6.op.startsWith("Placeholder") ? r.push(f[y6.name]) : y6.op === "Const" ? n.push(f[y6.name]) : (y6.input == null || y6.input.length === 0) && o.push(f[y6.name]), f), {});
    let l = [];
    const p6 = [];
    let m = {}, c = {};
    t != null && (m = this.mapSignatureEntries(t.inputs), c = this.mapSignatureEntries(t.outputs));
    const d = Object.keys(u);
    d.forEach((f) => {
      const y6 = u[f];
      y6.inputNames.forEach((T6, _6) => {
        const [w6, , I] = B(T6), E6 = u[w6];
        if (E6.outputs != null) {
          const D6 = E6.outputs.indexOf(I);
          if (D6 !== -1) {
            const V = `${w6}:${D6}`;
            y6.inputNames[_6] = V;
          }
        }
        y6.inputs.push(E6), E6.children.push(y6);
      });
    }), Object.keys(c).length === 0 ? d.forEach((f) => {
      const y6 = u[f];
      y6.children.length === 0 && p6.push(y6);
    }) : Object.keys(c).forEach((f) => {
      const [y6] = B(f), T6 = u[y6];
      T6 != null && (T6.signatureKey = c[f], p6.push(T6));
    }), Object.keys(m).length > 0 ? Object.keys(m).forEach((f) => {
      const [y6] = B(f), T6 = u[y6];
      T6 && (T6.signatureKey = m[f], l.push(T6));
    }) : l = r;
    let h6 = {};
    e.library != null && e.library.function != null && (h6 = e.library.function.reduce((f, y6) => (f[y6.signature.name] = this.mapFunction(y6), f), {}));
    const b6 = { nodes: u, inputs: l, outputs: p6, weights: n, placeholders: r, signature: t, functions: h6 };
    return o.length > 0 && (b6.initNodes = o), b6;
  }
  mapSignatureEntries(e) {
    return Object.keys(e || {}).reduce((t, a) => (t[e[a].name] = a, t), {});
  }
  mapNode(e) {
    const t = Jn2(e.op) || this.opMappers[e.op] || {};
    e.attr == null && (e.attr = {});
    const a = {
      name: e.name,
      op: e.op,
      category: t.category,
      inputNames: (e.input || []).map((r) => r.startsWith("^") ? r.slice(1) : r),
      inputs: [],
      children: [],
      inputParams: {},
      attrParams: {},
      rawAttrs: e.attr,
      outputs: t.outputs
    };
    return t.inputs != null && (a.inputParams = t.inputs.reduce((r, n) => (r[n.name] = {
      type: n.type,
      inputIndexStart: n.start,
      inputIndexEnd: n.end
    }, r), {})), t.attrs != null && (a.attrParams = t.attrs.reduce((r, n) => {
      const o = n.type;
      let u;
      switch (n.type) {
        case "string":
          u = Re2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = Re2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "string[]":
          u = Ge2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = Ge2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "number":
          u = Be2(e.attr, n.tfName, n.defaultValue || 0), u === void 0 && n.tfDeprecatedName && (u = Be2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "number[]":
          u = Ue2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = Ue2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "bool":
          u = je2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = je2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "bool[]":
          u = Je2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = Je2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "shape":
          u = qe2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = qe2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "shape[]":
          u = Ke2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = Ke2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "dtype":
          u = He2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = He2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "dtype[]":
          u = We2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = We2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "func":
          u = Ft2(e.attr, n.tfName, n.defaultValue), u === void 0 && n.tfDeprecatedName && (u = Ft2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "tensor":
        case "tensors":
          break;
        default:
          throw new Error(`Unsupported param type: ${n.type} for op: ${e.op}`);
      }
      return r[n.name] = { value: u, type: o }, r;
    }, {})), a;
  }
  // map the TFunctionDef to TFJS graph object
  mapFunction(e) {
    const t = e.nodeDef, a = [], r = [];
    let n = {};
    t != null && (n = t.reduce((c, d) => (c[d.name] = this.mapNode(d), d.op === "Const" && r.push(c[d.name]), c), {}));
    const o = [], u = [];
    e.signature.inputArg.forEach((c) => {
      const [d] = B(c.name), h6 = {
        name: d,
        op: "Placeholder",
        inputs: [],
        inputNames: [],
        category: "graph",
        inputParams: {},
        attrParams: { dtype: { value: vt2(c.type), type: "dtype" } },
        children: []
      };
      h6.signatureKey = c.name, o.push(h6), n[d] = h6;
    }), Object.keys(n).forEach((c) => {
      const d = n[c];
      d.inputNames.forEach((h6, b6) => {
        const [f, , y6] = B(h6), T6 = n[f];
        if (T6.outputs != null) {
          const _6 = T6.outputs.indexOf(y6);
          if (_6 !== -1) {
            const w6 = `${f}:${_6}`;
            d.inputNames[b6] = w6;
          }
        }
        d.inputs.push(T6), T6.children.push(d);
      });
    });
    const p6 = e.ret;
    e.signature.outputArg.forEach((c) => {
      const [d, h6] = B(p6[c.name]), b6 = n[d];
      b6 != null && (b6.defaultOutput = h6, u.push(b6));
    });
    const m = this.mapArgsToSignature(e);
    return { nodes: n, inputs: o, outputs: u, weights: r, placeholders: a, signature: m };
  }
  mapArgsToSignature(e) {
    return {
      methodName: e.signature.name,
      inputs: e.signature.inputArg.reduce((t, a) => (t[a.name] = this.mapArgToTensorInfo(a), t), {}),
      outputs: e.signature.outputArg.reduce((t, a) => (t[a.name] = this.mapArgToTensorInfo(a, e.ret), t), {})
    };
  }
  mapArgToTensorInfo(e, t) {
    let a = e.name;
    return t != null && (a = t[a]), { name: a, dtype: e.type };
  }
};
function yg2(s) {
  const e = F().global;
  if (typeof e.atob < "u")
    return e.atob(s);
  if (typeof Buffer < "u")
    return new Buffer(s, "base64").toString();
  throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
}
function Qn2(s, e) {
  const t = Array.isArray(s) ? String.fromCharCode.apply(null, s) : yg2(s);
  return e ? t : t.toLowerCase();
}
function Re2(s, e, t, a = false) {
  const r = s[e];
  return r != null ? Qn2(r.s, a) : t;
}
function je2(s, e, t) {
  const a = s[e];
  return a ? a.b : t;
}
function Be2(s, e, t) {
  const a = s[e] || {}, r = a.i != null ? a.i : a.f != null ? a.f : t;
  return typeof r == "number" ? r : parseInt(r, 10);
}
function vt2(s) {
  switch (typeof s == "string" && (s = Am[s]), s) {
    case Am.DT_FLOAT:
    case Am.DT_HALF:
      return "float32";
    case Am.DT_INT32:
    case Am.DT_INT64:
    case Am.DT_INT8:
    case Am.DT_UINT8:
      return "int32";
    case Am.DT_BOOL:
      return "bool";
    case Am.DT_DOUBLE:
      return "float32";
    case Am.DT_STRING:
      return "string";
    default:
      return null;
  }
}
function Ft2(s, e, t) {
  const a = s[e];
  return a && a.func ? a.func.name : t;
}
function He2(s, e, t) {
  const a = s[e];
  return a && a.type ? vt2(a.type) : t;
}
function We2(s, e, t) {
  const a = s[e];
  return a && a.list && a.list.type ? a.list.type.map((r) => vt2(r)) : t;
}
function Xn2(s) {
  if (!s.unknownRank)
    return s.dim != null ? s.dim.map((e) => typeof e.size == "number" ? e.size : parseInt(e.size, 10)) : [];
}
function qe2(s, e, t) {
  const a = s[e];
  return a && a.shape ? Xn2(a.shape) : t;
}
function Ue2(s, e, t) {
  const a = s[e];
  return a ? ((a.list.f && a.list.f.length ? a.list.f : a.list.i) || []).map((r) => typeof r == "number" ? r : parseInt(r, 10)) : t;
}
function Ge2(s, e, t, a = false) {
  const r = s[e];
  return r && r.list && r.list.s ? r.list.s.map((n) => Qn2(n, a)) : t;
}
function Ke2(s, e, t) {
  const a = s[e];
  return a && a.list && a.list.shape ? a.list.shape.map((r) => Xn2(r)) : t;
}
function Je2(s, e, t) {
  const a = s[e];
  return a && a.list && a.list.b ? a.list.b : t;
}
var gg2 = class {
  constructor(e, t, a) {
    this.node = e, this.tensorMap = t, this.context = a, this.inputs = [], this.attrs = {}, this.inputs = e.inputNames.map((r) => this.getInput(r)), e.rawAttrs != null && (this.attrs = Object.keys(e.rawAttrs).reduce((r, n) => (r[n] = this.getAttr(n), r), {}));
  }
  /**
   * Return the value of the attribute or input param.
   * @param name String: name of attribute or input param.
   */
  getInput(e) {
    return k6(e, this.tensorMap, this.context);
  }
  /**
   * Return the value of the attribute or input param.
   * @param name String: name of attribute or input param.
   */
  getAttr(e, t) {
    const a = this.node.rawAttrs[e];
    if (a.tensor != null)
      return k6(e, this.tensorMap, this.context);
    if (a.i != null || a.f != null)
      return Be2(this.node.rawAttrs, e, t);
    if (a.s != null)
      return Re2(this.node.rawAttrs, e, t);
    if (a.b != null)
      return je2(this.node.rawAttrs, e, t);
    if (a.shape != null)
      return qe2(this.node.rawAttrs, e, t);
    if (a.type != null)
      return He2(this.node.rawAttrs, e, t);
    if (a.list != null) {
      if (a.list.i != null || a.list.f != null)
        return Ue2(this.node.rawAttrs, e, t);
      if (a.list.s != null)
        return Ge2(this.node.rawAttrs, e, t);
      if (a.list.shape != null)
        return Ke2(this.node.rawAttrs, e, t);
      if (a.list.b != null)
        return Je2(this.node.rawAttrs, e, t);
      if (a.list.type != null)
        return We2(this.node.rawAttrs, e, t);
    }
    return t;
  }
};
var A = Object.freeze(Object.defineProperty({
  __proto__: null,
  OP_SCOPE_SUFFIX: yC,
  abs: fe,
  acos: o2,
  acosh: i2,
  add: U,
  addN: Yr2,
  all: Nb,
  any: bd,
  argMax: Qr,
  argMin: d2,
  asin: p2,
  asinh: m2,
  atan: b2,
  atan2: y2,
  atanh: I2,
  avgPool: Bh,
  avgPool3d: $2,
  basicLSTMCell: Mr2,
  batchNorm: zc,
  batchNorm2d: X2,
  batchNorm3d: A2,
  batchNorm4d: K2,
  batchToSpaceND: _h,
  bincount: B2,
  booleanMaskAsync: Cn2,
  broadcastArgs: en2,
  broadcastTo: Br,
  buffer: vt,
  cast: et,
  ceil: U2,
  clipByValue: pn,
  clone: po,
  complex: bo,
  concat: Ge,
  concat1d: J2,
  concat2d: q2,
  concat3d: ev,
  concat4d: sv,
  conv1d: Rb,
  conv2d: Co,
  conv2dTranspose: $b,
  conv3d: cv,
  conv3dTranspose: hv,
  cos: Yh,
  cosh: Eb,
  cosineWindow: n0,
  cumprod: yd,
  cumsum: Lb,
  denseBincount: rm,
  depthToSpace: yv,
  depthwiseConv2d: Qh,
  diag: tn2,
  dilation2d: Cv,
  div: ut,
  divNoNan: Nv,
  dot: $v,
  dropout: oT,
  einsum: sn2,
  elu: Xc,
  enclosingPowerOfTwo: rT,
  equal: kn,
  erf: Lv,
  euclideanNorm: Av,
  exp: Tn,
  expandDims: Ue,
  expm1: Bv,
  eye: Db,
  fft: xp,
  fill: ua,
  floor: Ac,
  floorDiv: Tb,
  fused: Pn2,
  gather: jh,
  gatherND: Vn2,
  greater: sn,
  greaterEqual: Do,
  ifft: pl,
  imag: qh,
  image: uo,
  inTopKAsync: Fn2,
  irfft: Qb,
  isFinite: tS,
  isInf: nS,
  isNaN: oS,
  leakyRelu: tp,
  less: Fb,
  lessEqual: yr,
  linalg: zN,
  linspace: an2,
  localResponseNormalization: cS,
  log: Nn,
  log1p: ep,
  logSigmoid: gS,
  logSoftmax: Vb,
  logSumExp: zb,
  logicalAnd: ss,
  logicalNot: np,
  logicalOr: Xb,
  logicalXor: SS,
  losses: mY,
  lowerBound: rn2,
  matMul: Gt,
  max: Xn,
  maxPool: sp,
  maxPool3d: NS,
  maxPoolWithArgmax: nn2,
  maximum: _s,
  mean: se,
  meshgrid: on,
  min: ul,
  minimum: Kc,
  mirrorPad: LS,
  mod: WS,
  moments: op,
  movingAverage: zn2,
  mul: G,
  multiRNNCell: un2,
  multinomial: ln2,
  neg: jt,
  norm: Pc,
  notEqual: qr,
  oneHot: Pb,
  ones: Us,
  onesLike: Rn,
  op: L,
  outerProduct: pn2,
  pad: rp,
  pad1d: mn2,
  pad2d: cn2,
  pad3d: dn2,
  pad4d: hn2,
  pool: ZS,
  pow: ir,
  prelu: ap,
  print: QC,
  prod: _S,
  raggedGather: fn2,
  raggedRange: yn2,
  raggedTensorToTensor: gn2,
  rand: bn2,
  randomGamma: Tn2,
  randomNormal: hk,
  randomStandardNormal: Sn2,
  randomUniform: Zc,
  range: ti,
  real: dl,
  reciprocal: gk,
  relu: ws,
  relu6: Ob,
  reshape: W,
  reverse: ko,
  reverse1d: vn2,
  reverse2d: On2,
  reverse3d: _n2,
  reverse4d: An2,
  rfft: yp,
  round: Kb,
  rsqrt: Zb,
  scalar: gt,
  scatterND: xn2,
  searchSorted: De2,
  selu: Bb,
  separableConv2d: Hb,
  setdiff1dAsync: En2,
  sigmoid: xr,
  sign: kk,
  signal: fY,
  sin: _b,
  sinh: Ub,
  slice: Dt,
  slice1d: mp,
  slice2d: Yb,
  slice3d: gp,
  slice4d: hl,
  softmax: bp,
  softplus: da,
  spaceToBatchND: ip,
  sparse: gY,
  sparseToDense: Ln,
  spectral: pY,
  split: un,
  sqrt: De,
  square: At,
  squaredDifference: Jb,
  squeeze: ha,
  stack: os,
  step: pa,
  stridedSlice: Kk,
  string: bY,
  sub: lt,
  sum: at,
  tan: Bk,
  tanh: Hh,
  tensor: Re,
  tensor1d: Je,
  tensor2d: qa,
  tensor3d: Hk,
  tensor4d: kn2,
  tensor5d: In2,
  tensor6d: Dn2,
  tile: Vn,
  topk: Uk,
  transpose: kt,
  truncatedNormal: jb,
  unique: Jk,
  unsortedSegmentSum: qb,
  unstack: To,
  upperBound: $n2,
  variable: tT,
  where: Oe,
  whereAsync: gt2,
  zeros: ge,
  zerosLike: Tt
}, Symbol.toStringTag, { value: "Module" }));
var bg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "BiasAdd":
    case "AddV2":
    case "Add":
      return [a.add(i("a", s, e, t), i("b", s, e, t))];
    case "AddN":
      return [a.addN(i("tensors", s, e, t))];
    case "FloorMod":
    case "Mod":
      return [a.mod(i("a", s, e, t), i("b", s, e, t))];
    case "Mul":
      return [a.mul(i("a", s, e, t), i("b", s, e, t))];
    case "RealDiv":
    case "Div":
      return [a.div(i("a", s, e, t), i("b", s, e, t))];
    case "DivNoNan":
      return [a.divNoNan(i("a", s, e, t), i("b", s, e, t))];
    case "FloorDiv":
      return [a.floorDiv(i("a", s, e, t), i("b", s, e, t))];
    case "Sub":
      return [a.sub(i("a", s, e, t), i("b", s, e, t))];
    case "Minimum":
      return [a.minimum(i("a", s, e, t), i("b", s, e, t))];
    case "Maximum":
      return [a.maximum(i("a", s, e, t), i("b", s, e, t))];
    case "Pow":
      return [a.pow(i("a", s, e, t), i("b", s, e, t))];
    case "SquaredDifference":
      return [a.squaredDifference(i("a", s, e, t), i("b", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Ng2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "Abs":
    case "ComplexAbs":
      return [a.abs(i("x", s, e, t))];
    case "Acos":
      return [a.acos(i("x", s, e, t))];
    case "Acosh":
      return [a.acosh(i("x", s, e, t))];
    case "Asin":
      return [a.asin(i("x", s, e, t))];
    case "Asinh":
      return [a.asinh(i("x", s, e, t))];
    case "Atan":
      return [a.atan(i("x", s, e, t))];
    case "Atan2":
      return [a.atan2(i("x", s, e, t), i("y", s, e, t))];
    case "Atanh":
      return [a.atanh(i("x", s, e, t))];
    case "Ceil":
      return [a.ceil(i("x", s, e, t))];
    case "Complex":
      return [a.complex(i("real", s, e, t), i("imag", s, e, t))];
    case "Cos":
      return [a.cos(i("x", s, e, t))];
    case "Cosh":
      return [a.cosh(i("x", s, e, t))];
    case "Elu":
      return [a.elu(i("x", s, e, t))];
    case "Erf":
      return [a.erf(i("x", s, e, t))];
    case "Exp":
      return [a.exp(i("x", s, e, t))];
    case "Expm1":
      return [a.expm1(i("x", s, e, t))];
    case "Floor":
      return [a.floor(i("x", s, e, t))];
    case "Log":
      return [a.log(i("x", s, e, t))];
    case "Log1p":
      return [a.log1p(i("x", s, e, t))];
    case "Imag":
      return [a.imag(i("x", s, e, t))];
    case "Neg":
      return [a.neg(i("x", s, e, t))];
    case "Reciprocal":
      return [a.reciprocal(i("x", s, e, t))];
    case "Real":
      return [a.real(i("x", s, e, t))];
    case "Relu":
      return [a.relu(i("x", s, e, t))];
    case "Round":
      return [a.round(i("x", s, e, t))];
    case "Selu":
      return [a.selu(i("x", s, e, t))];
    case "Sigmoid":
      return [a.sigmoid(i("x", s, e, t))];
    case "Sin":
      return [a.sin(i("x", s, e, t))];
    case "Sign":
      return [a.sign(i("x", s, e, t))];
    case "Sinh":
      return [a.sinh(i("x", s, e, t))];
    case "Softplus":
      return [a.softplus(i("x", s, e, t))];
    case "Sqrt":
      return [a.sqrt(i("x", s, e, t))];
    case "Square":
      return [a.square(i("x", s, e, t))];
    case "Tanh":
      return [a.tanh(i("x", s, e, t))];
    case "Tan":
      return [a.tan(i("x", s, e, t))];
    case "ClipByValue":
      return [a.clipByValue(i("x", s, e, t), i("clipValueMin", s, e, t), i("clipValueMax", s, e, t))];
    case "Relu6":
      return [a.relu6(i("x", s, e, t))];
    case "Rsqrt":
      return [a.rsqrt(k6(s.inputNames[0], e, t))];
    case "Prod":
      return [a.prod(i("x", s, e, t), i("axes", s, e, t))];
    case "LeakyRelu":
      return [a.leakyRelu(i("x", s, e, t), i("alpha", s, e, t))];
    case "Prelu":
      return [a.prelu(i("x", s, e, t), i("alpha", s, e, t))];
    case "IsNan":
      return [a.isNaN(k6(s.inputNames[0], e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
function C(s, e, t = "") {
  if (!(typeof s == "number" || typeof e == "number")) {
    v2(s.length === e.length, () => t + ` Shapes ${s} and ${e} must match`);
    for (let a = 0; a < s.length; a++) {
      const r = s[a], n = e[a];
      v2(r < 0 || n < 0 || r === n, () => t + ` Shapes ${s} and ${e} must match`);
    }
  }
}
function Pt2(s) {
  return !(typeof s == "number" || s.some((e) => e < 0));
}
function re2(s, e, t) {
  let a = Qe2(s, t);
  const r = !Pt2(a);
  if (r && e.length === 0)
    throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${a}`);
  if (r && e.forEach((n) => {
    a = Qe2(n.shape, a);
  }), !Pt2(a))
    throw new Error(`Non-fully-defined elementShape: ${a}`);
  return a;
}
function Qe2(s, e) {
  if (typeof s == "number")
    return e;
  if (typeof e == "number")
    return s;
  if (s.length !== e.length)
    throw new Error(`Incompatible ranks during merge: ${s} vs. ${e}`);
  const t = [];
  for (let a = 0; a < s.length; ++a) {
    const r = s[a], n = e[a];
    if (r >= 0 && n >= 0 && r !== n)
      throw new Error(`Incompatible shape during merge: ${s} vs. ${e}`);
    t[a] = r >= 0 ? r : n;
  }
  return t;
}
var wg2 = class {
  constructor(e, t, a, r, n, o, u) {
    this.name = e, this.dtype = t, this.maxSize = a, this.elementShape = r, this.identicalElementShapes = n, this.dynamicSize = o, this.clearAfterRead = u, this.tensors = [], this.closed_ = false, this.idTensor = gt(0), cn(this.idTensor);
  }
  get id() {
    return this.idTensor.id;
  }
  get closed() {
    return this.closed_;
  }
  /**
   * Dispose the tensors and idTensor and mark the TensoryArray as closed.
   */
  clearAndClose(e) {
    this.tensors.forEach((t) => {
      (e == null || !e.has(t.tensor.id)) && t.tensor.dispose();
    }), this.tensors = [], this.closed_ = true, this.idTensor.dispose();
  }
  size() {
    return this.tensors.length;
  }
  /**
   * Read the value at location index in the TensorArray.
   * @param index Number the index to read from.
   */
  read(e) {
    if (this.closed_)
      throw new Error(`TensorArray ${this.name} has already been closed.`);
    if (e < 0 || e >= this.size())
      throw new Error(`Tried to read from index ${e}, but array size is: ${this.size()}`);
    const t = this.tensors[e];
    if (t.cleared)
      throw new Error(`TensorArray ${this.name}: Could not read index ${e} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);
    return this.clearAfterRead && (t.cleared = true), t.read = true, t.tensor;
  }
  /**
   * Helper method to read multiple tensors from the specified indices.
   */
  readMany(e) {
    return e.map((t) => this.read(t));
  }
  /**
   * Write value into the index of the TensorArray.
   * @param index number the index to write to.
   * @param tensor
   */
  write(e, t) {
    if (this.closed_)
      throw new Error(`TensorArray ${this.name} has already been closed.`);
    if (e < 0 || !this.dynamicSize && e >= this.maxSize)
      throw new Error(`Tried to write to index ${e}, but array is not resizeable and size is: ${this.maxSize}`);
    const a = this.tensors[e] || {};
    if (t.dtype !== this.dtype)
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e},
          because the value dtype is ${t.dtype}, but TensorArray dtype is ${this.dtype}.`);
    if (this.size() === 0 && (this.elementShape == null || this.elementShape.length === 0) && (this.elementShape = t.shape), C(this.elementShape, t.shape, `TensorArray ${this.name}: Could not write to TensorArray index ${e}.`), a.read)
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been read.`);
    if (a.written)
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been written.`);
    a.tensor = t, cn(t), a.written = true, this.tensors[e] = a;
  }
  /**
   * Helper method to write multiple tensors to the specified indices.
   */
  writeMany(e, t) {
    if (e.length !== t.length)
      throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${e.length} is not the same as tensors size: ${t.length}.`);
    e.forEach((a, r) => this.write(a, t[r]));
  }
  /**
   * Return selected values in the TensorArray as a packed Tensor. All of
   * selected values must have been written and their shapes must all match.
   * @param [indices] number[] Optional. Taking values in [0, max_value). If the
   *    TensorArray is not dynamic, max_value=size(). If not specified returns
   *    all tensors in the original order.
   * @param [dtype]
   */
  gather(e, t) {
    if (t && t !== this.dtype)
      throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${t}`);
    if (e)
      e = e.slice(0, this.size());
    else {
      e = [];
      for (let r = 0; r < this.size(); r++)
        e.push(r);
    }
    if (e.length === 0)
      return Re([], [0].concat(this.elementShape));
    const a = this.readMany(e);
    return C(this.elementShape, a[0].shape, "TensorArray shape mismatch: "), os(a, 0);
  }
  /**
   * Return the values in the TensorArray as a concatenated Tensor.
   */
  concat(e) {
    if (e && e !== this.dtype)
      throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${e}`);
    if (this.size() === 0)
      return Re([], [0].concat(this.elementShape));
    const t = [];
    for (let r = 0; r < this.size(); r++)
      t.push(r);
    const a = this.readMany(t);
    return C(this.elementShape, a[0].shape, `TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${a[0].shape})`), Ge(a, 0);
  }
  /**
   * Scatter the values of a Tensor in specific indices of a TensorArray.
   * @param indices nummber[] values in [0, max_value). If the
   *    TensorArray is not dynamic, max_value=size().
   * @param tensor Tensor input tensor.
   */
  scatter(e, t) {
    if (t.dtype !== this.dtype)
      throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);
    if (e.length !== t.shape[0])
      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);
    const a = Math.max(...e);
    if (!this.dynamicSize && a >= this.maxSize)
      throw new Error(`Max index must be < array size (${a}  vs. ${this.maxSize})`);
    this.writeMany(e, To(t, 0));
  }
  /**
   * Split the values of a Tensor into the TensorArray.
   * @param length number[] with the lengths to use when splitting value along
   *    its first dimension.
   * @param tensor Tensor, the tensor to split.
   */
  split(e, t) {
    if (t.dtype !== this.dtype)
      throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);
    let a = 0;
    const r = e.map((l) => (a += l, a));
    if (a !== t.shape[0])
      throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${a}, and tensor's shape is: ${t.shape}`);
    if (!this.dynamicSize && e.length !== this.maxSize)
      throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${e.length}), and the TensorArray is not marked as dynamically resizeable`);
    const n = a === 0 ? 0 : t.size / a, o = [];
    D(() => {
      t = W(t, [1, a, n]);
      for (let l = 0; l < e.length; ++l) {
        const m = [0, l === 0 ? 0 : r[l - 1], 0], c = [1, e[l], n];
        o[l] = W(Dt(t, m, c), this.elementShape);
      }
      return o;
    });
    const u = [];
    for (let l = 0; l < e.length; l++)
      u[l] = l;
    this.writeMany(u, o);
  }
};
var J = class {
  /**
   *
   * @param tensors list of tensors
   * @param elementShape shape of each tensor, this can be a single number (any
   * shape is allowed) or partial shape (dim = -1).
   * @param elementDtype data type of each tensor
   * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1
   *   meaning that the size of `tensors` is unbounded.
   */
  constructor(e, t, a, r = -1) {
    this.tensors = e, this.elementShape = t, this.elementDtype = a, e != null && e.forEach((n) => {
      if (a !== n.dtype)
        throw new Error(`Invalid data types; op elements ${a}, but list elements ${n.dtype}`);
      C(t, n.shape, "TensorList shape mismatch: "), cn(n);
    }), this.idTensor = gt(0), this.maxNumElements = r, cn(this.idTensor);
  }
  get id() {
    return this.idTensor.id;
  }
  /**
   * Get a new TensorList containing a copy of the underlying tensor container.
   */
  copy() {
    return new J([...this.tensors], this.elementShape, this.elementDtype);
  }
  /**
   * Dispose the tensors and idTensor and clear the tensor list.
   */
  clearAndClose(e) {
    this.tensors.forEach((t) => {
      (e == null || !e.has(t.id)) && t.dispose();
    }), this.tensors.length = 0, this.idTensor.dispose();
  }
  /**
   * The size of the tensors in the tensor list.
   */
  size() {
    return this.tensors.length;
  }
  /**
   * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)
   * tf.Tensor.
   * @param elementShape shape of each tensor
   * @param elementDtype data type of each tensor
   * @param numElements the number of elements to stack
   */
  stack(e, t, a = -1) {
    if (t !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);
    if (a !== -1 && this.tensors.length !== a)
      throw new Error(`Operation expected a list with ${a} elements but got a list with ${this.tensors.length} elements.`);
    C(e, this.elementShape, "TensorList shape mismatch: ");
    const r = re2(this.elementShape, this.tensors, e);
    return D(() => {
      const n = this.tensors.map((o) => W(o, r));
      return os(n, 0);
    });
  }
  /**
   * Pop a tensor from the end of the list.
   * @param elementShape shape of the tensor
   * @param elementDtype data type of the tensor
   */
  popBack(e, t) {
    if (t !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);
    if (this.size() === 0)
      throw new Error("Trying to pop from an empty list.");
    const a = re2(this.elementShape, this.tensors, e), r = this.tensors.pop();
    return r.kept = false, C(r.shape, e, "TensorList shape mismatch: "), W(r, a);
  }
  /**
   * Push a tensor to the end of the list.
   * @param tensor Tensor to be pushed.
   */
  pushBack(e) {
    if (e.dtype !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);
    if (C(e.shape, this.elementShape, "TensorList shape mismatch: "), this.maxNumElements === this.size())
      throw new Error("Trying to push element into a full list.");
    cn(e), this.tensors.push(e);
  }
  /**
   * Update the size of the list.
   * @param size the new size of the list.
   */
  resize(e) {
    if (e < 0)
      throw new Error(`TensorListResize expects size to be non-negative. Got: ${e}`);
    if (this.maxNumElements !== -1 && e > this.maxNumElements)
      throw new Error(`TensorListResize input size ${e} is greater maxNumElement ${this.maxNumElements}.`);
    const t = new J([], this.elementShape, this.elementDtype, this.maxNumElements);
    t.tensors.length = e;
    for (let a = 0; a < Math.min(this.tensors.length, e); ++a)
      t.tensors[a] = this.tensors[a];
    return t;
  }
  /**
   * Retrieve the element at the provided index
   * @param elementShape shape of the tensor
   * @param elementDtype dtype of the tensor
   * @param elementIndex index of the tensor
   */
  getItem(e, t, a) {
    if (a !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${a}, but list elements ${this.elementDtype}`);
    if (e < 0 || e > this.tensors.length)
      throw new Error(`Trying to access element ${e} in a list with ${this.tensors.length} elements.`);
    if (this.tensors[e] == null)
      throw new Error(`element at index ${e} is null.`);
    C(this.tensors[e].shape, t, "TensorList shape mismatch: ");
    const r = re2(this.elementShape, this.tensors, t);
    return W(this.tensors[e], r);
  }
  /**
   * Set the tensor at the index
   * @param elementIndex index of the tensor
   * @param tensor the tensor to be inserted into the list
   */
  setItem(e, t) {
    if (t.dtype !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);
    if (e < 0 || this.maxNumElements !== -1 && e >= this.maxNumElements)
      throw new Error(`Trying to set element ${e} in a list with max ${this.maxNumElements} elements.`);
    C(this.elementShape, t.shape, "TensorList shape mismatch: "), cn(t), this.tensors[e] != null && (this.tensors[e].kept = false), this.tensors[e] = t;
  }
  /**
   * Return selected values in the TensorList as a stacked Tensor. All of
   * selected values must have been written and their shapes must all match.
   * @param indices indices of tensors to gather
   * @param elementDtype output tensor dtype
   * @param elementShape output tensor element shape
   */
  gather(e, t, a) {
    if (t !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);
    C(this.elementShape, a, "TensorList shape mismatch: "), e = e.slice(0, this.size());
    const r = re2(this.elementShape, this.tensors, a);
    return e.length === 0 ? Re([], [0].concat(r)) : D(() => {
      const n = e.map((o) => W(this.tensors[o], r));
      return os(n, 0);
    });
  }
  /**
   * Return the values in the TensorList as a concatenated Tensor.
   * @param elementDtype output tensor dtype
   * @param elementShape output tensor element shape
   */
  concat(e, t) {
    if (e && e !== this.elementDtype)
      throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${e}`);
    C(this.elementShape, t, "TensorList shape mismatch: ");
    const a = re2(this.elementShape, this.tensors, t);
    return this.size() === 0 ? Re([], [0].concat(a)) : D(() => {
      const r = this.tensors.map((n) => W(n, a));
      return Ge(r, 0);
    });
  }
};
function Tg2(s, e, t) {
  const a = s.dtype;
  if (s.shape.length < 1)
    throw new Error(`Tensor must be at least a vector, but saw shape: ${s.shape}`);
  if (s.dtype !== t)
    throw new Error(`Invalid data types; op elements ${s.dtype}, but list elements ${t}`);
  const r = s.shape.slice(1);
  C(r, e, "TensorList shape mismatch: ");
  const n = To(s);
  return new J(n, e, a);
}
function Sg2(s, e, t, a) {
  return new J([], s, e, a);
}
function vg2(s, e, t, a) {
  if (e.length !== s.shape[0])
    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${s.shape[0]}`);
  const r = Math.max(...e);
  if (a != null && a !== -1 && r >= a)
    throw new Error(`Max index must be < array size (${r}  vs. ${a})`);
  const n = new J([], t, s.dtype, a), o = To(s, 0);
  return e.forEach((u, l) => {
    n.setItem(u, o[l]);
  }), n;
}
function Og2(s, e, t) {
  let a = 0;
  const r = e.map((m) => (a += m, a));
  if (a !== s.shape[0])
    throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${a}, and tensor's shape is: ${s.shape}`);
  const n = s.shape.slice(1), o = Qe2(n, t), u = a === 0 ? 0 : s.size / a, l = D(() => {
    const m = [];
    s = W(s, [1, a, u]);
    for (let c = 0; c < e.length; ++c) {
      const h6 = [0, c === 0 ? 0 : r[c - 1], 0], b6 = [1, e[c], u];
      m[c] = W(Dt(s, h6, b6), o);
    }
    return s.dispose(), m;
  }), p6 = new J([], t, s.dtype, e.length);
  for (let m = 0; m < l.length; m++)
    p6.setItem(m, l[m]);
  return p6;
}
var _g2 = async (s, e, t) => {
  switch (s.op) {
    case "If":
    case "StatelessIf": {
      const a = i("thenBranch", s, e, t), r = i("elseBranch", s, e, t), n = i("cond", s, e, t), o = i("args", s, e, t);
      return (await n.data())[0] ? t.functionMap[a].executeFunctionAsync(o, t.tensorArrayMap, t.tensorListMap) : t.functionMap[r].executeFunctionAsync(o, t.tensorArrayMap, t.tensorListMap);
    }
    case "While":
    case "StatelessWhile": {
      const a = i("body", s, e, t), r = i("cond", s, e, t), n = i("args", s, e, t), o = await t.functionMap[r].executeFunctionAsync(n, t.tensorArrayMap, t.tensorListMap), u = n.map((m) => m.id);
      let l = await o[0].data();
      o.forEach((m) => {
        !m.kept && u.indexOf(m.id) === -1 && m.dispose();
      });
      let p6 = n;
      for (; l[0]; ) {
        const m = p6;
        p6 = await t.functionMap[a].executeFunctionAsync(p6, t.tensorArrayMap, t.tensorListMap);
        const c = p6.map((h6) => h6.id);
        m.forEach((h6) => {
          !h6.kept && u.indexOf(h6.id) === -1 && c.indexOf(h6.id) === -1 && h6.dispose();
        });
        const d = await t.functionMap[r].executeFunctionAsync(p6, t.tensorArrayMap, t.tensorListMap);
        l = await d[0].data(), d.forEach((h6) => {
          !h6.kept && u.indexOf(h6.id) === -1 && c.indexOf(h6.id) === -1 && h6.dispose();
        });
      }
      return p6;
    }
    case "LoopCond": {
      const a = i("pred", s, e, t);
      return [H(a)];
    }
    case "Switch": {
      const a = i("pred", s, e, t);
      let r = i("data", s, e, t);
      return r.kept || (r = H(r)), (await a.data())[0] ? [void 0, r] : [r, void 0];
    }
    case "Merge": {
      const a = s.inputNames.find((r) => k6(r, e, t) !== void 0);
      if (a) {
        const r = k6(a, e, t);
        return [H(r)];
      }
      return;
    }
    case "Enter": {
      const a = i("frameName", s, e, t), r = i("tensor", s, e, t);
      return t.enterFrame(a), [H(r)];
    }
    case "Exit": {
      const a = i("tensor", s, e, t);
      return t.exitFrame(), [H(a)];
    }
    case "NextIteration": {
      const a = i("tensor", s, e, t);
      return t.nextIteration(), [H(a)];
    }
    case "TensorArrayV3": {
      const a = i("size", s, e, t), r = i("dtype", s, e, t), n = i("elementShape", s, e, t), o = i("dynamicSize", s, e, t), u = i("clearAfterRead", s, e, t), l = i("identicalElementShapes", s, e, t), p6 = i("name", s, e, t), m = new wg2(p6, r, a, n, l, o, u);
      return t.addTensorArray(m), [m.idTensor, gt(1)];
    }
    case "TensorArrayWriteV3": {
      const a = i("tensorArrayId", s, e, t), r = i("index", s, e, t), n = i("tensor", s, e, t), o = t.getTensorArray(a.id);
      return o.write(r, n), [o.idTensor];
    }
    case "TensorArrayReadV3": {
      const a = i("tensorArrayId", s, e, t), r = i("index", s, e, t);
      return [t.getTensorArray(a.id).read(r)];
    }
    case "TensorArrayGatherV3": {
      const a = i("tensorArrayId", s, e, t), r = i("indices", s, e, t), n = i("dtype", s, e, t);
      return [t.getTensorArray(a.id).gather(r, n)];
    }
    case "TensorArrayScatterV3": {
      const a = i("tensorArrayId", s, e, t), r = i("indices", s, e, t), n = i("tensor", s, e, t), o = t.getTensorArray(a.id);
      return o.scatter(r, n), [o.idTensor];
    }
    case "TensorArrayConcatV3": {
      const a = i("tensorArrayId", s, e, t), r = t.getTensorArray(a.id), n = i("dtype", s, e, t);
      return [r.concat(n)];
    }
    case "TensorArraySplitV3": {
      const a = i("tensorArrayId", s, e, t), r = i("tensor", s, e, t), n = i("lengths", s, e, t), o = t.getTensorArray(a.id);
      return o.split(n, r), [o.idTensor];
    }
    case "TensorArraySizeV3": {
      const a = i("tensorArrayId", s, e, t), r = t.getTensorArray(a.id);
      return [gt(r.size(), "int32")];
    }
    case "TensorArrayCloseV3": {
      const a = i("tensorArrayId", s, e, t), r = t.getTensorArray(a.id);
      return r.clearAndClose(), [r.idTensor];
    }
    case "TensorListSetItem": {
      const a = i("tensorListId", s, e, t), r = i("index", s, e, t), n = i("tensor", s, e, t), o = t.getTensorList(a.id);
      return o.setItem(r, n), [o.idTensor];
    }
    case "TensorListGetItem": {
      const a = i("tensorListId", s, e, t), r = i("index", s, e, t), n = i("elementShape", s, e, t), o = i("elementDType", s, e, t);
      return [t.getTensorList(a.id).getItem(r, n, o)];
    }
    case "TensorListScatterV2":
    case "TensorListScatter": {
      const a = i("indices", s, e, t), r = i("tensor", s, e, t), n = i("elementShape", s, e, t), o = i("numElements", s, e, t), u = vg2(r, a, n, o);
      return t.addTensorList(u), [u.idTensor];
    }
    case "TensorListReserve":
    case "EmptyTensorList": {
      const a = i("elementShape", s, e, t), r = i("elementDType", s, e, t);
      let n;
      s.op === "TensorListReserve" ? n = "numElements" : n = "maxNumElements";
      const o = i(n, s, e, t), u = s.op === "TensorListReserve" ? -1 : o, l = Sg2(a, r, o, u);
      return t.addTensorList(l), [l.idTensor];
    }
    case "TensorListGather": {
      const a = i("tensorListId", s, e, t), r = i("indices", s, e, t), n = i("elementShape", s, e, t), o = i("elementDType", s, e, t);
      return [t.getTensorList(a.id).gather(r, o, n)];
    }
    case "TensorListStack": {
      const a = i("tensorListId", s, e, t), r = i("elementShape", s, e, t), n = i("elementDType", s, e, t), o = i("numElements", s, e, t);
      return [t.getTensorList(a.id).stack(r, n, o)];
    }
    case "TensorListFromTensor": {
      const a = i("tensor", s, e, t), r = i("elementShape", s, e, t), n = i("elementDType", s, e, t), o = Tg2(a, r, n);
      return t.addTensorList(o), [o.idTensor];
    }
    case "TensorListConcat":
    case "TensorListConcatV2": {
      const a = i("tensorListId", s, e, t), r = t.getTensorList(a.id), n = i("dtype", s, e, t), o = i("elementShape", s, e, t);
      return [r.concat(n, o)];
    }
    case "TensorListPushBack": {
      const a = i("tensorListId", s, e, t), r = i("tensor", s, e, t), n = t.getTensorList(a.id);
      return n.pushBack(r), [n.idTensor];
    }
    case "TensorListPopBack": {
      const a = i("tensorListId", s, e, t), r = i("elementShape", s, e, t), n = i("elementDType", s, e, t);
      return [t.getTensorList(a.id).popBack(r, n)];
    }
    case "TensorListSplit": {
      const a = i("tensor", s, e, t), r = i("elementShape", s, e, t), n = i("lengths", s, e, t), o = Og2(a, n, r);
      return t.addTensorList(o), [o.idTensor];
    }
    case "TensorListLength": {
      const a = i("tensorListId", s, e, t), r = t.getTensorList(a.id);
      return [gt(r.size(), "int32")];
    }
    case "TensorListResize": {
      const a = i("tensorListId", s, e, t), r = i("size", s, e, t), o = t.getTensorList(a.id).resize(r);
      return t.addTensorList(o), [o.idTensor];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
function Rt2(s, e, t) {
  const [a, r] = i("fusedOps", s, e, t), n = a === "biasadd", o = !n, u = r === "prelu", l = a === "fusedbatchnorm", p6 = i("numArgs", s, e, t);
  if (n) {
    if (u && p6 !== 2)
      throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
    if (!u && n && p6 !== 1)
      throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
  }
  if (l)
    throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
  const m = i("strides", s, e, t), c = be2(s, e, t), d = i("dataFormat", s, e, t).toUpperCase(), h6 = i("dilations", s, e, t);
  let [b6, f] = i("args", s, e, t);
  o && (f = b6, b6 = void 0);
  const y6 = i("leakyreluAlpha", s, e, t);
  return {
    stride: m,
    pad: c,
    dataFormat: d,
    dilations: h6,
    biasArg: b6,
    preluArg: f,
    activationFunc: r,
    leakyreluAlpha: y6
  };
}
var Ag2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "Conv1D": {
      const r = i("stride", s, e, t), n = i("pad", s, e, t), o = i("dataFormat", s, e, t).toUpperCase(), u = i("dilation", s, e, t);
      return [a.conv1d(i("x", s, e, t), i("filter", s, e, t), r, n, o, u)];
    }
    case "Conv2D": {
      const r = i("strides", s, e, t), n = be2(s, e, t), o = i("dataFormat", s, e, t).toUpperCase(), u = i("dilations", s, e, t);
      return [a.conv2d(i("x", s, e, t), i("filter", s, e, t), [r[1], r[2]], n, o, [u[1], u[2]])];
    }
    case "_FusedConv2D": {
      const { stride: r, pad: n, dataFormat: o, dilations: u, biasArg: l, preluArg: p6, activationFunc: m, leakyreluAlpha: c } = Rt2(s, e, t);
      return [a.fused.conv2d({
        x: i("x", s, e, t),
        filter: i("filter", s, e, t),
        strides: [r[1], r[2]],
        pad: n,
        dataFormat: o,
        dilations: [u[1], u[2]],
        bias: l,
        activation: m,
        preluActivationWeights: p6,
        leakyreluAlpha: c
      })];
    }
    case "FusedDepthwiseConv2dNative": {
      const { stride: r, pad: n, dataFormat: o, dilations: u, biasArg: l, preluArg: p6, activationFunc: m, leakyreluAlpha: c } = Rt2(s, e, t);
      return [a.fused.depthwiseConv2d({
        x: i("x", s, e, t),
        filter: i("filter", s, e, t),
        strides: [r[1], r[2]],
        pad: n,
        dataFormat: o,
        dilations: [u[1], u[2]],
        bias: l,
        activation: m,
        preluActivationWeights: p6,
        leakyreluAlpha: c
      })];
    }
    case "Conv2DBackpropInput":
    case "Conv2dTranspose": {
      const r = i("outputShape", s, e, t), n = i("strides", s, e, t), o = be2(s, e, t);
      return [a.conv2dTranspose(i("x", s, e, t), i("filter", s, e, t), r, [n[1], n[2]], o)];
    }
    case "DepthwiseConv2dNative":
    case "DepthwiseConv2d": {
      const r = i("strides", s, e, t), n = be2(s, e, t), o = i("dilations", s, e, t), u = i("dataFormat", s, e, t).toUpperCase();
      return [a.depthwiseConv2d(i("input", s, e, t), i("filter", s, e, t), [r[1], r[2]], n, u, [o[1], o[2]])];
    }
    case "Conv3D": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), o = i("dataFormat", s, e, t).toUpperCase(), u = i("dilations", s, e, t);
      return [a.conv3d(i("x", s, e, t), i("filter", s, e, t), [r[1], r[2], r[3]], n, o, [u[1], u[2], u[3]])];
    }
    case "AvgPool": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), o = i("kernelSize", s, e, t);
      return [a.avgPool(i("x", s, e, t), [o[1], o[2]], [r[1], r[2]], n)];
    }
    case "MaxPool": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), o = i("kernelSize", s, e, t);
      return [a.maxPool(i("x", s, e, t), [o[1], o[2]], [r[1], r[2]], n)];
    }
    case "MaxPoolWithArgmax": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), o = i("kernelSize", s, e, t), u = i("includeBatchInIndex", s, e, t), { result: l, indexes: p6 } = a.maxPoolWithArgmax(i("x", s, e, t), [o[1], o[2]], [r[1], r[2]], n, u);
      return [l, p6];
    }
    case "AvgPool3D": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), o = i("kernelSize", s, e, t);
      return [a.avgPool3d(i("x", s, e, t), [o[1], o[2], o[3]], [r[1], r[2], r[3]], n)];
    }
    case "MaxPool3D": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), o = i("kernelSize", s, e, t);
      return [a.maxPool3d(i("x", s, e, t), [o[1], o[2], o[3]], [r[1], r[2], r[3]], n)];
    }
    case "Dilation2D": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), o = i("dilations", s, e, t), u = r[1], l = r[2], p6 = o[1], m = o[2];
      return [a.dilation2d(
        i("x", s, e, t),
        i("filter", s, e, t),
        [u, l],
        n,
        [p6, m],
        "NHWC"
        /* dataFormat */
      )];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Eg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "Fill": {
      const r = i("shape", s, e, t), n = i("dtype", s, e, t), o = i("value", s, e, t);
      return [a.fill(r, o, n)];
    }
    case "LinSpace": {
      const r = i("start", s, e, t), n = i("stop", s, e, t), o = i("num", s, e, t);
      return [a.linspace(r, n, o)];
    }
    case "Multinomial": {
      const r = i("logits", s, e, t), n = i("numSamples", s, e, t), o = i("seed", s, e, t);
      return [a.multinomial(r, n, o)];
    }
    case "OneHot": {
      const r = i("indices", s, e, t), n = i("depth", s, e, t), o = i("onValue", s, e, t), u = i("offValue", s, e, t), l = i("dtype", s, e, t);
      return [a.oneHot(r, n, o, u, l)];
    }
    case "Ones":
      return [a.ones(i("shape", s, e, t), i("dtype", s, e, t))];
    case "OnesLike":
      return [a.onesLike(i("x", s, e, t))];
    case "RandomStandardNormal":
      return [a.randomStandardNormal(i("shape", s, e, t), i("dtype", s, e, t), i("seed", s, e, t))];
    case "RandomUniform":
      return [a.randomUniform(
        // tslint:disable-next-line:no-any
        i("shape", s, e, t),
        i("minval", s, e, t),
        i("maxval", s, e, t),
        i("dtype", s, e, t)
      )];
    case "Range": {
      const r = i("start", s, e, t), n = i("stop", s, e, t), o = i("step", s, e, t);
      return [a.range(r, n, o, i("dtype", s, e, t))];
    }
    case "TruncatedNormal": {
      const r = i("shape", s, e, t), n = i("mean", s, e, t), o = i("stdDev", s, e, t), u = i("seed", s, e, t);
      return [a.truncatedNormal(r, n, o, i("dtype", s, e, t), u)];
    }
    case "Zeros":
      return [a.zeros(i("shape", s, e, t), i("dtype", s, e, t))];
    case "ZerosLike":
      return [a.zerosLike(i("x", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
function ze2(s, e, t) {
  const a = i("boxes", s, e, t), r = i("scores", s, e, t), n = i("maxOutputSize", s, e, t), o = i("iouThreshold", s, e, t), u = i("scoreThreshold", s, e, t), l = i("softNmsSigma", s, e, t);
  return {
    boxes: a,
    scores: r,
    maxOutputSize: n,
    iouThreshold: o,
    scoreThreshold: u,
    softNmsSigma: l
  };
}
var kg2 = async (s, e, t, a, r = A) => {
  switch (s.op) {
    case "NonMaxSuppressionV5": {
      const { boxes: n, scores: o, maxOutputSize: u, iouThreshold: l, scoreThreshold: p6, softNmsSigma: m } = ze2(s, e, t), c = await r.image.nonMaxSuppressionWithScoreAsync(n, o, u, l, p6, m);
      return [c.selectedIndices, c.selectedScores];
    }
    case "NonMaxSuppressionV4": {
      const { boxes: n, scores: o, maxOutputSize: u, iouThreshold: l, scoreThreshold: p6 } = ze2(s, e, t), m = i("padToMaxOutputSize", s, e, t), c = await r.image.nonMaxSuppressionPaddedAsync(n, o, u, l, p6, m);
      return [c.selectedIndices, c.validOutputs];
    }
    case "NonMaxSuppressionV3":
    case "NonMaxSuppressionV2": {
      const { boxes: n, scores: o, maxOutputSize: u, iouThreshold: l, scoreThreshold: p6 } = ze2(s, e, t);
      return [await r.image.nonMaxSuppressionAsync(n, o, u, l, p6)];
    }
    case "Where": {
      const n = r.cast(i("condition", s, e, t), "bool"), o = [await r.whereAsync(n)];
      return n.dispose(), o;
    }
    case "ListDiff":
      return r.setdiff1dAsync(i("x", s, e, t), i("y", s, e, t));
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Ig2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "LowerBound": {
      const r = i("sortedSequence", s, e, t), n = i("values", s, e, t);
      return [a.lowerBound(r, n)];
    }
    case "TopKV2": {
      const r = i("x", s, e, t), n = i("k", s, e, t), o = i("sorted", s, e, t), u = a.topk(r, n, o);
      return [u.values, u.indices];
    }
    case "UpperBound": {
      const r = i("sortedSequence", s, e, t), n = i("values", s, e, t);
      return [a.upperBound(r, n)];
    }
    case "Unique": {
      const r = i("x", s, e, t), n = a.unique(r);
      return [n.values, n.indices];
    }
    case "UniqueV2": {
      const r = i("x", s, e, t), n = i("axis", s, e, t), o = a.unique(r, n);
      return [o.values, o.indices];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Dg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "Const":
      return e[s.name];
    case "PlaceholderWithDefault":
      const r = i("default", s, e, t);
      return [k6(s.name, e, t) || r];
    case "Placeholder":
      return [k6(s.name, e, t)];
    case "Identity":
    case "StopGradient":
    case "FakeQuantWithMinMaxVars": {
      const m = i("x", s, e, t);
      return [H(m)];
    }
    case "IdentityN":
      return i("x", s, e, t).map((m) => H(m));
    case "Snapshot":
      const n = i("x", s, e, t);
      return [H(n)];
    case "Shape":
      return [a.tensor1d(i("x", s, e, t).shape, "int32")];
    case "ShapeN":
      return i("x", s, e, t).map((m) => a.tensor1d(m.shape));
    case "Size":
      return [a.scalar(i("x", s, e, t).size, "int32")];
    case "Rank":
      return [a.scalar(i("x", s, e, t).rank, "int32")];
    case "NoOp":
      return [a.scalar(1)];
    case "Print":
      const o = i("x", s, e, t), u = i("data", s, e, t), l = i("message", s, e, t), p6 = i("summarize", s, e, t);
      console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."), console.log(l);
      for (let m = 0; m < u.length; m++)
        console.log(Array.prototype.slice.call(u[m].dataSync()).slice(0, p6));
      return [o];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var $g2 = class {
  /**
   * Constructor of HashTable. Creates a hash table.
   *
   * @param keyDType `dtype` of the table keys.
   * @param valueDType `dtype` of the table values.
   */
  constructor(e, t) {
    this.keyDType = e, this.valueDType = t, this.handle = gt(0), this.tensorMap = /* @__PURE__ */ new Map(), cn(this.handle);
  }
  get id() {
    return this.handle.id;
  }
  /**
   * Dispose the tensors and handle and clear the hashtable.
   */
  clearAndClose() {
    this.tensorMap.forEach((e) => e.dispose()), this.tensorMap.clear(), this.handle.dispose();
  }
  /**
   * The number of items in the hash table.
   */
  size() {
    return this.tensorMap.size;
  }
  /**
   * The number of items in the hash table as a rank-0 tensor.
   */
  tensorSize() {
    return gt(this.size(), "int32");
  }
  /**
   * Replaces the contents of the table with the specified keys and values.
   * @param keys Keys to store in the hashtable.
   * @param values Values to store in the hashtable.
   */
  async import(e, t) {
    this.checkKeyAndValueTensor(e, t);
    const a = await e.data();
    return this.tensorMap.forEach((r) => r.dispose()), this.tensorMap.clear(), D(() => {
      const r = To(t), n = a.length, o = r.length;
      v2(n === o, () => `The number of elements doesn't match, keys has ${n} elements, the values has ${o} elements.`);
      for (let u = 0; u < n; u++) {
        const l = a[u], p6 = r[u];
        cn(p6), this.tensorMap.set(l, p6);
      }
      return this.handle;
    });
  }
  /**
   * Looks up keys in a hash table, outputs the corresponding values.
   *
   * Performs batch lookups, for every element in the key tensor, `find`
   * stacks the corresponding value into the return tensor.
   *
   * If an element is not present in the table, the given `defaultValue` is
   * used.
   *
   * @param keys Keys to look up. Must have the same type as the keys of the
   *     table.
   * @param defaultValue The scalar `defaultValue` is the value output for keys
   *     not present in the table. It must also be of the same type as the
   *     table values.
   */
  async find(e, t) {
    this.checkKeyAndValueTensor(e, t);
    const a = await e.data();
    return D(() => {
      const r = [];
      for (let n = 0; n < a.length; n++) {
        const o = a[n], u = this.findWithDefault(o, t);
        r.push(u);
      }
      return os(r);
    });
  }
  // tslint:disable-next-line: no-any
  findWithDefault(e, t) {
    const a = this.tensorMap.get(e);
    return a ?? t;
  }
  checkKeyAndValueTensor(e, t) {
    if (e.dtype !== this.keyDType)
      throw new Error(`Expect key dtype ${this.keyDType}, but got ${e.dtype}`);
    if (t.dtype !== this.valueDType)
      throw new Error(`Expect value dtype ${this.valueDType}, but got ${t.dtype}`);
  }
};
var Cg2 = async (s, e, t, a) => {
  switch (s.op) {
    case "HashTable":
    case "HashTableV2": {
      const r = a.getHashTableHandleByName(s.name);
      if (r != null)
        return [r];
      {
        const n = i("keyDType", s, e, t), o = i("valueDType", s, e, t), u = new $g2(n, o);
        return a.addHashTable(s.name, u), [u.handle];
      }
    }
    case "InitializeTable":
    case "InitializeTableV2":
    case "LookupTableImport":
    case "LookupTableImportV2": {
      const r = i("tableHandle", s, e, t, a), n = i("keys", s, e, t), o = i("values", s, e, t);
      return [await a.getHashTableById(r.id).import(n, o)];
    }
    case "LookupTableFind":
    case "LookupTableFindV2": {
      const r = i("tableHandle", s, e, t, a), n = i("keys", s, e, t), o = i("defaultValue", s, e, t);
      return [await a.getHashTableById(r.id).find(n, o)];
    }
    case "LookupTableSize":
    case "LookupTableSizeV2": {
      const r = i("tableHandle", s, e, t, a);
      return [a.getHashTableById(r.id).tensorSize()];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var zg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "ResizeBilinear": {
      const r = i("images", s, e, t), n = i("size", s, e, t), o = i("alignCorners", s, e, t), u = i("halfPixelCenters", s, e, t);
      return [a.image.resizeBilinear(r, [n[0], n[1]], o, u)];
    }
    case "ResizeNearestNeighbor": {
      const r = i("images", s, e, t), n = i("size", s, e, t), o = i("alignCorners", s, e, t), u = i("halfPixelCenters", s, e, t);
      return [a.image.resizeNearestNeighbor(r, [n[0], n[1]], o, u)];
    }
    case "CropAndResize": {
      const r = i("image", s, e, t), n = i("boxes", s, e, t), o = i("boxInd", s, e, t), u = i("cropSize", s, e, t), l = i("method", s, e, t), p6 = i("extrapolationValue", s, e, t);
      return [a.image.cropAndResize(r, n, o, u, l, p6)];
    }
    case "ImageProjectiveTransformV3": {
      const r = i("images", s, e, t), n = i("transforms", s, e, t), o = i("outputShape", s, e, t), u = i("fillValue", s, e, t), l = i("interpolation", s, e, t), p6 = i("fillMode", s, e, t);
      return [a.image.transform(r, n, l.toLowerCase(), p6.toLowerCase(), u, o)];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var xg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "Equal":
      return [a.equal(i("a", s, e, t), i("b", s, e, t))];
    case "NotEqual":
      return [a.notEqual(i("a", s, e, t), i("b", s, e, t))];
    case "Greater":
      return [a.greater(i("a", s, e, t), i("b", s, e, t))];
    case "GreaterEqual":
      return [a.greaterEqual(i("a", s, e, t), i("b", s, e, t))];
    case "Less":
      return [a.less(i("a", s, e, t), i("b", s, e, t))];
    case "LessEqual":
      return [a.lessEqual(i("a", s, e, t), i("b", s, e, t))];
    case "LogicalAnd":
      return [a.logicalAnd(i("a", s, e, t), i("b", s, e, t))];
    case "LogicalNot":
      return [a.logicalNot(i("a", s, e, t))];
    case "LogicalOr":
      return [a.logicalOr(i("a", s, e, t), i("b", s, e, t))];
    case "Select":
    case "SelectV2":
      return [a.where(i("condition", s, e, t), i("a", s, e, t), i("b", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Lg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "BatchMatMul":
    case "BatchMatMulV2":
    case "MatMul":
      return [a.matMul(i("a", s, e, t), i("b", s, e, t), i("transposeA", s, e, t), i("transposeB", s, e, t))];
    case "Einsum":
      return [a.einsum(i("equation", s, e, t), ...i("tensors", s, e, t))];
    case "Transpose":
      return [a.transpose(i("x", s, e, t), i("perm", s, e, t))];
    case "_FusedMatMul":
      const [r, n] = i("fusedOps", s, e, t), o = r === "biasadd", u = n === "prelu", l = i("numArgs", s, e, t), p6 = i("leakyreluAlpha", s, e, t);
      if (o) {
        if (u && l !== 2)
          throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
        if (!u && l !== 1)
          throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
      }
      const [m, c] = i("args", s, e, t);
      return [a.fused.matMul({
        a: i("a", s, e, t),
        b: i("b", s, e, t),
        transposeA: i("transposeA", s, e, t),
        transposeB: i("transposeB", s, e, t),
        bias: m,
        activation: n,
        preluActivationWeights: c,
        leakyreluAlpha: p6
      })];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Vg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "EuclideanNorm":
      return [a.euclideanNorm(i("x", s, e, t), i("axis", s, e, t), i("keepDims", s, e, t))];
    case "FusedBatchNorm":
    case "FusedBatchNormV2":
      return [a.batchNorm(i("x", s, e, t), i("mean", s, e, t), i("variance", s, e, t), i("offset", s, e, t), i("scale", s, e, t), i("epsilon", s, e, t))];
    case "FusedBatchNormV3":
      return [a.batchNorm(i("x", s, e, t), i("mean", s, e, t), i("variance", s, e, t), i("offset", s, e, t), i("scale", s, e, t), i("epsilon", s, e, t))];
    case "LRN":
      return [a.localResponseNormalization(i("x", s, e, t), i("radius", s, e, t), i("bias", s, e, t), i("alpha", s, e, t), i("beta", s, e, t))];
    case "Softmax":
      return [a.softmax(i("x", s, e, t))];
    case "LogSoftmax":
      return [a.logSoftmax(i("x", s, e, t))];
    case "SparseToDense":
      return [a.sparseToDense(i("sparseIndices", s, e, t), i("outputShape", s, e, t), i("sparseValues", s, e, t), i("defaultValue", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Fg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "RaggedGather": {
      const { outputNestedSplits: r, outputDenseValues: n } = a.raggedGather(i("paramsNestedSplits", s, e, t), i("paramsDenseValues", s, e, t), i("indices", s, e, t), i("outputRaggedRank", s, e, t));
      return r.concat(n);
    }
    case "RaggedRange": {
      const { rtNestedSplits: r, rtDenseValues: n } = a.raggedRange(i("starts", s, e, t), i("limits", s, e, t), i("splits", s, e, t));
      return [r, n];
    }
    case "RaggedTensorToTensor":
      return [a.raggedTensorToTensor(i("shape", s, e, t), i("values", s, e, t), i("defaultValue", s, e, t), i("rowPartitionTensors", s, e, t), i("rowPartitionTypes", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Pg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "Max": {
      const u = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.max(i("x", s, e, t), u, l)];
    }
    case "Mean": {
      const u = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.mean(i("x", s, e, t), u, l)];
    }
    case "Min": {
      const u = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.min(i("x", s, e, t), u, l)];
    }
    case "Sum": {
      const u = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.sum(i("x", s, e, t), u, l)];
    }
    case "All": {
      const u = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.all(i("x", s, e, t), u, l)];
    }
    case "Any": {
      const u = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.any(i("x", s, e, t), u, l)];
    }
    case "ArgMax": {
      const u = i("axis", s, e, t);
      return [a.argMax(i("x", s, e, t), u)];
    }
    case "ArgMin": {
      const u = i("axis", s, e, t);
      return [a.argMin(i("x", s, e, t), u)];
    }
    case "Prod": {
      const u = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.prod(i("x", s, e, t), u, l)];
    }
    case "Cumprod": {
      const u = i("axis", s, e, t), l = i("exclusive", s, e, t), p6 = i("reverse", s, e, t);
      return [a.cumprod(i("x", s, e, t), u, l, p6)];
    }
    case "Cumsum": {
      const u = i("axis", s, e, t), l = i("exclusive", s, e, t), p6 = i("reverse", s, e, t);
      return [a.cumsum(i("x", s, e, t), u, l, p6)];
    }
    case "Bincount":
      const r = i("x", s, e, t), n = i("weights", s, e, t), o = i("size", s, e, t);
      return [a.bincount(r, n, o)];
    case "DenseBincount": {
      const u = i("x", s, e, t), l = i("weights", s, e, t), p6 = i("size", s, e, t), m = i("binaryOutput", s, e, t);
      return [a.denseBincount(u, l, p6, m)];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Rg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "ConcatV2":
    case "Concat": {
      const r = i("n", s, e, t), n = i("axis", s, e, t);
      let o = i("tensors", s, e, t);
      return o = o.slice(0, r), [a.concat(o, n)];
    }
    case "Gather": {
      const r = i("x", s, e, t), n = i("indices", s, e, t);
      return [a.gather(r, a.cast(n, "int32"), 0)];
    }
    case "GatherV2": {
      const r = i("axis", s, e, t), n = i("batchDims", s, e, t), o = i("x", s, e, t), u = i("indices", s, e, t);
      return [a.gather(o, a.cast(u, "int32"), r, n)];
    }
    case "Reverse": {
      const r = i("dims", s, e, t), n = [];
      for (let u = 0; u < r.length; u++)
        r[u] && n.push(u);
      const o = i("x", s, e, t);
      return [a.reverse(o, n)];
    }
    case "ReverseV2": {
      const r = i("axis", s, e, t), n = i("x", s, e, t);
      return [a.reverse(n, r)];
    }
    case "Slice": {
      const r = i("begin", s, e, t), n = i("size", s, e, t);
      return [a.slice(i("x", s, e, t), r, n)];
    }
    case "StridedSlice": {
      const r = i("begin", s, e, t), n = i("end", s, e, t), o = i("strides", s, e, t), u = i("beginMask", s, e, t), l = i("endMask", s, e, t), p6 = i("ellipsisMask", s, e, t), m = i("newAxisMask", s, e, t), c = i("shrinkAxisMask", s, e, t), d = i("x", s, e, t);
      return [a.stridedSlice(d, r, n, o, u, l, p6, m, c)];
    }
    case "Pack":
      return D(() => {
        const r = i("axis", s, e, t), n = i("tensors", s, e, t), o = n[0].shape, u = a.squeeze(n[0]).shape, l = n.map((p6) => {
          const m = Rt(p6.shape, o);
          if (!m && !Rt(a.squeeze(p6).shape, u))
            throw new Error("the input tensors shape does not match");
          return m ? p6 : a.reshape(p6, o);
        });
        return [a.stack(l, r)];
      });
    case "Unpack": {
      const r = i("axis", s, e, t), n = i("tensor", s, e, t);
      return a.unstack(n, r);
    }
    case "Tile": {
      const r = i("reps", s, e, t);
      return [a.tile(i("x", s, e, t), r)];
    }
    case "Split":
    case "SplitV": {
      const r = i("axis", s, e, t), n = i("numOrSizeSplits", s, e, t), o = i("x", s, e, t);
      return a.split(o, n, r);
    }
    case "ScatterNd": {
      const r = i("indices", s, e, t), n = i("values", s, e, t), o = i("shape", s, e, t);
      return [a.scatterND(r, n, o)];
    }
    case "GatherNd": {
      const r = i("x", s, e, t), n = i("indices", s, e, t);
      return [a.gatherND(r, n)];
    }
    case "SparseToDense": {
      const r = i("sparseIndices", s, e, t), n = i("outputShape", s, e, t), o = i("sparseValues", s, e, t), u = i("defaultValue", s, e, t);
      return [a.sparseToDense(r, o, n, o.dtype === u.dtype ? u : a.cast(u, o.dtype))];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var jg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "SparseFillEmptyRows": {
      const { outputIndices: r, outputValues: n, emptyRowIndicator: o, reverseIndexMap: u } = a.sparse.sparseFillEmptyRows(i("indices", s, e, t), i("values", s, e, t), i("denseShape", s, e, t), i("defaultValue", s, e, t));
      return [
        r,
        n,
        o,
        u
      ];
    }
    case "SparseReshape": {
      const { outputIndices: r, outputShape: n } = a.sparse.sparseReshape(i("inputIndices", s, e, t), i("inputShape", s, e, t), i("newShape", s, e, t));
      return [r, n];
    }
    case "SparseSegmentMean":
      return [a.sparse.sparseSegmentMean(i("data", s, e, t), i("indices", s, e, t), i("segmentIds", s, e, t))];
    case "SparseSegmentSum":
      return [a.sparse.sparseSegmentSum(i("data", s, e, t), i("indices", s, e, t), i("segmentIds", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Bg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "FFT":
      return [a.fft(i("x", s, e, t))];
    case "IFFT":
      return [a.ifft(i("x", s, e, t))];
    case "RFFT":
      return [a.rfft(i("x", s, e, t))];
    case "IRFFT":
      return [a.irfft(i("x", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Hg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "StringNGrams": {
      const { nGrams: r, nGramsSplits: n } = a.string.stringNGrams(i("data", s, e, t), i("dataSplits", s, e, t), i("separator", s, e, t), i("nGramWidths", s, e, t), i("leftPad", s, e, t), i("rightPad", s, e, t), i("padWidth", s, e, t), i("preserveShortSequences", s, e, t));
      return [r, n];
    }
    case "StringSplit": {
      const { indices: r, values: n, shape: o } = a.string.stringSplit(i("input", s, e, t), i("delimiter", s, e, t), i("skipEmpty", s, e, t));
      return [r, n, o];
    }
    case "StringToHashBucketFast":
      return [a.string.stringToHashBucketFast(i("input", s, e, t), i("numBuckets", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Wg2 = (s, e, t, a = A) => {
  switch (s.op) {
    case "Cast":
      return [a.cast(i("x", s, e, t), i("dtype", s, e, t))];
    case "ExpandDims": {
      const r = i("axis", s, e, t);
      return [a.expandDims(i("x", s, e, t), r)];
    }
    case "Squeeze": {
      const r = i("axis", s, e, t);
      return [a.squeeze(i("x", s, e, t), r)];
    }
    case "Reshape":
      return [a.reshape(i("x", s, e, t), i("shape", s, e, t))];
    case "MirrorPad":
      return [a.mirrorPad(i("x", s, e, t), i("padding", s, e, t), i("mode", s, e, t))];
    case "PadV2":
    case "Pad":
      return [a.pad(i("x", s, e, t), i("padding", s, e, t), i("constantValue", s, e, t))];
    case "SpaceToBatchND": {
      const r = i("blockShape", s, e, t), n = i("paddings", s, e, t);
      return [a.spaceToBatchND(i("x", s, e, t), r, n)];
    }
    case "BatchToSpaceND": {
      const r = i("blockShape", s, e, t), n = i("crops", s, e, t);
      return [a.batchToSpaceND(i("x", s, e, t), r, n)];
    }
    case "DepthToSpace": {
      const r = i("blockSize", s, e, t), n = i("dataFormat", s, e, t).toUpperCase();
      return [a.depthToSpace(i("x", s, e, t), r, n)];
    }
    case "BroadcastTo":
      return [a.broadcastTo(i("x", s, e, t), i("shape", s, e, t))];
    case "BroadcastArgs":
      return [a.broadcastArgs(i("s0", s, e, t), i("s1", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
function jt2(s, e, t, a, r = D) {
  const n = ((o, u, l) => {
    switch (o.category) {
      case "arithmetic":
        return r(() => bg2(o, u, l));
      case "basic_math":
        return r(() => Ng2(o, u, l));
      case "control":
        return _g2(o, u, l);
      case "convolution":
        return r(() => Ag2(o, u, l));
      case "creation":
        return r(() => Eg2(o, u, l));
      case "dynamic":
        return kg2(o, u, l);
      case "evaluation":
        return r(() => Ig2(o, u, l));
      case "image":
        return r(() => zg2(o, u, l));
      case "graph":
        return r(() => Dg2(o, u, l));
      case "logical":
        return r(() => xg2(o, u, l));
      case "matrices":
        return r(() => Lg2(o, u, l));
      case "normalization":
        return r(() => Vg2(o, u, l));
      case "ragged":
        return r(() => Fg2(o, u, l));
      case "reduction":
        return r(() => Pg2(o, u, l));
      case "slice_join":
        return r(() => Rg2(o, u, l));
      case "sparse":
        return r(() => jg2(o, u, l));
      case "spectral":
        return r(() => Bg2(o, u, l));
      case "string":
        return r(() => Hg2(o, u, l));
      case "transformation":
        return r(() => Wg2(o, u, l));
      case "hash_table":
        return Cg2(o, u, l, a);
      case "custom":
        const p6 = Jn2(o.op);
        if (p6 && p6.customExecutor)
          return p6.customExecutor(new gg2(o, u, l));
        throw TypeError(`Custom op ${o.op} is not registered.`);
      default:
        throw TypeError(`Unknown op '${o.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`);
    }
  })(s, e, t);
  return ui(n) ? n.then((o) => [].concat(o)) : [].concat(n);
}
var Bt2 = class {
  constructor(e = {}, t = {}, a = {}, r = {}) {
    this.weightMap = e, this.tensorArrayMap = t, this.tensorListMap = a, this.functionMap = r, this.rootContext = { id: 0, frameName: "", iterationId: 0 }, this.contexts = [this.rootContext], this.lastId = 0, this.generateCurrentContextIds();
  }
  newFrame(e, t) {
    return { id: e, frameName: t, iterationId: 0 };
  }
  /**
   * Set the current context
   * @param contexts: ExecutionContextInfo[] the current path of execution
   * frames
   */
  set currentContext(e) {
    this.contexts !== e && (this.contexts = e, this.generateCurrentContextIds());
  }
  get currentContext() {
    return this.contexts;
  }
  /**
   * Returns the current context in string format.
   */
  get currentContextId() {
    return this._currentContextIds[0];
  }
  /**
   * Returns the current context and all parent contexts in string format.
   * This allow access to the nodes in the current and parent frames.
   */
  get currentContextIds() {
    return this._currentContextIds;
  }
  generateCurrentContextIds() {
    const e = [];
    for (let t = 0; t < this.contexts.length - 1; t++) {
      const a = this.contexts.slice(0, this.contexts.length - t);
      e.push(this.contextIdforContexts(a));
    }
    e.push(""), this._currentContextIds = e;
  }
  contextIdforContexts(e) {
    return e ? e.map((t) => t.id === 0 && t.iterationId === 0 ? "" : `${t.frameName}-${t.iterationId}`).join("/") : "";
  }
  /**
   * Enter a new frame, a new context is pushed on the current context list.
   * @param frameId new frame id
   */
  enterFrame(e) {
    this.contexts && (this.lastId++, this.contexts = this.contexts.slice(), this.contexts.push(this.newFrame(this.lastId, e)), this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)));
  }
  /**
   * Exit the current frame, the last context is removed from the current
   * context list.
   */
  exitFrame() {
    if (this.contexts && this.contexts.length > 1)
      this.contexts = this.contexts.slice(), this.contexts.splice(-1), this.currentContextIds.shift();
    else
      throw new Error("Cannot exit frame, the context is empty");
  }
  /**
   * Enter the next iteration of a loop, the iteration id of last context is
   * increased.
   */
  nextIteration() {
    if (this.contexts && this.contexts.length > 0) {
      this.contexts = this.contexts.slice(), this.lastId++;
      const e = Object.assign({}, this.contexts[this.contexts.length - 1]);
      e.iterationId += 1, e.id = this.lastId, this.contexts.splice(-1, 1, e), this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
    } else
      throw new Error("Cannot increase frame iteration, the context is empty");
  }
  getWeight(e) {
    return this.weightMap[e];
  }
  addTensorArray(e) {
    this.tensorArrayMap[e.id] = e;
  }
  getTensorArray(e) {
    return this.tensorArrayMap[e];
  }
  addTensorList(e) {
    this.tensorListMap[e.id] = e;
  }
  getTensorList(e) {
    return this.tensorListMap[e];
  }
  dispose(e) {
    for (const t in this.tensorArrayMap)
      this.tensorArrayMap[t].clearAndClose(e);
    for (const t in this.tensorListMap)
      this.tensorListMap[t].clearAndClose(e);
  }
};
function Ht2(s, e, t, a) {
  const r = /* @__PURE__ */ new Set(), n = [];
  let o = null, u = null;
  const l = /* @__PURE__ */ new Set(), p6 = Object.keys(s).map((d) => $6(d)[0]);
  let m = [];
  a != null && (m = a.map((d) => $6(d.name)[0]));
  const c = [...e];
  for (; c.length > 0; ) {
    const d = c.pop();
    if ((Zn2(d) || Jg2(d) || Qg2(d)) && o == null && (o = d, u = o.children.map((h6) => h6.name).filter((h6) => r.has(h6))), r.add(d.name), t[d.name] == null && p6.indexOf(d.name) === -1 && m.indexOf(d.name) === -1) {
      if (d.inputs.length === 0) {
        n.push(d.name);
        continue;
      }
      d.inputs.forEach((h6) => {
        l.has(h6.name) || (l.add(h6.name), c.push(h6));
      });
    }
  }
  return { inputs: s, outputs: e, usedNodes: r, missingInputs: n, dynamicNode: o, syncInputs: u };
}
function qg2(s, e, t) {
  const { usedNodes: a, inputs: r } = t, n = [], o = Object.keys(r).map((m) => $6(m)[0]).map((m) => s.nodes[m]), u = s.initNodes;
  o.forEach((m) => {
    a.has(m.name) && n.push(m);
  }), s.weights.forEach((m) => {
    a.has(m.name) && n.push(m);
  }), u != null && u.forEach((m) => {
    a.has(m.name) && n.push(m);
  });
  const l = /* @__PURE__ */ new Set(), p6 = [];
  for (; n.length > 0; ) {
    const m = n.pop();
    l.add(m.name), e[m.name] || p6.push(m), m.children.forEach((c) => {
      !l.has(c.name) && a.has(c.name) && c.inputs.every((d) => l.has(d.name)) && n.push(c);
    });
  }
  return p6;
}
var Ug2 = [
  "Switch",
  "Merge",
  "Enter",
  "Exit",
  "NextIteration",
  "StatelessIf",
  "StatelessWhile",
  "if",
  "While"
];
var Gg2 = [
  "NonMaxSuppressionV2",
  "NonMaxSuppressionV3",
  "NonMaxSuppressionV5",
  "Where"
];
var Kg2 = [
  "HashTable",
  "HashTableV2",
  "LookupTableImport",
  "LookupTableImportV2",
  "LookupTableFind",
  "LookupTableFindV2",
  "LookupTableSize",
  "LookupTableSizeV2"
];
function Zn2(s) {
  return Ug2.indexOf(s.op) >= 0;
}
function Jg2(s) {
  return Gg2.indexOf(s.op) >= 0;
}
function Qg2(s) {
  return Kg2.indexOf(s.op) >= 0;
}
var Ee2 = class {
  /**
   *
   * @param graph Graph the model or function graph to be executed.
   * @param parent When building function exector you need to set the parent
   * executor. Since the weights and function executor maps are set at parant
   * level, that function executor can access the function maps and weight maps
   * through the parent.
   */
  constructor(e, t) {
    this.graph = e, this.parent = t, this.compiledMap = /* @__PURE__ */ new Map(), this._weightMap = {}, this.SEPERATOR = ",", this._functions = {}, this._functionExecutorMap = {}, this.keepIntermediateTensors = false, this._outputs = e.outputs, this._inputs = e.inputs, this._initNodes = e.initNodes, this._signature = e.signature, this._functions = e.functions, e.functions != null && Object.keys(e.functions).forEach((a) => {
      this._functionExecutorMap[a] = new Ee2(e.functions[a], this);
    });
  }
  get weightIds() {
    return this.parent ? this.parent.weightIds : this._weightIds;
  }
  get functionExecutorMap() {
    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
  }
  get weightMap() {
    return this.parent ? this.parent.weightMap : this._weightMap;
  }
  set weightMap(e) {
    const t = Object.keys(e).map((a) => e[a].map((r) => r.id));
    this._weightIds = [].concat(...t), this._weightMap = e;
  }
  /**
   * Set `ResourceManager` shared by executors of a model.
   * @param resourceManager: `ResourceManager` of the `GraphModel`.
   */
  set resourceManager(e) {
    this._resourceManager = e;
  }
  get inputs() {
    return this._inputs.map((e) => ({
      name: e.name,
      shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,
      dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0
    }));
  }
  get outputs() {
    return this._outputs.map((e) => ({
      name: e.name,
      shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,
      dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0
    }));
  }
  get inputNodes() {
    return this._inputs.map((e) => e.signatureKey || e.name);
  }
  get outputNodes() {
    return this._outputs.map((e) => {
      const t = e.signatureKey || e.name;
      return e.defaultOutput ? `${t}:${e.defaultOutput}` : t;
    });
  }
  get functions() {
    return Object.keys(this._functions).reduce((e, t) => (e[t] = this._functions[t].signature, e), {});
  }
  getCompilationKey(e, t) {
    const a = e.map((n) => n.name).sort(), r = t.map((n) => n.name).sort();
    return a.join(this.SEPERATOR) + "--" + r.join(this.SEPERATOR);
  }
  /**
   * Compiles the inference graph and returns the minimal set of nodes that are
   * required for execution, in the correct execution order.
   */
  compile(e, t) {
    const a = Ht2(e, t, this.weightMap, this._initNodes), { missingInputs: r, dynamicNode: n, syncInputs: o } = a;
    if (n != null)
      throw new Error(`This execution contains the node '${n.name}', which has the dynamic op '${n.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${o}]`);
    if (r.length > 0) {
      const u = t.map((p6) => p6.name), l = Object.keys(e);
      throw new Error(`Cannot compute the outputs [${u}] from the provided inputs [${l}]. Missing the following inputs: [${r}]`);
    }
    return qg2(this.graph, this.weightMap, a);
  }
  cloneAndKeepTensor(e) {
    if (e == null)
      return null;
    const t = e.clone();
    return cn(t), t;
  }
  cloneTensorList(e) {
    return e ? e.map((a) => this.cloneAndKeepTensor(a)) : null;
  }
  cloneTensorMap(e) {
    return Object.fromEntries(Object.entries(e).map(([t, a]) => [t, this.cloneTensorList(a)]));
  }
  /**
   * Executes the inference for given input tensors.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs Optional. output node name from the Tensorflow model, if
   * no outputs are specified, the default outputs of the model would be used.
   * You can inspect intermediate nodes of the model by adding them to the
   * outputs array.
   */
  execute(e, t) {
    this.disposeIntermediateTensors(), e = this.mapInputs(e);
    const a = Object.keys(e).sort();
    this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t);
    const r = a.map((c) => this.graph.nodes[$6(c)[0]]), n = t.map((c) => $6(c)[0]);
    let o = n.map((c) => this.graph.nodes[c]);
    o.length === 0 && (o = this._outputs);
    const u = this.getCompilationKey(r, o);
    let l = this.compiledMap.get(u);
    l == null && (l = this.compile(e, o), this.compiledMap.set(u, l));
    try {
      this.keepIntermediateTensors = F().getBool("KEEP_INTERMEDIATE_TENSORS");
    } catch (c) {
      this.keepIntermediateTensors = false, console.warn(c.message);
    }
    const p6 = {}, m = {};
    return D(() => {
      const c = new Bt2(this.weightMap, p6, m, this.functionExecutorMap), d = Object.assign({}, this.weightMap);
      this.keepIntermediateTensors && (this.clonedTensorsMap = this.cloneTensorMap(this.weightMap)), Object.keys(e).forEach((f) => {
        const [y6, T6] = $6(f), _6 = [];
        _6[T6] = e[f], d[y6] = _6, this.keepIntermediateTensors && (this.clonedTensorsMap[y6] = this.cloneTensorList(_6));
      });
      const h6 = this.getFrozenTensorIds(d), b6 = {};
      for (let f = 0; f < l.length; f++) {
        const y6 = l[f];
        if (!d[y6.name]) {
          const T6 = jt2(y6, d, c, this._resourceManager);
          if (ui(T6))
            throw new Error(`The execution of the op '${y6.op}' returned a promise. Please use model.executeAsync() instead.`);
          d[y6.name] = T6, this.keepIntermediateTensors && (this.clonedTensorsMap[y6.name] = this.cloneTensorList(T6)), this.checkTensorForDisposal(y6.name, y6, d, c, h6, n, b6);
        }
      }
      return this.parent == null && c.dispose(h6), t.map((f) => k6(f, d, c));
    });
  }
  getFrozenTensorIds(e) {
    const t = [].concat.apply([], Object.keys(e).map((a) => e[a]).map((a) => a.map((r) => r.id)));
    return new Set(t);
  }
  checkTensorForDisposal(e, t, a, r, n, o, u) {
    t.category === "control" || o.indexOf(e) !== -1 || (a[e].forEach((l) => {
      l != null && (u[l.id] = (u[l.id] || 0) + t.children.length);
    }), t.inputs.forEach((l) => {
      if (l.category !== "control") {
        const p6 = $y2(l.name, a, r);
        p6 != null && p6.forEach((m) => {
          if (m && !m.kept && !n.has(m.id)) {
            const c = u[m.id];
            c === 1 ? (m.dispose(), delete u[m.id]) : c != null && u[m.id]--;
          }
        });
      }
    }));
  }
  /**
   * Executes the inference for given input tensors in Async fashion.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs output node name from the Tensorflow model, if no outputs
   * are specified, the default outputs of the model would be used. You can
   * inspect intermediate nodes of the model by adding them to the outputs
   * array.
   */
  async executeAsync(e, t) {
    return this._executeAsync(e, t);
  }
  disposeIntermediateTensors() {
    this.clonedTensorsMap && (Object.values(this.clonedTensorsMap).forEach((e) => {
      for (const t of e)
        t && !t.isDisposed && t.dispose();
    }), this.clonedTensorsMap = null);
  }
  getIntermediateTensors() {
    return this.clonedTensorsMap;
  }
  /**
   * Executes the inference for given input tensors in Async fashion.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs Optional. output node name from the Tensorflow model,
   * if no outputs are specified, the default outputs of the model would be
   * used. You can inspect intermediate nodes of the model by adding them to
   * the outputs array.
   * @param isFunctionExecution Optional. Flag for executing a function.
   * @param tensorArrayMap Optional, global TensorArray map by id. Used for
   * function execution.
   * @param tensorArrayMap Optinal global TensorList map by id. Used for
   * function execution.
   */
  async _executeAsync(e, t, a = false, r = {}, n = {}) {
    this.disposeIntermediateTensors(), a || (e = this.mapInputs(e), this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t));
    try {
      this.keepIntermediateTensors = F().getBool("KEEP_INTERMEDIATE_TENSORS");
    } catch (d) {
      this.keepIntermediateTensors = false, console.warn(d.message);
    }
    const o = new Bt2(this.weightMap, r, n, this.functionExecutorMap);
    this.keepIntermediateTensors && (this.clonedTensorsMap = this.cloneTensorMap(this.weightMap));
    const u = await this.executeWithControlFlow(e, o, t, a), l = t.map((d) => k6(d, u, o)), p6 = l.map((d) => d.id), m = Object.keys(e).map((d) => e[d].id), c = /* @__PURE__ */ new Set([...p6, ...m, ...this.weightIds]);
    return Object.values(u).forEach((d) => {
      d.forEach((h6) => {
        h6 && !h6.isDisposed && !c.has(h6.id) && h6.dispose();
      });
    }), this.parent == null && o.dispose(c), l;
  }
  async executeFunctionAsync(e, t, a) {
    const r = e.reduce((n, o, u) => (n[this.inputs[u].name] = o, n), {});
    return this._executeAsync(r, this.outputNodes, true, t, a);
  }
  /**
   * When there are control flow nodes in the graph, the graph execution use
   * ExecutionContext to keep track of the frames and loop iterators.
   * @param inputs placeholder tensors for the graph.
   * @param context the execution context object for current execution.
   * @param outputNames Optional. output node name from the Tensorflow model,
   * if no outputs are specified, the default outputs of the model would be
   * used. You can inspect intermediate nodes of the model by adding them to
   * the outputs array.
   * @param isFunctionExecution Flag for executing a function.
   */
  async executeWithControlFlow(e, t, a, r) {
    const n = Object.keys(e), o = n.map((w6) => this.graph.nodes[$6(w6)[0]]), u = a.map((w6) => $6(w6)[0]);
    let l = u.map((w6) => this.graph.nodes[w6]);
    l.length === 0 && (l = this._outputs);
    const { usedNodes: p6, missingInputs: m, dynamicNode: c, syncInputs: d } = Ht2(e, l, this.weightMap, this._initNodes), h6 = [
      ...o,
      ...this.graph.weights,
      ...this._initNodes || []
    ].map((w6) => ({ node: w6, contexts: t.currentContext })), b6 = Object.assign({}, this.weightMap);
    Object.keys(e).forEach((w6) => {
      const [I, E6] = $6(w6), D6 = [];
      D6[E6] = e[w6], b6[I] = D6;
    });
    const f = {}, y6 = this.getFrozenTensorIds(b6), T6 = {};
    for (; h6.length > 0; ) {
      const w6 = this.processStack(o, h6, t, b6, T6, y6, u, f, p6);
      await Promise.all(w6);
    }
    c == null && !r && console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");
    const _6 = l.filter((w6) => !Zn2(w6) && !k6(w6.name, b6, t)).map((w6) => w6.name);
    if (_6.length > 0) {
      let w6 = "";
      throw c != null && (w6 = `Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${d}]`), new Error(`Cannot compute the outputs [${_6}] from the provided inputs [${n}]. Consider providing the following inputs: [${m}]. ${w6}`);
    }
    return b6;
  }
  processStack(e, t, a, r, n, o, u, l, p6) {
    const m = [];
    for (; t.length > 0; ) {
      const c = t.pop();
      a.currentContext = c.contexts;
      let d = "";
      if (c.node.op === "Enter" && i("isConstant", c.node, r, a) && ([d] = B(c.node.name, a)), r[c.node.name] == null) {
        const h6 = jt2(c.node, r, a, this._resourceManager);
        d || ([d] = B(c.node.name, a));
        const b6 = a.currentContext;
        ui(h6) ? m.push(h6.then((f) => (r[d] = f, this.keepIntermediateTensors && (this.clonedTensorsMap[d] = this.cloneTensorList(f)), a.currentContext = b6, this.checkTensorForDisposal(d, c.node, r, a, o, u, l), this.processChildNodes(c.node, t, a, r, n, p6), f))) : (r[d] = h6, this.keepIntermediateTensors && (this.clonedTensorsMap[d] = this.cloneTensorList(h6)), this.checkTensorForDisposal(d, c.node, r, a, o, u, l), this.processChildNodes(c.node, t, a, r, n, p6));
      } else
        this.processChildNodes(c.node, t, a, r, n, p6);
    }
    return m;
  }
  processChildNodes(e, t, a, r, n, o) {
    e.children.forEach((u) => {
      const [l] = B(u.name, a);
      n[l] || !o.has(u.name) || (u.op === "Merge" ? u.inputNames.some((p6) => !!k6(p6, r, a)) && (n[l] = true, t.push({ contexts: a.currentContext, node: u })) : u.inputNames.every((p6) => !!k6(p6, r, a)) && (n[l] = true, t.push({ contexts: a.currentContext, node: u })));
    });
  }
  /**
   * Releases the memory used by the weight tensors.
   */
  dispose() {
    Object.keys(this.weightMap).forEach((e) => this.weightMap[e].forEach((t) => t.dispose()));
  }
  checkInputShapeAndType(e) {
    Object.keys(e).forEach((t) => {
      const a = e[t], [r] = $6(t), n = this.graph.nodes[r];
      if (n.attrParams.shape && n.attrParams.shape.value) {
        const o = n.attrParams.shape.value, u = o.length === a.shape.length && a.shape.every((l, p6) => o[p6] === -1 || o[p6] === l);
        v2(u, () => `The shape of dict['${n.name}'] provided in model.execute(dict) must be [${o}], but was [${a.shape}]`);
      }
      n.attrParams.dtype && n.attrParams.dtype.value && v2(a.dtype === n.attrParams.dtype.value, () => `The dtype of dict['${n.name}'] provided in model.execute(dict) must be ${n.attrParams.dtype.value}, but was ${a.dtype}`);
    });
  }
  mapInputs(e) {
    var t, a;
    const r = {};
    for (const n in e) {
      const o = (a = (t = this._signature) === null || t === void 0 ? void 0 : t.inputs) === null || a === void 0 ? void 0 : a[n];
      o != null ? r[o.name] = e[n] : r[n] = e[n];
    }
    return r;
  }
  checkInputs(e) {
    const t = Object.keys(e).filter((a) => {
      const [r] = $6(a);
      return this.graph.nodes[r] == null;
    });
    if (t.length > 0)
      throw new Error(`The dict provided in model.execute(dict) has keys: [${t}] that are not part of graph`);
  }
  mapOutputs(e) {
    return e.map((t) => {
      var a, r;
      const n = (r = (a = this._signature) === null || a === void 0 ? void 0 : a.outputs) === null || r === void 0 ? void 0 : r[t];
      return n != null ? n.name : t;
    }, {});
  }
  checkOutputs(e) {
    e.forEach((t) => {
      const [a] = $6(t);
      if (!this.graph.nodes[a])
        throw new Error(`The output '${t}' is not found in the graph`);
    });
  }
};
var Xg2 = class {
  constructor(e = {}, t = {}) {
    this.hashTableNameToHandle = e, this.hashTableMap = t;
  }
  /**
   * Register a `HashTable` in the resource manager.
   *
   * The `HashTable` can be retrieved by `resourceManager.getHashTableById`,
   * where id is the table handle tensor's id.
   *
   * @param name Op node name that creates the `HashTable`.
   * @param hashTable The `HashTable` to be added to resource manager.
   */
  addHashTable(e, t) {
    this.hashTableNameToHandle[e] = t.handle, this.hashTableMap[t.id] = t;
  }
  /**
   * Get the table handle by node name.
   * @param name Op node name that creates the `HashTable`. This name is also
   *     used in the inputs list of lookup and import `HashTable` ops.
   */
  getHashTableHandleByName(e) {
    return this.hashTableNameToHandle[e];
  }
  /**
   * Get the actual `HashTable` by its handle tensor's id.
   * @param id The id of the handle tensor.
   */
  getHashTableById(e) {
    return this.hashTableMap[e];
  }
  /**
   * Dispose `ResourceManager`, including its hashTables and tensors in them.
   */
  dispose() {
    for (const e in this.hashTableMap)
      this.hashTableMap[e].clearAndClose(), delete this.hashTableMap[e];
    for (const e in this.hashTableNameToHandle)
      this.hashTableNameToHandle[e].dispose(), delete this.hashTableNameToHandle[e];
  }
};
var Zg2 = "?tfjs-format=file";
var Yg2 = "model.json";
var Ot2 = class {
  /**
   * @param modelUrl url for the model, or an `io.IOHandler`.
   * @param weightManifestUrl url for the weight file generated by
   * scripts/convert.py script.
   * @param requestOption options for Request, which allows to send credentials
   * and custom headers.
   * @param onProgress Optional, progress callback function, fired periodically
   * before the load is completed.
   */
  constructor(e, t = {}, a = bt2) {
    this.modelUrl = e, this.loadOptions = t, this.version = "n/a", this.io = a, t == null && (this.loadOptions = {}), this.resourceManager = new Xg2();
  }
  // Returns the version information for the tensorflow model GraphDef.
  get modelVersion() {
    return this.version;
  }
  get inputNodes() {
    return this.executor.inputNodes;
  }
  get outputNodes() {
    return this.executor.outputNodes;
  }
  get inputs() {
    return this.executor.inputs;
  }
  get outputs() {
    return this.executor.outputs;
  }
  get weights() {
    return this.executor.weightMap;
  }
  get metadata() {
    return this.artifacts.userDefinedMetadata;
  }
  get modelSignature() {
    return this.signature;
  }
  get modelStructuredOutputKeys() {
    return this.structuredOutputKeys;
  }
  findIOHandler() {
    const e = this.modelUrl;
    if (e.load != null)
      this.handler = e;
    else if (this.loadOptions.requestInit != null)
      this.handler = this.io.browserHTTPRequest(e, this.loadOptions);
    else {
      const t = this.io.getLoadHandlers(e, this.loadOptions);
      if (t.length === 0)
        t.push(this.io.browserHTTPRequest(e, this.loadOptions));
      else if (t.length > 1)
        throw new Error(`Found more than one (${t.length}) load handlers for URL '${[e]}'`);
      this.handler = t[0];
    }
  }
  /**
   * Loads the model and weight files, construct the in memory weight map and
   * compile the inference graph.
   */
  load() {
    if (this.findIOHandler(), this.handler.load == null)
      throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
    const e = this.handler.load();
    return ui(e) ? e.then((t) => this.loadSync(t)) : this.loadSync(e);
  }
  /**
   * Synchronously construct the in memory weight map and
   * compile the inference graph.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  loadSync(e) {
    this.artifacts = e;
    const t = this.artifacts.modelTopology;
    let a = this.artifacts.signature;
    if (this.artifacts.userDefinedMetadata != null) {
      const n = this.artifacts.userDefinedMetadata;
      n.signature != null && (a = n.signature), n.structuredOutputKeys != null && (this.structuredOutputKeys = n.structuredOutputKeys);
    }
    this.signature = a, this.version = `${t.versions.producer}.${t.versions.minConsumer}`;
    const r = this.io.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs);
    if (this.executor = new Ee2(Vt.Instance.transformGraph(t, this.signature)), this.executor.weightMap = this.convertTensorMapToTensorsMap(r), this.executor.resourceManager = this.resourceManager, e.modelInitializer != null && e.modelInitializer.node != null) {
      const n = Vt.Instance.transformGraph(e.modelInitializer);
      this.initializer = new Ee2(n), this.initializer.weightMap = this.executor.weightMap, this.initializer.resourceManager = this.resourceManager, this.initializerSignature = e.initializerSignature;
    }
    return true;
  }
  /**
   * Save the configuration and/or weights of the GraphModel.
   *
   * An `IOHandler` is an object that has a `save` method of the proper
   * signature defined. The `save` method manages the storing or
   * transmission of serialized data ("artifacts") that represent the
   * model's topology and weights onto or via a specific medium, such as
   * file downloads, local storage, IndexedDB in the web browser and HTTP
   * requests to a server. TensorFlow.js provides `IOHandler`
   * implementations for a number of frequently used saving mediums, such as
   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`
   * for more details.
   *
   * This method also allows you to refer to certain types of `IOHandler`s
   * as URL-like string shortcuts, such as 'localstorage://' and
   * 'indexeddb://'.
   *
   * Example 1: Save `model`'s topology and weights to browser [local
   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);
   * then load it back.
   *
   * ```js
   * const modelUrl =
   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';
   * const model = await tf.loadGraphModel(modelUrl);
   * const zeros = tf.zeros([1, 224, 224, 3]);
   * model.predict(zeros).print();
   *
   * const saveResults = await model.save('localstorage://my-model-1');
   *
   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');
   * console.log('Prediction from loaded model:');
   * model.predict(zeros).print();
   * ```
   *
   * @param handlerOrURL An instance of `IOHandler` or a URL-like,
   * scheme-based string shortcut for `IOHandler`.
   * @param config Options for saving the model.
   * @returns A `Promise` of `SaveResult`, which summarizes the result of
   * the saving, such as byte sizes of the saved artifacts for the model's
   *   topology and weight values.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  async save(e, t) {
    if (typeof e == "string") {
      const a = this.io.getSaveHandlers(e);
      if (a.length === 0)
        throw new Error(`Cannot find any save handlers for URL '${e}'`);
      if (a.length > 1)
        throw new Error(`Found more than one (${a.length}) save handlers for URL '${e}'`);
      e = a[0];
    }
    if (e.save == null)
      throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    return e.save(this.artifacts);
  }
  addStructuredOutputNames(e) {
    if (this.structuredOutputKeys) {
      const t = e instanceof Lt ? [e] : e, a = {};
      return t.forEach((r, n) => a[this.structuredOutputKeys[n]] = r), a;
    }
    return e;
  }
  /**
   * Execute the inference for the input tensors.
   *
   * @param input The input tensors, when there is single input for the model,
   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,
   * inputs params should be in either `tf.Tensor`[] if the input order is
   * fixed, or otherwise NamedTensorMap format.
   *
   * For model with multiple inputs, we recommend you use NamedTensorMap as the
   * input type, if you use `tf.Tensor`[], the order of the array needs to
   * follow the
   * order of inputNodes array. @see {@link GraphModel.inputNodes}
   *
   * You can also feed any intermediate nodes using the NamedTensorMap as the
   * input type. For example, given the graph
   *    InputNode => Intermediate => OutputNode,
   * you can execute the subgraph Intermediate => OutputNode by calling
   *    model.execute('IntermediateNode' : tf.tensor(...));
   *
   * This is useful for models that uses tf.dynamic_rnn, where the intermediate
   * state needs to be fed manually.
   *
   * For batch inference execution, the tensors for each input need to be
   * concatenated together. For example with mobilenet, the required input shape
   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].
   * If we are provide a batched data of 100 images, the input tensor should be
   * in the shape of [100, 244, 244, 3].
   *
   * @param config Prediction configuration for specifying the batch size.
   * Currently the batch size option is ignored for graph model.
   *
   * @returns Inference result tensors. If the model is converted and it
   * originally had structured_outputs in tensorflow, then a NamedTensorMap
   * will be returned matching the structured_outputs. If no structured_outputs
   * are present, the output will be single `tf.Tensor` if the model has single
   * output node, otherwise Tensor[].
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predict(e, t) {
    const a = this.execute(e, this.outputNodes);
    return this.addStructuredOutputNames(a);
  }
  /**
   * Execute the inference for the input tensors in async fashion, use this
   * method when your model contains control flow ops.
   *
   * @param input The input tensors, when there is single input for the model,
   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,
   * inputs params should be in either `tf.Tensor`[] if the input order is
   * fixed, or otherwise NamedTensorMap format.
   *
   * For model with multiple inputs, we recommend you use NamedTensorMap as the
   * input type, if you use `tf.Tensor`[], the order of the array needs to
   * follow the
   * order of inputNodes array. @see {@link GraphModel.inputNodes}
   *
   * You can also feed any intermediate nodes using the NamedTensorMap as the
   * input type. For example, given the graph
   *    InputNode => Intermediate => OutputNode,
   * you can execute the subgraph Intermediate => OutputNode by calling
   *    model.execute('IntermediateNode' : tf.tensor(...));
   *
   * This is useful for models that uses tf.dynamic_rnn, where the intermediate
   * state needs to be fed manually.
   *
   * For batch inference execution, the tensors for each input need to be
   * concatenated together. For example with mobilenet, the required input shape
   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].
   * If we are provide a batched data of 100 images, the input tensor should be
   * in the shape of [100, 244, 244, 3].
   *
   * @param config Prediction configuration for specifying the batch size.
   * Currently the batch size option is ignored for graph model.
   *
   * @returns A Promise of inference result tensors. If the model is converted
   * and it originally had structured_outputs in tensorflow, then a
   * NamedTensorMap will be returned matching the structured_outputs. If no
   * structured_outputs are present, the output will be single `tf.Tensor` if
   * the model has single output node, otherwise Tensor[].
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async predictAsync(e, t) {
    const a = await this.executeAsync(e, this.outputNodes);
    return this.addStructuredOutputNames(a);
  }
  normalizeInputs(e) {
    var t;
    if (!(e instanceof Lt) && !Array.isArray(e)) {
      const n = (t = this.signature) === null || t === void 0 ? void 0 : t.inputs;
      if (n != null)
        for (const o in n) {
          const u = n[o];
          u.resourceId != null && (e[o] = this.resourceIdToCapturedInput[u.resourceId]);
        }
      return e;
    }
    e = Array.isArray(e) ? e : [e];
    const a = Object.keys(this.resourceIdToCapturedInput).length;
    if (e.length + a !== this.inputNodes.length)
      throw new Error(`Input tensor count mismatch, the graph model has ${this.inputNodes.length - a} non-resource placeholders, while there are ${e.length} input tensors provided.`);
    let r = 0;
    return this.inputNodes.reduce((n, o) => {
      var u, l, p6;
      const m = (p6 = (l = (u = this.signature) === null || u === void 0 ? void 0 : u.inputs) === null || l === void 0 ? void 0 : l[o]) === null || p6 === void 0 ? void 0 : p6.resourceId;
      return m != null ? n[o] = this.resourceIdToCapturedInput[m] : n[o] = e[r++], n;
    }, {});
  }
  normalizeOutputs(e) {
    return e = e || this.outputNodes, Array.isArray(e) ? e : [e];
  }
  executeInitializerGraph() {
    return this.initializer == null ? [] : this.initializerSignature == null ? this.initializer.execute({}, []) : this.initializer.execute({}, Object.keys(this.initializerSignature.outputs));
  }
  async executeInitializerGraphAsync() {
    return this.initializer == null ? [] : this.initializerSignature == null ? this.initializer.executeAsync({}, []) : this.initializer.executeAsync({}, Object.keys(this.initializerSignature.outputs));
  }
  setResourceIdToCapturedInput(e) {
    if (this.resourceIdToCapturedInput = {}, this.initializerSignature) {
      const t = this.initializerSignature.outputs, a = Object.keys(t);
      for (let r = 0; r < a.length; r++) {
        const n = a[r], o = t[n];
        this.resourceIdToCapturedInput[o.resourceId] = e[r];
      }
    }
  }
  /**
   * Executes inference for the model for given input tensors.
   * @param inputs tensor, tensor array or tensor map of the inputs for the
   * model, keyed by the input node names.
   * @param outputs output node name from the TensorFlow model, if no
   * outputs are specified, the default outputs of the model would be used.
   * You can inspect intermediate nodes of the model by adding them to the
   * outputs array.
   *
   * @returns A single tensor if provided with a single output or no outputs
   * are provided and there is only one default output, otherwise return a
   * tensor array. The order of the tensor array is the same as the outputs
   * if provided, otherwise the order of outputNodes attribute of the model.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  execute(e, t) {
    this.resourceIdToCapturedInput == null && this.setResourceIdToCapturedInput(this.executeInitializerGraph()), e = this.normalizeInputs(e), t = this.normalizeOutputs(t);
    const a = this.executor.execute(e, t);
    return a.length > 1 ? a : a[0];
  }
  /**
   * Executes inference for the model for given input tensors in async
   * fashion, use this method when your model contains control flow ops.
   * @param inputs tensor, tensor array or tensor map of the inputs for the
   * model, keyed by the input node names.
   * @param outputs output node name from the TensorFlow model, if no outputs
   * are specified, the default outputs of the model would be used. You can
   * inspect intermediate nodes of the model by adding them to the outputs
   * array.
   *
   * @returns A Promise of single tensor if provided with a single output or
   * no outputs are provided and there is only one default output, otherwise
   * return a tensor map.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async executeAsync(e, t) {
    this.resourceIdToCapturedInput == null && this.setResourceIdToCapturedInput(await this.executeInitializerGraphAsync()), e = this.normalizeInputs(e), t = this.normalizeOutputs(t);
    const a = await this.executor.executeAsync(e, t);
    return a.length > 1 ? a : a[0];
  }
  /**
   * Get intermediate tensors for model debugging mode (flag
   * KEEP_INTERMEDIATE_TENSORS is true).
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  getIntermediateTensors() {
    return this.executor.getIntermediateTensors();
  }
  /**
   * Dispose intermediate tensors for model debugging mode (flag
   * KEEP_INTERMEDIATE_TENSORS is true).
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  disposeIntermediateTensors() {
    this.executor.disposeIntermediateTensors();
  }
  convertTensorMapToTensorsMap(e) {
    return Object.keys(e).reduce((t, a) => (t[a] = [e[a]], t), {});
  }
  /**
   * Releases the memory used by the weight tensors and resourceManager.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  dispose() {
    this.executor.dispose(), this.initializer && (this.initializer.dispose(), this.resourceIdToCapturedInput && yt(this.resourceIdToCapturedInput)), this.resourceManager.dispose();
  }
};
async function Mg2(s, e = {}, t = bt2) {
  if (s == null)
    throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
  e == null && (e = {}), e.fromTFHub && typeof s == "string" && (s = tb2(s));
  const a = new Ot2(s, e, t);
  return await a.load(), a;
}
function eb2(s) {
  if (s == null)
    throw new Error("modelUrl in loadGraphModelSync() cannot be null. Please provide model artifacts or an IOHandler that loads the model");
  let e;
  if (s instanceof Array) {
    const [a, r] = s;
    if (!a)
      throw new Error("modelJSON must be the first element of the array");
    if (!r || !(r instanceof ArrayBuffer))
      throw new Error("An ArrayBuffer of weights must be the second element of the array");
    if (!("modelTopology" in a))
      throw new Error("Model JSON is missing 'modelTopology'");
    if (!("weightsManifest" in a))
      throw new Error("Model JSON is missing 'weightsManifest'");
    const n = NC(a.weightsManifest), o = kC(a, n, r);
    e = _e2(o);
  } else if ("load" in s)
    e = s;
  else if ("modelTopology" in s && "weightSpecs" in s && "weightData" in s)
    e = _e2(s);
  else
    throw new Error("Unknown model format");
  const t = new Ot2(e);
  return t.load(), t;
}
function tb2(s) {
  return s.endsWith("/") || (s = s + "/"), `${s}${Yg2}${Zg2}`;
}
var Yn2 = "4.2.0";
var Mn2 = class extends Tf {
  /**
   * Create a `TextLineDataset`.
   *
   * @param input A `DataSource` providing a chunked, UTF8-encoded byte stream.
   */
  constructor(e) {
    super(), this.input = e;
  }
  async iterator() {
    return (await this.input.iterator()).decodeUTF8().split(`
`).map((r) => (r.endsWith("\r") && (r = r.slice(0, -1)), r));
  }
};
var ye2 = '"';
var ne2 = Symbol("out");
var Wt = Symbol("field");
var ge2 = Symbol("quote");
var xe2 = Symbol("quoteafterquote");
var qt2 = Symbol("quoteinquote");
var ei2 = class extends Tf {
  /**
   * Create a `CSVDataset`.
   *
   * @param input A `DataSource` providing a chunked, UTF8-encoded byte stream.
   * @param csvConfig (Optional) A CSVConfig object that contains configurations
   *     of reading and decoding from CSV file(s).
   *
   *     hasHeader: (Optional) A boolean value that indicates whether the first
   *     row of provided CSV file is a header line with column names, and should
   *     not be included in the data. Defaults to `true`.
   *
   *     columnNames: (Optional) A list of strings that corresponds to
   *     the CSV column names, in order. If provided, it ignores the column
   *     names inferred from the header row. If not provided, infers the column
   *     names from the first row of the records. If hasHeader is false and
   *     columnNames is not provided, this method throws an error.
   *
   *     columnConfigs: (Optional) A dictionary whose key is column names, value
   *     is an object stating if this column is required, column's data type,
   *     default value, and if this column is label. If provided, keys must
   *     correspond to names provided in columnNames or inferred from the file
   *     header lines. If isLabel is true any column, returns an array of two
   *     items: the first item is a dict of features key/value pairs, the second
   *     item is a dict of labels key/value pairs. If no feature is marked as
   *     label, returns a dict of features only.
   *
   *     configuredColumnsOnly (Optional) If true, only columns provided in
   *     columnConfigs will be parsed and provided during iteration.
   *
   *     delimiter (Optional) The string used to parse each line of the input
   *     file. Defaults to `,`.
   */
  constructor(e, t) {
    super(), this.input = e, this.hasHeader = true, this.fullColumnNames = null, this.columnNamesValidated = false, this.columnConfigs = null, this.configuredColumnsOnly = false, this.delimiter = ",", this.delimWhitespace = false, this.base = new Mn2(e), t || (t = {}), this.hasHeader = t.hasHeader !== false, this.fullColumnNames = t.columnNames, this.columnConfigs = t.columnConfigs, this.configuredColumnsOnly = t.configuredColumnsOnly, t.delimWhitespace ? (v2(t.delimiter == null, () => "Delimiter should not be provided when delimWhitespace is true."), this.delimWhitespace = true, this.delimiter = " ") : this.delimiter = t.delimiter ? t.delimiter : ",";
  }
  /**
   * Returns column names of the csv dataset. If `configuredColumnsOnly` is
   * true, return column names in `columnConfigs`. If `configuredColumnsOnly` is
   * false and `columnNames` is provided, `columnNames`. If
   * `configuredColumnsOnly` is false and `columnNames` is not provided, return
   * all column names parsed from the csv file. For example usage please go to
   * `tf.data.csv`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  async columnNames() {
    return this.columnNamesValidated || await this.setColumnNames(), this.configuredColumnsOnly ? Object.keys(this.columnConfigs) : this.fullColumnNames;
  }
  /* 1) If `columnNames` is provided as string[], use this string[] as output
   * keys in corresponding order. The length must match the number of inferred
   * columns if `hasHeader` is true .
   * 2) If `columnNames` is not provided, parse header line as `columnNames` if
   * hasHeader is true. If `hasHeader` is false, throw an error.
   * 3) If `columnConfigs` is provided, all the keys in `columnConfigs` must
   * exist in parsed `columnNames`.
   */
  async setColumnNames() {
    const e = await this.maybeReadHeaderLine();
    if (!this.fullColumnNames && !e)
      throw new Error("Column names must be provided if there is no header line.");
    this.fullColumnNames && e && v2(e.length === this.fullColumnNames.length, () => "The length of provided columnNames (" + this.fullColumnNames.length.toString() + ") does not match the length of the header line read from file (" + e.length.toString() + ")."), this.fullColumnNames || (this.fullColumnNames = e);
    const t = this.fullColumnNames.reduce((r, n) => (r[n] = r[n] + 1 || 1, r), {}), a = Object.keys(t).filter((r) => t[r] > 1);
    if (v2(a.length === 0, () => "Duplicate column names found: " + a.toString()), this.columnConfigs) {
      for (const r of Object.keys(this.columnConfigs))
        if (this.fullColumnNames.indexOf(r) === -1)
          throw new Error('The key "' + r + '" provided in columnConfigs does not match any of the column names (' + this.fullColumnNames.toString() + ").");
    }
    this.columnNamesValidated = true;
  }
  async maybeReadHeaderLine() {
    if (this.hasHeader) {
      const t = await (await this.base.iterator()).next();
      if (t.done)
        throw new Error("No data was found for CSV parsing.");
      const a = t.value;
      return this.parseRow(a, false);
    } else
      return null;
  }
  async iterator() {
    this.columnNamesValidated || await this.setColumnNames();
    let e = await this.base.iterator();
    return this.hasHeader && (e = e.skip(1)), e.map((t) => this.makeDataElement(t));
  }
  makeDataElement(e) {
    const t = this.parseRow(e), a = {}, r = {};
    for (let n = 0; n < this.fullColumnNames.length; n++) {
      const o = this.fullColumnNames[n], u = this.columnConfigs ? this.columnConfigs[o] : null;
      if (!(this.configuredColumnsOnly && !u)) {
        const l = t[n];
        let p6 = null;
        if (l === "")
          if (u && u.default !== void 0)
            p6 = u.default;
          else {
            if (u && (u.required || u.isLabel))
              throw new Error(`Required column ${o} is empty in this line: ${e}`);
            p6 = void 0;
          }
        else {
          const m = Number(l);
          if (isNaN(m))
            u && u.dtype === "bool" ? p6 = this.getBoolean(l) : p6 = l;
          else if (!u || !u.dtype)
            p6 = m;
          else
            switch (u.dtype) {
              case "float32":
                p6 = m;
                break;
              case "int32":
                p6 = Math.floor(m);
                break;
              case "bool":
                p6 = this.getBoolean(l);
                break;
              default:
                p6 = m;
            }
        }
        u && u.isLabel ? r[o] = p6 : a[o] = p6;
      }
    }
    return Object.keys(r).length === 0 ? a : { xs: a, ys: r };
  }
  getBoolean(e) {
    return e === "1" || e.toLowerCase() === "true" ? 1 : 0;
  }
  // adapted from https://beta.observablehq.com/@mbostock/streaming-csv
  parseRow(e, t = true) {
    const a = [];
    let r = 0;
    const n = e.length;
    let o = ne2;
    for (let u = 0; u < n; u++)
      switch (o) {
        case ne2:
          switch (e.charAt(u)) {
            case ye2:
              r = u + 1, o = ge2;
              break;
            case this.delimiter:
              if (r = u + 1, this.delimiter === " " && this.delimWhitespace)
                break;
              a.push(""), o = ne2;
              break;
            default:
              o = Wt, r = u;
              break;
          }
          break;
        case Wt:
          switch (e.charAt(u)) {
            case this.delimiter:
              a.push(e.substring(r, u)), o = ne2, r = u + 1;
              break;
          }
          break;
        case ge2:
          switch (e.charAt(u)) {
            case ye2:
              o = xe2;
              break;
          }
          break;
        case xe2:
          switch (e.charAt(u)) {
            case this.delimiter:
              a.push(e.substring(r, u - 1)), o = ne2, r = u + 1;
              break;
            case ye2:
              o = ge2;
              break;
            default:
              o = qt2;
              break;
          }
          break;
        case qt2:
          switch (e.charAt(u)) {
            case ye2:
              o = ge2;
              break;
          }
          break;
      }
    if (o === xe2 ? a.push(e.substring(r, n - 1)) : a.push(e.substring(r)), t && a.length !== this.fullColumnNames.length)
      throw new Error(`Invalid row in csv file. Should have ${this.fullColumnNames.length} elements in a row, but got ${a}`);
    return a;
  }
};
var _t = class extends Ke {
  constructor(e) {
    super(), this.microphoneConfig = e, this.isClosed = false, this.fftSize = e.fftSize || 1024;
    const t = Math.log2(this.fftSize);
    if (this.fftSize < 0 || t < 4 || t > 14 || !Number.isInteger(t))
      throw new Error(`Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ${this.fftSize}`);
    if (this.numFrames = e.numFramesPerSpectrogram || 43, this.sampleRateHz = e.sampleRateHz, this.columnTruncateLength = e.columnTruncateLength || this.fftSize, this.audioTrackConstraints = e.audioTrackConstraints, this.smoothingTimeConstant = e.smoothingTimeConstant || 0, this.includeSpectrogram = e.includeSpectrogram !== false, this.includeWaveform = e.includeWaveform === true, !this.includeSpectrogram && !this.includeWaveform)
      throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.");
  }
  summary() {
    return "microphone";
  }
  // Construct a MicrophoneIterator and start the audio stream.
  static async create(e = {}) {
    if (!F().get("IS_BROWSER"))
      throw new Error("microphone API is only supported in browser environment.");
    const t = new _t(e);
    return await t.start(), t;
  }
  // Start the audio stream and FFT.
  async start() {
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: this.audioTrackConstraints == null ? true : this.audioTrackConstraints,
        video: false
      });
    } catch (a) {
      throw new Error(`Error thrown while initializing video stream: ${a.message}`);
    }
    if (!this.stream)
      throw new Error("Could not obtain audio from microphone.");
    const e = (
      // tslint:disable-next-line:no-any
      window.AudioContext || window.webkitAudioContext
    );
    if (this.audioContext = new e(), !this.sampleRateHz)
      this.sampleRateHz = this.audioContext.sampleRate;
    else if (this.audioContext.sampleRate !== this.sampleRateHz)
      throw new Error(`Mismatch in sampling rate: Expected: ${this.sampleRateHz}; Actual: ${this.audioContext.sampleRate}`);
    const t = this.audioContext.createMediaStreamSource(this.stream);
    this.analyser = this.audioContext.createAnalyser(), this.analyser.fftSize = this.fftSize * 2, this.analyser.smoothingTimeConstant = this.smoothingTimeConstant, t.connect(this.analyser), this.freqData = new Float32Array(this.fftSize), this.timeData = new Float32Array(this.fftSize);
  }
  async next() {
    if (this.isClosed)
      return { value: null, done: true };
    let e, t;
    const a = await this.getAudioData();
    if (this.includeSpectrogram) {
      const r = this.flattenQueue(a.freqDataQueue);
      e = this.getTensorFromAudioDataArray(r, [this.numFrames, this.columnTruncateLength, 1]);
    }
    if (this.includeWaveform) {
      const r = this.flattenQueue(a.timeDataQueue);
      t = this.getTensorFromAudioDataArray(r, [this.numFrames * this.fftSize, 1]);
    }
    return {
      value: { spectrogram: e, waveform: t },
      done: false
    };
  }
  // Capture one result from the audio stream, and extract the value from
  // iterator.next() result.
  async capture() {
    return (await this.next()).value;
  }
  async getAudioData() {
    const e = [], t = [];
    let a = 0;
    return new Promise((r) => {
      const n = setInterval(() => {
        this.includeSpectrogram && (this.analyser.getFloatFrequencyData(this.freqData), this.freqData[0] === -1 / 0 && r({ freqDataQueue: e, timeDataQueue: t }), e.push(this.freqData.slice(0, this.columnTruncateLength))), this.includeWaveform && (this.analyser.getFloatTimeDomainData(this.timeData), t.push(this.timeData.slice())), ++a === this.numFrames && (clearInterval(n), r({ freqDataQueue: e, timeDataQueue: t }));
      }, this.fftSize / this.sampleRateHz * 1e3);
    });
  }
  // Stop the audio stream and pause the iterator.
  stop() {
    this.isClosed || (this.isClosed = true, this.analyser.disconnect(), this.audioContext.close(), this.stream != null && this.stream.getTracks().length > 0 && this.stream.getTracks()[0].stop());
  }
  // Override toArray() function to prevent collecting.
  toArray() {
    throw new Error("Can not convert infinite audio stream to array.");
  }
  // Return audio sampling rate in Hz
  getSampleRate() {
    return this.sampleRateHz;
  }
  flattenQueue(e) {
    const t = e[0].length, a = new Float32Array(e.length * t);
    return e.forEach((r, n) => a.set(r, n * t)), a;
  }
  getTensorFromAudioDataArray(e, t) {
    const a = new Float32Array(O(t));
    return a.set(e, a.length - e.length), Re(a, t);
  }
};
var At2 = class extends Ke {
  constructor(e, t) {
    if (super(), this.webcamVideoElement = e, this.webcamConfig = t, this.isClosed = true, this.resize = false, this.needToResize())
      if (this.resize = true, this.cropSize = [this.webcamConfig.resizeHeight, this.webcamConfig.resizeWidth], this.cropBoxInd = Je([0], "int32"), this.webcamConfig.centerCrop) {
        const a = this.webcamConfig.resizeWidth * 1 / this.webcamVideoElement.width, r = this.webcamConfig.resizeHeight * 1 / this.webcamVideoElement.height, n = (1 - a) / 2, o = (1 - r) / 2, u = n + a, l = r + o;
        this.cropBox = qa([o, n, l, u], [1, 4]);
      } else
        this.cropBox = qa([0, 0, 1, 1], [1, 4]);
  }
  summary() {
    return "webcam";
  }
  // Construct a WebcamIterator and start it's video stream.
  static async create(e, t = {}) {
    if (!F().get("IS_BROWSER"))
      throw new Error("tf.data.webcam is only supported in browser environment.");
    if (!e) {
      if (e = document.createElement("video"), !t.resizeWidth || !t.resizeHeight)
        throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");
      e.width = t.resizeWidth, e.height = t.resizeHeight;
    }
    const a = new At2(e, t);
    return await a.start(), a;
  }
  // Async function to start video stream.
  async start() {
    this.webcamConfig.facingMode && v2(this.webcamConfig.facingMode === "user" || this.webcamConfig.facingMode === "environment", () => `Invalid webcam facing mode: ${this.webcamConfig.facingMode}. Please provide 'user' or 'environment'`);
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        video: {
          deviceId: this.webcamConfig.deviceId,
          facingMode: this.webcamConfig.facingMode ? this.webcamConfig.facingMode : "user",
          width: this.webcamVideoElement.width,
          height: this.webcamVideoElement.height
        }
      });
    } catch (e) {
      throw e.message = `Error thrown while initializing video stream: ${e.message}`, e;
    }
    if (!this.stream)
      throw new Error("Could not obtain video from webcam.");
    try {
      this.webcamVideoElement.srcObject = this.stream;
    } catch (e) {
      console.log(e), this.webcamVideoElement.src = window.URL.createObjectURL(this.stream);
    }
    return this.webcamVideoElement.play(), this.isClosed = false, new Promise((e) => {
      this.webcamVideoElement.onloadedmetadata = () => {
        e();
      };
    });
  }
  async next() {
    if (this.isClosed)
      return { value: null, done: true };
    let e;
    try {
      e = b0(this.webcamVideoElement);
    } catch (t) {
      throw new Error(`Error thrown converting video to pixels: ${JSON.stringify(t)}`);
    }
    if (this.resize)
      try {
        return { value: this.cropAndResizeFrame(e), done: false };
      } catch (t) {
        throw new Error(`Error thrown cropping the video: ${t.message}`);
      } finally {
        e.dispose();
      }
    else
      return { value: e, done: false };
  }
  needToResize() {
    return !!(this.webcamConfig.resizeWidth && this.webcamConfig.resizeHeight && (this.webcamVideoElement.width !== this.webcamConfig.resizeWidth || this.webcamVideoElement.height !== this.webcamConfig.resizeHeight));
  }
  // Cropping and resizing each frame based on config
  cropAndResizeFrame(e) {
    return D(() => {
      const t = Ue(et(e, "float32"), 0);
      let a;
      a = uo.cropAndResize(t, this.cropBox, this.cropBoxInd, this.cropSize, "bilinear");
      const r = a.shape;
      return W(a, r.slice(1));
    });
  }
  // Capture one frame from the video stream, and extract the value from
  // iterator.next() result.
  async capture() {
    return (await this.next()).value;
  }
  // Stop the video stream and pause webcam iterator.
  stop() {
    this.stream.getTracks().forEach((t) => t.stop());
    try {
      this.webcamVideoElement.srcObject = null;
    } catch (t) {
      console.log(t), this.webcamVideoElement.src = null;
    }
    this.isClosed = true;
  }
  // Override toArray() function to prevent collecting.
  toArray() {
    throw new Error("Can not convert infinite video stream to array.");
  }
};
var ti2 = class {
};
var si2 = class extends Ke {
  /**
   * Splits a string stream on a given separator.
   *
   * It is assumed that the incoming chunk boundaries have no semantic meaning,
   * so conceptually the incoming stream is treated simply as the concatenation
   * of its elements.
   *
   * The outgoing stream provides chunks corresponding to the results of the
   * standard string split() operation (even if such a chunk spanned incoming
   * chunks).  The separators are not included.
   *
   * A typical usage is to split a text file (represented as a stream with
   * arbitrary chunk boundaries) into lines.
   *
   * @param upstream A readable stream of strings that can be treated as
   *   concatenated.
   * @param separator A character to split on.
   */
  split(e) {
    return new sb2(this, e);
  }
};
var sb2 = class extends si2 {
  constructor(e, t) {
    super(), this.upstream = e, this.impl = new ab2(e, t);
  }
  summary() {
    return this.impl.summary();
  }
  async next() {
    return this.impl.next();
  }
};
var ab2 = class extends SL {
  constructor(e, t) {
    super(), this.upstream = e, this.separator = t, this.carryover = "";
  }
  summary() {
    return `${this.upstream.summary()} -> Split('${this.separator}')`;
  }
  async pump() {
    const e = await this.upstream.next();
    if (e.done)
      return this.carryover === "" ? false : (this.outputQueue.push(this.carryover), this.carryover = "", true);
    const t = e.value.split(this.separator);
    t[0] = this.carryover + t[0];
    for (const a of t.slice(0, -1))
      this.outputQueue.push(a);
    return this.carryover = t[t.length - 1], true;
  }
};
var rb2 = class extends Ke {
  /**
   * Decode a stream of UTF8-encoded byte arrays to a stream of strings.
   *
   * The byte arrays producetd from the ByteChunkIterator on which this is
   * called will be interpreted as concatenated.  No assumptions are made about
   * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a
   * character may span the boundary between chunks.  This naturally happens,
   * for instance, when reading fixed-size byte arrays from a file.
   */
  decodeUTF8() {
    return new nb2(this);
  }
};
var nb2 = class extends si2 {
  constructor(e) {
    super(), this.upstream = e, this.impl = new ib2(e);
  }
  summary() {
    return this.impl.summary();
  }
  async next() {
    return this.impl.next();
  }
};
var ib2 = class extends SL {
  constructor(e) {
    if (super(), this.upstream = e, F().get("IS_BROWSER"))
      this.decoder = new TextDecoder("utf-8");
    else {
      const { StringDecoder: t } = require_string_decoder();
      this.decoder = new t("utf8");
    }
  }
  summary() {
    return `${this.upstream.summary()} -> Utf8`;
  }
  async pump() {
    const e = await this.upstream.next();
    let t;
    if (e.done)
      return false;
    t = e.value;
    let a;
    return F().get("IS_BROWSER") ? a = this.decoder.decode(t, { stream: true }) : a = this.decoder.write(Buffer.from(t.buffer)), this.outputQueue.push(a), true;
  }
};
var ai2 = class extends rb2 {
  constructor(e, t = {}) {
    super(), this.file = e, this.options = t, v2(e instanceof Uint8Array || (F().get("IS_BROWSER") ? e instanceof File || e instanceof Blob : false), () => "FileChunkIterator only supports File, Blob and Uint8Array right now."), this.offset = t.offset || 0, this.chunkSize = t.chunkSize || 1024 * 1024;
  }
  summary() {
    return `FileChunks ${this.file}`;
  }
  async next() {
    return this.offset >= (this.file instanceof Uint8Array ? this.file.byteLength : this.file.size) ? { value: null, done: true } : { value: await new Promise((t, a) => {
      const r = this.offset + this.chunkSize;
      if (this.file instanceof Uint8Array)
        t(new Uint8Array(this.file.slice(this.offset, r)));
      else {
        const n = new FileReader();
        n.onload = (u) => {
          let l = n.result;
          if (l instanceof ArrayBuffer && (l = new Uint8Array(l)), !(l instanceof Uint8Array))
            return a(new TypeError("FileReader returned unknown type."));
          t(l);
        }, n.onabort = (u) => a(new Error("Aborted")), n.onerror = (u) => a(new Error(u.type));
        const o = this.file.slice(this.offset, r);
        n.readAsArrayBuffer(o);
      }
      this.offset = r;
    }), done: false };
  }
};
async function ob2(s, e = {}, t) {
  let a, r;
  typeof s == "string" ? a = s : (a = s.url, r = ub2(s));
  const n = await (t || nC)(a, r);
  if (n.ok) {
    const o = new Uint8Array(await n.arrayBuffer());
    return new ai2(o, e);
  } else
    throw new Error(n.statusText);
}
var ub2 = (s) => ({
  method: s.method,
  headers: s.headers,
  body: s.body,
  mode: s.mode,
  credentials: s.credentials,
  cache: s.cache,
  redirect: s.redirect,
  referrer: s.referrer,
  integrity: s.integrity
});
function ri2(s) {
  return typeof s == "string" && s.slice(0, 7) === "file://";
}
var ni2 = class extends ti2 {
  /**
   * Create a `FileDataSource`.
   *
   * @param input Local file path, or `File`/`Blob`/`Uint8Array` object to
   *     read. Local file only works in node environment.
   * @param options Options passed to the underlying `FileChunkIterator`s,
   *   such as {chunksize: 1024}.
   */
  constructor(e, t = {}) {
    super(), this.input = e, this.options = t;
  }
  async iterator() {
    if (ri2(this.input) && F().get("IS_NODE")) {
      const e = require_fs();
      this.input = e.readFileSync(this.input.slice(7));
    }
    return new ai2(this.input, this.options);
  }
};
var ii2 = class extends ti2 {
  /**
   * Create a `URLDataSource`.
   *
   * @param url A source URL string, or a `Request` object.
   * @param options Options passed to the underlying `FileChunkIterator`s,
   *   such as {chunksize: 1024}.
   */
  constructor(e, t = {}) {
    super(), this.url = e, this.fileOptions = t;
  }
  // TODO(soergel): provide appropriate caching options.  Currently this
  // will download the URL anew for each call to iterator().  Since we have
  // to treat the downloaded file as a blob/buffer anyway, we may as well retain
  // it-- but that raises GC issues.  Also we may want a persistent disk cache.
  async iterator() {
    return ri2(this.url) ? new ni2(this.url, this.fileOptions).iterator() : ob2(this.url, this.fileOptions);
  }
};
function lb2(s, e = {}) {
  return new ei2(new ii2(s), e);
}
function pb2(s) {
  const e = hL(s);
  return bn(async () => e);
}
function mb2(s) {
  return bn(async () => {
    const e = await s();
    return hL(() => e.next());
  });
}
async function cb2(s, e) {
  return At2.create(s, e);
}
async function db2(s) {
  return _t.create(s);
}
var oi2 = "4.2.0";
var hb2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  CSVDataset: ei2,
  Dataset: Tf,
  FileDataSource: ni2,
  TextLineDataset: Mn2,
  URLDataSource: ii2,
  array: EY,
  csv: lb2,
  func: pb2,
  generator: mb2,
  microphone: db2,
  version_data: oi2,
  webcam: cb2,
  zip: LY
}, Symbol.toStringTag, { value: "Module" }));
var fb2 = "4.2.0";
var yb2 = "4.2.0";
var gb2 = "4.2.0";
var bb2 = {
  "tfjs-core": jn2,
  "tfjs-backend-cpu": fb2,
  "tfjs-backend-webgl": yb2,
  "tfjs-data": oi2,
  "tfjs-layers": Gx,
  "tfjs-converter": Yn2,
  tfjs: gb2
};
var Nb2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  Abs: Vl,
  Acos: di,
  Acosh: hi,
  AdadeltaOptimizer: a0,
  AdagradOptimizer: l0,
  AdamOptimizer: c0,
  AdamaxOptimizer: u0,
  Add: br,
  AddN: Bd,
  All: Hd,
  Any: _d,
  ArgMax: zl,
  ArgMin: Xl,
  Asin: pi,
  Asinh: fi,
  Atan: mi,
  Atan2: bi,
  Atanh: gi,
  AvgPool: Pl,
  AvgPool3D: Al,
  AvgPool3DGrad: Yd,
  AvgPoolGrad: Ud,
  BatchMatMul: Ol,
  BatchToSpaceND: Kl,
  Bincount: Qd,
  BroadcastArgs: Kg,
  BroadcastTo: BI,
  Callback: Gn2,
  CallbackList: jG,
  Cast: xi,
  Ceil: yi,
  ClipByValue: wi,
  Complex: Jd,
  ComplexAbs: Zl,
  Concat: Bl,
  Conv2D: Hl,
  Conv2DBackpropFilter: jd,
  Conv2DBackpropInput: _l,
  Conv3D: Ul,
  Conv3DBackpropFilterV2: qd,
  Conv3DBackpropInputV2: th,
  Cos: Ii,
  Cosh: Ci,
  CropAndResize: nh,
  Cumprod: eh,
  Cumsum: Yl,
  CustomCallback: eE,
  DataStorage: Mg,
  DenseBincount: sh,
  DepthToSpace: oh,
  DepthwiseConv2dNative: Ql,
  DepthwiseConv2dNativeBackpropFilter: rh,
  DepthwiseConv2dNativeBackpropInput: ih,
  Diag: Zg,
  Dilation2D: Jl,
  Dilation2DBackpropFilter: nd,
  Dilation2DBackpropInput: ed,
  get ENV() {
    return Ag;
  },
  EarlyStopping: Kn2,
  Einsum: Bg,
  Elu: Si,
  EluGrad: ah,
  Environment: XI,
  Equal: jl,
  Erf: ki,
  Exp: Ti,
  ExpandDims: ql,
  Expm1: Ni,
  FFT: lh,
  Fill: ch,
  FlipLeftRight: uh,
  Floor: Ri,
  FloorDiv: $i,
  FromPixels: sd,
  FusedBatchNorm: tc,
  FusedConv2D: rl,
  FusedDepthwiseConv2D: nb,
  GatherNd: Hg,
  GatherV2: ec,
  GraphModel: Ot2,
  Greater: nc,
  GreaterEqual: Gi,
  History: tE,
  IFFT: dh,
  Identity: Ei,
  Imag: hh,
  InputSpec: de,
  IsFinite: Li,
  IsInf: Mi,
  IsNan: Wi,
  KernelBackend: Xd,
  LRN: cc,
  LRNGrad: ph,
  LayerVariable: zG,
  LayersModel: tr,
  LeakyRelu: sc,
  Less: oc,
  LessEqual: rc,
  LinSpace: _g,
  Log: Di,
  Log1p: Fi,
  LogSoftmax: HI,
  LogicalAnd: ic,
  LogicalNot: ac,
  LogicalOr: lc,
  LogicalXor: $4,
  LowerBound: G4,
  Max: uc,
  MaxPool: dc,
  MaxPool3D: hc,
  MaxPool3DGrad: mh,
  MaxPoolGrad: fh,
  MaxPoolWithArgmax: Ug,
  Maximum: Vi,
  Mean: pc,
  Min: fc,
  Minimum: zi,
  MirrorPad: mc,
  Mod: Xi,
  MomentumOptimizer: d0,
  Multinomial: Yg,
  Multiply: Pi,
  Neg: gc,
  NonMaxSuppressionV3: gh,
  NonMaxSuppressionV4: bh,
  NonMaxSuppressionV5: xh,
  NotEqual: bc,
  OP_SCOPE_SUFFIX: yC,
  OneHot: yc,
  OnesLike: xc,
  Optimizer: Ys,
  OptimizerConstructors: oR,
  Pack: wc,
  PadV2: Ic,
  Pool: E4,
  Pow: Ai,
  Prelu: Cc,
  Prod: vc,
  RMSPropOptimizer: h0,
  RNN: Qs,
  RaggedGather: Qg,
  RaggedRange: Jg,
  RaggedTensorToTensor: jg,
  Range: yh,
  get Rank() {
    return tm;
  },
  Real: wh,
  RealDiv: vi,
  Reciprocal: Oi,
  get Reduction() {
    return Ae;
  },
  Relu: Ki,
  Relu6: Zi,
  Reshape: Sc,
  ResizeBilinear: Tc,
  ResizeBilinearGrad: Ch,
  ResizeNearestNeighbor: kc,
  ResizeNearestNeighborGrad: Ih,
  Reverse: Nc,
  RotateWithOffset: Dh,
  Round: Bi,
  Rsqrt: Hi,
  SGDOptimizer: Gp,
  ScatterNd: qg,
  SearchSorted: tb,
  Select: Rc,
  Selu: _i,
  Sequential: oi,
  Sigmoid: Ji,
  Sign: Qi,
  Sin: Ui,
  Sinh: Yi,
  Slice: $c,
  Softmax: Mc,
  Softplus: ji,
  SpaceToBatchND: Ec,
  SparseFillEmptyRows: vh,
  SparseReshape: Sh,
  SparseSegmentMean: kh,
  SparseSegmentSum: Th,
  SparseToDense: eb,
  SplitV: Lc,
  Sqrt: qi,
  Square: Nh,
  SquaredDifference: ta,
  Step: ra,
  StridedSlice: Rh,
  StringNGrams: $h,
  StringSplit: Gh,
  StringToHashBucketFast: Eh,
  Sub: ea,
  Sum: Gc,
  SymbolicTensor: jn,
  Tan: na,
  Tanh: sa,
  Tensor: Lt,
  TensorBuffer: $e,
  Tile: oa,
  TopK: Lh,
  Transform: Mh,
  Transpose: Jo,
  Unique: Wh,
  Unpack: Wc,
  UnsortedSegmentSum: Dc,
  UpperBound: L4,
  Variable: al,
  ZerosLike: Fc,
  _FusedMatMul: ol,
  abs: fe,
  acos: o2,
  acosh: i2,
  add: U,
  addN: Yr2,
  all: Nb,
  any: bd,
  argMax: Qr,
  argMin: d2,
  asin: p2,
  asinh: m2,
  atan: b2,
  atan2: y2,
  atanh: I2,
  avgPool: Bh,
  avgPool3d: $2,
  backend: $s,
  backend_util: cR,
  basicLSTMCell: Mr2,
  batchNorm: zc,
  batchNorm2d: X2,
  batchNorm3d: A2,
  batchNorm4d: K2,
  batchToSpaceND: _h,
  bincount: B2,
  booleanMaskAsync: Cn2,
  broadcastArgs: en2,
  broadcastTo: Br,
  broadcast_util: iY,
  browser: yY,
  buffer: vt,
  callbacks: ky2,
  cast: et,
  ceil: U2,
  clipByValue: pn,
  clone: po,
  complex: bo,
  concat: Ge,
  concat1d: J2,
  concat2d: q2,
  concat3d: ev,
  concat4d: sv,
  constraints: Oh2,
  conv1d: Rb,
  conv2d: Co,
  conv2dTranspose: $b,
  conv3d: cv,
  conv3dTranspose: hv,
  copyRegisteredKernels: D4,
  cos: Yh,
  cosh: Eb,
  cosineWindow: n0,
  cumprod: yd,
  cumsum: Lb,
  customGrad: So,
  data: hb2,
  denseBincount: rm,
  deprecationWarn: Y4,
  depthToSpace: yv,
  depthwiseConv2d: Qh,
  deregisterOp: Dy2,
  device_util: z4,
  diag: tn2,
  dilation2d: Cv,
  disableDeprecationWarnings: U4,
  dispose: yt,
  disposeVariables: Q4,
  div: ut,
  divNoNan: Nv,
  dot: $v,
  dropout: oT,
  einsum: sn2,
  elu: Xc,
  enableDebugMode: _4,
  enableProdMode: H4,
  enclosingPowerOfTwo: rT,
  engine: Xt,
  env: F,
  equal: kn,
  erf: Lv,
  euclideanNorm: Av,
  exp: Tn,
  expandDims: Ue,
  expm1: Bv,
  eye: Db,
  fft: xp,
  fill: ua,
  findBackend: sY,
  findBackendFactory: oY,
  floor: Ac,
  floorDiv: Tb,
  fused: Pn2,
  gather: jh,
  gatherND: Vn2,
  gather_util: wY,
  getBackend: eY,
  getGradient: Hf,
  getKernel: od,
  getKernelsForBackend: rd,
  grad: aY,
  grads: lY,
  greater: sn,
  greaterEqual: Do,
  ifft: pl,
  imag: qh,
  image: uo,
  inTopKAsync: Fn2,
  initializers: jh2,
  input: Bn2,
  io: bt2,
  irfft: Qb,
  isFinite: tS,
  isInf: nS,
  isNaN: oS,
  keep: cn,
  kernel_impls: Nh2,
  layers: ny2,
  leakyRelu: tp,
  less: Fb,
  lessEqual: yr,
  linalg: zN,
  linspace: an2,
  loadGraphModel: Mg2,
  loadGraphModelSync: eb2,
  loadLayersModel: vY,
  localResponseNormalization: cS,
  log: Nn,
  log1p: ep,
  logSigmoid: gS,
  logSoftmax: Vb,
  logSumExp: zb,
  logicalAnd: ss,
  logicalNot: np,
  logicalOr: Xb,
  logicalXor: SS,
  losses: mY,
  lowerBound: rn2,
  matMul: Gt,
  math: bh2,
  max: Xn,
  maxPool: sp,
  maxPool3d: NS,
  maxPoolWithArgmax: nn2,
  maximum: _s,
  mean: se,
  memory: cl,
  meshgrid: on,
  metrics: Ty2,
  min: ul,
  minimum: Kc,
  mirrorPad: LS,
  mod: WS,
  model: Bh2,
  models: Sy2,
  moments: op,
  movingAverage: zn2,
  mul: G,
  multiRNNCell: un2,
  multinomial: ln2,
  neg: jt,
  nextFrame: _c,
  norm: Pc,
  notEqual: qr,
  oneHot: Pb,
  ones: Us,
  onesLike: Rn,
  op: L,
  outerProduct: pn2,
  pad: rp,
  pad1d: mn2,
  pad2d: cn2,
  pad3d: dn2,
  pad4d: hn2,
  pool: ZS,
  pow: ir,
  prelu: ap,
  print: QC,
  prod: _S,
  profile: J4,
  raggedGather: fn2,
  raggedRange: yn2,
  raggedTensorToTensor: gn2,
  rand: bn2,
  randomGamma: Tn2,
  randomNormal: hk,
  randomStandardNormal: Sn2,
  randomUniform: Zc,
  range: ti,
  ready: tY,
  real: dl,
  reciprocal: gk,
  registerBackend: kb,
  registerCallbackConstructor: Wh2,
  registerGradient: UI,
  registerKernel: en,
  registerOp: Iy2,
  regularizers: Ay2,
  relu: ws,
  relu6: Ob,
  removeBackend: nY,
  reshape: W,
  reverse: ko,
  reverse1d: vn2,
  reverse2d: On2,
  reverse3d: _n2,
  reverse4d: An2,
  rfft: yp,
  round: Kb,
  rsqrt: Zb,
  scalar: gt,
  scatterND: xn2,
  scatter_util: hY,
  searchSorted: De2,
  selu: Bb,
  separableConv2d: Hb,
  sequential: Hh2,
  serialization: xY,
  setBackend: q4,
  setPlatform: rY,
  setdiff1dAsync: En2,
  sigmoid: xr,
  sign: kk,
  signal: fY,
  sin: _b,
  sinh: Ub,
  slice: Dt,
  slice1d: mp,
  slice2d: Yb,
  slice3d: gp,
  slice4d: hl,
  slice_util: sR,
  softmax: bp,
  softplus: da,
  spaceToBatchND: ip,
  sparse: gY,
  sparseToDense: Ln,
  spectral: pY,
  split: un,
  sqrt: De,
  square: At,
  squaredDifference: Jb,
  squeeze: ha,
  stack: os,
  step: pa,
  stridedSlice: Kk,
  string: bY,
  sub: lt,
  sum: at,
  sumOutType: zh,
  tan: Bk,
  tanh: Hh,
  tensor: Re,
  tensor1d: Je,
  tensor2d: qa,
  tensor3d: Hk,
  tensor4d: kn2,
  tensor5d: In2,
  tensor6d: Dn2,
  tensor_util: V4,
  test_util: Bd2,
  tidy: D,
  tile: Vn,
  time: j4,
  topk: Uk,
  train: Ko,
  transpose: kt,
  truncatedNormal: jb,
  unique: Jk,
  unregisterGradient: W4,
  unregisterKernel: M4,
  unsortedSegmentSum: qb,
  unstack: To,
  upcastType: je,
  upperBound: $n2,
  util: F4,
  valueAndGrad: cY,
  valueAndGrads: uY,
  variable: tT,
  variableGrads: hS,
  version: bb2,
  version_converter: Yn2,
  version_core: jn2,
  version_layers: Gx,
  where: Oe,
  whereAsync: gt2,
  zeros: ge,
  zerosLike: Tt
}, Symbol.toStringTag, { value: "Module" }));
var ui2 = new Matrix4();
ui2.compose(new Vector3(), new Quaternion(), new Vector3(1e-3, 1e-3, 1e-3));
var wb2 = new Matrix4().set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1);
var Tb2 = class {
  constructor({
    container: e,
    imageTargetSrc: t,
    maxTrack: a,
    uiLoading: r = "yes",
    uiScanning: n = "yes",
    uiError: o = "yes",
    filterMinCF: u = null,
    filterBeta: l = null,
    warmupTolerance: p6 = null,
    missTolerance: m = null,
    userDeviceId: c = null,
    environmentDeviceId: d = null
  }) {
    this.container = e, this.imageTargetSrc = t, this.maxTrack = a, this.filterMinCF = u, this.filterBeta = l, this.warmupTolerance = p6, this.missTolerance = m, this.ui = new k({ uiLoading: r, uiScanning: n, uiError: o }), this.userDeviceId = c, this.environmentDeviceId = d, this.shouldFaceUser = false, this.scene = new Scene(), this.cssScene = new Scene(), this.renderer = new WebGLRenderer({ antialias: true, alpha: true }), this.cssRenderer = new CSS3DRenderer({ antialias: true }), this.renderer.outputEncoding = sRGBEncoding, this.renderer.setPixelRatio(window.devicePixelRatio), this.camera = new PerspectiveCamera(), this.anchors = [], this.renderer.domElement.style.position = "absolute", this.cssRenderer.domElement.style.position = "absolute", this.container.appendChild(this.renderer.domElement), this.container.appendChild(this.cssRenderer.domElement), window.addEventListener("resize", this.resize.bind(this));
  }
  async start() {
    this.ui.showLoading(), await this._startVideo(), await this._startAR();
  }
  stop() {
    this.controller.stopProcessVideo(), this.video.srcObject.getTracks().forEach(function(t) {
      t.stop();
    }), this.video.remove();
  }
  switchCamera() {
    this.shouldFaceUser = !this.shouldFaceUser, this.stop(), this.start();
  }
  addAnchor(e) {
    const t = new Group();
    t.visible = false, t.matrixAutoUpdate = false;
    const a = { group: t, targetIndex: e, onTargetFound: null, onTargetLost: null, onTargetUpdate: null, css: false, visible: false };
    return this.anchors.push(a), this.scene.add(t), a;
  }
  addCSSAnchor(e) {
    const t = new Group();
    t.visible = false, t.matrixAutoUpdate = false;
    const a = { group: t, targetIndex: e, onTargetFound: null, onTargetLost: null, onTargetUpdate: null, css: true, visible: false };
    return this.anchors.push(a), this.cssScene.add(t), a;
  }
  _startVideo() {
    return new Promise((e, t) => {
      if (this.video = document.createElement("video"), this.video.setAttribute("autoplay", ""), this.video.setAttribute("muted", ""), this.video.setAttribute("playsinline", ""), this.video.style.position = "absolute", this.video.style.top = "0px", this.video.style.left = "0px", this.video.style.zIndex = "-2", this.container.appendChild(this.video), !navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        this.ui.showCompatibility(), t();
        return;
      }
      const a = {
        audio: false,
        video: {}
      };
      this.shouldFaceUser ? this.userDeviceId ? a.video.deviceId = { exact: this.userDeviceId } : a.video.facingMode = "user" : this.environmentDeviceId ? a.video.deviceId = { exact: this.environmentDeviceId } : a.video.facingMode = "environment", navigator.mediaDevices.getUserMedia(a).then((r) => {
        this.video.addEventListener("loadedmetadata", () => {
          this.video.setAttribute("width", this.video.videoWidth), this.video.setAttribute("height", this.video.videoHeight), e();
        }), this.video.srcObject = r;
      }).catch((r) => {
        console.log("getUserMedia error", r), t();
      });
    });
  }
  _startAR() {
    return new Promise(async (e, t) => {
      const a = this.video;
      this.container, this.controller = new MY({
        inputWidth: a.videoWidth,
        inputHeight: a.videoHeight,
        filterMinCF: this.filterMinCF,
        filterBeta: this.filterBeta,
        warmupTolerance: this.warmupTolerance,
        missTolerance: this.missTolerance,
        maxTrack: this.maxTrack,
        onUpdate: (n) => {
          if (n.type === "updateMatrix") {
            const { targetIndex: o, worldMatrix: u } = n;
            for (let p6 = 0; p6 < this.anchors.length; p6++)
              if (this.anchors[p6].targetIndex === o) {
                if (this.anchors[p6].css ? this.anchors[p6].group.children.forEach((m) => {
                  m.element.style.visibility = u === null ? "hidden" : "visible";
                }) : this.anchors[p6].group.visible = u !== null, u !== null) {
                  let m = new Matrix4();
                  m.elements = [...u], m.multiply(this.postMatrixs[o]), this.anchors[p6].css && m.multiply(ui2), this.anchors[p6].group.matrix = m;
                } else
                  this.anchors[p6].group.matrix = wb2;
                this.anchors[p6].visible && u === null && (this.anchors[p6].visible = false, this.anchors[p6].onTargetLost && this.anchors[p6].onTargetLost()), !this.anchors[p6].visible && u !== null && (this.anchors[p6].visible = true, this.anchors[p6].onTargetFound && this.anchors[p6].onTargetFound()), this.anchors[p6].onTargetUpdate && this.anchors[p6].onTargetUpdate();
              }
            this.anchors.reduce((p6, m) => p6 || m.visible, false) ? this.ui.hideScanning() : this.ui.showScanning();
          }
        }
      }), this.resize();
      const { dimensions: r } = await this.controller.addImageTargets(this.imageTargetSrc);
      this.postMatrixs = [];
      for (let n = 0; n < r.length; n++) {
        const o = new Vector3(), u = new Quaternion(), l = new Vector3(), [p6, m] = r[n];
        o.x = p6 / 2, o.y = p6 / 2 + (m - p6) / 2, l.x = p6, l.y = p6, l.z = p6;
        const c = new Matrix4();
        c.compose(o, u, l), this.postMatrixs.push(c);
      }
      await this.controller.dummyRun(this.video), this.ui.hideLoading(), this.ui.showScanning(), this.controller.processVideo(this.video), e();
    });
  }
  resize() {
    const { renderer: e, cssRenderer: t, camera: a, container: r, video: n } = this;
    if (!n)
      return;
    this.video.setAttribute("width", this.video.videoWidth), this.video.setAttribute("height", this.video.videoHeight);
    let o, u;
    const l = n.videoWidth / n.videoHeight, p6 = r.clientWidth / r.clientHeight;
    l > p6 ? (u = r.clientHeight, o = u * l) : (o = r.clientWidth, u = o / l);
    const m = this.controller.getProjectionMatrix(), c = this.controller.inputWidth / this.controller.inputHeight;
    let d;
    c > p6 ? d = this.video.width / this.controller.inputWidth : d = this.video.height / this.controller.inputHeight;
    let h6, b6;
    c > p6 ? (h6 = r.clientHeight, h6 *= d) : (b6 = r.clientWidth, h6 = b6 / this.controller.inputWidth * this.controller.inputHeight, h6 *= d);
    let f = r.clientHeight / h6;
    const y6 = 2 * Math.atan(1 / m[5] * f) * 180 / Math.PI, T6 = m[14] / (m[10] - 1), _6 = m[14] / (m[10] + 1);
    m[5] / m[0], a.fov = y6, a.near = T6, a.far = _6, a.aspect = r.clientWidth / r.clientHeight, a.updateProjectionMatrix(), n.style.top = -(u - r.clientHeight) / 2 + "px", n.style.left = -(o - r.clientWidth) / 2 + "px", n.style.width = o + "px", n.style.height = u + "px";
    const w6 = e.domElement, I = t.domElement;
    w6.style.position = "absolute", w6.style.left = 0, w6.style.top = 0, w6.style.width = r.clientWidth + "px", w6.style.height = r.clientHeight + "px", I.style.position = "absolute", I.style.left = 0, I.style.top = 0, I.style.width = r.clientWidth + "px", I.style.height = r.clientHeight + "px", e.setSize(r.clientWidth, r.clientHeight), t.setSize(r.clientWidth, r.clientHeight);
  }
};
window.MINDAR || (window.MINDAR = {});
window.MINDAR.IMAGE || (window.MINDAR.IMAGE = {});
window.MINDAR.IMAGE.MindARThree = Tb2;
window.MINDAR.IMAGE.tf = Nb2;
export {
  Tb2 as MindARThree
};
/*! Bundled license information:

safe-buffer/index.js:
  (*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> *)

mind-ar/dist/controller-495b585f.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)
  (**
   * @license
   * Copyright 2020 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

mind-ar/dist/mindar-image-three.prod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
*/
//# sourceMappingURL=mind-ar_dist_mindar-image-three__prod__js.js.map
